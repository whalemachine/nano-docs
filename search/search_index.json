{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Nano Node and Protocol Documentation \u00b6 Welcome! This documentation is focused on helping developers understand the Nano protocol, as well as setup, maintain and build on top of the Nano node. Details of how this documentation has been arranged are below: Section Details Audience What is Nano? Take a high-level tour - this is a great place to learn about how Nano is uniquely suited to being a global digital currency. All users, node operators, developers Running a Node Set up a Nano node to manage the ledger, create and publish blocks and participate in consensus. Node operators, developers Integration Guides Learn practical concepts, structures and features for building wallets, payment systems and other services on the Nano network. Developers Commands Explore an exhaustive list of interaction methods for the node via RPC and CLI. Node operators, developers Protocol Design Dig deeper into the design and behaviors driving the protocol, including the election process, peering mechanics and more. Developers Node Implementation Details of the Nano Foundation managed node implementation of the protocol. Developers Releases Review past node releases and get details about the features coming soon in new releases. Everyone Glossary Commonly used terms throughout the documentation and Nano ecosystem. Everyone Join the Community If you are looking for other details about Nano, links to wallets, discussions about the network and more, check out our community: Nano.org | Forum | GitHub | Twitter | Discord | Reddit | Medium Facebook | LinkedIn | YouTube | Instagram","title":"Home"},{"location":"#nano-node-and-protocol-documentation","text":"Welcome! This documentation is focused on helping developers understand the Nano protocol, as well as setup, maintain and build on top of the Nano node. Details of how this documentation has been arranged are below: Section Details Audience What is Nano? Take a high-level tour - this is a great place to learn about how Nano is uniquely suited to being a global digital currency. All users, node operators, developers Running a Node Set up a Nano node to manage the ledger, create and publish blocks and participate in consensus. Node operators, developers Integration Guides Learn practical concepts, structures and features for building wallets, payment systems and other services on the Nano network. Developers Commands Explore an exhaustive list of interaction methods for the node via RPC and CLI. Node operators, developers Protocol Design Dig deeper into the design and behaviors driving the protocol, including the election process, peering mechanics and more. Developers Node Implementation Details of the Nano Foundation managed node implementation of the protocol. Developers Releases Review past node releases and get details about the features coming soon in new releases. Everyone Glossary Commonly used terms throughout the documentation and Nano ecosystem. Everyone Join the Community If you are looking for other details about Nano, links to wallets, discussions about the network and more, check out our community: Nano.org | Forum | GitHub | Twitter | Discord | Reddit | Medium Facebook | LinkedIn | YouTube | Instagram","title":"Nano Node and Protocol Documentation"},{"location":"glossary/","text":"Glossary \u00b6 account \u00b6 Refers to an address (starts with xrb_ or nano_ which are interchangeable) that you control the private keys of. An address is a reinterpretation of the 256-bit public key using BASE32 encoding and a checksum. Previously supported xrb- or nano- prefixes are deprecated. active transaction \u00b6 A newly downloaded block to the node which enters into the voting process. ad hoc accounts \u00b6 Accounts not derived from a private seed which can be held in the node wallet through the wallet ID. These accounts are only recommended for use with advanced systems. announcement rounds \u00b6 A repeating half-second cycle on the node during which votes are collected for active transactions in attempt to reach quorum. Block \u00b6 A single Nano transaction. All new transactions (e.g. sends, receives, representative changes, etc) on the Nano Protocol are communicated via state blocks (since node V11). The account's entire state, including the balance after each transaction, is recorded in each block. Transaction amounts are interpreted as the difference in balance between consecutive blocks. Before V11, each transaction type (open, send, receive, change) had its own legacy block type. block hash \u00b6 A 64 character, uppercase hexadecimal string (0-9A-F) value representing a unique block on an account. Block height \u00b6 A local integer value that represents the order of a block in an account chain. For example, the 15 th block in an account would have a block height of 15. Related to (but different from) confirmation height . Block Lattice \u00b6 The Block Lattice is a data-structure in which individual accounts control their own blockchain. This allows transactions to be added quickly without conflict and sent to the network for confirmation. Blocks Per Second (BPS) \u00b6 The transmission rate of unconfirmed blocks (transactions) on the network. bootstrap network \u00b6 A sub-network established between peers via Transmission Control Protocol (TCP) for managing bulk transmission of blocks. This is used on initial bootstrapping of peers and when out-of-sync peers attempt to fill large gaps in their ledgers. This is available within all Nano networks (main, beta and test networks). bootstrapping \u00b6 During initial sync, the nano_node requests old transactions to independently verify and populate its local ledger database. Bootstrapping will also occur when the nano_node becomes out of sync with the network. circulating supply \u00b6 133,248,297.920938463463374607431768211455 Nano. This is the supply that resulted after burns were made from the genesis account, landing account and faucet account, following original distribution. Actual circulating supply is lower due to lost keys and sends to burn accounts. The original supply minus any amounts sent to the burn account can be found using the available_supply RPC. Cementing \u00b6 When a specific node marks a confirmed transaction as locally irreversible by setting the account's confirmation height (in the node database) to the now higher block height of the confirmed transaction. Cementing is a node-level operation. Confirmation \u00b6 When a block (transaction) gathers enough votes from the network to pass quorum . Note that confirmed sends are irreversible (i.e. fully-settled), but the receiver must publish a corresponding receive block before they will be able to spend the pending funds. Confirmation is a network-level decision. Confirmation Height \u00b6 A number stored in the local node database that represents the highest (most recent) confirmed block in an account chain. Related to (but different from) block height . Confirmations Per Second (CPS) \u00b6 The rate of confirmed blocks (send or receive). election \u00b6 frontier \u00b6 The most recent block added to the account chain. Also called the head block. Can be either confirmed or unconfirmed. genesis \u00b6 head block \u00b6 See frontier . inbound send \u00b6 A block with funds being transferred to an account owned by a wallet on your node. legacy blocks \u00b6 Blocks on an account chain before the first v1 block (which is often the v1 epoch block but can be other types). The first v1 block and all subsequent blocks are stateful blocks. live network \u00b6 A sub-network established between peers via Transmission Control Protocol (TCP) for communicating newly published blocks, votes and other non-bootstrap related traffic. This is available within all Nano networks (main, beta and test networks). In versions prior to V19, this was done via User Datagram Protocol (UDP). UDP was retained as a fallback for peer connection for versions 19 and 20. As of V21, use of UDP is deprecated. node version \u00b6 The version used to identify a unique release build of the node. Each node version is tied to a single protocol version , but they are updated independently. online voting weight \u00b6 Also called online stake, it is a trended value. The node samples online representative weights every 5 minutes across a rolling 2 week period. The online voting weight value is the median of those samples. peers \u00b6 Nodes connected over the public internet to share Nano network data. pending \u00b6 A transaction state where a block sending funds was published and confirmed by the network, but a matching block receiving those funds has not yet been confirmed. Open Representative Voting (ORV) \u00b6 A consensus mechanism unique to Nano which involves accounts delegating their balance as voting weight to Representatives . The Representatives vote themselves on the validity of transactions published to the network using the voting weight delegated to them. These votes are shared with their directly connected peers and they also rebroadcast votes seen from Principal Representatives . Votes are tallied and once quorum is reached on a published block, it is considered confirmed by the network. Proof-of-Work (PoW) \u00b6 A Proof-of-Work is a piece of data which satisfies certain requirements and is difficult (costly, time-consuming) to produce, but easy for others to verify. In some systems this data is a central part of the security model used to protect against double-spends and other types of attacks, but with Nano it is only used to increase economic costs of spamming the network. quorum \u00b6 When the delta between the two successive blocks of a root is > 50% of the online voting weight. Principal Representative \u00b6 A Nano account with >= 0.1% of the online voting weight delegated to it. When configured on a node which is voting, the votes it produces will be rebroadcasted by other nodes to who receive them, helping the network reach consensus more quickly. protocol version \u00b6 The version used to identify the set of protocol rules nodes are required to follow in order to properly communicate with peers. Nodes running older protocol versions are periodically de-peered on the network to keep communication efficient - see Active Releases and Inactive Releases for the latest versions allowed to peer with one another. Representative \u00b6 A Nano account with > 0 voting weight, but < 0.1% of the online voting weight , delegated to it. Unlike Principal Representatives , when configured on a node which is voting, the votes it produces and sends to directly connected peers won't be rebroadcasted by those peers. root \u00b6 The account if the block is the first block on the account, otherwise it is the previous hash included in the block. seed \u00b6 A 256-bit random value usually represented to the user as a 64 character hexidecimal (0-9 and A-F) value. Private keys are derived from a seed. Transactions Per Second (TPS) \u00b6 Historically, TPS was a per-node measurement that represented a node's perception of the rate of transactions on the network ( BPS ). This measurement was found to be inaccurate due to peering and propagation differences between nodes, so CPS is now the preferred term for describing overall Nano network scalability. It's also important to note that while Nano sends do not require a corresponding receive to be confirmed , a receive block must be confirmed before received funds can be sent again (see pending ). unchecked (blocks) \u00b6 Blocks (transactions) that have been downloaded but not yet processed by the Nano node. The node software downloads all bocks from other nodes as unchecked, processes them and adds to block count, confirms the frontier blocks for each account, and then marks them as cemented . unopened account \u00b6 An account address that does not have a first block on it (which must be a block to receive Nano sent from another account, cannot be a block only changing the Representative). unpocketed \u00b6 See pending . vote-by-hash \u00b6 Allows representatives to only include the hash of a block in each vote to save bandwidth. Before vote-by-hash was activated the entire block contents were required. voting \u00b6 Each node configured with a Representative votes on every block by appending their Representative signature and a sequence number to the hash. These will be sent out to directly connected peers and if the vote originates from a Principal Representative , it will subsequently be rebroadcasted by nodes to their peers. voting weight \u00b6 The amount of weight delegated to a Representative . wallet \u00b6 A wallet is an organizational object in a nano_node that holds a single seed from which multiple accounts are deterministically derived via a 32-bit unsigned integer index starting at 0. Private keys are derived from the seed and index as follows: ( || means concatenation; blake2b is a highly optimized cryptographic hash function ) k_{private} = blake2b(\\text{seed} || \\text{index}) k_{private} = blake2b(\\text{seed} || \\text{index}) WALLET_ID \u00b6 A 256-bit random value name/identifier for a specific wallet in the local nano_node database. The WALLET_ID is not stored anywhere in the network and is only used in the local nano_node. Even though a WALLET_ID looks identical to a seed, do not confuse the WALLET_ID with a seed; funds cannot be restored with a WALLET_ID. Do not backup the WALLET_ID as a means to backup funds. work peers \u00b6 Node peers which are configured to generate work for transactions at the originating nodes request.","title":"Glossary"},{"location":"glossary/#glossary","text":"","title":"Glossary"},{"location":"glossary/#account","text":"Refers to an address (starts with xrb_ or nano_ which are interchangeable) that you control the private keys of. An address is a reinterpretation of the 256-bit public key using BASE32 encoding and a checksum. Previously supported xrb- or nano- prefixes are deprecated.","title":"account"},{"location":"glossary/#active-transaction","text":"A newly downloaded block to the node which enters into the voting process.","title":"active transaction"},{"location":"glossary/#ad-hoc-accounts","text":"Accounts not derived from a private seed which can be held in the node wallet through the wallet ID. These accounts are only recommended for use with advanced systems.","title":"ad hoc accounts"},{"location":"glossary/#announcement-rounds","text":"A repeating half-second cycle on the node during which votes are collected for active transactions in attempt to reach quorum.","title":"announcement rounds"},{"location":"glossary/#block","text":"A single Nano transaction. All new transactions (e.g. sends, receives, representative changes, etc) on the Nano Protocol are communicated via state blocks (since node V11). The account's entire state, including the balance after each transaction, is recorded in each block. Transaction amounts are interpreted as the difference in balance between consecutive blocks. Before V11, each transaction type (open, send, receive, change) had its own legacy block type.","title":"Block"},{"location":"glossary/#block-hash","text":"A 64 character, uppercase hexadecimal string (0-9A-F) value representing a unique block on an account.","title":"block hash"},{"location":"glossary/#block-height","text":"A local integer value that represents the order of a block in an account chain. For example, the 15 th block in an account would have a block height of 15. Related to (but different from) confirmation height .","title":"Block height"},{"location":"glossary/#block-lattice","text":"The Block Lattice is a data-structure in which individual accounts control their own blockchain. This allows transactions to be added quickly without conflict and sent to the network for confirmation.","title":"Block Lattice"},{"location":"glossary/#blocks-per-second-bps","text":"The transmission rate of unconfirmed blocks (transactions) on the network.","title":"Blocks Per Second (BPS)"},{"location":"glossary/#bootstrap-network","text":"A sub-network established between peers via Transmission Control Protocol (TCP) for managing bulk transmission of blocks. This is used on initial bootstrapping of peers and when out-of-sync peers attempt to fill large gaps in their ledgers. This is available within all Nano networks (main, beta and test networks).","title":"bootstrap network"},{"location":"glossary/#bootstrapping","text":"During initial sync, the nano_node requests old transactions to independently verify and populate its local ledger database. Bootstrapping will also occur when the nano_node becomes out of sync with the network.","title":"bootstrapping"},{"location":"glossary/#circulating-supply","text":"133,248,297.920938463463374607431768211455 Nano. This is the supply that resulted after burns were made from the genesis account, landing account and faucet account, following original distribution. Actual circulating supply is lower due to lost keys and sends to burn accounts. The original supply minus any amounts sent to the burn account can be found using the available_supply RPC.","title":"circulating supply"},{"location":"glossary/#cementing","text":"When a specific node marks a confirmed transaction as locally irreversible by setting the account's confirmation height (in the node database) to the now higher block height of the confirmed transaction. Cementing is a node-level operation.","title":"Cementing"},{"location":"glossary/#confirmation","text":"When a block (transaction) gathers enough votes from the network to pass quorum . Note that confirmed sends are irreversible (i.e. fully-settled), but the receiver must publish a corresponding receive block before they will be able to spend the pending funds. Confirmation is a network-level decision.","title":"Confirmation"},{"location":"glossary/#confirmation-height","text":"A number stored in the local node database that represents the highest (most recent) confirmed block in an account chain. Related to (but different from) block height .","title":"Confirmation Height"},{"location":"glossary/#confirmations-per-second-cps","text":"The rate of confirmed blocks (send or receive).","title":"Confirmations Per Second (CPS)"},{"location":"glossary/#election","text":"","title":"election"},{"location":"glossary/#frontier","text":"The most recent block added to the account chain. Also called the head block. Can be either confirmed or unconfirmed.","title":"frontier"},{"location":"glossary/#genesis","text":"","title":"genesis"},{"location":"glossary/#head-block","text":"See frontier .","title":"head block"},{"location":"glossary/#inbound-send","text":"A block with funds being transferred to an account owned by a wallet on your node.","title":"inbound send"},{"location":"glossary/#legacy-blocks","text":"Blocks on an account chain before the first v1 block (which is often the v1 epoch block but can be other types). The first v1 block and all subsequent blocks are stateful blocks.","title":"legacy blocks"},{"location":"glossary/#live-network","text":"A sub-network established between peers via Transmission Control Protocol (TCP) for communicating newly published blocks, votes and other non-bootstrap related traffic. This is available within all Nano networks (main, beta and test networks). In versions prior to V19, this was done via User Datagram Protocol (UDP). UDP was retained as a fallback for peer connection for versions 19 and 20. As of V21, use of UDP is deprecated.","title":"live network"},{"location":"glossary/#node-version","text":"The version used to identify a unique release build of the node. Each node version is tied to a single protocol version , but they are updated independently.","title":"node version"},{"location":"glossary/#online-voting-weight","text":"Also called online stake, it is a trended value. The node samples online representative weights every 5 minutes across a rolling 2 week period. The online voting weight value is the median of those samples.","title":"online voting weight"},{"location":"glossary/#peers","text":"Nodes connected over the public internet to share Nano network data.","title":"peers"},{"location":"glossary/#pending","text":"A transaction state where a block sending funds was published and confirmed by the network, but a matching block receiving those funds has not yet been confirmed.","title":"pending"},{"location":"glossary/#open-representative-voting-orv","text":"A consensus mechanism unique to Nano which involves accounts delegating their balance as voting weight to Representatives . The Representatives vote themselves on the validity of transactions published to the network using the voting weight delegated to them. These votes are shared with their directly connected peers and they also rebroadcast votes seen from Principal Representatives . Votes are tallied and once quorum is reached on a published block, it is considered confirmed by the network.","title":"Open Representative Voting (ORV)"},{"location":"glossary/#proof-of-work-pow","text":"A Proof-of-Work is a piece of data which satisfies certain requirements and is difficult (costly, time-consuming) to produce, but easy for others to verify. In some systems this data is a central part of the security model used to protect against double-spends and other types of attacks, but with Nano it is only used to increase economic costs of spamming the network.","title":"Proof-of-Work (PoW)"},{"location":"glossary/#quorum","text":"When the delta between the two successive blocks of a root is > 50% of the online voting weight.","title":"quorum"},{"location":"glossary/#principal-representative","text":"A Nano account with >= 0.1% of the online voting weight delegated to it. When configured on a node which is voting, the votes it produces will be rebroadcasted by other nodes to who receive them, helping the network reach consensus more quickly.","title":"Principal Representative"},{"location":"glossary/#protocol-version","text":"The version used to identify the set of protocol rules nodes are required to follow in order to properly communicate with peers. Nodes running older protocol versions are periodically de-peered on the network to keep communication efficient - see Active Releases and Inactive Releases for the latest versions allowed to peer with one another.","title":"protocol version"},{"location":"glossary/#representative","text":"A Nano account with > 0 voting weight, but < 0.1% of the online voting weight , delegated to it. Unlike Principal Representatives , when configured on a node which is voting, the votes it produces and sends to directly connected peers won't be rebroadcasted by those peers.","title":"Representative"},{"location":"glossary/#root","text":"The account if the block is the first block on the account, otherwise it is the previous hash included in the block.","title":"root"},{"location":"glossary/#seed","text":"A 256-bit random value usually represented to the user as a 64 character hexidecimal (0-9 and A-F) value. Private keys are derived from a seed.","title":"seed"},{"location":"glossary/#transactions-per-second-tps","text":"Historically, TPS was a per-node measurement that represented a node's perception of the rate of transactions on the network ( BPS ). This measurement was found to be inaccurate due to peering and propagation differences between nodes, so CPS is now the preferred term for describing overall Nano network scalability. It's also important to note that while Nano sends do not require a corresponding receive to be confirmed , a receive block must be confirmed before received funds can be sent again (see pending ).","title":"Transactions Per Second (TPS)"},{"location":"glossary/#unchecked-blocks","text":"Blocks (transactions) that have been downloaded but not yet processed by the Nano node. The node software downloads all bocks from other nodes as unchecked, processes them and adds to block count, confirms the frontier blocks for each account, and then marks them as cemented .","title":"unchecked (blocks)"},{"location":"glossary/#unopened-account","text":"An account address that does not have a first block on it (which must be a block to receive Nano sent from another account, cannot be a block only changing the Representative).","title":"unopened account"},{"location":"glossary/#unpocketed","text":"See pending .","title":"unpocketed"},{"location":"glossary/#vote-by-hash","text":"Allows representatives to only include the hash of a block in each vote to save bandwidth. Before vote-by-hash was activated the entire block contents were required.","title":"vote-by-hash"},{"location":"glossary/#voting","text":"Each node configured with a Representative votes on every block by appending their Representative signature and a sequence number to the hash. These will be sent out to directly connected peers and if the vote originates from a Principal Representative , it will subsequently be rebroadcasted by nodes to their peers.","title":"voting"},{"location":"glossary/#voting-weight","text":"The amount of weight delegated to a Representative .","title":"voting weight"},{"location":"glossary/#wallet","text":"A wallet is an organizational object in a nano_node that holds a single seed from which multiple accounts are deterministically derived via a 32-bit unsigned integer index starting at 0. Private keys are derived from the seed and index as follows: ( || means concatenation; blake2b is a highly optimized cryptographic hash function ) k_{private} = blake2b(\\text{seed} || \\text{index}) k_{private} = blake2b(\\text{seed} || \\text{index})","title":"wallet"},{"location":"glossary/#wallet_id","text":"A 256-bit random value name/identifier for a specific wallet in the local nano_node database. The WALLET_ID is not stored anywhere in the network and is only used in the local nano_node. Even though a WALLET_ID looks identical to a seed, do not confuse the WALLET_ID with a seed; funds cannot be restored with a WALLET_ID. Do not backup the WALLET_ID as a means to backup funds.","title":"WALLET_ID"},{"location":"glossary/#work-peers","text":"Node peers which are configured to generate work for transactions at the originating nodes request.","title":"work peers"},{"location":"commands/command-line-interface/","text":"Command Line Interface \u00b6 --account_create --wallet= <wallet> \u00b6 Insert next deterministic key into <wallet> --account_get --key= <key> \u00b6 Get account number for the <key> --account_key --account= <account> \u00b6 Get the public key for <account> --clear_send_ids \u00b6 Remove all send IDs from the database (dangerous: not intended for production use) --compare_rep_weights \u00b6 version 21.0+ Displays a summarized comparison between the hardcoded bootstrap weights and representative weights from the ledger. Full comparison is output to logs. Optional --data_path . Differences between total weights ( hardcoded weight and ledger weight ) are due to unreceived (pending) blocks mismatched : samples : the number of mismatched samples is equal to the number of hardcoded weights, even those with zero mismatch total : sum of the absolute difference between individual samples from hardcoded and ledger weights mean : total divided by samples sigma : from the samples, a distribution N(\\mu, \\sigma) N(\\mu, \\sigma) is obtained outliers : mismatch samples above \\mu + \\sigma \\mu + \\sigma , for potential inspection newcomers : large voting weights found in the ledger but not hardcoded, for potential inspection --config key=value \u00b6 version 20.0+ Pass node configuration values. This takes precedence over any values in the configuration file. This option can be repeated multiple times. --confirmation_height_clear \u00b6 version 19.0+ Sets the confirmation heights of all accounts to 0. Optional --account to only reset a single account. Do not use while the node is running. --daemon \u00b6 Start node daemon. Since version 19.0, network and path will be output, similar to: ./nano_node --daemon --network test Network: test, version: 19.0 Path: /home/USER/NanoTest --data_path= <path> \u00b6 Use the supplied <path> as the data directory. --diagnostics \u00b6 Run internal diagnostics and validate existing config file (or create default config file if it doesn't exist) --generate_config node|rpc \u00b6 version 20.0+ Write configuration to stdout, populated with commented-out defaults suitable for this system. Pass the configuration type, node or rpc . If --use_defaults is passed, the generated config will not have values commented-out. This is not recommended except for testing and debugging. The output can be piped to a file, using the locations defined in configuration . --help \u00b6 Print out options --key_create \u00b6 Generates a adhoc random keypair and prints it to stdout --key_expand --key= <key> \u00b6 Derive public key and account number from <key> --migrate_database_lmdb_to_rocksdb \u00b6 version 22.0+ Deletes existing rocksdb subfolder if it exists and migrates the ledger from LMDB to RocksDB. Does not delete the data.ldb file afterwards. --network \u00b6 version 19.0+ Allows selection of a different network at runtime. Values live , beta and test supported. --online_weight_clear \u00b6 version 18.0+ Clear record history for long term online weight trending --peer_clear \u00b6 version 18.0+ Clear cached peers --rebuild_database \u00b6 version 21.0+ Rebuild LMDB database with --vacuum for best compaction. Requires approximately data.ldb size * 2 free space on disk. --snapshot \u00b6 Compact database and create snapshot, functions similar to vacuum but does not replace the existing database. Optional --unchecked_clear , --clear_send_ids , --online_weight_clear , --peer_clear . Optional --confirmation_height_clear in version 19.0+. --unchecked_clear \u00b6 Clear unchecked blocks --vacuum \u00b6 Compact database. If data_path is missing, the database in data directory is compacted. Optional --unchecked_clear , --clear_send_ids , --online_weight_clear , --peer_clear . Optional --confirmation_height_clear in version 19.0+. Optional --rebuild_database in version 21.0+. Requires approximately data.ldb size * 2 free space on disk. --validate_blocks \u00b6 version 21.0+ ( version 19.0+ as --debug_validate_blocks ) Validate blocks in the ledger, includes checks for confirmation height. Optional --threads for multithreaded validation in version 21.0+. Multithreaded validation can limit other host operations with high I/O & CPU usage. --version \u00b6 Prints out version --vote_dump \u00b6 Dump most recent votes from representatives --wallet_add_adhoc --wallet= <wallet> --key= <key> \u00b6 Insert <key> in to <wallet> --wallet_create --seed= <seed> --password= <password> \u00b6 Creates a new wallet with optional <seed> and optional <password> , and prints the ID. Note the legacy --key option can still be used and will function the same as --seed . --wallet_change_seed --wallet= <wallet> --seed= <seed> \u00b6 Changes seed for <wallet> to <seed> . Note the legacy --key option can still be used and will function the same as --seed . --wallet_decrypt_unsafe --wallet= <wallet> --password= <password> \u00b6 Decrypts <wallet> using <password> Danger USE WITH CAUTION: THIS WILL PRINT YOUR PRIVATE KEY AND SEED TO STDOUT If you didn't set password yet, use --wallet_decrypt_unsafe --wallet= <wallet> --wallet_destroy --wallet= <wallet> \u00b6 Destroys <wallet> and all keys it contains --wallet_import --file= <filepath> --wallet= <wallet> --password= <password> \u00b6 Imports keys in <filepath> using <password> in to <wallet> . If the provided wallet id does not exist and --force is included, a new wallet will be created with the provided wallet id value, and the json file will be imported as is with existing seed and password (instead of a set of private keys without a change of seed). --wallet_list \u00b6 Dumps wallet IDs and public keys --wallet_remove --wallet= <wallet> --account= <account> \u00b6 Remove <account> from <wallet> --wallet_representative_get --wallet= <wallet> \u00b6 Prints default representative for <wallet> --wallet_representative_set --wallet= <wallet> --account= <account> \u00b6 Set <account> as default representative for <wallet> Launch options \u00b6 When initially starting the nano_node or nano_wallet as a service the following launch options are available. Intended for developer use These options are only for developer use so please understand the impacts before use. --allow_bootstrap_peers_duplicates \u00b6 version 21.0+ Allow multiple connections to the same peer in bootstrap attempts --block_processor_batch_size \u00b6 Increase block processor transaction batch write size, default 0 (limited by config block_processor_batch_max_time), 256k for fast_bootstrap --block_processor_full_size \u00b6 Increase block processor allowed blocks queue size before dropping live network packets and holding bootstrap download, default 65536, 1 million for fast_bootstrap --block_processor_verification_size \u00b6 Increase batch signature verification size in block processor, default 0 (limited by config signature_checker_threads), unlimited for fast_bootstrap --disable_backup \u00b6 Turn off automatic wallet backup process --disable_lazy_bootstrap \u00b6 Turn off use of lazy bootstrap --disable_legacy_bootstrap \u00b6 Turn off use of legacy bootstrap --disable_wallet_bootstrap \u00b6 Turn off use of wallet-based bootstrap --disable_bootstrap_listener \u00b6 Turn off listener on the bootstrap network so incoming TCP (bootstrap) connections are rejected. Note: this does not impact TCP traffic for the live network. --disable_tcp_realtime \u00b6 version 19.0+ Turn off use of TCP live network (TCP for bootstrap will remain available) --disable_unchecked_cleanup \u00b6 Prevent periodic cleaning of unchecked table --disable_unchecked_drop \u00b6 Prevent drop of all unchecked entries at node/wallet start --disable_providing_telemetry_metrics \u00b6 version 21.0+ Do not provide any telemetry data to nodes requesting it. Responses are still made to requests, but they will have an empty payload. --disable_block_processor_unchecked_deletion \u00b6 version 21.0+ Disable deletion of unchecked blocks after processing. --enable_udp \u00b6 version 21.0+ Turn on use of the UDP live network. --fast_bootstrap \u00b6 Increase bootstrap processor limits to allow more blocks before hitting full state and verify/write more per database call. Also disable deletion of processed unchecked blocks. --inactive_votes_cache_size \u00b6 version 21.0+ Increase cached votes without active elections size, default 16384 --vote_processor_capacity \u00b6 version 21.0+ Vote processor queue size before dropping votes, default 144k Debug commands \u00b6 --debug_account_count \u00b6 Display the number of accounts --debug_account_versions \u00b6 version 20.0+ Display the total counts of each version for all accounts (including unpocketed) --debug_block_count \u00b6 Display the number of blocks --debug_bootstrap_generate \u00b6 Generate bootstrap sequence of blocks --debug_cemented_block_count \u00b6 version 19.0+ Display the number of cemented blocks (blocks which are under the confirmation height of their accounts) --debug_dump_frontier_unchecked_dependents \u00b6 version 19.0+ Dump frontiers which have matching unchecked keys --debug_dump_online_weight \u00b6 List online weights table and current online_weights value --debug_dump_representatives \u00b6 List representatives and weights --debug_generate_crash_report \u00b6 version 21.0+ After a node crash on linux, this command consumes the dump files generated from that crash and produces a \"nano_node_crash_report.txt\" file. Requires addr2line to be installed on the system. See the troubleshooting guide for more information. --debug_opencl \u00b6 Profile OpenCL work generation for (optional) --device=<device> on --device=<platform> using --threads=<threads> count. To retrieve available platforms & devices run --diagnostics . --debug_output_last_backtrace_dump \u00b6 version 19.0+ Output the stacktrace stored after a node crash. Optionals --difficulty and --multiplier (only the latter is used if both given) in version 21.0+ to set the work generation threshold. --debug_profile_bootstrap \u00b6 Profile simulated bootstrap process --debug_profile_generate \u00b6 Profile work generation Optional --pow_sleep_interval in version 19.0+ which sets an amount to sleep (in nanoseconds) between batches of POW calculations when using the CPU. Optionals --difficulty and --multiplier (only the latter is used if both given) in version 21.0+ to set the work generation threshold. --debug_profile_validate \u00b6 Profile work validation --debug_profile_kdf \u00b6 Profile kdf function --debug_profile_sign \u00b6 Profile signature generation --debug_profile_votes \u00b6 Profile vote verification --debug_profile_frontiers_confirmation \u00b6 version 21.0+ Profile frontiers confirmation speed --debug_rpc \u00b6 version 18.0+ Allows running RPC commands without enabling the RPC server. Not recommended for daily usage. Example: echo '{\"action\": \"block_count\"}' | nano_node --debug_rpc --debug_stacktrace \u00b6 version 20.0+ Prints a stacktrace example, useful to verify that it includes the desired information, such as files, function names and line numbers --debug_sys_logging \u00b6 version 19.0+ On *nix system this checks writing to the system log. On Windows it writes to the event viewer, a registry entry needs to exist for this to work correctly which can be created by running this command for the first time as an administrator --debug_unconfirmed_frontiers \u00b6 version 22.0+ Prints the account, height, frontiers and cemented frontier for all accounts which are not fully confirmed. Sorted by height in descending order --debug_validate_blocks \u00b6 Alias to --validate_blocks --debug_verify_profile \u00b6 Profile signature verification Deprecated commands \u00b6 Launch options \u00b6 --disable_udp version 21.0+ This option has been deprecated and will be removed in future versions. It has no effect because it is now the default. version 19.0+ Turn off use of UDP live network Removed commands \u00b6 Debug \u00b6 --debug_mass_activity Generates fake debug activity. Deprecated in v21 and removed in v22. Use slow_test --gtest_filter=system.generate_mass_activity instead. --debug_xorshift_profile Profile xorshift algorithms Launch options \u00b6 --batch_size version 18.0+ Increase sideband upgrade batch size (default 512). Deprecated in v21 and removed in v22 as no longer required.","title":"Command Line Interface"},{"location":"commands/command-line-interface/#command-line-interface","text":"","title":"Command Line Interface"},{"location":"commands/command-line-interface/#-account_create-walletwallet","text":"Insert next deterministic key into <wallet>","title":"--account_create --wallet=&lt;wallet&gt;"},{"location":"commands/command-line-interface/#-account_get-keykey","text":"Get account number for the <key>","title":"--account_get --key=&lt;key&gt;"},{"location":"commands/command-line-interface/#-account_key-accountaccount","text":"Get the public key for <account>","title":"--account_key --account=&lt;account&gt;"},{"location":"commands/command-line-interface/#-clear_send_ids","text":"Remove all send IDs from the database (dangerous: not intended for production use)","title":"--clear_send_ids"},{"location":"commands/command-line-interface/#-compare_rep_weights","text":"version 21.0+ Displays a summarized comparison between the hardcoded bootstrap weights and representative weights from the ledger. Full comparison is output to logs. Optional --data_path . Differences between total weights ( hardcoded weight and ledger weight ) are due to unreceived (pending) blocks mismatched : samples : the number of mismatched samples is equal to the number of hardcoded weights, even those with zero mismatch total : sum of the absolute difference between individual samples from hardcoded and ledger weights mean : total divided by samples sigma : from the samples, a distribution N(\\mu, \\sigma) N(\\mu, \\sigma) is obtained outliers : mismatch samples above \\mu + \\sigma \\mu + \\sigma , for potential inspection newcomers : large voting weights found in the ledger but not hardcoded, for potential inspection","title":"--compare_rep_weights"},{"location":"commands/command-line-interface/#-config-keyvalue","text":"version 20.0+ Pass node configuration values. This takes precedence over any values in the configuration file. This option can be repeated multiple times.","title":"--config key=value"},{"location":"commands/command-line-interface/#-confirmation_height_clear","text":"version 19.0+ Sets the confirmation heights of all accounts to 0. Optional --account to only reset a single account. Do not use while the node is running.","title":"--confirmation_height_clear"},{"location":"commands/command-line-interface/#-daemon","text":"Start node daemon. Since version 19.0, network and path will be output, similar to: ./nano_node --daemon --network test Network: test, version: 19.0 Path: /home/USER/NanoTest","title":"--daemon"},{"location":"commands/command-line-interface/#-data_pathpath","text":"Use the supplied <path> as the data directory.","title":"--data_path=&lt;path&gt;"},{"location":"commands/command-line-interface/#-diagnostics","text":"Run internal diagnostics and validate existing config file (or create default config file if it doesn't exist)","title":"--diagnostics"},{"location":"commands/command-line-interface/#-generate_config-noderpc","text":"version 20.0+ Write configuration to stdout, populated with commented-out defaults suitable for this system. Pass the configuration type, node or rpc . If --use_defaults is passed, the generated config will not have values commented-out. This is not recommended except for testing and debugging. The output can be piped to a file, using the locations defined in configuration .","title":"--generate_config node|rpc"},{"location":"commands/command-line-interface/#-help","text":"Print out options","title":"--help"},{"location":"commands/command-line-interface/#-key_create","text":"Generates a adhoc random keypair and prints it to stdout","title":"--key_create"},{"location":"commands/command-line-interface/#-key_expand-keykey","text":"Derive public key and account number from <key>","title":"--key_expand --key=&lt;key&gt;"},{"location":"commands/command-line-interface/#-migrate_database_lmdb_to_rocksdb","text":"version 22.0+ Deletes existing rocksdb subfolder if it exists and migrates the ledger from LMDB to RocksDB. Does not delete the data.ldb file afterwards.","title":"--migrate_database_lmdb_to_rocksdb"},{"location":"commands/command-line-interface/#-network","text":"version 19.0+ Allows selection of a different network at runtime. Values live , beta and test supported.","title":"--network"},{"location":"commands/command-line-interface/#-online_weight_clear","text":"version 18.0+ Clear record history for long term online weight trending","title":"--online_weight_clear"},{"location":"commands/command-line-interface/#-peer_clear","text":"version 18.0+ Clear cached peers","title":"--peer_clear"},{"location":"commands/command-line-interface/#-rebuild_database","text":"version 21.0+ Rebuild LMDB database with --vacuum for best compaction. Requires approximately data.ldb size * 2 free space on disk.","title":"--rebuild_database"},{"location":"commands/command-line-interface/#-snapshot","text":"Compact database and create snapshot, functions similar to vacuum but does not replace the existing database. Optional --unchecked_clear , --clear_send_ids , --online_weight_clear , --peer_clear . Optional --confirmation_height_clear in version 19.0+.","title":"--snapshot"},{"location":"commands/command-line-interface/#-unchecked_clear","text":"Clear unchecked blocks","title":"--unchecked_clear"},{"location":"commands/command-line-interface/#-vacuum","text":"Compact database. If data_path is missing, the database in data directory is compacted. Optional --unchecked_clear , --clear_send_ids , --online_weight_clear , --peer_clear . Optional --confirmation_height_clear in version 19.0+. Optional --rebuild_database in version 21.0+. Requires approximately data.ldb size * 2 free space on disk.","title":"--vacuum"},{"location":"commands/command-line-interface/#-validate_blocks","text":"version 21.0+ ( version 19.0+ as --debug_validate_blocks ) Validate blocks in the ledger, includes checks for confirmation height. Optional --threads for multithreaded validation in version 21.0+. Multithreaded validation can limit other host operations with high I/O & CPU usage.","title":"--validate_blocks"},{"location":"commands/command-line-interface/#-version","text":"Prints out version","title":"--version"},{"location":"commands/command-line-interface/#-vote_dump","text":"Dump most recent votes from representatives","title":"--vote_dump"},{"location":"commands/command-line-interface/#-wallet_add_adhoc-walletwallet-keykey","text":"Insert <key> in to <wallet>","title":"--wallet_add_adhoc --wallet=&lt;wallet&gt; --key=&lt;key&gt;"},{"location":"commands/command-line-interface/#-wallet_create-seedseed-passwordpassword","text":"Creates a new wallet with optional <seed> and optional <password> , and prints the ID. Note the legacy --key option can still be used and will function the same as --seed .","title":"--wallet_create --seed=&lt;seed&gt; --password=&lt;password&gt;"},{"location":"commands/command-line-interface/#-wallet_change_seed-walletwallet-seedseed","text":"Changes seed for <wallet> to <seed> . Note the legacy --key option can still be used and will function the same as --seed .","title":"--wallet_change_seed --wallet=&lt;wallet&gt; --seed=&lt;seed&gt;"},{"location":"commands/command-line-interface/#-wallet_decrypt_unsafe-walletwallet-passwordpassword","text":"Decrypts <wallet> using <password> Danger USE WITH CAUTION: THIS WILL PRINT YOUR PRIVATE KEY AND SEED TO STDOUT If you didn't set password yet, use --wallet_decrypt_unsafe --wallet= <wallet>","title":"--wallet_decrypt_unsafe --wallet=&lt;wallet&gt; --password=&lt;password&gt;"},{"location":"commands/command-line-interface/#-wallet_destroy-walletwallet","text":"Destroys <wallet> and all keys it contains","title":"--wallet_destroy --wallet=&lt;wallet&gt;"},{"location":"commands/command-line-interface/#-wallet_import-filefilepath-walletwallet-passwordpassword","text":"Imports keys in <filepath> using <password> in to <wallet> . If the provided wallet id does not exist and --force is included, a new wallet will be created with the provided wallet id value, and the json file will be imported as is with existing seed and password (instead of a set of private keys without a change of seed).","title":"--wallet_import  --file=&lt;filepath&gt; --wallet=&lt;wallet&gt; --password=&lt;password&gt;"},{"location":"commands/command-line-interface/#-wallet_list","text":"Dumps wallet IDs and public keys","title":"--wallet_list"},{"location":"commands/command-line-interface/#-wallet_remove-walletwallet-accountaccount","text":"Remove <account> from <wallet>","title":"--wallet_remove --wallet=&lt;wallet&gt; --account=&lt;account&gt;"},{"location":"commands/command-line-interface/#-wallet_representative_get-walletwallet","text":"Prints default representative for <wallet>","title":"--wallet_representative_get --wallet=&lt;wallet&gt;"},{"location":"commands/command-line-interface/#-wallet_representative_set-walletwallet-accountaccount","text":"Set <account> as default representative for <wallet>","title":"--wallet_representative_set --wallet=&lt;wallet&gt; --account=&lt;account&gt;"},{"location":"commands/command-line-interface/#launch-options","text":"When initially starting the nano_node or nano_wallet as a service the following launch options are available. Intended for developer use These options are only for developer use so please understand the impacts before use.","title":"Launch options"},{"location":"commands/command-line-interface/#-allow_bootstrap_peers_duplicates","text":"version 21.0+ Allow multiple connections to the same peer in bootstrap attempts","title":"--allow_bootstrap_peers_duplicates"},{"location":"commands/command-line-interface/#-block_processor_batch_size","text":"Increase block processor transaction batch write size, default 0 (limited by config block_processor_batch_max_time), 256k for fast_bootstrap","title":"--block_processor_batch_size"},{"location":"commands/command-line-interface/#-block_processor_full_size","text":"Increase block processor allowed blocks queue size before dropping live network packets and holding bootstrap download, default 65536, 1 million for fast_bootstrap","title":"--block_processor_full_size"},{"location":"commands/command-line-interface/#-block_processor_verification_size","text":"Increase batch signature verification size in block processor, default 0 (limited by config signature_checker_threads), unlimited for fast_bootstrap","title":"--block_processor_verification_size"},{"location":"commands/command-line-interface/#-disable_backup","text":"Turn off automatic wallet backup process","title":"--disable_backup"},{"location":"commands/command-line-interface/#-disable_lazy_bootstrap","text":"Turn off use of lazy bootstrap","title":"--disable_lazy_bootstrap"},{"location":"commands/command-line-interface/#-disable_legacy_bootstrap","text":"Turn off use of legacy bootstrap","title":"--disable_legacy_bootstrap"},{"location":"commands/command-line-interface/#-disable_wallet_bootstrap","text":"Turn off use of wallet-based bootstrap","title":"--disable_wallet_bootstrap"},{"location":"commands/command-line-interface/#-disable_bootstrap_listener","text":"Turn off listener on the bootstrap network so incoming TCP (bootstrap) connections are rejected. Note: this does not impact TCP traffic for the live network.","title":"--disable_bootstrap_listener"},{"location":"commands/command-line-interface/#-disable_tcp_realtime","text":"version 19.0+ Turn off use of TCP live network (TCP for bootstrap will remain available)","title":"--disable_tcp_realtime"},{"location":"commands/command-line-interface/#-disable_unchecked_cleanup","text":"Prevent periodic cleaning of unchecked table","title":"--disable_unchecked_cleanup"},{"location":"commands/command-line-interface/#-disable_unchecked_drop","text":"Prevent drop of all unchecked entries at node/wallet start","title":"--disable_unchecked_drop"},{"location":"commands/command-line-interface/#-disable_providing_telemetry_metrics","text":"version 21.0+ Do not provide any telemetry data to nodes requesting it. Responses are still made to requests, but they will have an empty payload.","title":"--disable_providing_telemetry_metrics"},{"location":"commands/command-line-interface/#-disable_block_processor_unchecked_deletion","text":"version 21.0+ Disable deletion of unchecked blocks after processing.","title":"--disable_block_processor_unchecked_deletion"},{"location":"commands/command-line-interface/#-enable_udp","text":"version 21.0+ Turn on use of the UDP live network.","title":"--enable_udp"},{"location":"commands/command-line-interface/#-fast_bootstrap","text":"Increase bootstrap processor limits to allow more blocks before hitting full state and verify/write more per database call. Also disable deletion of processed unchecked blocks.","title":"--fast_bootstrap"},{"location":"commands/command-line-interface/#-inactive_votes_cache_size","text":"version 21.0+ Increase cached votes without active elections size, default 16384","title":"--inactive_votes_cache_size"},{"location":"commands/command-line-interface/#-vote_processor_capacity","text":"version 21.0+ Vote processor queue size before dropping votes, default 144k","title":"--vote_processor_capacity"},{"location":"commands/command-line-interface/#debug-commands","text":"","title":"Debug commands"},{"location":"commands/command-line-interface/#-debug_account_count","text":"Display the number of accounts","title":"--debug_account_count"},{"location":"commands/command-line-interface/#-debug_account_versions","text":"version 20.0+ Display the total counts of each version for all accounts (including unpocketed)","title":"--debug_account_versions"},{"location":"commands/command-line-interface/#-debug_block_count","text":"Display the number of blocks","title":"--debug_block_count"},{"location":"commands/command-line-interface/#-debug_bootstrap_generate","text":"Generate bootstrap sequence of blocks","title":"--debug_bootstrap_generate"},{"location":"commands/command-line-interface/#-debug_cemented_block_count","text":"version 19.0+ Display the number of cemented blocks (blocks which are under the confirmation height of their accounts)","title":"--debug_cemented_block_count"},{"location":"commands/command-line-interface/#-debug_dump_frontier_unchecked_dependents","text":"version 19.0+ Dump frontiers which have matching unchecked keys","title":"--debug_dump_frontier_unchecked_dependents"},{"location":"commands/command-line-interface/#-debug_dump_online_weight","text":"List online weights table and current online_weights value","title":"--debug_dump_online_weight"},{"location":"commands/command-line-interface/#-debug_dump_representatives","text":"List representatives and weights","title":"--debug_dump_representatives"},{"location":"commands/command-line-interface/#-debug_generate_crash_report","text":"version 21.0+ After a node crash on linux, this command consumes the dump files generated from that crash and produces a \"nano_node_crash_report.txt\" file. Requires addr2line to be installed on the system. See the troubleshooting guide for more information.","title":"--debug_generate_crash_report"},{"location":"commands/command-line-interface/#-debug_opencl","text":"Profile OpenCL work generation for (optional) --device=<device> on --device=<platform> using --threads=<threads> count. To retrieve available platforms & devices run --diagnostics .","title":"--debug_opencl"},{"location":"commands/command-line-interface/#-debug_output_last_backtrace_dump","text":"version 19.0+ Output the stacktrace stored after a node crash. Optionals --difficulty and --multiplier (only the latter is used if both given) in version 21.0+ to set the work generation threshold.","title":"--debug_output_last_backtrace_dump"},{"location":"commands/command-line-interface/#-debug_profile_bootstrap","text":"Profile simulated bootstrap process","title":"--debug_profile_bootstrap"},{"location":"commands/command-line-interface/#-debug_profile_generate","text":"Profile work generation Optional --pow_sleep_interval in version 19.0+ which sets an amount to sleep (in nanoseconds) between batches of POW calculations when using the CPU. Optionals --difficulty and --multiplier (only the latter is used if both given) in version 21.0+ to set the work generation threshold.","title":"--debug_profile_generate"},{"location":"commands/command-line-interface/#-debug_profile_validate","text":"Profile work validation","title":"--debug_profile_validate"},{"location":"commands/command-line-interface/#-debug_profile_kdf","text":"Profile kdf function","title":"--debug_profile_kdf"},{"location":"commands/command-line-interface/#-debug_profile_sign","text":"Profile signature generation","title":"--debug_profile_sign"},{"location":"commands/command-line-interface/#-debug_profile_votes","text":"Profile vote verification","title":"--debug_profile_votes"},{"location":"commands/command-line-interface/#-debug_profile_frontiers_confirmation","text":"version 21.0+ Profile frontiers confirmation speed","title":"--debug_profile_frontiers_confirmation"},{"location":"commands/command-line-interface/#-debug_rpc","text":"version 18.0+ Allows running RPC commands without enabling the RPC server. Not recommended for daily usage. Example: echo '{\"action\": \"block_count\"}' | nano_node --debug_rpc","title":"--debug_rpc"},{"location":"commands/command-line-interface/#-debug_stacktrace","text":"version 20.0+ Prints a stacktrace example, useful to verify that it includes the desired information, such as files, function names and line numbers","title":"--debug_stacktrace"},{"location":"commands/command-line-interface/#-debug_sys_logging","text":"version 19.0+ On *nix system this checks writing to the system log. On Windows it writes to the event viewer, a registry entry needs to exist for this to work correctly which can be created by running this command for the first time as an administrator","title":"--debug_sys_logging"},{"location":"commands/command-line-interface/#-debug_unconfirmed_frontiers","text":"version 22.0+ Prints the account, height, frontiers and cemented frontier for all accounts which are not fully confirmed. Sorted by height in descending order","title":"--debug_unconfirmed_frontiers"},{"location":"commands/command-line-interface/#-debug_validate_blocks","text":"Alias to --validate_blocks","title":"--debug_validate_blocks"},{"location":"commands/command-line-interface/#-debug_verify_profile","text":"Profile signature verification","title":"--debug_verify_profile"},{"location":"commands/command-line-interface/#deprecated-commands","text":"","title":"Deprecated commands"},{"location":"commands/command-line-interface/#launch-options_1","text":"","title":"Launch options"},{"location":"commands/command-line-interface/#removed-commands","text":"","title":"Removed commands"},{"location":"commands/command-line-interface/#debug","text":"","title":"Debug"},{"location":"commands/command-line-interface/#launch-options_2","text":"","title":"Launch options"},{"location":"commands/rpc-protocol/","text":"RPC Protocol \u00b6 The RPC protocol accepts JSON HTTP POST requests. The following are RPC commands along with the responses that are expected. This page is split into the following sections: Section Purpose Node RPCs For interacting with the node and ledger. Wallet RPCs For interacting with the built-in, QT-based node wallet. NOTE : This wallet is only recommended for development and testing. Unit Conversion RPCs For converting different units to and from raw. Deprecated RPCs No longer recommended for use. Node RPCs \u00b6 Unconfirmed blocks returned Unless otherwise specified, RPC calls can return unconfirmed blocks and related details. In the most important cases where balances or similar details may include unconfirmed amounts, additional warnings have been included. Refer to Block confirmation procedures for details. account_balance \u00b6 Returns how many RAW is owned and how many have not yet been received by account Unconfirmed information This call returns information that may be based on unconfirmed blocks. These details should not be relied on for any process or integration that requires confirmed blocks. The pending balance is calculated from potentially unconfirmed blocks. The account's balance is obtained from its frontier. An atomic account_info RPC call is recommended for the purposes of creating transactions. Request: { \"action\" : \"account_balance\" , \"account\" : \"nano_3e3j5tkog48pnny9dmfzj1r16pg8t1e76dz5tmac6iq689wyjfpi00000000\" } Response: { \"balance\" : \"10000\" , \"pending\" : \"10000\" } account_block_count \u00b6 Get number of blocks for a specific account Request: { \"action\" : \"account_block_count\" , \"account\" : \"nano_3t6k35gi95xu6tergt6p69ck76ogmitsa8mnijtpxm9fkcm736xtoncuohr3\" } Response: { \"block_count\" : \"19\" } account_get \u00b6 Get account number for the public key Request: { \"action\" : \"account_get\" , \"key\" : \"3068BB1CA04525BB0E416C485FE6A67FD52540227D267CC8B6E8DA958A7FA039\" } Response: { \"account\" : \"nano_1e5aqegc1jb7qe964u4adzmcezyo6o146zb8hm6dft8tkp79za3sxwjym5rx\" } account_history \u00b6 Reports send/receive information for an account. Returns only send & receive blocks by default (unless raw is set to true - see optional parameters below): change, state change & state epoch blocks are skipped, open & state open blocks will appear as receive, state receive/send blocks will appear as receive/send entries. Response will start with the latest block for the account (the frontier), and will list all blocks back to the open block of this account when \"count\" is set to \"-1\". Note : \"local_timestamp\" returned since version 18.0, \"height\" field returned since version 19.0 Includes unconfirmed blocks This call may return results that include unconfirmed blocks, so it should not be used in any processes or integrations requiring only details from blocks confirmed by the network. Request: { \"action\" : \"account_history\" , \"account\" : \"nano_1ipx847tk8o46pwxt5qjdbncjqcbwcc1rrmqnkztrfjy5k7z4imsrata9est\" , \"count\" : \"1\" } Response: { \"account\" : \"nano_1ipx847tk8o46pwxt5qjdbncjqcbwcc1rrmqnkztrfjy5k7z4imsrata9est\" , \"history\" : [ { \"type\" : \"send\" , \"account\" : \"nano_38ztgpejb7yrm7rr586nenkn597s3a1sqiy3m3uyqjicht7kzuhnihdk6zpz\" , \"amount\" : \"80000000000000000000000000000000000\" , \"local_timestamp\" : \"1551532723\" , \"height\" : \"60\" , \"hash\" : \"80392607E85E73CC3E94B4126F24488EBDFEB174944B890C97E8F36D89591DC5\" } ], \"previous\" : \"8D3AB98B301224253750D448B4BD997132400CEDD0A8432F775724F2D9821C72\" } If the count limit results in stopping before the end of the account chain, then the response will also contain a previous field (outside of the history field) which contains the block hash that would be next to process if count was larger. Optional parameters: raw (bool): if set to true instead of the default false , instead of outputting a simplified send or receive explanation of blocks (intended for wallets), output all parameters of the block itself as seen in block_create or other APIs returning blocks. It still includes the \"account\" and \"amount\" properties you'd see without this option. State/universal blocks in the raw history will also have a subtype field indicating their equivalent \"old\" block. Unfortunately, the \"account\" parameter for open blocks is the account of the source block, not the account of the open block, to preserve similarity with the non-raw history. head (64 hexadecimal digits string, 256 bit): instead of using the latest block for a specified account, use this block as the head of the account instead. Useful for pagination. offset (decimal integer): skips a number of blocks starting from head (if given). Not often used. Available since version 11.0 reverse (bool): if set to true instead of the default false , the response starts from head (if given, otherwise the first block of the account), and lists blocks up to the frontier (limited by \"count\"). Note : the field previous in the response changes to next . Available since version 19.0 account_filter (array of public addresses): results will be filtered to only show sends/receives connected to the provided account(s). Available since version 19.0 . Note: In v19.0, this option does not handle receive blocks; fixed in v20.0. account_info \u00b6 Returns frontier, open block, change representative block, balance, last modified timestamp from local database & block count for account . Only works for accounts that have received their first transaction and have an entry on the ledger, will return \"Account not found\" otherwise. To open an account, use receive . Unconfirmed information This call returns information that may be based on unconfirmed blocks. These details should not be relied on for any process or integration that requires confirmed blocks. The balance is obtained from the frontier, which may be unconfirmed. As long as you follow the guidelines , you can rely on the balance for the purposes of creating transactions for this account. If the frontier is never confirmed, then the blocks that proceed it will also never be confirmed. Request: { \"action\" : \"account_info\" , \"account\" : \"nano_3t6k35gi95xu6tergt6p69ck76ogmitsa8mnijtpxm9fkcm736xtoncuohr3\" } Response: { \"frontier\" : \"FF84533A571D953A596EA401FD41743AC85D04F406E76FDE4408EAED50B473C5\" , \"open_block\" : \"991CF190094C00F0B68E2E5F75F6BEE95A2E0BD93CEAA4A6734DB9F19B728948\" , \"representative_block\" : \"991CF190094C00F0B68E2E5F75F6BEE95A2E0BD93CEAA4A6734DB9F19B728948\" , \"balance\" : \"235580100176034320859259343606608761791\" , \"modified_timestamp\" : \"1501793775\" , \"block_count\" : \"33\" , \"confirmation_height\" : \"28\" , \"confirmation_height_frontier\" : \"34C70FCA0952E29ADC7BEE6F20381466AE42BD1CFBA4B7DFFE8BD69DF95449EB\" , \"account_version\" : \"1\" } In response confirmation_height only available for version 19.0+ In response confirmation_height_frontier only available for version 21.0+ which is the block hash at that confirmation height. Optional \"representative\", \"weight\", \"pending\" version 9.0+ Booleans, false by default. Additionally returns representative, voting weight, pending balance for account Request: { \"action\" : \"account_info\" , \"account\" : \"nano_3t6k35gi95xu6tergt6p69ck76ogmitsa8mnijtpxm9fkcm736xtoncuohr3\" , \"representative\" : \"true\" , \"weight\" : \"true\" , \"pending\" : \"true\" } Response: { \"frontier\" : \"FF84533A571D953A596EA401FD41743AC85D04F406E76FDE4408EAED50B473C5\" , \"open_block\" : \"991CF190094C00F0B68E2E5F75F6BEE95A2E0BD93CEAA4A6734DB9F19B728948\" , \"representative_block\" : \"991CF190094C00F0B68E2E5F75F6BEE95A2E0BD93CEAA4A6734DB9F19B728948\" , \"balance\" : \"235580100176034320859259343606608761791\" , \"modified_timestamp\" : \"1501793775\" , \"block_count\" : \"33\" , \"representative\" : \"nano_3t6k35gi95xu6tergt6p69ck76ogmitsa8mnijtpxm9fkcm736xtoncuohr3\" , \"weight\" : \"1105577030935649664609129644855132177\" , \"pending\" : \"2309370929000000000000000000000000\" } account_key \u00b6 Get the public key for account Request: { \"action\" : \"account_key\" , \"account\" : \"nano_1e5aqegc1jb7qe964u4adzmcezyo6o146zb8hm6dft8tkp79za3sxwjym5rx\" } Response: { \"key\" : \"3068BB1CA04525BB0E416C485FE6A67FD52540227D267CC8B6E8DA958A7FA039\" } account_representative \u00b6 Returns the representative for account Request: { \"action\" : \"account_representative\" , \"account\" : \"nano_39a73oy5ungrhxy5z5oao1xso4zo7dmgpjd4u74xcrx3r1w6rtazuouw6qfi\" } Response: { \"representative\" : \"nano_16u1uufyoig8777y6r8iqjtrw8sg8maqrm36zzcm95jmbd9i9aj5i8abr8u5\" } account_weight \u00b6 Returns the voting weight for account Request: { \"action\" : \"account_weight\" , \"account\" : \"nano_3e3j5tkog48pnny9dmfzj1r16pg8t1e76dz5tmac6iq689wyjfpi00000000\" } Response: { \"weight\" : \"10000\" } accounts_balances \u00b6 Returns how many RAW is owned and how many have not yet been received by accounts list Unconfirmed information This call returns information that may be based on unconfirmed blocks. These details should not be relied on for any process or integration that requires confirmed blocks. The pending balances are calculated from potentially unconfirmed blocks. Account balances are obtained from their frontiers. An atomic account_info RPC call is recommended for the purposes of creating transactions. Request: { \"action\" : \"accounts_balances\" , \"accounts\" : [ \"nano_3e3j5tkog48pnny9dmfzj1r16pg8t1e76dz5tmac6iq689wyjfpi00000000\" , \"nano_3i1aq1cchnmbn9x5rsbap8b15akfh7wj7pwskuzi7ahz8oq6cobd99d4r3b7\" ] } Response: { \"balances\" : { \"nano_3e3j5tkog48pnny9dmfzj1r16pg8t1e76dz5tmac6iq689wyjfpi00000000\" : { \"balance\" : \"10000\" , \"pending\" : \"10000\" }, \"nano_3i1aq1cchnmbn9x5rsbap8b15akfh7wj7pwskuzi7ahz8oq6cobd99d4r3b7\" : { \"balance\" : \"10000000\" , \"pending\" : \"0\" } } } accounts_frontiers \u00b6 Returns a list of pairs of account and block hash representing the head block for accounts list Includes unconfirmed blocks This call may return results that include unconfirmed blocks, so it should not be used in any processes or integrations requiring only details from blocks confirmed by the network. Request: { \"action\" : \"accounts_frontiers\" , \"accounts\" : [ \"nano_3t6k35gi95xu6tergt6p69ck76ogmitsa8mnijtpxm9fkcm736xtoncuohr3\" , \"nano_3i1aq1cchnmbn9x5rsbap8b15akfh7wj7pwskuzi7ahz8oq6cobd99d4r3b7\" ] } Response: { \"frontiers\" : { \"nano_3t6k35gi95xu6tergt6p69ck76ogmitsa8mnijtpxm9fkcm736xtoncuohr3\" : \"791AF413173EEE674A6FCF633B5DFC0F3C33F397F0DA08E987D9E0741D40D81A\" , \"nano_3i1aq1cchnmbn9x5rsbap8b15akfh7wj7pwskuzi7ahz8oq6cobd99d4r3b7\" : \"6A32397F4E95AF025DE29D9BF1ACE864D5404362258E06489FABDBA9DCCC046F\" } } accounts_pending \u00b6 Returns a list of block hashes which have not yet been received by these accounts Optional include_only_confirmed recommended By default this will return blocks not in active elections but unconfirmed (e.g., block was received but node was restarted, election was dropped, new ledger with reset confirmation height). To avoid potential issues related to these situations setting the include_only_confirmed = true is recommended for most use cases. Request: { \"action\" : \"accounts_pending\" , \"accounts\" : [ \"nano_1111111111111111111111111111111111111111111111111117353trpda\" , \"nano_3t6k35gi95xu6tergt6p69ck76ogmitsa8mnijtpxm9fkcm736xtoncuohr3\" ], \"count\" : \"1\" } Response: { \"blocks\" : { \"nano_1111111111111111111111111111111111111111111111111117353trpda\" : [ \"142A538F36833D1CC78B94E11C766F75818F8B940771335C6C1B8AB880C5BB1D\" ], \"nano_3t6k35gi95xu6tergt6p69ck76ogmitsa8mnijtpxm9fkcm736xtoncuohr3\" : [ \"4C1FEEF0BEA7F50BE35489A1233FE002B212DEA554B55B1B470D78BD8F210C74\" ] } } Optional \"threshold\" version 8.0+ Number (128 bit, decimal). Returns a list of pending block hashes with amount more or equal to threshold Request: { \"action\" : \"accounts_pending\" , \"accounts\" : [ \"nano_1111111111111111111111111111111111111111111111111117353trpda\" , \"nano_3t6k35gi95xu6tergt6p69ck76ogmitsa8mnijtpxm9fkcm736xtoncuohr3\" ], \"count\" : \"1\" , \"threshold\" : \"1000000000000000000000000\" } Response: { \"blocks\" : { \"nano_1111111111111111111111111111111111111111111111111117353trpda\" : { \"142A538F36833D1CC78B94E11C766F75818F8B940771335C6C1B8AB880C5BB1D\" : \"6000000000000000000000000000000\" }, \"nano_3t6k35gi95xu6tergt6p69ck76ogmitsa8mnijtpxm9fkcm736xtoncuohr3\" : { \"4C1FEEF0BEA7F50BE35489A1233FE002B212DEA554B55B1B470D78BD8F210C74\" : \"106370018000000000000000000000000\" } } } Optional \"source\" version 9.0+ Boolean, false by default. Returns a list of pending block hashes with amount and source accounts Request: { \"action\" : \"accounts_pending\" , \"accounts\" : [ \"nano_1111111111111111111111111111111111111111111111111117353trpda\" , \"nano_3t6k35gi95xu6tergt6p69ck76ogmitsa8mnijtpxm9fkcm736xtoncuohr3\" ], \"count\" : \"1\" , \"source\" : \"true\" } Response: { \"blocks\" : { \"nano_1111111111111111111111111111111111111111111111111117353trpda\" : { \"142A538F36833D1CC78B94E11C766F75818F8B940771335C6C1B8AB880C5BB1D\" : { \"amount\" : \"6000000000000000000000000000000\" , \"source\" : \"nano_3dcfozsmekr1tr9skf1oa5wbgmxt81qepfdnt7zicq5x3hk65fg4fqj58mbr\" } }, \"nano_3t6k35gi95xu6tergt6p69ck76ogmitsa8mnijtpxm9fkcm736xtoncuohr3\" : { \"4C1FEEF0BEA7F50BE35489A1233FE002B212DEA554B55B1B470D78BD8F210C74\" : { \"amount\" : \"106370018000000000000000000000000\" , \"source\" : \"nano_13ezf4od79h1tgj9aiu4djzcmmguendtjfuhwfukhuucboua8cpoihmh8byo\" } } } } Optional \"include_active\" version 15.0+ Boolean, false by default. Include active (not confirmed) blocks Request: { \"action\" : \"accounts_pending\" , \"accounts\" : [ \"nano_1111111111111111111111111111111111111111111111111117353trpda\" , \"nano_3t6k35gi95xu6tergt6p69ck76ogmitsa8mnijtpxm9fkcm736xtoncuohr3\" ], \"count\" : \"1\" , \"include_active\" : \"true\" } Optional \"sorting\" version 19.0+ Boolean, false by default. Additionally sorts each account's blocks by their amounts in descending order. Optional \"include_only_confirmed\" version 19.0+ Boolean, false by default. Only returns blocks which have their confirmation height set or are undergoing confirmation height processing. active_difficulty \u00b6 version 19.0+ Returns the difficulty values (16 hexadecimal digits string, 64 bit) for the minimum required on the network ( network_minimum ) as well as the current active difficulty seen on the network ( network_current , 10 second trended average of adjusted difficulty seen on prioritized transactions, refreshed every 500ms) which can be used to perform rework for better prioritization of transaction processing. A multiplier of the network_current from the base difficulty of network_minimum is also provided for comparison. network_receive_minimum and network_receive_current are also provided as lower thresholds exclusively for receive blocks. Request: { \"action\" : \"active_difficulty\" } Response: { \"multiplier\" : \"1.5\" , \"network_current\" : \"fffffffaaaaaaaab\" , \"network_minimum\" : \"fffffff800000000\" , \"network_receive_current\" : \"fffffff07c1f07c2\" , // si n ce V 21.2 \"network_receive_minimum\" : \"fffffe0000000000\" // si n ce V 21.2 } Optional \"include_trend\" Boolean, false by default. Also returns the trend of difficulty seen on the network as a list of multipliers . Sampling occurs every 500ms. The list is ordered such that the first value is the most recent sample. Note: Before v20, the sampling period was between 16 and 36 seconds. Request: { \"action\" : \"active_difficulty\" , \"include_trend\" : \"true\" } Response: { ... , \"difficulty_trend\" : [ \"1.156096135149775\" , \"1.190133894573061\" , \"1.135567138563921\" , \"1.000000000000000\" , \"...\" , \"1.000000000000000\" ] } available_supply \u00b6 Returns how many raw are in the public supply Request: { \"action\" : \"available_supply\" } Response: { \"available\" : \"133248061996216572282917317807824970865\" } block_account \u00b6 Returns the account containing block Request: { \"action\" : \"block_account\" , \"hash\" : \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\" } Response: { \"account\" : \"nano_3e3j5tkog48pnny9dmfzj1r16pg8t1e76dz5tmac6iq689wyjfpi00000000\" } block_confirm \u00b6 version 12.2+ Request confirmation for block from known online representative nodes. Check results with confirmation history . Request: { \"action\" : \"block_confirm\" , \"hash\" : \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\" } Response: { \"started\" : \"1\" } block_count \u00b6 Reports the number of blocks in the ledger and unchecked synchronizing blocks Request: { \"action\" : \"block_count\" } Response: { \"count\" : \"1000\" , \"unchecked\" : \"10\" , \"cemented\" : \"25\" } Optional \"include_cemented\" version 19.0+ (enable_control required in version 19.0, not required in version 20.0+) Default \"true\". If \"true\", \"cemented\" in the response will contain the number of cemented blocks. (In V19.0 default was \"false\") Dangerous RPC calls controlled by enable_control This RPC command/option requires enable_control to be enabled within the RPC config file. Enabling this means that anyone with access to the RPC port could potentially access wallet funds , stop the node from running and take other dangerous actions. Use caution when enabling this option, especially with external RPC access available. For more details see the Node Security page . block_create \u00b6 enable_control required, version 9.0+ Creates a json representations of new block based on input data & signed with private key or account in wallet . Use for offline signing. Using the optional json_block is recommended since v19.0. Dangerous RPC calls controlled by enable_control This RPC command/option requires enable_control to be enabled within the RPC config file. Enabling this means that anyone with access to the RPC port could potentially access wallet funds , stop the node from running and take other dangerous actions. Use caution when enabling this option, especially with external RPC access available. For more details see the Node Security page . Request sample for state block: { \"action\" : \"block_create\" , \"json_block\" : \"true\" , \"type\" : \"state\" , \"balance\" : \"1000000000000000000000\" , \"key\" : \"0000000000000000000000000000000000000000000000000000000000000002\" , \"representative\" : \"nano_1hza3f7wiiqa7ig3jczyxj5yo86yegcmqk3criaz838j91sxcckpfhbhhra1\" , \"link\" : \"19D3D919475DEED4696B5D13018151D1AF88B2BD3BCFF048B45031C1F36D1858\" , \"previous\" : \"F47B23107E5F34B2CE06F562B5C435DF72A533251CB414C51B2B62A8F63A00E4\" } Parameters for state block: balance : final balance for account after block creation, formatted in 'raw' units using a decimal integer. If balance is less than previous, block is considered as send subtype! wallet (optional): The wallet ID that the account the block is being created for is in. account (optional): The account the block is being created for (nano_youraccount). key (optional): Instead of using \"wallet\" & \"account\" parameters, you can directly pass in a private key. source (optional): The block hash of the source of funds for this receive block (the send block that this receive block will pocket). destination (optional): The account that the sent funds should be accessible to. link (optional): Instead of using \"source\" & \"destination\" parameters, you can directly pass \"link\" (source to receive or destination public key to send). representative : The account that block account will use as its representative. previous : The block hash of the previous block on this account's block chain (\"0\" for first block). Warning: It is critical that balance is the balance of the account after created block! Optional \"json_block\" version 19.0+ Default \"false\". If \"true\", \"block\" in the response will contain a JSON subtree instead of a JSON string. Examples Response sample for above request : { \"hash\" : \"FF0144381CFF0B2C079A115E7ADA7E96F43FD219446E7524C48D1CC9900C4F17\" , \"difficulty\" : \"ffffffe1278b3dc6\" , // si n ce V 21.0 \"block\" : { \"type\" : \"state\" , \"account\" : \"nano_3qgmh14nwztqw4wmcdzy4xpqeejey68chx6nciczwn9abji7ihhum9qtpmdr\" , \"previous\" : \"F47B23107E5F34B2CE06F562B5C435DF72A533251CB414C51B2B62A8F63A00E4\" , \"representative\" : \"nano_1hza3f7wiiqa7ig3jczyxj5yo86yegcmqk3criaz838j91sxcckpfhbhhra1\" , \"balance\" : \"1000000000000000000000\" , \"link\" : \"19D3D919475DEED4696B5D13018151D1AF88B2BD3BCFF048B45031C1F36D1858\" , \"link_as_account\" : \"nano_18gmu6engqhgtjnppqam181o5nfhj4sdtgyhy36dan3jr9spt84rzwmktafc\" , \"signature\" : \"3BFBA64A775550E6D49DF1EB8EEC2136DCD74F090E2ED658FBD9E80F17CB1C9F9F7BDE2B93D95558EC2F277FFF15FD11E6E2162A1714731B743D1E941FA4560A\" , \"work\" : \"cab7404f0b5449d0\" } } Optional \"work\" Work value (16 hexadecimal digits string, 64 bit). Uses work value for block from external source Optional \"version\" version 21.0+ Work version string. Currently \"work_1\" is the default and only valid option. Only used if optional work is not given. Optional \"difficulty\" version 21.0+ Difficulty value (16 hexadecimal digits string, 64 bit). Uses difficulty value to generate work. Only used if optional work is not given. If difficulty and work values are both not given, RPC processor tries to calculate difficulty for work generation based on ledger data: epoch from previous block or from link for receive subtype; block subtype from previous block balance. block_hash \u00b6 version 13.0+ Returning block hash for given block content. Using the optional json_block is recommended since v19.0. Request: { \"action\" : \"block_hash\" , \"json_block\" : \"true\" , \"block\" : { \"type\" : \"state\" , \"account\" : \"nano_3qgmh14nwztqw4wmcdzy4xpqeejey68chx6nciczwn9abji7ihhum9qtpmdr\" , \"previous\" : \"F47B23107E5F34B2CE06F562B5C435DF72A533251CB414C51B2B62A8F63A00E4\" , \"representative\" : \"nano_1hza3f7wiiqa7ig3jczyxj5yo86yegcmqk3criaz838j91sxcckpfhbhhra1\" , \"balance\" : \"1000000000000000000000\" , \"link\" : \"19D3D919475DEED4696B5D13018151D1AF88B2BD3BCFF048B45031C1F36D1858\" , \"link_as_account\" : \"nano_18gmu6engqhgtjnppqam181o5nfhj4sdtgyhy36dan3jr9spt84rzwmktafc\" , \"signature\" : \"3BFBA64A775550E6D49DF1EB8EEC2136DCD74F090E2ED658FBD9E80F17CB1C9F9F7BDE2B93D95558EC2F277FFF15FD11E6E2162A1714731B743D1E941FA4560A\" , \"work\" : \"cab7404f0b5449d0\" } } Response: { \"hash\" : \"FF0144381CFF0B2C079A115E7ADA7E96F43FD219446E7524C48D1CC9900C4F17\" } Optional \"json_block\" version 19.0+ Default \"false\". If \"true\", \"block\" must contain a JSON subtree instead of a JSON string. block_info \u00b6 Retrieves a json representation of the block in contents along with: since version 18.0 : block_account , transaction amount , block balance , block height in account chain, block local modification timestamp since version 19.0 : Whether block was confirmed , subtype ( for state blocks ) of send , receive , change or epoch Using the optional json_block is recommended since v19.0. Request: { \"action\" : \"block_info\" , \"json_block\" : \"true\" , \"hash\" : \"87434F8041869A01C8F6F263B87972D7BA443A72E0A97D7A3FD0CCC2358FD6F9\" } Response: { \"block_account\" : \"nano_1ipx847tk8o46pwxt5qjdbncjqcbwcc1rrmqnkztrfjy5k7z4imsrata9est\" , \"amount\" : \"30000000000000000000000000000000000\" , \"balance\" : \"5606157000000000000000000000000000000\" , \"height\" : \"58\" , \"local_timestamp\" : \"0\" , \"confirmed\" : \"true\" , \"contents\" : { \"type\" : \"state\" , \"account\" : \"nano_1ipx847tk8o46pwxt5qjdbncjqcbwcc1rrmqnkztrfjy5k7z4imsrata9est\" , \"previous\" : \"CE898C131AAEE25E05362F247760F8A3ACF34A9796A5AE0D9204E86B0637965E\" , \"representative\" : \"nano_1stofnrxuz3cai7ze75o174bpm7scwj9jn3nxsn8ntzg784jf1gzn1jjdkou\" , \"balance\" : \"5606157000000000000000000000000000000\" , \"link\" : \"5D1AA8A45F8736519D707FCB375976A7F9AF795091021D7E9C7548D6F45DD8D5\" , \"link_as_account\" : \"nano_1qato4k7z3spc8gq1zyd8xeqfbzsoxwo36a45ozbrxcatut7up8ohyardu1z\" , \"signature\" : \"82D41BC16F313E4B2243D14DFFA2FB04679C540C2095FEE7EAE0F2F26880AD56DD48D87A7CC5DD760C5B2D76EE2C205506AA557BF00B60D8DEE312EC7343A501\" , \"work\" : \"8a142e07a10996d5\" }, \"subtype\" : \"send\" } Note: The Balance in contents is a uint128. However, it will be a hex-encoded (like 0000000C9F2C9CD04674EDEA40000000 for 1 Mnano ) when the block is a legacy Send Block . If the block is a State-Block , the same Balance will be a numeric-string (like 1000000000000000000000000000000 ). Optional \"json_block\" version 19.0+ Default \"false\". If \"true\", \"contents\" will contain a JSON subtree instead of a JSON string. blocks \u00b6 Retrieves a json representations of blocks . Using the optional json_block is recommended since v19.0. Request: { \"action\" : \"blocks\" , \"json_block\" : \"true\" , \"hashes\" : [ \"87434F8041869A01C8F6F263B87972D7BA443A72E0A97D7A3FD0CCC2358FD6F9\" ] } Response: { \"blocks\" : { \"87434F8041869A01C8F6F263B87972D7BA443A72E0A97D7A3FD0CCC2358FD6F9\" : { \"type\" : \"state\" , \"account\" : \"nano_1ipx847tk8o46pwxt5qjdbncjqcbwcc1rrmqnkztrfjy5k7z4imsrata9est\" , \"previous\" : \"CE898C131AAEE25E05362F247760F8A3ACF34A9796A5AE0D9204E86B0637965E\" , \"representative\" : \"nano_1stofnrxuz3cai7ze75o174bpm7scwj9jn3nxsn8ntzg784jf1gzn1jjdkou\" , \"balance\" : \"5606157000000000000000000000000000000\" , \"link\" : \"5D1AA8A45F8736519D707FCB375976A7F9AF795091021D7E9C7548D6F45DD8D5\" , \"link_as_account\" : \"nano_1qato4k7z3spc8gq1zyd8xeqfbzsoxwo36a45ozbrxcatut7up8ohyardu1z\" , \"signature\" : \"82D41BC16F313E4B2243D14DFFA2FB04679C540C2095FEE7EAE0F2F26880AD56DD48D87A7CC5DD760C5B2D76EE2C205506AA557BF00B60D8DEE312EC7343A501\" , \"work\" : \"8a142e07a10996d5\" } } } Optional \"json_block\" version 19.0+ Default \"false\". If \"true\", \"contents\" will contain a JSON subtree instead of a JSON string. blocks_info \u00b6 Retrieves a json representations of blocks in contents along with: since version 18.0 : block_account , transaction amount , block balance , block height in account chain, block local modification timestamp since version 19.0 : Whether block was confirmed , subtype ( for state blocks ) of send , receive , change or epoch Using the optional json_block is recommended since v19.0. Request: { \"action\" : \"blocks_info\" , \"json_block\" : \"true\" , \"hashes\" : [ \"87434F8041869A01C8F6F263B87972D7BA443A72E0A97D7A3FD0CCC2358FD6F9\" ] } Response: { \"blocks\" : { \"87434F8041869A01C8F6F263B87972D7BA443A72E0A97D7A3FD0CCC2358FD6F9\" : { \"block_account\" : \"nano_1ipx847tk8o46pwxt5qjdbncjqcbwcc1rrmqnkztrfjy5k7z4imsrata9est\" , \"amount\" : \"30000000000000000000000000000000000\" , \"balance\" : \"5606157000000000000000000000000000000\" , \"height\" : \"58\" , \"local_timestamp\" : \"0\" , \"confirmed\" : \"true\" , \"contents\" : { \"type\" : \"state\" , \"account\" : \"nano_1ipx847tk8o46pwxt5qjdbncjqcbwcc1rrmqnkztrfjy5k7z4imsrata9est\" , \"previous\" : \"CE898C131AAEE25E05362F247760F8A3ACF34A9796A5AE0D9204E86B0637965E\" , \"representative\" : \"nano_1stofnrxuz3cai7ze75o174bpm7scwj9jn3nxsn8ntzg784jf1gzn1jjdkou\" , \"balance\" : \"5606157000000000000000000000000000000\" , \"link\" : \"5D1AA8A45F8736519D707FCB375976A7F9AF795091021D7E9C7548D6F45DD8D5\" , \"link_as_account\" : \"nano_1qato4k7z3spc8gq1zyd8xeqfbzsoxwo36a45ozbrxcatut7up8ohyardu1z\" , \"signature\" : \"82D41BC16F313E4B2243D14DFFA2FB04679C540C2095FEE7EAE0F2F26880AD56DD48D87A7CC5DD760C5B2D76EE2C205506AA557BF00B60D8DEE312EC7343A501\" , \"work\" : \"8a142e07a10996d5\" }, \"subtype\" : \"send\" } } } Optional \"pending\", \"source\", \"balance\" pending, source: version 9.0+ balance: version 12.0+ Booleans, false by default. Additionally checks if block is pending, returns source account for receive & open blocks (0 for send & change blocks), and returns the balance of the account at the time of the block. Request: { \"action\" : \"blocks_info\" , \"hashes\" : [ \"E2FB233EF4554077A7BF1AA85851D5BF0B36965D2B0FB504B2BC778AB89917D3\" ], \"pending\" : \"true\" , \"source\" : \"true\" , \"balance\" : \"true\" } Response: { \"blocks\" : { \"E2FB233EF4554077A7BF1AA85851D5BF0B36965D2B0FB504B2BC778AB89917D3\" : { \"block_account\" : \"nano_1qato4k7z3spc8gq1zyd8xeqfbzsoxwo36a45ozbrxcatut7up8ohyardu1z\" , \"amount\" : \"30000000000000000000000000000000000\" , \"contents\" : { ... }, \"pending\" : \"0\" , \"source_account\" : \"nano_1ipx847tk8o46pwxt5qjdbncjqcbwcc1rrmqnkztrfjy5k7z4imsrata9est\" , \"balance\" : \"40200000001000000000000000000000000\" } } } Optional \"json_block\" version 19.0+ Default \"false\". If \"true\", \"contents\" will contain a JSON subtree instead of a JSON string. Optional \"include_not_found\" version 19.0+ Default \"false\". If \"true\", an additional \"blocks_not_found\" is provided in the response, containing a list of the block hashes that were not found in the local database. Previously to this version an error would be produced if any block was not found. Request: { \"action\" : \"blocks_info\" , \"include_not_found\" : \"true\" , \"hashes\" : [ \"87434F8041869A01C8F6F263B87972D7BA443A72E0A97D7A3FD0CCC2358FD6F9\" , \"0000000000000000000000000000000000000000000000000000000000000001\" ] } Response: { \"blocks\" : { \"87434F8041869A01C8F6F263B87972D7BA443A72E0A97D7A3FD0CCC2358FD6F9\" : { \"block_account\" : \"nano_1ipx847tk8o46pwxt5qjdbncjqcbwcc1rrmqnkztrfjy5k7z4imsrata9est\" , \"amount\" : \"30000000000000000000000000000000000\" , \"balance\" : \"5606157000000000000000000000000000000\" , \"height\" : \"58\" , \"local_timestamp\" : \"0\" , \"confirmed\" : \"false\" , \"contents\" : { ... } } }, \"blocks_not_found\" : [ \"0000000000000000000000000000000000000000000000000000000000000001\" ] } bootstrap \u00b6 Initialize bootstrap to specific IP address and port . Not compatible with launch flag --disable_legacy_bootstrap Request: { \"action\" : \"bootstrap\" , \"address\" : \"::ffff:138.201.94.249\" , \"port\" : \"7075\" } Response: { \"success\" : \"\" } Optional \"bypass_frontier_confirmation\" version 20.0+ Default \"false\". If \"true\", frontier confirmation will not be performed for this bootstrap. Normally not to be changed. Optional \"id\" version 21.0+ String, empty by default. Set specific ID for new bootstrap attempt for better tracking. bootstrap_any \u00b6 Initialize multi-connection bootstrap to random peers. Not compatible with launch flag --disable_legacy_bootstrap Request: { \"action\" : \"bootstrap_any\" } Response: { \"success\" : \"\" } Optional \"force\" version 20.0+ Boolean, false by default. Manually force closing of all current bootstraps Optional \"id\" version 21.0+ String, empty by default. Set specific ID for new bootstrap attempt for better tracking. bootstrap_lazy \u00b6 version 17.0+ Initialize lazy bootstrap with given block hash . Not compatible with launch flag --disable_lazy_bootstrap Request: { \"action\" : \"bootstrap_lazy\" , \"hash\" : \"FF0144381CFF0B2C079A115E7ADA7E96F43FD219446E7524C48D1CC9900C4F17\" } Response: { \"started\" : \"1\" } Optional \"force\" Boolean, false by default. Manually force closing of all current bootstraps Optional \"id\" version 21.0+ String, empty by default. Set specific ID for new bootstrap attempt for better tracking. bootstrap_status \u00b6 version 17.0+ Debug purposes only This call is for internal diagnostics/debug purposes only. Do not rely on this interface being stable and do not use in a production system. Returning status of current bootstrap attempt Request: { \"action\" : \"bootstrap_status\" } Response: versions 21.0+ { \"bootstrap_threads\" : \"2\" , \"running_attempts_count\" : \"2\" , \"total_attempts_count\" : \"6\" , \"connections\" : { \"clients\" : \"31\" , \"connections\" : \"45\" , \"idle\" : \"0\" , \"target_connections\" : \"64\" , \"pulls\" : \"1158514\" }, \"attempts\" : [ { \"id\" : \"EE778222D6407F94A666B8A9E03D242D\" , \"mode\" : \"legacy\" , \"started\" : \"true\" , \"pulling\" : \"1158544\" , \"total_blocks\" : \"4311\" , \"requeued_pulls\" : \"7\" , \"frontier_pulls\" : \"0\" , \"frontiers_received\" : \"true\" , \"frontiers_confirmed\" : \"false\" , \"frontiers_confirmation_pending\" : \"false\" , \"duration\" : \"133\" }, { \"id\" : \"291D2CC32F44E004896C4215A6CDEDAFEF317F6AC802C244E8F4B4F2456175CB\" , \"mode\" : \"lazy\" , \"started\" : \"true\" , \"pulling\" : \"1\" , \"total_blocks\" : \"1878\" , \"requeued_pulls\" : \"4\" , \"lazy_blocks\" : \"1878\" , \"lazy_state_backlog\" : \"1\" , \"lazy_balances\" : \"4\" , \"lazy_destinations\" : \"0\" , \"lazy_undefined_links\" : \"0\" , \"lazy_pulls\" : \"13\" , \"lazy_keys\" : \"2\" , \"lazy_key_1\" : \"E6D0B5BD5EBDB3CEC7DBC32EDC3C2DBD5ABA17C54E34485A358BF8948039ED6A\" , \"duration\" : \"17\" } ] } Response V17.0-V20.0 { \"clients\" : \"0\" , \"pulls\" : \"0\" , \"pulling\" : \"0\" , \"connections\" : \"31\" , \"idle\" : \"31\" , \"target_connections\" : \"16\" , \"total_blocks\" : \"13558\" , \"runs_count\" : \"0\" , \"requeued_pulls\" : \"31\" , \"frontiers_received\" : \"true\" , \"frontiers_confirmed\" : \"false\" , \"mode\" : \"legacy\" , \"lazy_blocks\" : \"0\" , \"lazy_state_backlog\" : \"0\" , \"lazy_balances\" : \"0\" , \"lazy_destinations\" : \"0\" , \"lazy_undefined_links\" : \"0\" , \"lazy_pulls\" : \"32\" , \"lazy_keys\" : \"32\" , \"lazy_key_1\" : \"36897874BDA3028DC8544C106BE1394891F23DDDF84DE100FED450F6FBC8122C\" , \"duration\" : \"29\" } chain \u00b6 Returns a consecutive list of block hashes in the account chain starting at block back to count (direction from frontier back to open block, from newer blocks to older). Will list all blocks back to the open block of this chain when count is set to \"-1\". The requested block hash is included in the answer. Request: { \"action\" : \"chain\" , \"block\" : \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\" , \"count\" : \"1\" } Response: { \"blocks\" : [ \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\" ] } Optional \"offset\" version 18.0+ Number, 0 by default. Return the account chain block hashes offset by the specified number of blocks Optional \"reverse\" version 18.0+ Boolean, false by default. Returns a list of block hashes in the account chain starting at block up to count (direction from open block up to frontier, from older blocks to newer). Equal to successors confirmation_active \u00b6 version 16.0+ Returns list of active elections roots (excluding stopped & aborted elections); since V21, also includes the number of unconfirmed and confirmed active elections. Find info about specific root with confirmation_info Note The roots provided are two parts and differ between the first account block and subsequent blocks: First account block (open): 0000000000000000000000000000000000000000000000000000000000000000 + account public key Other blocks: previous hash + previous hash Request: { \"action\" : \"confirmation_active\" } Response: { \"confirmations\" : [ \"8031B600827C5CC05FDC911C28BBAC12A0E096CCB30FA8324F56C123676281B28031B600827C5CC05FDC911C28BBAC12A0E096CCB30FA8324F56C123676281B2\" ], \"unconfirmed\" : \"133\" , // si n ce V 21.0 \"confirmed\" : \"5\" // si n ce V 21.0 } Optional \"announcements\" Number, 0 by default. Returns only active elections with equal or higher announcements count. Useful to find long running elections confirmation_height_currently_processing \u00b6 version 19.0+ Debug purposes only This call is for internal diagnostics/debug purposes only. Do not rely on this interface being stable and do not use in a production system. Returns the hash of the block which is having the confirmation height set for, error otherwise. When a block is being confirmed, it must confirm all blocks in the chain below and iteratively follow all receive blocks. This can take a long time, so it can be useful to find which block was the original being confirmed. Request: { \"action\" : \"confirmation_height_currently_processing\" } Response: { \"hash\" : \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\" } confirmation_history \u00b6 version 12.0+ Debug purposes only This call is for internal diagnostics/debug purposes only. Do not rely on this interface being stable and do not use in a production system. duration, time, confirmation_stats: version 17.0+_ Returns hash, tally weight, election duration (in milliseconds), election confirmation timestamp for recent elections winners; since V20.0, the confirmation request count; since V21.0, the number of blocks and voters. Also returns stats: count of elections in history (limited to 2048) & average duration time. With version 19.0+ confirmation_history_size can be managed in the configuration file to adjust the number of elections to be kept in history and returned by this call. Due to timings inside the node, the default 2048 limit will return all confirmations up to traffic levels of approximately 56 confirmations/sec. To properly track levels above this, increase this value or use the confirmation subscription through the websocket instead. Request: { \"action\" : \"confirmation_history\" } Response: { \"confirmation_stats\" : { \"count\" : \"2\" , \"average\" : \"5000\" }, \"confirmations\" : [ { \"hash\" : \"EA70B32C55C193345D625F766EEA2FCA52D3F2CCE0B3A30838CC543026BB0FEA\" , \"duration\" : \"4000\" , \"time\" : \"1544819986\" , \"tally\" : \"80394786589602980996311817874549318248\" , \"blocks\" : \"1\" , // si n ce V 21.0 \"voters\" : \"37\" , // si n ce V 21.0 \"request_count\" : \"2\" // si n ce V 20.0 }, { \"hash\" : \"F2F8DA6D2CA0A4D78EB043A7A29E12BDE5B4CE7DE1B99A93A5210428EE5B8667\" , \"duration\" : \"6000\" , \"time\" : \"1544819988\" , \"tally\" : \"68921714529890443063672782079965877749\" , \"blocks\" : \"1\" , // si n ce V 21.0 \"voters\" : \"64\" , // si n ce V 21.0 \"request_count\" : \"7\" // si n ce V 20.0 } ] } Optional \"hash\" Valid block hash, filters return for only the provided hash. If there is no confirmation available for that hash anymore, the following return can be expected: { \"confirmation_stats\" : { \"count\" : \"0\" }, \"confirmations\" : \"\" } If the block is unknown on the node, the following error will be returned: \"error\": \"Invalid block hash\" confirmation_info \u00b6 version 16.0+ Returns info about an unconfirmed active election by root . Including announcements count, last winner (initially local ledger block), total tally of voted representatives, concurrent blocks with tally & block contents for each. Using the optional json_block is recommended since v19.0. Note The roots provided are two parts and differ between the first account block and subsequent blocks: First account block (open): 0000000000000000000000000000000000000000000000000000000000000000 + account public key Other blocks: previous hash + previous hash Request: { \"action\" : \"confirmation_info\" , \"json_block\" : \"true\" , \"root\" : \"EE125B1B1D85D3C24636B3590E1642D9F21B166C0C6CD99C9C6087A1224A0C44EE125B1B1D85D3C24636B3590E1642D9F21B166C0C6CD99C9C6087A1224A0C44\" } Response: { \"announcements\" : \"2\" , \"voters\" : \"29\" , \"last_winner\" : \"B94C505029F04BC057A0486ADA8BD07981B4A8736AE6581F2E98C6D18498146F\" , \"total_tally\" : \"51145880360832646375807054724596663794\" , \"blocks\" : { \"B94C505029F04BC057A0486ADA8BD07981B4A8736AE6581F2E98C6D18498146F\" : { \"tally\" : \"51145880360832646375807054724596663794\" , \"contents\" : { \"type\" : \"state\" , \"account\" : \"nano_3fihmbtuod33s4nrbqfczhk9zy9ddqimwjshzg4c3857es8c9631i5rg6h9p\" , \"previous\" : \"EE125B1B1D85D3C24636B3590E1642D9F21B166C0C6CD99C9C6087A1224A0C44\" , \"representative\" : \"nano_3o7uzba8b9e1wqu5ziwpruteyrs3scyqr761x7ke6w1xctohxfh5du75qgaj\" , \"balance\" : \"218195000000000000000000000000\" , \"link\" : \"0000000000000000000000000000000000000000000000000000000000000000\" , \"link_as_account\" : \"nano_1111111111111111111111111111111111111111111111111111hifc8npp\" , \"signature\" : \"B1BD285235C612C5A141FA61793D7C6C762D3F104A85102DED5FBD6B4514971C4D044ACD3EC8C06A9495D8E83B6941B54F8DABA825ADF799412ED9E2C86D7A0C\" , \"work\" : \"05bb28cd8acbe71d\" } } } } Optional \"contents\" Boolean, true by default. Disable contents for each block Optional \"json_block\" version 19.0+ Default \"false\". If \"true\", \"contents\" will contain a JSON subtree instead of a JSON string. Optional \"representatives\" Boolean, false by default. Returns list of votes representatives & its weights for each block Request: { \"action\" : \"confirmation_info\" , \"json_block\" : \"true\" , \"root\" : \"F8BA8CBE61C679231EB06FA03A0CD7CFBE68746396CBBA169BD9E12725682B44\" , \"representatives\" : \"true\" } Response: { \"announcements\" : \"5\" , \"last_winner\" : \"B94C505029F04BC057A0486ADA8BD07981B4A8736AE6581F2E98C6D18498146F\" , \"total_tally\" : \"51145880360792646375807054724596663794\" , \"blocks\" : { \"B94C505029F04BC057A0486ADA8BD07981B4A8736AE6581F2E98C6D18498146F\" : { \"tally\" : \"51145880360792646375807054724596663794\" , \"contents\" : { \"type\" : \"state\" , \"account\" : \"nano_3fihmbtuod33s4nrbqfczhk9zy9ddqimwjshzg4c3857es8c9631i5rg6h9p\" , \"previous\" : \"EE125B1B1D85D3C24636B3590E1642D9F21B166C0C6CD99C9C6087A1224A0C44\" , \"representative\" : \"nano_3o7uzba8b9e1wqu5ziwpruteyrs3scyqr761x7ke6w1xctohxfh5du75qgaj\" , \"balance\" : \"218195000000000000000000000000\" , \"link\" : \"0000000000000000000000000000000000000000000000000000000000000000\" , \"link_as_account\" : \"nano_1111111111111111111111111111111111111111111111111111hifc8npp\" , \"signature\" : \"B1BD285235C612C5A141FA61793D7C6C762D3F104A85102DED5FBD6B4514971C4D044ACD3EC8C06A9495D8E83B6941B54F8DABA825ADF799412ED9E2C86D7A0C\" , \"work\" : \"05bb28cd8acbe71d\" }, \"representatives\" : { \"nano_3pczxuorp48td8645bs3m6c3xotxd3idskrenmi65rbrga5zmkemzhwkaznh\" : \"12617828599372664613607727105312358589\" , \"nano_1stofnrxuz3cai7ze75o174bpm7scwj9jn3nxsn8ntzg784jf1gzn1jjdkou\" : \"5953738757270291536911559258663615240\" , ... \"nano_3i4n5n6c6xssapbdtkdoutm88c5zjmatc5tc77xyzdkpef8akid9errcpjnx\" : \"0\" } } } } confirmation_quorum \u00b6 version 16.0+ Returns information about node elections settings & observed network state: delta tally required to rollback block, percentage of online weight for delta, minimum online weight to confirm block, currently observed online total weight, known peers total weight Request: { \"action\" : \"confirmation_quorum\" } Response: { \"quorum_delta\" : \"41469707173777717318245825935516662250\" , \"online_weight_quorum_percent\" : \"50\" , \"online_weight_minimum\" : \"60000000000000000000000000000000000000\" , \"online_stake_total\" : \"82939414347555434636491651871033324568\" , \"peers_stake_total\" : \"69026910610720098597176027400951402360\" , \"peers_stake_required\" : \"60000000000000000000000000000000000000\" } Optional \"peer_details\" version 17.0+ Boolean, false by default. If true, add account/ip/rep weight for each peer considered in the summation of peers_stake_total . Response field \"peers_stake_required\" version 19.0+ The effective stake needed from directly connected peers for quorum. Per v19, this field is computed as max(quorum_delta, online_weight_minimum) . If peers_stake_total is lower than this value, the node will not mark blocks as confirmed. database_txn_tracker \u00b6 v19.0+ Debug purposes only This call is for internal diagnostics/debug purposes only. Do not rely on this interface being stable and do not use in a production system. Returns a list of open database transactions which are equal or greater than the min_read_time or min_write_time for reads and read-writes respectively. Request: { \"action\" : \"database_txn_tracker\" , \"min_read_time\" : \"1000\" , \"min_write_time\" : \"0\" } Response on Windows/Debug: { \"txn_tracking\" : [ { \"thread\" : \"Blck processing\" , // Which t hread held t he transa c t io n \"time_held_open\" : \"2\" , // Seco n ds t he transa c t io n has curre ntl y bee n held ope n f or \"write\" : \"true\" , // I f true i t is a wri te lock , o t herwise false . \"stacktrace\" : [ { \"name\" : \"nano::mdb_store::tx_begin_write\" , \"address\" : \"00007FF7142C5F86\" , \"source_file\" : \"c:\\\\users\\\\wesley\\\\documents\\\\raiblocks\\\\nano\\\\node\\\\lmdb.cpp\" , \"source_line\" : \"825\" }, { \"name\" : \"nano::block_processor::process_batch\" , \"address\" : \"00007FF714121EEA\" , \"source_file\" : \"c:\\\\users\\\\wesley\\\\documents\\\\raiblocks\\\\nano\\\\node\\\\blockprocessor.cpp\" , \"source_line\" : \"243\" }, { \"name\" : \"nano::block_processor::process_blocks\" , \"address\" : \"00007FF71411F8A6\" , \"source_file\" : \"c:\\\\users\\\\wesley\\\\documents\\\\raiblocks\\\\nano\\\\node\\\\blockprocessor.cpp\" , \"source_line\" : \"103\" }, ... ] } ... // o t her t hreads ] } delegators \u00b6 version 8.0+ Returns a list of pairs of delegator names given account a representative and its balance Request: { \"action\" : \"delegators\" , \"account\" : \"nano_1111111111111111111111111111111111111111111111111117353trpda\" } Response: { \"delegators\" : { \"nano_13bqhi1cdqq8yb9szneoc38qk899d58i5rcrgdk5mkdm86hekpoez3zxw5sd\" : \"500000000000000000000000000000000000\" , \"nano_17k6ug685154an8gri9whhe5kb5z1mf5w6y39gokc1657sh95fegm8ht1zpn\" : \"961647970820730000000000000000000000\" } } delegators_count \u00b6 version 8.0+ Get number of delegators for a specific representative account Request: { \"action\" : \"delegators_count\" , \"account\" : \"nano_1111111111111111111111111111111111111111111111111117353trpda\" } Response: { \"count\" : \"2\" } deterministic_key \u00b6 Derive deterministic keypair from seed based on index Request: { \"action\" : \"deterministic_key\" , \"seed\" : \"0000000000000000000000000000000000000000000000000000000000000000\" , \"index\" : \"0\" } Response: { \"private\" : \"9F0E444C69F77A49BD0BE89DB92C38FE713E0963165CCA12FAF5712D7657120F\" , \"public\" : \"C008B814A7D269A1FA3C6528B19201A24D797912DB9996FF02A1FF356E45552B\" , \"account\" : \"nano_3i1aq1cchnmbn9x5rsbap8b15akfh7wj7pwskuzi7ahz8oq6cobd99d4r3b7\" } epoch_upgrade \u00b6 enable_control required, version 20.0+ Debug purposes only This call is for internal diagnostics/debug purposes only. Do not rely on this interface being stable and do not use in a production system. Upgrade network to new epoch with epoch signer private key Dangerous RPC calls controlled by enable_control This RPC command/option requires enable_control to be enabled within the RPC config file. Enabling this means that anyone with access to the RPC port could potentially access wallet funds , stop the node from running and take other dangerous actions. Use caution when enabling this option, especially with external RPC access available. For more details see the Node Security page . Request: { \"action\" : \"epoch_upgrade\" , \"epoch\" : \"1\" , \"key\" : \"0000000000000000000000000000000000000000000000000000000000000000\" } Response: { \"started\" : \"1\" } Optional \"count\" Number. Determines limit of number of accounts to upgrade. Optional \"threads\" version 21.0+ Number. Determines limit of work threads to use for concurrent upgrade processes (useful with multiple work peers or high work peer latency). frontier_count \u00b6 Reports the number of accounts in the ledger Request: { \"action\" : \"frontier_count\" } Response: { \"count\" : \"920471\" } frontiers \u00b6 Returns a list of pairs of account and block hash representing the head block starting at account up to count Request: { \"action\" : \"frontiers\" , \"account\" : \"nano_1111111111111111111111111111111111111111111111111111hifc8npp\" , \"count\" : \"1\" } Response: { \"frontiers\" : { \"nano_3e3j5tkog48pnny9dmfzj1r16pg8t1e76dz5tmac6iq689wyjfpi00000000\" : \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\" } } keepalive \u00b6 enable_control required Tells the node to send a keepalive packet to address : port Dangerous RPC calls controlled by enable_control This RPC command/option requires enable_control to be enabled within the RPC config file. Enabling this means that anyone with access to the RPC port could potentially access wallet funds , stop the node from running and take other dangerous actions. Use caution when enabling this option, especially with external RPC access available. For more details see the Node Security page . Request: { \"action\" : \"keepalive\" , \"address\" : \"::ffff:192.169.0.1\" , \"port\" : \"1024\" } Response: { \"started\" : \"1\" } key_create \u00b6 Generates an adhoc random keypair Request: { \"action\" : \"key_create\" } Response: { \"private\" : \"781186FB9EF17DB6E3D1056550D9FAE5D5BBADA6A6BC370E4CBB938B1DC71DA3\" , \"public\" : \"3068BB1CA04525BB0E416C485FE6A67FD52540227D267CC8B6E8DA958A7FA039\" , \"account\" : \"nano_1e5aqegc1jb7qe964u4adzmcezyo6o146zb8hm6dft8tkp79za3sxwjym5rx\" } key_expand \u00b6 Derive public key and account number from private key Request: { \"action\" : \"key_expand\" , \"key\" : \"781186FB9EF17DB6E3D1056550D9FAE5D5BBADA6A6BC370E4CBB938B1DC71DA3\" } Response: { \"private\" : \"781186FB9EF17DB6E3D1056550D9FAE5D5BBADA6A6BC370E4CBB938B1DC71DA3\" , \"public\" : \"3068BB1CA04525BB0E416C485FE6A67FD52540227D267CC8B6E8DA958A7FA039\" , \"account\" : \"nano_1e5aqegc1jb7qe964u4adzmcezyo6o146zb8hm6dft8tkp79za3sxwjym5rx\" } ledger \u00b6 enable_control required, version 9.0+ Returns frontier, open block, change representative block, balance, last modified timestamp from local database & block count starting at account up to count Dangerous RPC calls controlled by enable_control This RPC command/option requires enable_control to be enabled within the RPC config file. Enabling this means that anyone with access to the RPC port could potentially access wallet funds , stop the node from running and take other dangerous actions. Use caution when enabling this option, especially with external RPC access available. For more details see the Node Security page . Includes unconfirmed blocks This call may return results that include unconfirmed blocks, so it should not be used in any processes or integrations requiring only details from blocks confirmed by the network. Request: { \"action\" : \"ledger\" , \"account\" : \"nano_1111111111111111111111111111111111111111111111111111hifc8npp\" , \"count\" : \"1\" } Response: { \"accounts\" : { \"nano_11119gbh8hb4hj1duf7fdtfyf5s75okzxdgupgpgm1bj78ex3kgy7frt3s9n\" : { \"frontier\" : \"E71AF3E9DD86BBD8B4620EFA63E065B34D358CFC091ACB4E103B965F95783321\" , \"open_block\" : \"643B77F1ECEFBDBE1CC909872964C1DBBE23A6149BD3CEF2B50B76044659B60F\" , \"representative_block\" : \"643B77F1ECEFBDBE1CC909872964C1DBBE23A6149BD3CEF2B50B76044659B60F\" , \"balance\" : \"0\" , \"modified_timestamp\" : \"1511476234\" , \"block_count\" : \"2\" } } } Optional \"representative\", \"weight\", \"pending\" Booleans, false by default. Additionally returns representative, voting weight, pending balance for each account Request: { \"action\" : \"ledger\" , \"account\" : \"nano_1111111111111111111111111111111111111111111111111111hifc8npp\" , \"count\" : \"1\" , \"representative\" : \"true\" , \"weight\" : \"true\" , \"pending\" : \"true\" } Response: { \"accounts\" : { \"nano_11119gbh8hb4hj1duf7fdtfyf5s75okzxdgupgpgm1bj78ex3kgy7frt3s9n\" : { \"frontier\" : \"E71AF3E9DD86BBD8B4620EFA63E065B34D358CFC091ACB4E103B965F95783321\" , \"open_block\" : \"643B77F1ECEFBDBE1CC909872964C1DBBE23A6149BD3CEF2B50B76044659B60F\" , \"representative_block\" : \"643B77F1ECEFBDBE1CC909872964C1DBBE23A6149BD3CEF2B50B76044659B60F\" , \"balance\" : \"0\" , \"modified_timestamp\" : \"1511476234\" , \"block_count\" : \"2\" , \"representative\" : \"nano_1anrzcuwe64rwxzcco8dkhpyxpi8kd7zsjc1oeimpc3ppca4mrjtwnqposrs\" , \"weight\" : \"0\" , \"pending\" : \"0\" } } } Optional \"modified_since\" version 11.0+ UNIX timestamp (number), 0 by default. Return only accounts modified in local database after specific timestamp Optional \"sorting\" Boolean, false by default. Additional sorting accounts in descending order NOTE: The \"count\" option is ignored if \"sorting\" is specified Optional \"threshold\" version 19.0+ Number (128 bit, decimal), default 0. Return only accounts with balance above threshold . If pending is also given, the number compared with the threshold is the sum of account balance and pending balance. node_id \u00b6 enable_control required, version 17.0+ Debug purposes only This call is for internal diagnostics/debug purposes only. Do not rely on this interface being stable and do not use in a production system. Derive private key, public key and node ID number with checksum (similar to account representation). \"as_account\" field is deprecated version 20.0 will generate the node_id with node_ prefix, earlier versions will generate with nano_ prefix Dangerous RPC calls controlled by enable_control This RPC command/option requires enable_control to be enabled within the RPC config file. Enabling this means that anyone with access to the RPC port could potentially access wallet funds , stop the node from running and take other dangerous actions. Use caution when enabling this option, especially with external RPC access available. For more details see the Node Security page . Request: { \"action\" : \"node_id\" } Response: { \"private\" : \"2AD75C9DC20EA497E41722290C4DC966ECC4D6C75CAA4E447961F918FD73D8C7\" , \"public\" : \"78B11E1777B8E7DF9090004376C3EDE008E84680A497C0805F68CA5928626E1C\" , \"as_account\" : \"nano_1y7j5rdqhg99uyab1145gu3yur1ax35a3b6qr417yt8cd6n86uiw3d4whty3\" , \"node_id\" : \"node_1y7j5rdqhg99uyab1145gu3yur1ax35a3b6qr417yt8cd6n86uiw3d4whty3\" } node_id_delete \u00b6 enable_control required, version 17.0+ Debug purposes only This call is for internal diagnostics/debug purposes only. Do not rely on this interface being stable and do not use in a production system. Removing node ID (restart required to take effect) Dangerous RPC calls controlled by enable_control This RPC command/option requires enable_control to be enabled within the RPC config file. Enabling this means that anyone with access to the RPC port could potentially access wallet funds , stop the node from running and take other dangerous actions. Use caution when enabling this option, especially with external RPC access available. For more details see the Node Security page . Request: { \"action\" : \"node_id_delete\" } Response: { \"deprecated\" : \"1\" } peers \u00b6 Returns a list of pairs of online peer IPv6:port and its node protocol network version Request: { \"action\" : \"peers\" } Response version 8.0+: { \"peers\" : { \"[::ffff:172.17.0.1]:32841\" : \"16\" } } Response before version 8.0: { \"peers\" : [ \"[::ffff:172.17.0.1]:32841\" ] } Optional \"peer_details\" version 18.0+ Boolean, false by default. Returns a list of peers IPv6:port with its node protocol network version and node ID. The node ID is random and is not a Nano address. type returned in version 19.0+ as either tcp (preferred) or udp (fallback) used for peering with that node. version 20.0 will generate the node_id with node_ prefix, earlier versions will generate with nano_ prefix Response: { \"peers\" : { \"[::ffff:172.17.0.1]:32841\" : { \"protocol_version\" : \"16\" , \"node_id\" : \"node_1y7j5rdqhg99uyab1145gu3yur1ax35a3b6qr417yt8cd6n86uiw3d4whty3\" , \"type\" : \"udp\" } } } pending \u00b6 Returns a list of block hashes which have not yet been received by this account. Optional include_only_confirmed recommended By default this will return blocks not in active elections but unconfirmed (e.g., block was received but node was restarted, election was dropped, new ledger with reset confirmation height). To avoid potential issues related to these situations setting the include_only_confirmed = true is recommended for most use cases. Request: { \"action\" : \"pending\" , \"account\" : \"nano_1111111111111111111111111111111111111111111111111117353trpda\" , \"count\" : \"1\" } Response: { \"blocks\" : [ \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\" ] } Optional \"count\" Number. Determines limit of number of blocks to return. Optional \"threshold\" version 8.0+ Number (128 bit, decimal). Returns a list of pending block hashes with amount more or equal to threshold Request: { \"action\" : \"pending\" , \"account\" : \"nano_1111111111111111111111111111111111111111111111111117353trpda\" , \"count\" : \"1\" , \"threshold\" : \"1000000000000000000000000\" } Response: { \"blocks\" : { \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\" : \"6000000000000000000000000000000\" } } Optional \"source\" version 9.0+ Boolean, false by default. Returns a list of pending block hashes with amount and source accounts Request: { \"action\" : \"pending\" , \"account\" : \"nano_1111111111111111111111111111111111111111111111111117353trpda\" , \"count\" : \"1\" , \"source\" : \"true\" } Response: { \"blocks\" : { \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\" : { \"amount\" : \"6000000000000000000000000000000\" , \"source\" : \"nano_3dcfozsmekr1tr9skf1oa5wbgmxt81qepfdnt7zicq5x3hk65fg4fqj58mbr\" } } } Optional \"include_active\" version 15.0+ Boolean, false by default. Include active blocks without finished confirmations Request: { \"action\" : \"pending\" , \"account\" : \"nano_1111111111111111111111111111111111111111111111111117353trpda\" , \"count\" : \"1\" , \"include_active\" : \"true\" } Optional \"min_version\" version 15.0+ Boolean, false by default. Returns the minimum version (epoch) of a block which can pocket this pending block. Optional \"sorting\" Boolean, false by default. Additionally sorts the blocks by their amounts in descending order. version 22.0+ If used with \"count\" returns the absolute sorted values. version 19.0+ If used with \"count\" only sorts relative to the first pending entries found up to count so not necessarily the ones with the largest pending balance. Optional \"include_only_confirmed\" version 19.0+ Boolean, false by default. Only returns block which have their confirmation height set or are undergoing confirmation height processing. pending_exists \u00b6 version 8.0+ Check whether block is pending by hash Request: { \"action\" : \"pending_exists\" , \"hash\" : \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\" } Response: { \"exists\" : \"1\" } Optional \"include_active\" version 15.0+ Boolean, false by default. Include active blocks without finished confirmations Request: { \"action\" : \"pending_exists\" , \"hash\" : \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\" , \"include_active\" : \"true\" } Optional \"include_only_confirmed\" version 19.0+ Boolean, false by default. Only returns hashes which have their confirmation height set or are undergoing confirmation height processing. process \u00b6 Publish block to the network. Using the optional json_block is recommended since v19.0. Since v20.0, blocks are watched for confirmation by default (see optional watch_work ). Including subtype in process RPC calls highly recommended In order to avoid potential incorrect sends including the optional subtype parameter on all process RPC calls is highly recommended . In the next version of the RPC this parameter will be required. Request: { \"action\" : \"process\" , \"json_block\" : \"true\" , \"subtype\" : \"send\" , \"block\" : { \"type\" : \"state\" , \"account\" : \"nano_1qato4k7z3spc8gq1zyd8xeqfbzsoxwo36a45ozbrxcatut7up8ohyardu1z\" , \"previous\" : \"6CDDA48608C7843A0AC1122BDD46D9E20E21190986B19EAC23E7F33F2E6A6766\" , \"representative\" : \"nano_3pczxuorp48td8645bs3m6c3xotxd3idskrenmi65rbrga5zmkemzhwkaznh\" , \"balance\" : \"40200000001000000000000000000000000\" , \"link\" : \"87434F8041869A01C8F6F263B87972D7BA443A72E0A97D7A3FD0CCC2358FD6F9\" , \"link_as_account\" : \"nano_33t5by1653nt196hfwm5q3wq7oxtaix97r7bhox5zn8eratrzoqsny49ftsd\" , \"signature\" : \"A5DB164F6B81648F914E49CAB533900C389FAAD64FBB24F6902F9261312B29F730D07E9BCCD21D918301419B4E05B181637CF8419ED4DCBF8EF2539EB2467F07\" , \"work\" : \"000bc55b014e807d\" } } Response: { \"hash\" : \"E2FB233EF4554077A7BF1AA85851D5BF0B36965D2B0FB504B2BC778AB89917D3\" } Optional \"force\" version 13.1+ Boolean, false by default. Manually forcing fork resolution if processed block is not accepted as fork Optional \"subtype\" version 18.0+ String, empty by default. Additional check for state blocks subtype, i.e. prevent accidental sending to incorrect accounts instead of receiving pending blocks. Options: send - account balance is reduced receive - account balance is increased open - first block on account with account balance initially set higher than 0 change - account balance is unchanged, representative field value changed to valid public address epoch - block signed with epoch signer private key (does not allow balance or representative changes) Optional \"json_block\" version 19.0+ Default \"false\". If \"true\", \"block\" must contain a JSON subtree instead of a JSON string. Optional \"watch_work\" version 20.0+ Default \"true\". If \"true\", block will be placed on watch for confirmation, with equivalent functionality to in-wallet transactions using send , receive and account_representative_set , including republishing and rework if confirmation is delayed (default is 5 seconds, set by work_watcher_period config entry) and if active_difficulty is higher than the block's PoW difficulty. representatives \u00b6 Returns a list of pairs of representative and its voting weight Request: { \"action\" : \"representatives\" } Response: { \"representatives\" : { \"nano_1111111111111111111111111111111111111111111111111117353trpda\" : \"3822372327060170000000000000000000000\" , \"nano_1111111111111111111111111111111111111111111111111awsq94gtecn\" : \"30999999999999999999999999000000\" , \"nano_114nk4rwjctu6n6tr6g6ps61g1w3hdpjxfas4xj1tq6i8jyomc5d858xr1xi\" : \"0\" } } Optional \"count\" version 9.0+ Number. Returns a list of pairs of representative and its voting weight up to count Optional \"sorting\" version 9.0+ Boolean, false by default. Additional sorting representatives in descending order NOTE: The \"count\" option is ignored if \"sorting\" is specified representatives_online \u00b6 version 18.0+ Returns a list of online representative accounts that have voted recently Request: { \"action\" : \"representatives_online\" } Response: { \"representatives\" : [ \"nano_1111111111111111111111111111111111111111111111111117353trpda\" , \"nano_1111111111111111111111111111111111111111111111111awsq94gtecn\" , \"nano_114nk4rwjctu6n6tr6g6ps61g1w3hdpjxfas4xj1tq6i8jyomc5d858xr1xi\" ] } versions 11.2\u201317.1 Returns a list of pairs of online representative accounts that have voted recently and empty strings Response: { \"representatives\" : { \"nano_1111111111111111111111111111111111111111111111111117353trpda\" : \"\" , \"nano_1111111111111111111111111111111111111111111111111awsq94gtecn\" : \"\" , \"nano_114nk4rwjctu6n6tr6g6ps61g1w3hdpjxfas4xj1tq6i8jyomc5d858xr1xi\" : \"\" } } Optional \"weight\" version 17.0+ Boolean, false by default. Returns voting weight for each representative. Response: { \"representatives\" : { \"nano_114nk4rwjctu6n6tr6g6ps61g1w3hdpjxfas4xj1tq6i8jyomc5d858xr1xi\" : { \"weight\" : \"150462654614686936429917024683496890\" } } } republish \u00b6 Rebroadcast blocks starting at hash to the network Request: { \"action\" : \"republish\" , \"hash\" : \"991CF190094C00F0B68E2E5F75F6BEE95A2E0BD93CEAA4A6734DB9F19B728948\" } Response: { \"success\" : \"\" , \"blocks\" : [ \"991CF190094C00F0B68E2E5F75F6BEE95A2E0BD93CEAA4A6734DB9F19B728948\" , \"A170D51B94E00371ACE76E35AC81DC9405D5D04D4CEBC399AEACE07AE05DD293\" ] } Optional \"sources\" version 8.0+ Boolean, false by default. Additionally rebroadcast source chain blocks for receive/open up to sources depth Request: { \"action\" : \"republish\" , \"hash\" : \"90D0C16AC92DD35814E84BFBCC739A039615D0A42A76EF44ADAEF1D99E9F8A35\" , \"count\" : \"1\" , \"sources\" : \"2\" } Response: { \"blocks\" : [ \"991CF190094C00F0B68E2E5F75F6BEE95A2E0BD93CEAA4A6734DB9F19B728948\" , \"A170D51B94E00371ACE76E35AC81DC9405D5D04D4CEBC399AEACE07AE05DD293\" , \"90D0C16AC92DD35814E84BFBCC739A039615D0A42A76EF44ADAEF1D99E9F8A35\" ] } Optional \"destinations\" version 8.0+ Boolean, false by default. Additionally rebroadcast destination chain blocks from receive up to destinations depth Request: { \"action\" : \"republish\" , \"hash\" : \"A170D51B94E00371ACE76E35AC81DC9405D5D04D4CEBC399AEACE07AE05DD293\" , \"count\" : \"1\" , \"destinations\" : \"2\" } Response: { \"blocks\" : [ \"A170D51B94E00371ACE76E35AC81DC9405D5D04D4CEBC399AEACE07AE05DD293\" , \"90D0C16AC92DD35814E84BFBCC739A039615D0A42A76EF44ADAEF1D99E9F8A35\" , \"18563C814A54535B7C12BF76A0E23291BA3769536634AB90AD0305776A533E8E\" ] } sign \u00b6 version 18.0+ Signing provided block with private key or key of account from wallet . Using the optional json_block is recommended since v19.0. Request with private key: { \"action\" : \"sign\" , \"json_block\" : \"true\" , \"key\" : \"1D3759BB2CA187A66875D3B8497624159A576FD315E07F702B99B92BC59FC14A\" , \"block\" : { \"type\" : \"state\" , \"account\" : \"nano_1qato4k7z3spc8gq1zyd8xeqfbzsoxwo36a45ozbrxcatut7up8ohyardu1z\" , \"previous\" : \"6CDDA48608C7843A0AC1122BDD46D9E20E21190986B19EAC23E7F33F2E6A6766\" , \"representative\" : \"nano_3pczxuorp48td8645bs3m6c3xotxd3idskrenmi65rbrga5zmkemzhwkaznh\" , \"balance\" : \"40200000001000000000000000000000000\" , \"link\" : \"87434F8041869A01C8F6F263B87972D7BA443A72E0A97D7A3FD0CCC2358FD6F9\" , \"link_as_account\" : \"nano_33t5by1653nt196hfwm5q3wq7oxtaix97r7bhox5zn8eratrzoqsny49ftsd\" , \"signature\" : \"A5DB164F6B81648F914E49CAB533900C389FAAD64FBB24F6902F9261312B29F730D07E9BCCD21D918301419B4E05B181637CF8419ED4DCBF8EF2539EB2467F07\" , \"work\" : \"000bc55b014e807d\" } } Request with account from wallet: { \"action\" : \"sign\" , \"json_block\" : \"true\" , \"wallet\" : \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\" , \"account\" : \"nano_18ky5chy5ws89oi46ki4zjy6x5ezpmj98zg6icwke9bmuy99nosieyqf8c1h\" , \"block\" : { \"type\" : \"state\" , \"account\" : \"nano_1qato4k7z3spc8gq1zyd8xeqfbzsoxwo36a45ozbrxcatut7up8ohyardu1z\" , \"previous\" : \"6CDDA48608C7843A0AC1122BDD46D9E20E21190986B19EAC23E7F33F2E6A6766\" , \"representative\" : \"nano_3pczxuorp48td8645bs3m6c3xotxd3idskrenmi65rbrga5zmkemzhwkaznh\" , \"balance\" : \"40200000001000000000000000000000000\" , \"link\" : \"87434F8041869A01C8F6F263B87972D7BA443A72E0A97D7A3FD0CCC2358FD6F9\" , \"link_as_account\" : \"nano_33t5by1653nt196hfwm5q3wq7oxtaix97r7bhox5zn8eratrzoqsny49ftsd\" , \"signature\" : \"A5DB164F6B81648F914E49CAB533900C389FAAD64FBB24F6902F9261312B29F730D07E9BCCD21D918301419B4E05B181637CF8419ED4DCBF8EF2539EB2467F07\" , \"work\" : \"000bc55b014e807d\" } } Response: { \"signature\" : \"2A71F3877033F5966735F260E906BFCB7FA82CDD543BCD1224F180F85A96FC26CB3F0E4180E662332A0DFE4EE6A0F798A71C401011E635604E532383EC08C70D\" , \"block\" : { \"type\" : \"state\" , \"account\" : \"nano_1qato4k7z3spc8gq1zyd8xeqfbzsoxwo36a45ozbrxcatut7up8ohyardu1z\" , \"previous\" : \"6CDDA48608C7843A0AC1122BDD46D9E20E21190986B19EAC23E7F33F2E6A6766\" , \"representative\" : \"nano_3pczxuorp48td8645bs3m6c3xotxd3idskrenmi65rbrga5zmkemzhwkaznh\" , \"balance\" : \"40200000001000000000000000000000000\" , \"link\" : \"87434F8041869A01C8F6F263B87972D7BA443A72E0A97D7A3FD0CCC2358FD6F9\" , \"link_as_account\" : \"nano_33t5by1653nt196hfwm5q3wq7oxtaix97r7bhox5zn8eratrzoqsny49ftsd\" , \"signature\" : \"2A71F3877033F5966735F260E906BFCB7FA82CDD543BCD1224F180F85A96FC26CB3F0E4180E662332A0DFE4EE6A0F798A71C401011E635604E532383EC08C70D\" , \"work\" : \"000bc55b014e807d\" } } Optional \"json_block\" version 19.0+ Default \"false\". If \"true\", the input \"block\" must contain a JSON subtree instead of a JSON string. In addition, the response block will be a JSON subtree. Optional sign block hash Requires configuration changes. Set \"rpc.enable_sign_hash\" to \"true\" Request: { \"action\" : \"sign\" , \"hash\" : \"E2FB233EF4554077A7BF1AA85851D5BF0B36965D2B0FB504B2BC778AB89917D3\" } Response: { \"signature\" : \"2A71F3877033F5966735F260E906BFCB7FA82CDD543BCD1224F180F85A96FC26CB3F0E4180E662332A0DFE4EE6A0F798A71C401011E635604E532383EC08C70D\" } stats \u00b6 version 12.2+ For configuration and other details, please see Statistics from RPC Request counters: { \"action\" : \"stats\" , \"type\" : \"counters\" } Counters response: { \"type\" : \"counters\" , \"created\" : \"2018.03.29 01:46:36\" , \"entries\" : [ { \"time\" : \"01:46:36\" , \"type\" : \"traffic_tcp\" , \"detail\" : \"all\" , \"dir\" : \"in\" , \"value\" : \"3122792\" }, { \"time\" : \"01:46:36\" , \"type\" : \"traffic_tcp\" , \"detail\" : \"all\" , \"dir\" : \"out\" , \"value\" : \"203184\" } ... ] } version 18.0+ also returns \"stat_duration_seconds\": the number of seconds since startup or since the last \"stats_clear\" call Request samples: { \"action\" : \"stats\" , \"type\" : \"samples\" } Samples response: { \"type\" : \"samples\" , \"created\" : \"2018.03.29 01:47:08\" , \"entries\" : [ { \"time\" : \"01:47:04\" , \"type\" : \"traffic_tcp\" , \"detail\" : \"all\" , \"dir\" : \"in\" , \"value\" : \"59480\" }, { \"time\" : \"01:47:05\" , \"type\" : \"traffic_tcp\" , \"detail\" : \"all\" , \"dir\" : \"in\" , \"value\" : \"44496\" } ... ] } version 18.0+ NOTE: This call is for debug purposes only and is unstable as returned objects may be frequently changed. Request objects: { \"action\" : \"stats\" , \"type\" : \"objects\" } Objects response: { \"node\" : { \"ledger\" : { \"bootstrap_weights\" : { \"count\" : \"125\" , \"size\" : \"7000\" } }, \"peers\" : { \"peers\" : { \"count\" : \"38\" , \"size\" : \"7296\" }, \"attempts\" : { \"count\" : \"95\" , \"size\" : \"3800\" }, }, ... } } version 22.0+ NOTE: This call is for debug purposes only and is unstable as returned objects may be frequently changed and will be different depending on the ledger backend. Request database: { \"action\" : \"stats\" , \"type\" : \"database\" } Database response: LMDB: { \"branch_pages\" : \"0\" , \"depth\" : \"1\" , \"entries\" : \"11\" , \"leaf_pages\" : \"1\" , \"overflow_pages\" : \"0\" , \"page_size\" : \"4096\" } RocksDB: { \"cur-size-all-mem-tables\" : \"74063072\" , \"size-all-mem-tables\" : \"487744504\" , \"estimate-table-readers-mem\" : \"113431016\" , \"estimate-live-data-size\" : \"17756425993\" , \"compaction-pending\" : \"0\" , \"estimate-num-keys\" : \"81835964\" , \"estimate-pending-compaction-bytes\" : \"0\" , \"total-sst-files-size\" : \"20350606013\" , \"block-cache-capacity\" : \"318767104\" , \"block-cache-usage\" : \"150310696\" } stats_clear \u00b6 version 18.0+ Clears all collected statistics. The \"stat_duration_seconds\" value in the \"stats\" action is also reset. Request: { \"action\" : \"stats_clear\" } Response: { \"success\" : \"\" } stop \u00b6 enable_control required Method to safely shutdown node Dangerous RPC calls controlled by enable_control This RPC command/option requires enable_control to be enabled within the RPC config file. Enabling this means that anyone with access to the RPC port could potentially access wallet funds , stop the node from running and take other dangerous actions. Use caution when enabling this option, especially with external RPC access available. For more details see the Node Security page . Request: { \"action\" : \"stop\" } Response: { \"success\" : \"\" } successors \u00b6 Returns a list of block hashes in the account chain starting at block up to count (direction from open block up to frontier, from older blocks to newer). Will list all blocks up to frontier (latest block) of this chain when count is set to \"-1\". The requested block hash is included in the answer. Request: { \"action\" : \"successors\" , \"block\" : \"991CF190094C00F0B68E2E5F75F6BEE95A2E0BD93CEAA4A6734DB9F19B728948\" , \"count\" : \"1\" } Response: { \"blocks\" : [ \"991CF190094C00F0B68E2E5F75F6BEE95A2E0BD93CEAA4A6734DB9F19B728948\" ] } Optional \"offset\" version 18.0+ Number, 0 by default. Return the account chain block hashes offset by the specified number of blocks Optional \"reverse\" version 18.0+ Boolean, false by default. Returns a consecutive list of block hashes in the account chain starting at block back to count (direction from frontier back to open block, from newer blocks to older). Equal to chain telemetry \u00b6 version 21.0+ Return metrics from other nodes on the network. By default, returns a summarized view of the whole network. See below for details on obtaining local telemetry data. Networking - node telemetry contains more detailed information on the protocol implementation of telemetry. Request: { \"action\" : \"telemetry\" } Response: { \"block_count\" : \"5777903\" , \"cemented_count\" : \"688819\" , \"unchecked_count\" : \"443468\" , \"account_count\" : \"620750\" , \"bandwidth_cap\" : \"1572864\" , \"peer_count\" : \"32\" , \"protocol_version\" : \"18\" , \"uptime\" : \"556896\" , \"genesis_block\" : \"F824C697633FAB78B703D75189B7A7E18DA438A2ED5FFE7495F02F681CD56D41\" , \"major_version\" : \"21\" , \"minor_version\" : \"0\" , \"patch_version\" : \"0\" , \"pre_release_version\" : \"0\" , \"maker\" : \"0\" , \"timestamp\" : \"1587055945990\" , \"active_difficulty\" : \"ffffffcdbf40aa45\" } This contains a summarized view of the network with 10% of lower/upper bound results removed to reduce the effect of outliers. Returned values are calculated as follows: Field Name Response details block_count average count of blocks in ledger (including unconfirmed) cemented_count average count of blocks cemented in ledger (only confirmed) unchecked_count average count of unchecked blocks account_count average count of accounts in ledger bandwidth_cap 0 = unlimited; the mode is chosen if there is more than 1 common result otherwise the results are averaged (excluding 0 ) peer_count average count of peers nodes are connected to *_version mode (most common) of (protocol, major, minor, patch, pre_release) versions uptime average number of seconds since the UTC epoch at the point where the response is sent from the peer genesis_block mode (most common) of genesis block hashes maker mode (most common), meant for third party node software implementing the protocol so that it can be distinguished, 0 = Nano Foundation, 1 = Nano Foundation pruned node timestamp number of milliseconds since the UTC epoch at the point where the response is sent from the peer active_difficulty average of the current network difficulty, see active_difficulty \"network_current\" This only returns values which have been cached by the ongoing polling of peer metric data. Each response is cached for 60 seconds on the main network and 15 seconds on beta; a few additional seconds are added on for response delays. Optional \"raw\" When setting raw to true metrics from all nodes are displayed. It additionally contains signature , node_id , address and port from each peer. Request: { \"action\" : \"telemetry\" , \"raw\" : \"true\" } Response: { \"metrics\" : [ { \"block_count\" : \"5777903\" , ... \"node_id\" : \"node_1cmi8difuruopgzpnb4ybrnnj5rproxwuwe5mad7ucbsekakiwn37qqg1zo5\" , \"signature\" : \"5F8DEE5F895D53E122FDEB4B1B4118A41F9DDB818C6B299B09DF59131AF9F201BB7057769423F6B0C868B57509177B54D5D2C731405FE607527F5E2B6B2E290F\" , \"address\" : \"::ffff:152.89.106.89\" , \"port\" : \"54000\" }, { \"block_count\" : \"5777902\" , ... \"node_id\" : \"node_3ipxdjrha3rfg9h3spiz5jkprw8kdj7bph9fir51kf6pmryzznsyhakqznk3\" , \"signature\" : \"D691B855D9EC70EA6320DE609EB379EB706845433E034AD22721E8F91BF3A26156F40CCB2E98653F1E63D4CE5F10F530A835DE1B154D1213464E3B9BB9BE4908\" , \"address\" : \"::ffff:95.216.205.215\" , \"port\" : \"54006\" } ... ] } Optional \"address\" & \"port\" Get metrics from a specific peer. It accepts both ipv4 and ipv6 addresses { \"action\" : \"telemetry\" , \"address\" : \"246.125.123.456\" , \"port\" : \"7075\" } Requesting telemetry data from the local node Metrics for the local node can be requested using the peering port and any loopback address 127.0.0.1 , ::1 or [::1] validate_account_number \u00b6 Check whether account is a valid account number using checksum Request: { \"action\" : \"validate_account_number\" , \"account\" : \"nano_1111111111111111111111111111111111111111111111111117353trpda\" } Response: { \"valid\" : \"1\" } version \u00b6 Returns version information for RPC, Store, Protocol (network), Node (Major & Minor version). Since version 20.0 also returns the Network label and identifier (hash of the genesis open block), and Build Info. Since version 21.0 also returns Database backend information. RPC Version always returns \"1\" as of 01/11/2018 Request: { \"action\" : \"version\" } Response: { \"rpc_version\" : \"1\" , \"store_version\" : \"14\" , \"protocol_version\" : \"17\" , \"node_vendor\" : \"Nano 20.0\" , \"store_vendor\" : \"LMDB 0.9.23\" , // si n ce V 21.0 \"network\" : \"live\" , // si n ce v 20.0 \"network_identifier\" : \"991CF190094C00F0B68E2E5F75F6BEE95A2E0BD93CEAA4A6734DB9F19B728948\" , // si n ce v 20.0 \"build_info\" : \"Build Info <git hash> \\\"<compiler> version \\\" \\\"<compiler version string>\\\" \\\"BOOST <boost version>\\\" BUILT \\\"<build date>\\\"\" // si n ce v 20.0 } unchecked \u00b6 version 8.0+ Returns a list of pairs of unchecked block hashes and their json representation up to count . Using the optional json_block is recommended since v20.0. Request: { \"action\" : \"unchecked\" , \"json_block\" : \"true\" , \"count\" : \"1\" , } Response: { \"blocks\" : { \"87434F8041869A01C8F6F263B87972D7BA443A72E0A97D7A3FD0CCC2358FD6F9\" : { \"type\" : \"state\" , \"account\" : \"nano_1ipx847tk8o46pwxt5qjdbncjqcbwcc1rrmqnkztrfjy5k7z4imsrata9est\" , \"previous\" : \"CE898C131AAEE25E05362F247760F8A3ACF34A9796A5AE0D9204E86B0637965E\" , \"representative\" : \"nano_1stofnrxuz3cai7ze75o174bpm7scwj9jn3nxsn8ntzg784jf1gzn1jjdkou\" , \"balance\" : \"5606157000000000000000000000000000000\" , \"link\" : \"5D1AA8A45F8736519D707FCB375976A7F9AF795091021D7E9C7548D6F45DD8D5\" , \"link_as_account\" : \"nano_1qato4k7z3spc8gq1zyd8xeqfbzsoxwo36a45ozbrxcatut7up8ohyardu1z\" , \"signature\" : \"82D41BC16F313E4B2243D14DFFA2FB04679C540C2095FEE7EAE0F2F26880AD56DD48D87A7CC5DD760C5B2D76EE2C205506AA557BF00B60D8DEE312EC7343A501\" , \"work\" : \"8a142e07a10996d5\" } } } unchecked_clear \u00b6 enable_control required, version 8.0+ Clear unchecked synchronizing blocks Dangerous RPC calls controlled by enable_control This RPC command/option requires enable_control to be enabled within the RPC config file. Enabling this means that anyone with access to the RPC port could potentially access wallet funds , stop the node from running and take other dangerous actions. Use caution when enabling this option, especially with external RPC access available. For more details see the Node Security page . Request: { \"action\" : \"unchecked_clear\" } Response: { \"success\" : \"\" } unchecked_get \u00b6 version 8.0+ Retrieves a json representation of unchecked synchronizing block by hash . Using the optional json_block is recommended since v19.0. Request: { \"action\" : \"unchecked_get\" , \"json_block\" : \"true\" , \"hash\" : \"19BF0C268C2D9AED1A8C02E40961B67EA56B1681DE274CD0C50F3DD972F0655C\" } Response: { \"modified_timestamp\" : \"1565856525\" , \"contents\" : { \"type\" : \"state\" , \"account\" : \"nano_1hmqzugsmsn4jxtzo5yrm4rsysftkh9343363hctgrjch1984d8ey9zoyqex\" , \"previous\" : \"009C587914611E83EE7F75BD9C000C430C720D0364D032E84F37678D7D012911\" , \"representative\" : \"nano_1stofnrxuz3cai7ze75o174bpm7scwj9jn3nxsn8ntzg784jf1gzn1jjdkou\" , \"balance\" : \"189012679592109992600249228\" , \"link\" : \"0000000000000000000000000000000000000000000000000000000000000000\" , \"link_as_account\" : \"nano_1111111111111111111111111111111111111111111111111111hifc8npp\" , \"signature\" : \"845C8660750895843C013CE33E31B80EF0A7A69E52DDAF74A5F1BDFAA9A52E4D9EA2C3BE1AB0BD5790FCC1AD9B7A3D2F4B44EECE4279A8184D414A30A1B4620F\" , \"work\" : \"0dfb32653e189699\" } } Optional \"json_block\" version 19.0+ Default \"false\". If \"true\", \"contents\" will contain a JSON subtree instead of a JSON string. unchecked_keys \u00b6 version 8.0+ Retrieves unchecked database keys, blocks hashes & a json representations of unchecked pending blocks starting from key up to count . Using the optional json_block is recommended since v19.0. Request: { \"action\" : \"unchecked_keys\" , \"json_block\" : \"true\" , \"key\" : \"19BF0C268C2D9AED1A8C02E40961B67EA56B1681DE274CD0C50F3DD972F0655C\" , \"count\" : \"1\" } Response: { \"unchecked\" : [ { \"key\" : \"19BF0C268C2D9AED1A8C02E40961B67EA56B1681DE274CD0C50F3DD972F0655C\" , \"hash\" : \"A1A8558CBABD3F7C1D70F8CB882355F2EF688E7F30F5FDBD0204CAE157885056\" , \"modified_timestamp\" : \"1565856744\" , \"contents\" : { \"type\" : \"state\" , \"account\" : \"nano_1hmqzugsmsn4jxtzo5yrm4rsysftkh9343363hctgrjch1984d8ey9zoyqex\" , \"previous\" : \"19BF0C268C2D9AED1A8C02E40961B67EA56B1681DE274CD0C50F3DD972F0655C\" , \"representative\" : \"nano_1stofnrxuz3cai7ze75o174bpm7scwj9jn3nxsn8ntzg784jf1gzn1jjdkou\" , \"balance\" : \"189012679592109992600249226\" , \"link\" : \"0000000000000000000000000000000000000000000000000000000000000000\" , \"link_as_account\" : \"nano_1111111111111111111111111111111111111111111111111111hifc8npp\" , \"signature\" : \"FF5D49925AD3C8705E6EEDD993E8C4120E6107D7F1CB53B287773448DEA0B1D32918E67804248FC83609F0D93401D833DFA33127F21B6CD02F75D6E31A00450A\" , \"work\" : \"8193ddf00947e694\" } } ] } Optional \"json_block\" version 19.0+ Default \"false\". If \"true\", \"contents\" will contain a JSON subtree instead of a JSON string. unopened \u00b6 enable_control required, version 19.0+ Returns the total pending balance for unopened accounts in the local database, starting at account (optional) up to count (optional), sorted by account number. Notes: By default excludes the burn account. Dangerous RPC calls controlled by enable_control This RPC command/option requires enable_control to be enabled within the RPC config file. Enabling this means that anyone with access to the RPC port could potentially access wallet funds , stop the node from running and take other dangerous actions. Use caution when enabling this option, especially with external RPC access available. For more details see the Node Security page . Request: { \"action\" : \"unopened\" , \"account\" : \"nano_1111111111111111111111111111111111111111111111111111hifc8npp\" , \"count\" : \"1\" } Response: { \"accounts\" : { \"nano_1111111111111111111111111111111111111111111111111111hifc8npp\" : \"207034077034226183413773082289554618448\" } } Optional \"threshold\" Number (128 bit, decimal), default 0. Return only accounts with total pending balance above threshold . uptime \u00b6 version 18.0+ Return node uptime in seconds Request: { \"action\" : \"uptime\" } Response: { \"seconds\" : \"6000\" } work_cancel \u00b6 enable_control required Stop generating work for block Dangerous RPC calls controlled by enable_control This RPC command/option requires enable_control to be enabled within the RPC config file. Enabling this means that anyone with access to the RPC port could potentially access wallet funds , stop the node from running and take other dangerous actions. Use caution when enabling this option, especially with external RPC access available. For more details see the Node Security page . Request: { \"action\" : \"work_cancel\" , \"hash\" : \"718CC2121C3E641059BC1C2CFC45666C99E8AE922F7A807B7D07B62C995D79E2\" } Response: { } work_generate \u00b6 enable_control required Generates work for block. hash is the frontier of the account or in the case of an open block, the public key representation of the account which can be found with account_key . Dangerous RPC calls controlled by enable_control This RPC command/option requires enable_control to be enabled within the RPC config file. Enabling this means that anyone with access to the RPC port could potentially access wallet funds , stop the node from running and take other dangerous actions. Use caution when enabling this option, especially with external RPC access available. For more details see the Node Security page . Request: { \"action\" : \"work_generate\" , \"hash\" : \"718CC2121C3E641059BC1C2CFC45666C99E8AE922F7A807B7D07B62C995D79E2\" } Response: { \"work\" : \"2b3d689bbcb21dca\" , \"difficulty\" : \"fffffff93c41ec94\" , // o f t he resul t i n g work \"multiplier\" : \"1.182623871097636\" , // si n ce v 19.0 , calcula te d fr om de fault base di ff icul t y \"hash\" : \"718CC2121C3E641059BC1C2CFC45666C99E8AE922F7A807B7D07B62C995D79E2\" // si n ce v 20.0 } Optional \"use_peers\" version 14.0+ Boolean, false by default. If the optional use_peers parameter is set to true , then the node will query its work peers (if it has any). Without this parameter, the node will only generate work locally. Optional \"difficulty\" version 19.0+ Difficulty value (16 hexadecimal digits string, 64 bit). Uses difficulty value to generate work. Defaults to the network base difficulty. Optional \"multiplier\" version 20.0+ Multiplier from base difficulty (positive number). Uses equivalent difficulty as multiplier from base difficulty to generate work. Note: overrides the difficulty parameter. Optional \"account\" version 20.0+ A valid Nano account. If provided and use_peers is set to true , this information will be relayed to work peers. Optional \"version\" version 21.0+ Work version string. Currently \"work_1\" is the default and only valid option. Optional \"block\" version 21.0+ A valid Nano block (string or JSON). Using the optional json_block is recommended. If provided and difficulty or multiplier are both not given, RPC processor tries to calculate the appropriate difficulty threshold based on ledger data. Note: block should be the one where the resulting work value will be used, not the previous block. Optional \"json_block\" version 21.0+ Default \"false\". If \"true\", block in the request should contain a JSON subtree instead of a JSON string. work_peer_add \u00b6 enable_control required, version 8.0+ Add specific IP address and port as work peer for node until restart Dangerous RPC calls controlled by enable_control This RPC command/option requires enable_control to be enabled within the RPC config file. Enabling this means that anyone with access to the RPC port could potentially access wallet funds , stop the node from running and take other dangerous actions. Use caution when enabling this option, especially with external RPC access available. For more details see the Node Security page . Request: { \"action\" : \"work_peer_add\" , \"address\" : \"::ffff:172.17.0.1\" , \"port\" : \"7076\" } Response: { \"success\" : \"\" } work_peers \u00b6 enable_control required, version 8.0+ Dangerous RPC calls controlled by enable_control This RPC command/option requires enable_control to be enabled within the RPC config file. Enabling this means that anyone with access to the RPC port could potentially access wallet funds , stop the node from running and take other dangerous actions. Use caution when enabling this option, especially with external RPC access available. For more details see the Node Security page . Request: { \"action\" : \"work_peers\" } Response: { \"work_peers\" : [ \"::ffff:172.17.0.1:7076\" ] } work_peers_clear \u00b6 enable_control required, version 8.0+ Clear work peers node list until restart Dangerous RPC calls controlled by enable_control This RPC command/option requires enable_control to be enabled within the RPC config file. Enabling this means that anyone with access to the RPC port could potentially access wallet funds , stop the node from running and take other dangerous actions. Use caution when enabling this option, especially with external RPC access available. For more details see the Node Security page . Request: { \"action\" : \"work_peers_clear\" } Response: { \"success\" : \"\" } work_validate \u00b6 Check whether work is valid for block. Provides two values: valid_all is true if the work is valid at the current network difficulty (work can be used for any block). valid_receive is true if the work is valid for use in a receive block. Read the details below when using this RPC in V21 . Semantics change in V21.0 In V21.0, when the optional difficulty is not given, valid is no longer included in the response. Use the new response fields \"valid_all\" and \"valid_receive\" taking into account the subtype of the block using this work value: valid_all validates at the current network difficulty. As soon as the node processes the first epoch_2 block , this difficulty is increased. valid_receive is completely accurate only once the epoch_2 upgrade is finished. Until the upgrade is finished, it is only accurate if the account where this work will be used is already upgraded. The upgrade status of an account can be obtained from account_info . The account is upgraded if \"account_version\" is \"2\" . Request: { \"action\" : \"work_validate\" , \"work\" : \"2bf29ef00786a6bc\" , \"hash\" : \"718CC2121C3E641059BC1C2CFC45666C99E8AE922F7A807B7D07B62C995D79E2\" } Response since v21.0: { \"valid_all\" : \"1\" , \"valid_receive\" : \"1\" , \"difficulty\" : \"fffffff93c41ec94\" , \"multiplier\" : \"1.182623871097636\" // calcula te d fr om t he de fault base di ff icul t y } Response up to v20.0 { \"valid\" : \"1\" , \"difficulty\" : \"fffffff93c41ec94\" , // si n ce v 19.0 \"multiplier\" : \"9.4609\" // si n ce v 19.0 } Optional \"difficulty\" version 19.0+ Difficulty value (16 hexadecimal digits string, 64 bit). Uses difficulty value to validate work. Defaults to the network base difficulty. Response includes extra field valid signifying validity at the given difficulty. Request with given \"difficulty\" { \"action\" : \"work_validate\" , \"difficulty\" : \"ffffffffffffffff\" , \"work\" : \"2bf29ef00786a6bc\" , \"hash\" : \"718CC2121C3E641059BC1C2CFC45666C99E8AE922F7A807B7D07B62C995D79E2\" } Response with given \"difficulty: { \"valid\" : \"0\" , \"valid_all\" : \"1\" , // si n ce v 21.0 \"valid_receive\" : \"1\" , // si n ce v 21.0 \"difficulty\" : \"fffffff93c41ec94\" , \"multiplier\" : \"1.182623871097636\" } Optional \"multiplier\" version 20.0+ Multiplier from base difficulty (positive number). Uses equivalent difficulty as multiplier from base difficulty to validate work. Note: overrides the difficulty parameter. Optional \"version\" version 21.0+ Work version string. Currently \"work_1\" is the default and only valid option. Wallet RPCs \u00b6 For development and testing only Below are RPC commands that interact with the built-in, QT-based node wallet. This wallet is only recommended for development and testing. For production integrations, setting up custom External Management processes is required. account_create \u00b6 enable_control required Creates a new account, insert next deterministic key in wallet Dangerous RPC calls controlled by enable_control This RPC command/option requires enable_control to be enabled within the RPC config file. Enabling this means that anyone with access to the RPC port could potentially access wallet funds , stop the node from running and take other dangerous actions. Use caution when enabling this option, especially with external RPC access available. For more details see the Node Security page . Request: { \"action\" : \"account_create\" , \"wallet\" : \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\" } Response: { \"account\" : \"nano_3e3j5tkog48pnny9dmfzj1r16pg8t1e76dz5tmac6iq689wyjfpi00000000\" } Optional \"index\" version 18.0+ unset by default. Indicates which index to create account for starting with 0 Request: { \"action\" : \"account_create\" , \"wallet\" : \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\" , \"index\" : \"1\" } Optional \"work\" version 9.0+ Boolean, true by default. Setting false disables work generation after creating account Request: { \"action\" : \"account_create\" , \"wallet\" : \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\" , \"work\" : \"false\" } account_list \u00b6 Lists all the accounts inside wallet Request: { \"action\" : \"account_list\" , \"wallet\" : \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\" } Response: { \"accounts\" : [ \"nano_3e3j5tkog48pnny9dmfzj1r16pg8t1e76dz5tmac6iq689wyjfpi00000000\" ] } account_move \u00b6 enable_control required Moves accounts from source to wallet Dangerous RPC calls controlled by enable_control This RPC command/option requires enable_control to be enabled within the RPC config file. Enabling this means that anyone with access to the RPC port could potentially access wallet funds , stop the node from running and take other dangerous actions. Use caution when enabling this option, especially with external RPC access available. For more details see the Node Security page . Request: { \"action\" : \"account_move\" , \"wallet\" : \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\" , \"source\" : \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\" , \"accounts\" : [ \"nano_3e3j5tkog48pnny9dmfzj1r16pg8t1e76dz5tmac6iq689wyjfpi00000000\" ] } Response: { \"moved\" : \"1\" } account_remove \u00b6 enable_control required Remove account from wallet Dangerous RPC calls controlled by enable_control This RPC command/option requires enable_control to be enabled within the RPC config file. Enabling this means that anyone with access to the RPC port could potentially access wallet funds , stop the node from running and take other dangerous actions. Use caution when enabling this option, especially with external RPC access available. For more details see the Node Security page . Request: { \"action\" : \"account_remove\" , \"wallet\" : \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\" , \"account\" : \"nano_39a73oy5ungrhxy5z5oao1xso4zo7dmgpjd4u74xcrx3r1w6rtazuouw6qfi\" } Response: { \"removed\" : \"1\" } account_representative_set \u00b6 enable_control required Sets the representative for account in wallet Dangerous RPC calls controlled by enable_control This RPC command/option requires enable_control to be enabled within the RPC config file. Enabling this means that anyone with access to the RPC port could potentially access wallet funds , stop the node from running and take other dangerous actions. Use caution when enabling this option, especially with external RPC access available. For more details see the Node Security page . Request: { \"action\" : \"account_representative_set\" , \"wallet\" : \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\" , \"account\" : \"nano_39a73oy5ungrhxy5z5oao1xso4zo7dmgpjd4u74xcrx3r1w6rtazuouw6qfi\" , \"representative\" : \"nano_16u1uufyoig8777y6r8iqjtrw8sg8maqrm36zzcm95jmbd9i9aj5i8abr8u5\" } Response: { \"block\" : \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\" } Optional \"work\" version 9.0+ Work value (16 hexadecimal digits string, 64 bit). Uses work value for block from external source and disables work precaching for this account. Not using this field re-enables work precaching. accounts_create \u00b6 enable_control required, version 9.0+ Creates new accounts, insert next deterministic keys in wallet up to count Dangerous RPC calls controlled by enable_control This RPC command/option requires enable_control to be enabled within the RPC config file. Enabling this means that anyone with access to the RPC port could potentially access wallet funds , stop the node from running and take other dangerous actions. Use caution when enabling this option, especially with external RPC access available. For more details see the Node Security page . Request: { \"action\" : \"accounts_create\" , \"wallet\" : \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\" , \"count\" : \"2\" } Response: { \"accounts\" : [ \"nano_3e3j5tkog48pnny9dmfzj1r16pg8t1e76dz5tmac6iq689wyjfpi00000000\" , \"nano_1e5aqegc1jb7qe964u4adzmcezyo6o146zb8hm6dft8tkp79za3s00000000\" ] } Optional enabling work generation version 11.2+ Boolean, false by default. Enables work generation after creating accounts Request: { \"action\" : \"accounts_create\" , \"wallet\" : \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\" , \"count\" : \"2\" , \"work\" : \"true\" } Note: Before version 11.2 work generation was enabled by default, if you want to disable work generation for previous versions, use \"work\": \"false\" block_create (optional wallet) \u00b6 See block_create Node RPC command above password_change \u00b6 enable_control required Changes the password for wallet to password Dangerous RPC calls controlled by enable_control This RPC command/option requires enable_control to be enabled within the RPC config file. Enabling this means that anyone with access to the RPC port could potentially access wallet funds , stop the node from running and take other dangerous actions. Use caution when enabling this option, especially with external RPC access available. For more details see the Node Security page . Request: { \"action\" : \"password_change\" , \"wallet\" : \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\" , \"password\" : \"test\" } Response: { \"changed\" : \"1\" } password_enter \u00b6 Enters the password in to wallet to unlock it Request: { \"action\" : \"password_enter\" , \"wallet\" : \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\" , \"password\" : \"test\" } Response: { \"valid\" : \"1\" } password_valid \u00b6 Checks whether the password entered for wallet is valid Request: { \"action\" : \"password_valid\" , \"wallet\" : \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\" } Response: { \"valid\" : \"1\" } receive \u00b6 enable_control required Receive pending block for account in wallet . If receiving the block opens the account, sets the account representative to a wallet representative . Before v21, the representative is set to the account itself. Dangerous RPC calls controlled by enable_control This RPC command/option requires enable_control to be enabled within the RPC config file. Enabling this means that anyone with access to the RPC port could potentially access wallet funds , stop the node from running and take other dangerous actions. Use caution when enabling this option, especially with external RPC access available. For more details see the Node Security page . Request: { \"action\" : \"receive\" , \"wallet\" : \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\" , \"account\" : \"nano_3e3j5tkog48pnny9dmfzj1r16pg8t1e76dz5tmac6iq689wyjfpi00000000\" , \"block\" : \"53EAA25CE28FA0E6D55EA9704B32604A736966255948594D55CBB05267CECD48\" } Response: { \"block\" : \"EE5286AB32F580AB65FD84A69E107C69FBEB571DEC4D99297E19E3FA5529547B\" } Optional \"work\" version 9.0+ Work value (16 hexadecimal digits string, 64 bit). Uses work value for block from external source and disables work precaching for this account. Not using this field re-enables work precaching. receive_minimum \u00b6 enable_control required, version 8.0+ Returns receive minimum for node wallet Dangerous RPC calls controlled by enable_control This RPC command/option requires enable_control to be enabled within the RPC config file. Enabling this means that anyone with access to the RPC port could potentially access wallet funds , stop the node from running and take other dangerous actions. Use caution when enabling this option, especially with external RPC access available. For more details see the Node Security page . Request: { \"action\" : \"receive_minimum\" } Response: { \"amount\" : \"1000000000000000000000000\" } receive_minimum_set \u00b6 enable_control required, version 8.0+ Set amount as new receive minimum for node wallet until restart Dangerous RPC calls controlled by enable_control This RPC command/option requires enable_control to be enabled within the RPC config file. Enabling this means that anyone with access to the RPC port could potentially access wallet funds , stop the node from running and take other dangerous actions. Use caution when enabling this option, especially with external RPC access available. For more details see the Node Security page . Request: { \"action\" : \"receive_minimum_set\" , \"amount\" : \"1000000000000000000000000000000\" } Response: { \"success\" : \"\" } search_pending \u00b6 enable_control required Tells the node to look for pending blocks for any account in wallet Dangerous RPC calls controlled by enable_control This RPC command/option requires enable_control to be enabled within the RPC config file. Enabling this means that anyone with access to the RPC port could potentially access wallet funds , stop the node from running and take other dangerous actions. Use caution when enabling this option, especially with external RPC access available. For more details see the Node Security page . Request: { \"action\" : \"search_pending\" , \"wallet\" : \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\" } Response: { \"started\" : \"1\" } search_pending_all \u00b6 enable_control required, version 8.0+ Tells the node to look for pending blocks for any account in all available wallets Dangerous RPC calls controlled by enable_control This RPC command/option requires enable_control to be enabled within the RPC config file. Enabling this means that anyone with access to the RPC port could potentially access wallet funds , stop the node from running and take other dangerous actions. Use caution when enabling this option, especially with external RPC access available. For more details see the Node Security page . Request: { \"action\" : \"search_pending_all\" } Response: { \"success\" : \"\" } send \u00b6 enable_control required Send amount from source in wallet to destination Dangerous RPC calls controlled by enable_control This RPC command/option requires enable_control to be enabled within the RPC config file. Enabling this means that anyone with access to the RPC port could potentially access wallet funds , stop the node from running and take other dangerous actions. Use caution when enabling this option, especially with external RPC access available. For more details see the Node Security page . Use of id option is highly recommended Integrations using the node wallet must ensure idempotency for transactions and this can be done externally if preferred. Using the id field provides this option internally and is highly recommended for all node wallet uses. Request: { \"action\" : \"send\" , \"wallet\" : \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\" , \"source\" : \"nano_3e3j5tkog48pnny9dmfzj1r16pg8t1e76dz5tmac6iq689wyjfpi00000000\" , \"destination\" : \"nano_3e3j5tkog48pnny9dmfzj1r16pg8t1e76dz5tmac6iq689wyjfpi00000000\" , \"amount\" : \"1000000\" , \"id\" : \"your-unique-id\" } Response: { \"block\" : \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\" } Proof of Work is precomputed for one transaction in the background when you are using the node wallet to track accounts. If it has been a while since your last transaction it will send instantly, the next one will need to wait for Proof of Work to be generated. If the request times out, then the send may or may not have gone through. If you want to the ability to retry a failed send, all send calls must specify the id parameter as follows Highly recommended \"id\" version 10.0+ You can (and should) specify a unique id for each spend to provide idempotency . That means that if you call send two times with the same id, the second request won't send any additional Nano, and will return the first block instead. The id can be any string. This may be a required parameter in the future. If you accidentally reuse an id, the send will not go through (it will be seen as a duplicate request), so make sure your ids are unique! They must be unique per node, and are not segregated per wallet. Using the same id for requests with different parameters (wallet, source, destination, and amount) is undefined behavior and may result in an error in the future. Request: { \"action\" : \"send\" , \"wallet\" : \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\" , \"source\" : \"nano_3e3j5tkog48pnny9dmfzj1r16pg8t1e76dz5tmac6iq689wyjfpi00000000\" , \"destination\" : \"nano_3e3j5tkog48pnny9dmfzj1r16pg8t1e76dz5tmac6iq689wyjfpi00000000\" , \"amount\" : \"1000000\" , \"id\" : \"7081e2b8fec9146e\" } Response: { \"block\" : \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\" } Sending the request again will yield the same block, and will not affect the ledger. Optional \"work\" version 9.0+ Work value (16 hexadecimal digits string, 64 bit). Uses work value for block from external source and disables work precaching for this account. Not using this field re-enables work precaching. Request: { \"action\" : \"send\" , \"wallet\" : \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\" , \"source\" : \"nano_3e3j5tkog48pnny9dmfzj1r16pg8t1e76dz5tmac6iq689wyjfpi00000000\" , \"destination\" : \"nano_3e3j5tkog48pnny9dmfzj1r16pg8t1e76dz5tmac6iq689wyjfpi00000000\" , \"amount\" : \"1000000\" , \"work\" : \"2bf29ef00786a6bc\" } sign (optional wallet) \u00b6 See sign Node RPC command above wallet_add \u00b6 enable_control required Add an adhoc private key key to wallet Dangerous RPC calls controlled by enable_control This RPC command/option requires enable_control to be enabled within the RPC config file. Enabling this means that anyone with access to the RPC port could potentially access wallet funds , stop the node from running and take other dangerous actions. Use caution when enabling this option, especially with external RPC access available. For more details see the Node Security page . Request: { \"action\" : \"wallet_add\" , \"wallet\" : \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\" , \"key\" : \"34F0A37AAD20F4A260F0A5B3CB3D7FB50673212263E58A380BC10474BB039CE4\" } Response: { \"account\" : \"nano_3e3j5tkog48pnny9dmfzj1r16pg8t1e76dz5tmac6iq689wyjfpi00000000\" } Optional disabling work generation version 9.0+ Boolean, false by default. Disables work generation after adding account Request: { \"action\" : \"wallet_add\" , \"wallet\" : \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\" , \"key\" : \"34F0A37AAD20F4A260F0A5B3CB3D7FB50673212263E58A380BC10474BB039CE4\" , \"work\" : \"false\" } wallet_add_watch \u00b6 enable_control required, version 11.0+ Add watch-only accounts to wallet Dangerous RPC calls controlled by enable_control This RPC command/option requires enable_control to be enabled within the RPC config file. Enabling this means that anyone with access to the RPC port could potentially access wallet funds , stop the node from running and take other dangerous actions. Use caution when enabling this option, especially with external RPC access available. For more details see the Node Security page . Request: { \"action\" : \"wallet_add_watch\" , \"wallet\" : \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\" , \"accounts\" : [ \"nano_3e3j5tkog48pnny9dmfzj1r16pg8t1e76dz5tmac6iq689wyjfpi00000000\" , \"nano_111111111111111111111111111111111111111111111111111000000000\" ] } Response: { \"success\" : \"\" } wallet_balances \u00b6 Returns how many raw is owned and how many have not yet been received by all accounts in wallet Includes unconfirmed blocks This call may return results that include unconfirmed blocks, so it should not be used in any processes or integrations requiring only details from blocks confirmed by the network. Request: { \"action\" : \"wallet_balances\" , \"wallet\" : \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\" } Response: { \"balances\" : { \"nano_3e3j5tkog48pnny9dmfzj1r16pg8t1e76dz5tmac6iq689wyjfpi00000000\" : { \"balance\" : \"10000\" , \"pending\" : \"10000\" } } } Optional \"threshold\" version 9.0+ Number (128 bit, decimal). Returns wallet accounts balances more or equal to threshold wallet_change_seed \u00b6 enable_control required Changes seed for wallet to seed . Notes: Clear all deterministic accounts in wallet! To restore account from new seed use RPC accounts_create . last_restored_account and restored_count fields in response returned since version 19.0+ Dangerous RPC calls controlled by enable_control This RPC command/option requires enable_control to be enabled within the RPC config file. Enabling this means that anyone with access to the RPC port could potentially access wallet funds , stop the node from running and take other dangerous actions. Use caution when enabling this option, especially with external RPC access available. For more details see the Node Security page . Request: { \"action\" : \"wallet_change_seed\" , \"wallet\" : \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\" , \"seed\" : \"74F2B37AAD20F4A260F0A5B3CB3D7FB51673212263E58A380BC10474BB039CEE\" } Response: { \"success\" : \"\" , \"last_restored_account\" : \"nano_1mhdfre3zczr86mp44jd3xft1g1jg66jwkjtjqixmh6eajfexxti7nxcot9c\" , \"restored_count\" : \"1\" } Optional \"count\" version 18.0+ Number, 0 by default. Manually set count of accounts to restore from seed wallet_contains \u00b6 Check whether wallet contains account Request: { \"action\" : \"wallet_contains\" , \"wallet\" : \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\" , \"account\" : \"nano_3e3j5tkog48pnny9dmfzj1r16pg8t1e76dz5tmac6iq689wyjfpi00000000\" } Response: { \"exists\" : \"1\" } wallet_create \u00b6 enable_control required Creates a new random wallet id Dangerous RPC calls controlled by enable_control This RPC command/option requires enable_control to be enabled within the RPC config file. Enabling this means that anyone with access to the RPC port could potentially access wallet funds , stop the node from running and take other dangerous actions. Use caution when enabling this option, especially with external RPC access available. For more details see the Node Security page . Request: { \"action\" : \"wallet_create\" } Response: { \"wallet\" : \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\" } Optional \"seed\" version 18.0+ Seed value (64 hexadecimal digits string, 256 bit). Changes seed for a new wallet to seed , returning last restored account from given seed & restored count wallet_destroy \u00b6 enable_control required Destroys wallet and all contained accounts Dangerous RPC calls controlled by enable_control This RPC command/option requires enable_control to be enabled within the RPC config file. Enabling this means that anyone with access to the RPC port could potentially access wallet funds , stop the node from running and take other dangerous actions. Use caution when enabling this option, especially with external RPC access available. For more details see the Node Security page . Request: { \"action\" : \"wallet_destroy\" , \"wallet\" : \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\" } Response: { \"destroyed\" : \"1\" } wallet_export \u00b6 Return a json representation of wallet Request: { \"action\" : \"wallet_export\" , \"wallet\" : \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\" } Response: { \"json\" : \"{\\\"0000000000000000000000000000000000000000000000000000000000000000\\\": \\\"0000000000000000000000000000000000000000000000000000000000000001\\\"}\" } wallet_frontiers \u00b6 Returns a list of pairs of account and block hash representing the head block starting for accounts from wallet Request: { \"action\" : \"wallet_frontiers\" , \"wallet\" : \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\" } Response: { \"frontiers\" : { \"nano_3e3j5tkog48pnny9dmfzj1r16pg8t1e76dz5tmac6iq689wyjfpi00000000\" : \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\" } } wallet_history \u00b6 version 18.0+ Reports send/receive information for accounts in wallet. Change blocks are skipped, open blocks will appear as receive. Response will start with most recent blocks according to local ledger. Includes unconfirmed blocks This call may return results that include unconfirmed blocks, so it should not be used in any processes or integrations requiring only details from blocks confirmed by the network. Request: { \"action\" : \"wallet_history\" , \"wallet\" : \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\" } Response: { \"history\" : [ { \"type\" : \"send\" , \"account\" : \"nano_1qato4k7z3spc8gq1zyd8xeqfbzsoxwo36a45ozbrxcatut7up8ohyardu1z\" , \"amount\" : \"30000000000000000000000000000000000\" , \"block_account\" : \"nano_1ipx847tk8o46pwxt5qjdbncjqcbwcc1rrmqnkztrfjy5k7z4imsrata9est\" , \"hash\" : \"87434F8041869A01C8F6F263B87972D7BA443A72E0A97D7A3FD0CCC2358FD6F9\" , \"local_timestamp\" : \"1527698508\" }, { \"type\" : \"send\" , \"account\" : \"nano_38ztgpejb7yrm7rr586nenkn597s3a1sqiy3m3uyqjicht7kzuhnihdk6zpz\" , \"amount\" : \"40000000000000000000000000000000000\" , \"block_account\" : \"nano_1ipx847tk8o46pwxt5qjdbncjqcbwcc1rrmqnkztrfjy5k7z4imsrata9est\" , \"hash\" : \"CE898C131AAEE25E05362F247760F8A3ACF34A9796A5AE0D9204E86B0637965E\" , \"local_timestamp\" : \"1527698492\" } ] } Optional \"modified_since\" UNIX timestamp (number), 0 by default. Return only accounts modified in local database after specific timestamp wallet_info \u00b6 version 15.0+ Returns the sum of all accounts balances in wallet , number of accounts in wallet, number of deterministic & adhoc (non-deterministic) accounts, deterministic index (index of last account derived from seed. Equal to deterministic accounts number if no accounts were removed) Includes unconfirmed blocks This call may return results that include unconfirmed blocks, so it should not be used in any processes or integrations requiring only details from blocks confirmed by the network. Request: { \"action\" : \"wallet_info\" , \"wallet\" : \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\" } Response: { \"balance\" : \"10000\" , \"pending\" : \"10000\" , \"accounts_count\" : \"3\" , \"adhoc_count\" : \"1\" , \"deterministic_count\" : \"2\" , \"deterministic_index\" : \"2\" } wallet_ledger \u00b6 enable_control required, version 11.0+ Returns frontier, open block, change representative block, balance, last modified timestamp from local database & block count for accounts from wallet Includes unconfirmed blocks This call may return results that include unconfirmed blocks, so it should not be used in any processes or integrations requiring only details from blocks confirmed by the network. Dangerous RPC calls controlled by enable_control This RPC command/option requires enable_control to be enabled within the RPC config file. Enabling this means that anyone with access to the RPC port could potentially access wallet funds , stop the node from running and take other dangerous actions. Use caution when enabling this option, especially with external RPC access available. For more details see the Node Security page . Request: { \"action\" : \"wallet_ledger\" , \"wallet\" : \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\" } Response: { \"accounts\" : { \"nano_11119gbh8hb4hj1duf7fdtfyf5s75okzxdgupgpgm1bj78ex3kgy7frt3s9n\" : { \"frontier\" : \"E71AF3E9DD86BBD8B4620EFA63E065B34D358CFC091ACB4E103B965F95783321\" , \"open_block\" : \"643B77F1ECEFBDBE1CC909872964C1DBBE23A6149BD3CEF2B50B76044659B60F\" , \"representative_block\" : \"643B77F1ECEFBDBE1CC909872964C1DBBE23A6149BD3CEF2B50B76044659B60F\" , \"balance\" : \"0\" , \"modified_timestamp\" : \"1511476234\" , \"block_count\" : \"2\" } } } Optional \"representative\", \"weight\", \"pending\" Booleans, false by default. Additionally returns representative, voting weight, pending balance for each account Request: { \"action\" : \"wallet_ledger\" , \"wallet\" : \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\" , \"representative\" : \"true\" , \"weight\" : \"true\" , \"pending\" : \"true\" } Response: { \"accounts\" : { \"nano_11119gbh8hb4hj1duf7fdtfyf5s75okzxdgupgpgm1bj78ex3kgy7frt3s9n\" : { \"frontier\" : \"E71AF3E9DD86BBD8B4620EFA63E065B34D358CFC091ACB4E103B965F95783321\" , \"open_block\" : \"643B77F1ECEFBDBE1CC909872964C1DBBE23A6149BD3CEF2B50B76044659B60F\" , \"representative_block\" : \"643B77F1ECEFBDBE1CC909872964C1DBBE23A6149BD3CEF2B50B76044659B60F\" , \"balance\" : \"0\" , \"modified_timestamp\" : \"1511476234\" , \"block_count\" : \"2\" , \"representative\" : \"nano_1anrzcuwe64rwxzcco8dkhpyxpi8kd7zsjc1oeimpc3ppca4mrjtwnqposrs\" , \"weight\" : \"0\" , \"pending\" : \"0\" } } } Optional \"modified_since\" UNIX timestamp (number), 0 by default. Return only accounts modified in local database after specific timestamp wallet_lock \u00b6 enable_control required, version 9.0+ Locks wallet Dangerous RPC calls controlled by enable_control This RPC command/option requires enable_control to be enabled within the RPC config file. Enabling this means that anyone with access to the RPC port could potentially access wallet funds , stop the node from running and take other dangerous actions. Use caution when enabling this option, especially with external RPC access available. For more details see the Node Security page . Request: { \"action\" : \"wallet_lock\" , \"wallet\" : \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\" } Response: { \"locked\" : \"1\" } wallet_locked \u00b6 Checks whether wallet is locked Request: { \"action\" : \"wallet_locked\" , \"wallet\" : \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\" } Response: { \"locked\" : \"0\" } wallet_pending \u00b6 enable_control required, version 8.0+ Returns a list of block hashes which have not yet been received by accounts in this wallet Dangerous RPC calls controlled by enable_control This RPC command/option requires enable_control to be enabled within the RPC config file. Enabling this means that anyone with access to the RPC port could potentially access wallet funds , stop the node from running and take other dangerous actions. Use caution when enabling this option, especially with external RPC access available. For more details see the Node Security page . Request: { \"action\" : \"wallet_pending\" , \"wallet\" : \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\" , \"count\" : \"1\" } Response: { \"blocks\" : { \"nano_1111111111111111111111111111111111111111111111111117353trpda\" : [ \"142A538F36833D1CC78B94E11C766F75818F8B940771335C6C1B8AB880C5BB1D\" ], \"nano_3t6k35gi95xu6tergt6p69ck76ogmitsa8mnijtpxm9fkcm736xtoncuohr3\" : [ \"4C1FEEF0BEA7F50BE35489A1233FE002B212DEA554B55B1B470D78BD8F210C74\" ] } } Optional \"threshold\" Number (128 bit, decimal). Returns a list of pending block hashes with amount more or equal to threshold Request: { \"action\" : \"wallet_pending\" , \"wallet\" : \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\" , \"count\" : \"1\" , \"threshold\" : \"1000000000000000000000000\" } Response: { \"blocks\" : { \"nano_1111111111111111111111111111111111111111111111111117353trpda\" : { \"142A538F36833D1CC78B94E11C766F75818F8B940771335C6C1B8AB880C5BB1D\" : \"6000000000000000000000000000000\" }, \"nano_3t6k35gi95xu6tergt6p69ck76ogmitsa8mnijtpxm9fkcm736xtoncuohr3\" : { \"4C1FEEF0BEA7F50BE35489A1233FE002B212DEA554B55B1B470D78BD8F210C74\" : \"106370018000000000000000000000000\" } } } Optional \"source\" version 9.0+ Boolean, false by default. Returns a list of pending block hashes with amount and source accounts Request: { \"action\" : \"wallet_pending\" , \"wallet\" : \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\" , \"count\" : \"1\" , \"source\" : \"true\" } Response: { \"blocks\" : { \"nano_1111111111111111111111111111111111111111111111111117353trpda\" : { \"142A538F36833D1CC78B94E11C766F75818F8B940771335C6C1B8AB880C5BB1D\" : { \"amount\" : \"6000000000000000000000000000000\" , \"source\" : \"nano_3dcfozsmekr1tr9skf1oa5wbgmxt81qepfdnt7zicq5x3hk65fg4fqj58mbr\" } }, \"nano_3t6k35gi95xu6tergt6p69ck76ogmitsa8mnijtpxm9fkcm736xtoncuohr3\" : { \"4C1FEEF0BEA7F50BE35489A1233FE002B212DEA554B55B1B470D78BD8F210C74\" : { \"amount\" : \"106370018000000000000000000000000\" , \"source\" : \"nano_13ezf4od79h1tgj9aiu4djzcmmguendtjfuhwfukhuucboua8cpoihmh8byo\" } } } } Optional \"include_active\" version 15.0+ Boolean, false by default. Include active blocks without finished confirmations Request: { \"action\" : \"wallet_pending\" , \"wallet\" : \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\" , \"count\" : \"1\" , \"include_active\" : \"true\" } Optional \"min_version\" version 15.0+ Boolean, false by default. Returns the minimum version (epoch) of a block which can pocket this pending block. Optional \"include_only_confirmed\" version 19.0+ Boolean, false by default. Only returns block which have their confirmation height set or are undergoing confirmation height processing. wallet_representative \u00b6 Returns the default representative for wallet Request: { \"action\" : \"wallet_representative\" , \"wallet\" : \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\" } Response: { \"representative\" : \"nano_3e3j5tkog48pnny9dmfzj1r16pg8t1e76dz5tmac6iq689wyjfpi00000000\" } wallet_representative_set \u00b6 enable_control required Sets the default representative for wallet (used only for new accounts, already existing accounts use already set representatives) Dangerous RPC calls controlled by enable_control This RPC command/option requires enable_control to be enabled within the RPC config file. Enabling this means that anyone with access to the RPC port could potentially access wallet funds , stop the node from running and take other dangerous actions. Use caution when enabling this option, especially with external RPC access available. For more details see the Node Security page . Request: { \"action\" : \"wallet_representative_set\" , \"wallet\" : \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\" , \"representative\" : \"nano_3e3j5tkog48pnny9dmfzj1r16pg8t1e76dz5tmac6iq689wyjfpi00000000\" } Response: { \"set\" : \"1\" } Optional \"update_existing_accounts\" version 18.0+ Boolean, false by default. Change representative for existing accounts in wallet. May require a lot of time to complete for large wallets due to work generation for change type state blocks wallet_republish \u00b6 enable_control required, version 8.0+ Rebroadcast blocks for accounts from wallet starting at frontier down to count to the network Dangerous RPC calls controlled by enable_control This RPC command/option requires enable_control to be enabled within the RPC config file. Enabling this means that anyone with access to the RPC port could potentially access wallet funds , stop the node from running and take other dangerous actions. Use caution when enabling this option, especially with external RPC access available. For more details see the Node Security page . Request: { \"action\" : \"wallet_republish\" , \"wallet\" : \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\" , \"count\" : \"2\" } Response: { \"blocks\" : [ \"991CF190094C00F0B68E2E5F75F6BEE95A2E0BD93CEAA4A6734DB9F19B728948\" , \"A170D51B94E00371ACE76E35AC81DC9405D5D04D4CEBC399AEACE07AE05DD293\" , \"90D0C16AC92DD35814E84BFBCC739A039615D0A42A76EF44ADAEF1D99E9F8A35\" ] } wallet_work_get \u00b6 enable_control required, version 8.0+ Returns a list of pairs of account and work from wallet Dangerous RPC calls controlled by enable_control This RPC command/option requires enable_control to be enabled within the RPC config file. Enabling this means that anyone with access to the RPC port could potentially access wallet funds , stop the node from running and take other dangerous actions. Use caution when enabling this option, especially with external RPC access available. For more details see the Node Security page . Request: { \"action\" : \"wallet_work_get\" , \"wallet\" : \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\" } Response: { \"works\" : { \"nano_1111111111111111111111111111111111111111111111111111hifc8npp\" : \"432e5cf728c90f4f\" } } work_get \u00b6 enable_control required, version 8.0+ Retrieves work for account in wallet Dangerous RPC calls controlled by enable_control This RPC command/option requires enable_control to be enabled within the RPC config file. Enabling this means that anyone with access to the RPC port could potentially access wallet funds , stop the node from running and take other dangerous actions. Use caution when enabling this option, especially with external RPC access available. For more details see the Node Security page . Request: { \"action\" : \"work_get\" , \"wallet\" : \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\" , \"account\" : \"nano_1111111111111111111111111111111111111111111111111111hifc8npp\" } Response: { \"work\" : \"432e5cf728c90f4f\" } work_set \u00b6 enable_control required, version 8.0+ Set work for account in wallet Dangerous RPC calls controlled by enable_control This RPC command/option requires enable_control to be enabled within the RPC config file. Enabling this means that anyone with access to the RPC port could potentially access wallet funds , stop the node from running and take other dangerous actions. Use caution when enabling this option, especially with external RPC access available. For more details see the Node Security page . Request: { \"action\" : \"work_set\" , \"wallet\" : \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\" , \"account\" : \"nano_1111111111111111111111111111111111111111111111111111hifc8npp\" , \"work\" : \"0000000000000000\" } Response: { \"success\" : \"\" } Unit Conversion RPCs \u00b6 krai_from_raw \u00b6 Divide a raw amount down by the krai ratio. Request: { \"action\" : \"krai_from_raw\" , \"amount\" : \"1000000000000000000000000000\" } Response: { \"amount\" : \"1\" } krai_to_raw \u00b6 Multiply an krai amount by the krai ratio. Request: { \"action\" : \"krai_to_raw\" , \"amount\" : \"1\" } Response: { \"amount\" : \"1000000000000000000000000000\" } mrai_from_raw \u00b6 Divide a raw amount down by the Mrai ratio. Request: { \"action\" : \"mrai_from_raw\" , \"amount\" : \"1000000000000000000000000000000\" } Response: { \"amount\" : \"1\" } mrai_to_raw \u00b6 Multiply an Mrai amount by the Mrai ratio. Request: { \"action\" : \"mrai_to_raw\" , \"amount\" : \"1\" } Response: { \"amount\" : \"1000000000000000000000000000000\" } rai_from_raw \u00b6 Divide a raw amount down by the rai ratio. Request: { \"action\" : \"rai_from_raw\" , \"amount\" : \"1000000000000000000000000\" } Response: { \"amount\" : \"1\" } rai_to_raw \u00b6 Multiply an rai amount by the rai ratio. Request: { \"action\" : \"rai_to_raw\" , \"amount\" : \"1\" } Response: { \"amount\" : \"1000000000000000000000000\" } Deprecated RPCs \u00b6 history \u00b6 Deprecated : please use account_history instead. It provides a head option which is identical to the history hash option. Removed RPCs \u00b6 Removed in v22 \u00b6 block_count_type \u00b6 Reports the number of blocks in the ledger by type (send, receive, open, change, state with version) Request: { \"action\" : \"block_count_type\" } Response: { \"send\" : \"5016664\" , \"receive\" : \"4081228\" , \"open\" : \"546457\" , \"change\" : \"24193\" , \"state_v0\" : \"4216537\" , \"state_v1\" : \"10653709\" , \"state\" : \"14870246\" } payment_begin \u00b6 Begin a new payment session. Searches wallet for an account that's marked as available and has a 0 balance. If one is found, the account number is returned and is marked as unavailable. If no account is found, a new account is created, placed in the wallet, and returned. Request: { \"action\" : \"payment_begin\" , \"wallet\" : \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\" } Response: { \"account\" : \"nano_3e3j5tkog48pnny9dmfzj1r16pg8t1e76dz5tmac6iq689wyjfpi00000000\" } payment_end \u00b6 End a payment session. Marks the account as available for use in a payment session. Request: { \"action\" : \"payment_end\" , \"account\" : \"nano_3e3j5tkog48pnny9dmfzj1r16pg8t1e76dz5tmac6iq689wyjfpi00000000\" , \"wallet\" : \"FFFD1BAEC8EC20814BBB9059B393051AAA8380F9B5A2E6B2489A277D81789EEE\" } Response: { } payment_init \u00b6 Marks all accounts in wallet as available for being used as a payment session. Request: { \"action\" : \"payment_init\" , \"wallet\" : \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\" } Response: { \"status\" : \"Ready\" } payment_wait \u00b6 Wait for payment of 'amount' to arrive in 'account' or until 'timeout' milliseconds have elapsed. Request: { \"action\" : \"payment_wait\" , \"account\" : \"nano_3e3j5tkog48pnny9dmfzj1r16pg8t1e76dz5tmac6iq689wyjfpi00000000\" , \"amount\" : \"1\" , \"timeout\" : \"1000\" } Response: { \"deprecated\" : \"1\" , \"status\" : \"success\" }","title":"RPC Protocol"},{"location":"commands/rpc-protocol/#rpc-protocol","text":"The RPC protocol accepts JSON HTTP POST requests. The following are RPC commands along with the responses that are expected. This page is split into the following sections: Section Purpose Node RPCs For interacting with the node and ledger. Wallet RPCs For interacting with the built-in, QT-based node wallet. NOTE : This wallet is only recommended for development and testing. Unit Conversion RPCs For converting different units to and from raw. Deprecated RPCs No longer recommended for use.","title":"RPC Protocol"},{"location":"commands/rpc-protocol/#node-rpcs","text":"Unconfirmed blocks returned Unless otherwise specified, RPC calls can return unconfirmed blocks and related details. In the most important cases where balances or similar details may include unconfirmed amounts, additional warnings have been included. Refer to Block confirmation procedures for details.","title":"Node RPCs"},{"location":"commands/rpc-protocol/#account_balance","text":"Returns how many RAW is owned and how many have not yet been received by account Unconfirmed information This call returns information that may be based on unconfirmed blocks. These details should not be relied on for any process or integration that requires confirmed blocks. The pending balance is calculated from potentially unconfirmed blocks. The account's balance is obtained from its frontier. An atomic account_info RPC call is recommended for the purposes of creating transactions. Request: { \"action\" : \"account_balance\" , \"account\" : \"nano_3e3j5tkog48pnny9dmfzj1r16pg8t1e76dz5tmac6iq689wyjfpi00000000\" } Response: { \"balance\" : \"10000\" , \"pending\" : \"10000\" }","title":"account_balance"},{"location":"commands/rpc-protocol/#account_block_count","text":"Get number of blocks for a specific account Request: { \"action\" : \"account_block_count\" , \"account\" : \"nano_3t6k35gi95xu6tergt6p69ck76ogmitsa8mnijtpxm9fkcm736xtoncuohr3\" } Response: { \"block_count\" : \"19\" }","title":"account_block_count"},{"location":"commands/rpc-protocol/#account_get","text":"Get account number for the public key Request: { \"action\" : \"account_get\" , \"key\" : \"3068BB1CA04525BB0E416C485FE6A67FD52540227D267CC8B6E8DA958A7FA039\" } Response: { \"account\" : \"nano_1e5aqegc1jb7qe964u4adzmcezyo6o146zb8hm6dft8tkp79za3sxwjym5rx\" }","title":"account_get"},{"location":"commands/rpc-protocol/#account_history","text":"Reports send/receive information for an account. Returns only send & receive blocks by default (unless raw is set to true - see optional parameters below): change, state change & state epoch blocks are skipped, open & state open blocks will appear as receive, state receive/send blocks will appear as receive/send entries. Response will start with the latest block for the account (the frontier), and will list all blocks back to the open block of this account when \"count\" is set to \"-1\". Note : \"local_timestamp\" returned since version 18.0, \"height\" field returned since version 19.0 Includes unconfirmed blocks This call may return results that include unconfirmed blocks, so it should not be used in any processes or integrations requiring only details from blocks confirmed by the network. Request: { \"action\" : \"account_history\" , \"account\" : \"nano_1ipx847tk8o46pwxt5qjdbncjqcbwcc1rrmqnkztrfjy5k7z4imsrata9est\" , \"count\" : \"1\" } Response: { \"account\" : \"nano_1ipx847tk8o46pwxt5qjdbncjqcbwcc1rrmqnkztrfjy5k7z4imsrata9est\" , \"history\" : [ { \"type\" : \"send\" , \"account\" : \"nano_38ztgpejb7yrm7rr586nenkn597s3a1sqiy3m3uyqjicht7kzuhnihdk6zpz\" , \"amount\" : \"80000000000000000000000000000000000\" , \"local_timestamp\" : \"1551532723\" , \"height\" : \"60\" , \"hash\" : \"80392607E85E73CC3E94B4126F24488EBDFEB174944B890C97E8F36D89591DC5\" } ], \"previous\" : \"8D3AB98B301224253750D448B4BD997132400CEDD0A8432F775724F2D9821C72\" } If the count limit results in stopping before the end of the account chain, then the response will also contain a previous field (outside of the history field) which contains the block hash that would be next to process if count was larger. Optional parameters: raw (bool): if set to true instead of the default false , instead of outputting a simplified send or receive explanation of blocks (intended for wallets), output all parameters of the block itself as seen in block_create or other APIs returning blocks. It still includes the \"account\" and \"amount\" properties you'd see without this option. State/universal blocks in the raw history will also have a subtype field indicating their equivalent \"old\" block. Unfortunately, the \"account\" parameter for open blocks is the account of the source block, not the account of the open block, to preserve similarity with the non-raw history. head (64 hexadecimal digits string, 256 bit): instead of using the latest block for a specified account, use this block as the head of the account instead. Useful for pagination. offset (decimal integer): skips a number of blocks starting from head (if given). Not often used. Available since version 11.0 reverse (bool): if set to true instead of the default false , the response starts from head (if given, otherwise the first block of the account), and lists blocks up to the frontier (limited by \"count\"). Note : the field previous in the response changes to next . Available since version 19.0 account_filter (array of public addresses): results will be filtered to only show sends/receives connected to the provided account(s). Available since version 19.0 . Note: In v19.0, this option does not handle receive blocks; fixed in v20.0.","title":"account_history"},{"location":"commands/rpc-protocol/#account_info","text":"Returns frontier, open block, change representative block, balance, last modified timestamp from local database & block count for account . Only works for accounts that have received their first transaction and have an entry on the ledger, will return \"Account not found\" otherwise. To open an account, use receive . Unconfirmed information This call returns information that may be based on unconfirmed blocks. These details should not be relied on for any process or integration that requires confirmed blocks. The balance is obtained from the frontier, which may be unconfirmed. As long as you follow the guidelines , you can rely on the balance for the purposes of creating transactions for this account. If the frontier is never confirmed, then the blocks that proceed it will also never be confirmed. Request: { \"action\" : \"account_info\" , \"account\" : \"nano_3t6k35gi95xu6tergt6p69ck76ogmitsa8mnijtpxm9fkcm736xtoncuohr3\" } Response: { \"frontier\" : \"FF84533A571D953A596EA401FD41743AC85D04F406E76FDE4408EAED50B473C5\" , \"open_block\" : \"991CF190094C00F0B68E2E5F75F6BEE95A2E0BD93CEAA4A6734DB9F19B728948\" , \"representative_block\" : \"991CF190094C00F0B68E2E5F75F6BEE95A2E0BD93CEAA4A6734DB9F19B728948\" , \"balance\" : \"235580100176034320859259343606608761791\" , \"modified_timestamp\" : \"1501793775\" , \"block_count\" : \"33\" , \"confirmation_height\" : \"28\" , \"confirmation_height_frontier\" : \"34C70FCA0952E29ADC7BEE6F20381466AE42BD1CFBA4B7DFFE8BD69DF95449EB\" , \"account_version\" : \"1\" } In response confirmation_height only available for version 19.0+ In response confirmation_height_frontier only available for version 21.0+ which is the block hash at that confirmation height. Optional \"representative\", \"weight\", \"pending\" version 9.0+ Booleans, false by default. Additionally returns representative, voting weight, pending balance for account Request: { \"action\" : \"account_info\" , \"account\" : \"nano_3t6k35gi95xu6tergt6p69ck76ogmitsa8mnijtpxm9fkcm736xtoncuohr3\" , \"representative\" : \"true\" , \"weight\" : \"true\" , \"pending\" : \"true\" } Response: { \"frontier\" : \"FF84533A571D953A596EA401FD41743AC85D04F406E76FDE4408EAED50B473C5\" , \"open_block\" : \"991CF190094C00F0B68E2E5F75F6BEE95A2E0BD93CEAA4A6734DB9F19B728948\" , \"representative_block\" : \"991CF190094C00F0B68E2E5F75F6BEE95A2E0BD93CEAA4A6734DB9F19B728948\" , \"balance\" : \"235580100176034320859259343606608761791\" , \"modified_timestamp\" : \"1501793775\" , \"block_count\" : \"33\" , \"representative\" : \"nano_3t6k35gi95xu6tergt6p69ck76ogmitsa8mnijtpxm9fkcm736xtoncuohr3\" , \"weight\" : \"1105577030935649664609129644855132177\" , \"pending\" : \"2309370929000000000000000000000000\" }","title":"account_info"},{"location":"commands/rpc-protocol/#account_key","text":"Get the public key for account Request: { \"action\" : \"account_key\" , \"account\" : \"nano_1e5aqegc1jb7qe964u4adzmcezyo6o146zb8hm6dft8tkp79za3sxwjym5rx\" } Response: { \"key\" : \"3068BB1CA04525BB0E416C485FE6A67FD52540227D267CC8B6E8DA958A7FA039\" }","title":"account_key"},{"location":"commands/rpc-protocol/#account_representative","text":"Returns the representative for account Request: { \"action\" : \"account_representative\" , \"account\" : \"nano_39a73oy5ungrhxy5z5oao1xso4zo7dmgpjd4u74xcrx3r1w6rtazuouw6qfi\" } Response: { \"representative\" : \"nano_16u1uufyoig8777y6r8iqjtrw8sg8maqrm36zzcm95jmbd9i9aj5i8abr8u5\" }","title":"account_representative"},{"location":"commands/rpc-protocol/#account_weight","text":"Returns the voting weight for account Request: { \"action\" : \"account_weight\" , \"account\" : \"nano_3e3j5tkog48pnny9dmfzj1r16pg8t1e76dz5tmac6iq689wyjfpi00000000\" } Response: { \"weight\" : \"10000\" }","title":"account_weight"},{"location":"commands/rpc-protocol/#accounts_balances","text":"Returns how many RAW is owned and how many have not yet been received by accounts list Unconfirmed information This call returns information that may be based on unconfirmed blocks. These details should not be relied on for any process or integration that requires confirmed blocks. The pending balances are calculated from potentially unconfirmed blocks. Account balances are obtained from their frontiers. An atomic account_info RPC call is recommended for the purposes of creating transactions. Request: { \"action\" : \"accounts_balances\" , \"accounts\" : [ \"nano_3e3j5tkog48pnny9dmfzj1r16pg8t1e76dz5tmac6iq689wyjfpi00000000\" , \"nano_3i1aq1cchnmbn9x5rsbap8b15akfh7wj7pwskuzi7ahz8oq6cobd99d4r3b7\" ] } Response: { \"balances\" : { \"nano_3e3j5tkog48pnny9dmfzj1r16pg8t1e76dz5tmac6iq689wyjfpi00000000\" : { \"balance\" : \"10000\" , \"pending\" : \"10000\" }, \"nano_3i1aq1cchnmbn9x5rsbap8b15akfh7wj7pwskuzi7ahz8oq6cobd99d4r3b7\" : { \"balance\" : \"10000000\" , \"pending\" : \"0\" } } }","title":"accounts_balances"},{"location":"commands/rpc-protocol/#accounts_frontiers","text":"Returns a list of pairs of account and block hash representing the head block for accounts list Includes unconfirmed blocks This call may return results that include unconfirmed blocks, so it should not be used in any processes or integrations requiring only details from blocks confirmed by the network. Request: { \"action\" : \"accounts_frontiers\" , \"accounts\" : [ \"nano_3t6k35gi95xu6tergt6p69ck76ogmitsa8mnijtpxm9fkcm736xtoncuohr3\" , \"nano_3i1aq1cchnmbn9x5rsbap8b15akfh7wj7pwskuzi7ahz8oq6cobd99d4r3b7\" ] } Response: { \"frontiers\" : { \"nano_3t6k35gi95xu6tergt6p69ck76ogmitsa8mnijtpxm9fkcm736xtoncuohr3\" : \"791AF413173EEE674A6FCF633B5DFC0F3C33F397F0DA08E987D9E0741D40D81A\" , \"nano_3i1aq1cchnmbn9x5rsbap8b15akfh7wj7pwskuzi7ahz8oq6cobd99d4r3b7\" : \"6A32397F4E95AF025DE29D9BF1ACE864D5404362258E06489FABDBA9DCCC046F\" } }","title":"accounts_frontiers"},{"location":"commands/rpc-protocol/#accounts_pending","text":"Returns a list of block hashes which have not yet been received by these accounts Optional include_only_confirmed recommended By default this will return blocks not in active elections but unconfirmed (e.g., block was received but node was restarted, election was dropped, new ledger with reset confirmation height). To avoid potential issues related to these situations setting the include_only_confirmed = true is recommended for most use cases. Request: { \"action\" : \"accounts_pending\" , \"accounts\" : [ \"nano_1111111111111111111111111111111111111111111111111117353trpda\" , \"nano_3t6k35gi95xu6tergt6p69ck76ogmitsa8mnijtpxm9fkcm736xtoncuohr3\" ], \"count\" : \"1\" } Response: { \"blocks\" : { \"nano_1111111111111111111111111111111111111111111111111117353trpda\" : [ \"142A538F36833D1CC78B94E11C766F75818F8B940771335C6C1B8AB880C5BB1D\" ], \"nano_3t6k35gi95xu6tergt6p69ck76ogmitsa8mnijtpxm9fkcm736xtoncuohr3\" : [ \"4C1FEEF0BEA7F50BE35489A1233FE002B212DEA554B55B1B470D78BD8F210C74\" ] } } Optional \"threshold\" version 8.0+ Number (128 bit, decimal). Returns a list of pending block hashes with amount more or equal to threshold Request: { \"action\" : \"accounts_pending\" , \"accounts\" : [ \"nano_1111111111111111111111111111111111111111111111111117353trpda\" , \"nano_3t6k35gi95xu6tergt6p69ck76ogmitsa8mnijtpxm9fkcm736xtoncuohr3\" ], \"count\" : \"1\" , \"threshold\" : \"1000000000000000000000000\" } Response: { \"blocks\" : { \"nano_1111111111111111111111111111111111111111111111111117353trpda\" : { \"142A538F36833D1CC78B94E11C766F75818F8B940771335C6C1B8AB880C5BB1D\" : \"6000000000000000000000000000000\" }, \"nano_3t6k35gi95xu6tergt6p69ck76ogmitsa8mnijtpxm9fkcm736xtoncuohr3\" : { \"4C1FEEF0BEA7F50BE35489A1233FE002B212DEA554B55B1B470D78BD8F210C74\" : \"106370018000000000000000000000000\" } } } Optional \"source\" version 9.0+ Boolean, false by default. Returns a list of pending block hashes with amount and source accounts Request: { \"action\" : \"accounts_pending\" , \"accounts\" : [ \"nano_1111111111111111111111111111111111111111111111111117353trpda\" , \"nano_3t6k35gi95xu6tergt6p69ck76ogmitsa8mnijtpxm9fkcm736xtoncuohr3\" ], \"count\" : \"1\" , \"source\" : \"true\" } Response: { \"blocks\" : { \"nano_1111111111111111111111111111111111111111111111111117353trpda\" : { \"142A538F36833D1CC78B94E11C766F75818F8B940771335C6C1B8AB880C5BB1D\" : { \"amount\" : \"6000000000000000000000000000000\" , \"source\" : \"nano_3dcfozsmekr1tr9skf1oa5wbgmxt81qepfdnt7zicq5x3hk65fg4fqj58mbr\" } }, \"nano_3t6k35gi95xu6tergt6p69ck76ogmitsa8mnijtpxm9fkcm736xtoncuohr3\" : { \"4C1FEEF0BEA7F50BE35489A1233FE002B212DEA554B55B1B470D78BD8F210C74\" : { \"amount\" : \"106370018000000000000000000000000\" , \"source\" : \"nano_13ezf4od79h1tgj9aiu4djzcmmguendtjfuhwfukhuucboua8cpoihmh8byo\" } } } } Optional \"include_active\" version 15.0+ Boolean, false by default. Include active (not confirmed) blocks Request: { \"action\" : \"accounts_pending\" , \"accounts\" : [ \"nano_1111111111111111111111111111111111111111111111111117353trpda\" , \"nano_3t6k35gi95xu6tergt6p69ck76ogmitsa8mnijtpxm9fkcm736xtoncuohr3\" ], \"count\" : \"1\" , \"include_active\" : \"true\" } Optional \"sorting\" version 19.0+ Boolean, false by default. Additionally sorts each account's blocks by their amounts in descending order. Optional \"include_only_confirmed\" version 19.0+ Boolean, false by default. Only returns blocks which have their confirmation height set or are undergoing confirmation height processing.","title":"accounts_pending"},{"location":"commands/rpc-protocol/#active_difficulty","text":"version 19.0+ Returns the difficulty values (16 hexadecimal digits string, 64 bit) for the minimum required on the network ( network_minimum ) as well as the current active difficulty seen on the network ( network_current , 10 second trended average of adjusted difficulty seen on prioritized transactions, refreshed every 500ms) which can be used to perform rework for better prioritization of transaction processing. A multiplier of the network_current from the base difficulty of network_minimum is also provided for comparison. network_receive_minimum and network_receive_current are also provided as lower thresholds exclusively for receive blocks. Request: { \"action\" : \"active_difficulty\" } Response: { \"multiplier\" : \"1.5\" , \"network_current\" : \"fffffffaaaaaaaab\" , \"network_minimum\" : \"fffffff800000000\" , \"network_receive_current\" : \"fffffff07c1f07c2\" , // si n ce V 21.2 \"network_receive_minimum\" : \"fffffe0000000000\" // si n ce V 21.2 } Optional \"include_trend\" Boolean, false by default. Also returns the trend of difficulty seen on the network as a list of multipliers . Sampling occurs every 500ms. The list is ordered such that the first value is the most recent sample. Note: Before v20, the sampling period was between 16 and 36 seconds. Request: { \"action\" : \"active_difficulty\" , \"include_trend\" : \"true\" } Response: { ... , \"difficulty_trend\" : [ \"1.156096135149775\" , \"1.190133894573061\" , \"1.135567138563921\" , \"1.000000000000000\" , \"...\" , \"1.000000000000000\" ] }","title":"active_difficulty"},{"location":"commands/rpc-protocol/#available_supply","text":"Returns how many raw are in the public supply Request: { \"action\" : \"available_supply\" } Response: { \"available\" : \"133248061996216572282917317807824970865\" }","title":"available_supply"},{"location":"commands/rpc-protocol/#block_account","text":"Returns the account containing block Request: { \"action\" : \"block_account\" , \"hash\" : \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\" } Response: { \"account\" : \"nano_3e3j5tkog48pnny9dmfzj1r16pg8t1e76dz5tmac6iq689wyjfpi00000000\" }","title":"block_account"},{"location":"commands/rpc-protocol/#block_confirm","text":"version 12.2+ Request confirmation for block from known online representative nodes. Check results with confirmation history . Request: { \"action\" : \"block_confirm\" , \"hash\" : \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\" } Response: { \"started\" : \"1\" }","title":"block_confirm"},{"location":"commands/rpc-protocol/#block_count","text":"Reports the number of blocks in the ledger and unchecked synchronizing blocks Request: { \"action\" : \"block_count\" } Response: { \"count\" : \"1000\" , \"unchecked\" : \"10\" , \"cemented\" : \"25\" } Optional \"include_cemented\" version 19.0+ (enable_control required in version 19.0, not required in version 20.0+) Default \"true\". If \"true\", \"cemented\" in the response will contain the number of cemented blocks. (In V19.0 default was \"false\") Dangerous RPC calls controlled by enable_control This RPC command/option requires enable_control to be enabled within the RPC config file. Enabling this means that anyone with access to the RPC port could potentially access wallet funds , stop the node from running and take other dangerous actions. Use caution when enabling this option, especially with external RPC access available. For more details see the Node Security page .","title":"block_count"},{"location":"commands/rpc-protocol/#block_create","text":"enable_control required, version 9.0+ Creates a json representations of new block based on input data & signed with private key or account in wallet . Use for offline signing. Using the optional json_block is recommended since v19.0. Dangerous RPC calls controlled by enable_control This RPC command/option requires enable_control to be enabled within the RPC config file. Enabling this means that anyone with access to the RPC port could potentially access wallet funds , stop the node from running and take other dangerous actions. Use caution when enabling this option, especially with external RPC access available. For more details see the Node Security page . Request sample for state block: { \"action\" : \"block_create\" , \"json_block\" : \"true\" , \"type\" : \"state\" , \"balance\" : \"1000000000000000000000\" , \"key\" : \"0000000000000000000000000000000000000000000000000000000000000002\" , \"representative\" : \"nano_1hza3f7wiiqa7ig3jczyxj5yo86yegcmqk3criaz838j91sxcckpfhbhhra1\" , \"link\" : \"19D3D919475DEED4696B5D13018151D1AF88B2BD3BCFF048B45031C1F36D1858\" , \"previous\" : \"F47B23107E5F34B2CE06F562B5C435DF72A533251CB414C51B2B62A8F63A00E4\" } Parameters for state block: balance : final balance for account after block creation, formatted in 'raw' units using a decimal integer. If balance is less than previous, block is considered as send subtype! wallet (optional): The wallet ID that the account the block is being created for is in. account (optional): The account the block is being created for (nano_youraccount). key (optional): Instead of using \"wallet\" & \"account\" parameters, you can directly pass in a private key. source (optional): The block hash of the source of funds for this receive block (the send block that this receive block will pocket). destination (optional): The account that the sent funds should be accessible to. link (optional): Instead of using \"source\" & \"destination\" parameters, you can directly pass \"link\" (source to receive or destination public key to send). representative : The account that block account will use as its representative. previous : The block hash of the previous block on this account's block chain (\"0\" for first block). Warning: It is critical that balance is the balance of the account after created block! Optional \"json_block\" version 19.0+ Default \"false\". If \"true\", \"block\" in the response will contain a JSON subtree instead of a JSON string. Examples Response sample for above request : { \"hash\" : \"FF0144381CFF0B2C079A115E7ADA7E96F43FD219446E7524C48D1CC9900C4F17\" , \"difficulty\" : \"ffffffe1278b3dc6\" , // si n ce V 21.0 \"block\" : { \"type\" : \"state\" , \"account\" : \"nano_3qgmh14nwztqw4wmcdzy4xpqeejey68chx6nciczwn9abji7ihhum9qtpmdr\" , \"previous\" : \"F47B23107E5F34B2CE06F562B5C435DF72A533251CB414C51B2B62A8F63A00E4\" , \"representative\" : \"nano_1hza3f7wiiqa7ig3jczyxj5yo86yegcmqk3criaz838j91sxcckpfhbhhra1\" , \"balance\" : \"1000000000000000000000\" , \"link\" : \"19D3D919475DEED4696B5D13018151D1AF88B2BD3BCFF048B45031C1F36D1858\" , \"link_as_account\" : \"nano_18gmu6engqhgtjnppqam181o5nfhj4sdtgyhy36dan3jr9spt84rzwmktafc\" , \"signature\" : \"3BFBA64A775550E6D49DF1EB8EEC2136DCD74F090E2ED658FBD9E80F17CB1C9F9F7BDE2B93D95558EC2F277FFF15FD11E6E2162A1714731B743D1E941FA4560A\" , \"work\" : \"cab7404f0b5449d0\" } } Optional \"work\" Work value (16 hexadecimal digits string, 64 bit). Uses work value for block from external source Optional \"version\" version 21.0+ Work version string. Currently \"work_1\" is the default and only valid option. Only used if optional work is not given. Optional \"difficulty\" version 21.0+ Difficulty value (16 hexadecimal digits string, 64 bit). Uses difficulty value to generate work. Only used if optional work is not given. If difficulty and work values are both not given, RPC processor tries to calculate difficulty for work generation based on ledger data: epoch from previous block or from link for receive subtype; block subtype from previous block balance.","title":"block_create"},{"location":"commands/rpc-protocol/#block_hash","text":"version 13.0+ Returning block hash for given block content. Using the optional json_block is recommended since v19.0. Request: { \"action\" : \"block_hash\" , \"json_block\" : \"true\" , \"block\" : { \"type\" : \"state\" , \"account\" : \"nano_3qgmh14nwztqw4wmcdzy4xpqeejey68chx6nciczwn9abji7ihhum9qtpmdr\" , \"previous\" : \"F47B23107E5F34B2CE06F562B5C435DF72A533251CB414C51B2B62A8F63A00E4\" , \"representative\" : \"nano_1hza3f7wiiqa7ig3jczyxj5yo86yegcmqk3criaz838j91sxcckpfhbhhra1\" , \"balance\" : \"1000000000000000000000\" , \"link\" : \"19D3D919475DEED4696B5D13018151D1AF88B2BD3BCFF048B45031C1F36D1858\" , \"link_as_account\" : \"nano_18gmu6engqhgtjnppqam181o5nfhj4sdtgyhy36dan3jr9spt84rzwmktafc\" , \"signature\" : \"3BFBA64A775550E6D49DF1EB8EEC2136DCD74F090E2ED658FBD9E80F17CB1C9F9F7BDE2B93D95558EC2F277FFF15FD11E6E2162A1714731B743D1E941FA4560A\" , \"work\" : \"cab7404f0b5449d0\" } } Response: { \"hash\" : \"FF0144381CFF0B2C079A115E7ADA7E96F43FD219446E7524C48D1CC9900C4F17\" } Optional \"json_block\" version 19.0+ Default \"false\". If \"true\", \"block\" must contain a JSON subtree instead of a JSON string.","title":"block_hash"},{"location":"commands/rpc-protocol/#block_info","text":"Retrieves a json representation of the block in contents along with: since version 18.0 : block_account , transaction amount , block balance , block height in account chain, block local modification timestamp since version 19.0 : Whether block was confirmed , subtype ( for state blocks ) of send , receive , change or epoch Using the optional json_block is recommended since v19.0. Request: { \"action\" : \"block_info\" , \"json_block\" : \"true\" , \"hash\" : \"87434F8041869A01C8F6F263B87972D7BA443A72E0A97D7A3FD0CCC2358FD6F9\" } Response: { \"block_account\" : \"nano_1ipx847tk8o46pwxt5qjdbncjqcbwcc1rrmqnkztrfjy5k7z4imsrata9est\" , \"amount\" : \"30000000000000000000000000000000000\" , \"balance\" : \"5606157000000000000000000000000000000\" , \"height\" : \"58\" , \"local_timestamp\" : \"0\" , \"confirmed\" : \"true\" , \"contents\" : { \"type\" : \"state\" , \"account\" : \"nano_1ipx847tk8o46pwxt5qjdbncjqcbwcc1rrmqnkztrfjy5k7z4imsrata9est\" , \"previous\" : \"CE898C131AAEE25E05362F247760F8A3ACF34A9796A5AE0D9204E86B0637965E\" , \"representative\" : \"nano_1stofnrxuz3cai7ze75o174bpm7scwj9jn3nxsn8ntzg784jf1gzn1jjdkou\" , \"balance\" : \"5606157000000000000000000000000000000\" , \"link\" : \"5D1AA8A45F8736519D707FCB375976A7F9AF795091021D7E9C7548D6F45DD8D5\" , \"link_as_account\" : \"nano_1qato4k7z3spc8gq1zyd8xeqfbzsoxwo36a45ozbrxcatut7up8ohyardu1z\" , \"signature\" : \"82D41BC16F313E4B2243D14DFFA2FB04679C540C2095FEE7EAE0F2F26880AD56DD48D87A7CC5DD760C5B2D76EE2C205506AA557BF00B60D8DEE312EC7343A501\" , \"work\" : \"8a142e07a10996d5\" }, \"subtype\" : \"send\" } Note: The Balance in contents is a uint128. However, it will be a hex-encoded (like 0000000C9F2C9CD04674EDEA40000000 for 1 Mnano ) when the block is a legacy Send Block . If the block is a State-Block , the same Balance will be a numeric-string (like 1000000000000000000000000000000 ). Optional \"json_block\" version 19.0+ Default \"false\". If \"true\", \"contents\" will contain a JSON subtree instead of a JSON string.","title":"block_info"},{"location":"commands/rpc-protocol/#blocks","text":"Retrieves a json representations of blocks . Using the optional json_block is recommended since v19.0. Request: { \"action\" : \"blocks\" , \"json_block\" : \"true\" , \"hashes\" : [ \"87434F8041869A01C8F6F263B87972D7BA443A72E0A97D7A3FD0CCC2358FD6F9\" ] } Response: { \"blocks\" : { \"87434F8041869A01C8F6F263B87972D7BA443A72E0A97D7A3FD0CCC2358FD6F9\" : { \"type\" : \"state\" , \"account\" : \"nano_1ipx847tk8o46pwxt5qjdbncjqcbwcc1rrmqnkztrfjy5k7z4imsrata9est\" , \"previous\" : \"CE898C131AAEE25E05362F247760F8A3ACF34A9796A5AE0D9204E86B0637965E\" , \"representative\" : \"nano_1stofnrxuz3cai7ze75o174bpm7scwj9jn3nxsn8ntzg784jf1gzn1jjdkou\" , \"balance\" : \"5606157000000000000000000000000000000\" , \"link\" : \"5D1AA8A45F8736519D707FCB375976A7F9AF795091021D7E9C7548D6F45DD8D5\" , \"link_as_account\" : \"nano_1qato4k7z3spc8gq1zyd8xeqfbzsoxwo36a45ozbrxcatut7up8ohyardu1z\" , \"signature\" : \"82D41BC16F313E4B2243D14DFFA2FB04679C540C2095FEE7EAE0F2F26880AD56DD48D87A7CC5DD760C5B2D76EE2C205506AA557BF00B60D8DEE312EC7343A501\" , \"work\" : \"8a142e07a10996d5\" } } } Optional \"json_block\" version 19.0+ Default \"false\". If \"true\", \"contents\" will contain a JSON subtree instead of a JSON string.","title":"blocks"},{"location":"commands/rpc-protocol/#blocks_info","text":"Retrieves a json representations of blocks in contents along with: since version 18.0 : block_account , transaction amount , block balance , block height in account chain, block local modification timestamp since version 19.0 : Whether block was confirmed , subtype ( for state blocks ) of send , receive , change or epoch Using the optional json_block is recommended since v19.0. Request: { \"action\" : \"blocks_info\" , \"json_block\" : \"true\" , \"hashes\" : [ \"87434F8041869A01C8F6F263B87972D7BA443A72E0A97D7A3FD0CCC2358FD6F9\" ] } Response: { \"blocks\" : { \"87434F8041869A01C8F6F263B87972D7BA443A72E0A97D7A3FD0CCC2358FD6F9\" : { \"block_account\" : \"nano_1ipx847tk8o46pwxt5qjdbncjqcbwcc1rrmqnkztrfjy5k7z4imsrata9est\" , \"amount\" : \"30000000000000000000000000000000000\" , \"balance\" : \"5606157000000000000000000000000000000\" , \"height\" : \"58\" , \"local_timestamp\" : \"0\" , \"confirmed\" : \"true\" , \"contents\" : { \"type\" : \"state\" , \"account\" : \"nano_1ipx847tk8o46pwxt5qjdbncjqcbwcc1rrmqnkztrfjy5k7z4imsrata9est\" , \"previous\" : \"CE898C131AAEE25E05362F247760F8A3ACF34A9796A5AE0D9204E86B0637965E\" , \"representative\" : \"nano_1stofnrxuz3cai7ze75o174bpm7scwj9jn3nxsn8ntzg784jf1gzn1jjdkou\" , \"balance\" : \"5606157000000000000000000000000000000\" , \"link\" : \"5D1AA8A45F8736519D707FCB375976A7F9AF795091021D7E9C7548D6F45DD8D5\" , \"link_as_account\" : \"nano_1qato4k7z3spc8gq1zyd8xeqfbzsoxwo36a45ozbrxcatut7up8ohyardu1z\" , \"signature\" : \"82D41BC16F313E4B2243D14DFFA2FB04679C540C2095FEE7EAE0F2F26880AD56DD48D87A7CC5DD760C5B2D76EE2C205506AA557BF00B60D8DEE312EC7343A501\" , \"work\" : \"8a142e07a10996d5\" }, \"subtype\" : \"send\" } } } Optional \"pending\", \"source\", \"balance\" pending, source: version 9.0+ balance: version 12.0+ Booleans, false by default. Additionally checks if block is pending, returns source account for receive & open blocks (0 for send & change blocks), and returns the balance of the account at the time of the block. Request: { \"action\" : \"blocks_info\" , \"hashes\" : [ \"E2FB233EF4554077A7BF1AA85851D5BF0B36965D2B0FB504B2BC778AB89917D3\" ], \"pending\" : \"true\" , \"source\" : \"true\" , \"balance\" : \"true\" } Response: { \"blocks\" : { \"E2FB233EF4554077A7BF1AA85851D5BF0B36965D2B0FB504B2BC778AB89917D3\" : { \"block_account\" : \"nano_1qato4k7z3spc8gq1zyd8xeqfbzsoxwo36a45ozbrxcatut7up8ohyardu1z\" , \"amount\" : \"30000000000000000000000000000000000\" , \"contents\" : { ... }, \"pending\" : \"0\" , \"source_account\" : \"nano_1ipx847tk8o46pwxt5qjdbncjqcbwcc1rrmqnkztrfjy5k7z4imsrata9est\" , \"balance\" : \"40200000001000000000000000000000000\" } } } Optional \"json_block\" version 19.0+ Default \"false\". If \"true\", \"contents\" will contain a JSON subtree instead of a JSON string. Optional \"include_not_found\" version 19.0+ Default \"false\". If \"true\", an additional \"blocks_not_found\" is provided in the response, containing a list of the block hashes that were not found in the local database. Previously to this version an error would be produced if any block was not found. Request: { \"action\" : \"blocks_info\" , \"include_not_found\" : \"true\" , \"hashes\" : [ \"87434F8041869A01C8F6F263B87972D7BA443A72E0A97D7A3FD0CCC2358FD6F9\" , \"0000000000000000000000000000000000000000000000000000000000000001\" ] } Response: { \"blocks\" : { \"87434F8041869A01C8F6F263B87972D7BA443A72E0A97D7A3FD0CCC2358FD6F9\" : { \"block_account\" : \"nano_1ipx847tk8o46pwxt5qjdbncjqcbwcc1rrmqnkztrfjy5k7z4imsrata9est\" , \"amount\" : \"30000000000000000000000000000000000\" , \"balance\" : \"5606157000000000000000000000000000000\" , \"height\" : \"58\" , \"local_timestamp\" : \"0\" , \"confirmed\" : \"false\" , \"contents\" : { ... } } }, \"blocks_not_found\" : [ \"0000000000000000000000000000000000000000000000000000000000000001\" ] }","title":"blocks_info"},{"location":"commands/rpc-protocol/#bootstrap","text":"Initialize bootstrap to specific IP address and port . Not compatible with launch flag --disable_legacy_bootstrap Request: { \"action\" : \"bootstrap\" , \"address\" : \"::ffff:138.201.94.249\" , \"port\" : \"7075\" } Response: { \"success\" : \"\" } Optional \"bypass_frontier_confirmation\" version 20.0+ Default \"false\". If \"true\", frontier confirmation will not be performed for this bootstrap. Normally not to be changed. Optional \"id\" version 21.0+ String, empty by default. Set specific ID for new bootstrap attempt for better tracking.","title":"bootstrap"},{"location":"commands/rpc-protocol/#bootstrap_any","text":"Initialize multi-connection bootstrap to random peers. Not compatible with launch flag --disable_legacy_bootstrap Request: { \"action\" : \"bootstrap_any\" } Response: { \"success\" : \"\" } Optional \"force\" version 20.0+ Boolean, false by default. Manually force closing of all current bootstraps Optional \"id\" version 21.0+ String, empty by default. Set specific ID for new bootstrap attempt for better tracking.","title":"bootstrap_any"},{"location":"commands/rpc-protocol/#bootstrap_lazy","text":"version 17.0+ Initialize lazy bootstrap with given block hash . Not compatible with launch flag --disable_lazy_bootstrap Request: { \"action\" : \"bootstrap_lazy\" , \"hash\" : \"FF0144381CFF0B2C079A115E7ADA7E96F43FD219446E7524C48D1CC9900C4F17\" } Response: { \"started\" : \"1\" } Optional \"force\" Boolean, false by default. Manually force closing of all current bootstraps Optional \"id\" version 21.0+ String, empty by default. Set specific ID for new bootstrap attempt for better tracking.","title":"bootstrap_lazy"},{"location":"commands/rpc-protocol/#bootstrap_status","text":"version 17.0+ Debug purposes only This call is for internal diagnostics/debug purposes only. Do not rely on this interface being stable and do not use in a production system. Returning status of current bootstrap attempt Request: { \"action\" : \"bootstrap_status\" } Response: versions 21.0+ { \"bootstrap_threads\" : \"2\" , \"running_attempts_count\" : \"2\" , \"total_attempts_count\" : \"6\" , \"connections\" : { \"clients\" : \"31\" , \"connections\" : \"45\" , \"idle\" : \"0\" , \"target_connections\" : \"64\" , \"pulls\" : \"1158514\" }, \"attempts\" : [ { \"id\" : \"EE778222D6407F94A666B8A9E03D242D\" , \"mode\" : \"legacy\" , \"started\" : \"true\" , \"pulling\" : \"1158544\" , \"total_blocks\" : \"4311\" , \"requeued_pulls\" : \"7\" , \"frontier_pulls\" : \"0\" , \"frontiers_received\" : \"true\" , \"frontiers_confirmed\" : \"false\" , \"frontiers_confirmation_pending\" : \"false\" , \"duration\" : \"133\" }, { \"id\" : \"291D2CC32F44E004896C4215A6CDEDAFEF317F6AC802C244E8F4B4F2456175CB\" , \"mode\" : \"lazy\" , \"started\" : \"true\" , \"pulling\" : \"1\" , \"total_blocks\" : \"1878\" , \"requeued_pulls\" : \"4\" , \"lazy_blocks\" : \"1878\" , \"lazy_state_backlog\" : \"1\" , \"lazy_balances\" : \"4\" , \"lazy_destinations\" : \"0\" , \"lazy_undefined_links\" : \"0\" , \"lazy_pulls\" : \"13\" , \"lazy_keys\" : \"2\" , \"lazy_key_1\" : \"E6D0B5BD5EBDB3CEC7DBC32EDC3C2DBD5ABA17C54E34485A358BF8948039ED6A\" , \"duration\" : \"17\" } ] } Response V17.0-V20.0 { \"clients\" : \"0\" , \"pulls\" : \"0\" , \"pulling\" : \"0\" , \"connections\" : \"31\" , \"idle\" : \"31\" , \"target_connections\" : \"16\" , \"total_blocks\" : \"13558\" , \"runs_count\" : \"0\" , \"requeued_pulls\" : \"31\" , \"frontiers_received\" : \"true\" , \"frontiers_confirmed\" : \"false\" , \"mode\" : \"legacy\" , \"lazy_blocks\" : \"0\" , \"lazy_state_backlog\" : \"0\" , \"lazy_balances\" : \"0\" , \"lazy_destinations\" : \"0\" , \"lazy_undefined_links\" : \"0\" , \"lazy_pulls\" : \"32\" , \"lazy_keys\" : \"32\" , \"lazy_key_1\" : \"36897874BDA3028DC8544C106BE1394891F23DDDF84DE100FED450F6FBC8122C\" , \"duration\" : \"29\" }","title":"bootstrap_status"},{"location":"commands/rpc-protocol/#chain","text":"Returns a consecutive list of block hashes in the account chain starting at block back to count (direction from frontier back to open block, from newer blocks to older). Will list all blocks back to the open block of this chain when count is set to \"-1\". The requested block hash is included in the answer. Request: { \"action\" : \"chain\" , \"block\" : \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\" , \"count\" : \"1\" } Response: { \"blocks\" : [ \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\" ] } Optional \"offset\" version 18.0+ Number, 0 by default. Return the account chain block hashes offset by the specified number of blocks Optional \"reverse\" version 18.0+ Boolean, false by default. Returns a list of block hashes in the account chain starting at block up to count (direction from open block up to frontier, from older blocks to newer). Equal to successors","title":"chain"},{"location":"commands/rpc-protocol/#confirmation_active","text":"version 16.0+ Returns list of active elections roots (excluding stopped & aborted elections); since V21, also includes the number of unconfirmed and confirmed active elections. Find info about specific root with confirmation_info Note The roots provided are two parts and differ between the first account block and subsequent blocks: First account block (open): 0000000000000000000000000000000000000000000000000000000000000000 + account public key Other blocks: previous hash + previous hash Request: { \"action\" : \"confirmation_active\" } Response: { \"confirmations\" : [ \"8031B600827C5CC05FDC911C28BBAC12A0E096CCB30FA8324F56C123676281B28031B600827C5CC05FDC911C28BBAC12A0E096CCB30FA8324F56C123676281B2\" ], \"unconfirmed\" : \"133\" , // si n ce V 21.0 \"confirmed\" : \"5\" // si n ce V 21.0 } Optional \"announcements\" Number, 0 by default. Returns only active elections with equal or higher announcements count. Useful to find long running elections","title":"confirmation_active"},{"location":"commands/rpc-protocol/#confirmation_height_currently_processing","text":"version 19.0+ Debug purposes only This call is for internal diagnostics/debug purposes only. Do not rely on this interface being stable and do not use in a production system. Returns the hash of the block which is having the confirmation height set for, error otherwise. When a block is being confirmed, it must confirm all blocks in the chain below and iteratively follow all receive blocks. This can take a long time, so it can be useful to find which block was the original being confirmed. Request: { \"action\" : \"confirmation_height_currently_processing\" } Response: { \"hash\" : \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\" }","title":"confirmation_height_currently_processing"},{"location":"commands/rpc-protocol/#confirmation_history","text":"version 12.0+ Debug purposes only This call is for internal diagnostics/debug purposes only. Do not rely on this interface being stable and do not use in a production system. duration, time, confirmation_stats: version 17.0+_ Returns hash, tally weight, election duration (in milliseconds), election confirmation timestamp for recent elections winners; since V20.0, the confirmation request count; since V21.0, the number of blocks and voters. Also returns stats: count of elections in history (limited to 2048) & average duration time. With version 19.0+ confirmation_history_size can be managed in the configuration file to adjust the number of elections to be kept in history and returned by this call. Due to timings inside the node, the default 2048 limit will return all confirmations up to traffic levels of approximately 56 confirmations/sec. To properly track levels above this, increase this value or use the confirmation subscription through the websocket instead. Request: { \"action\" : \"confirmation_history\" } Response: { \"confirmation_stats\" : { \"count\" : \"2\" , \"average\" : \"5000\" }, \"confirmations\" : [ { \"hash\" : \"EA70B32C55C193345D625F766EEA2FCA52D3F2CCE0B3A30838CC543026BB0FEA\" , \"duration\" : \"4000\" , \"time\" : \"1544819986\" , \"tally\" : \"80394786589602980996311817874549318248\" , \"blocks\" : \"1\" , // si n ce V 21.0 \"voters\" : \"37\" , // si n ce V 21.0 \"request_count\" : \"2\" // si n ce V 20.0 }, { \"hash\" : \"F2F8DA6D2CA0A4D78EB043A7A29E12BDE5B4CE7DE1B99A93A5210428EE5B8667\" , \"duration\" : \"6000\" , \"time\" : \"1544819988\" , \"tally\" : \"68921714529890443063672782079965877749\" , \"blocks\" : \"1\" , // si n ce V 21.0 \"voters\" : \"64\" , // si n ce V 21.0 \"request_count\" : \"7\" // si n ce V 20.0 } ] } Optional \"hash\" Valid block hash, filters return for only the provided hash. If there is no confirmation available for that hash anymore, the following return can be expected: { \"confirmation_stats\" : { \"count\" : \"0\" }, \"confirmations\" : \"\" } If the block is unknown on the node, the following error will be returned: \"error\": \"Invalid block hash\"","title":"confirmation_history"},{"location":"commands/rpc-protocol/#confirmation_info","text":"version 16.0+ Returns info about an unconfirmed active election by root . Including announcements count, last winner (initially local ledger block), total tally of voted representatives, concurrent blocks with tally & block contents for each. Using the optional json_block is recommended since v19.0. Note The roots provided are two parts and differ between the first account block and subsequent blocks: First account block (open): 0000000000000000000000000000000000000000000000000000000000000000 + account public key Other blocks: previous hash + previous hash Request: { \"action\" : \"confirmation_info\" , \"json_block\" : \"true\" , \"root\" : \"EE125B1B1D85D3C24636B3590E1642D9F21B166C0C6CD99C9C6087A1224A0C44EE125B1B1D85D3C24636B3590E1642D9F21B166C0C6CD99C9C6087A1224A0C44\" } Response: { \"announcements\" : \"2\" , \"voters\" : \"29\" , \"last_winner\" : \"B94C505029F04BC057A0486ADA8BD07981B4A8736AE6581F2E98C6D18498146F\" , \"total_tally\" : \"51145880360832646375807054724596663794\" , \"blocks\" : { \"B94C505029F04BC057A0486ADA8BD07981B4A8736AE6581F2E98C6D18498146F\" : { \"tally\" : \"51145880360832646375807054724596663794\" , \"contents\" : { \"type\" : \"state\" , \"account\" : \"nano_3fihmbtuod33s4nrbqfczhk9zy9ddqimwjshzg4c3857es8c9631i5rg6h9p\" , \"previous\" : \"EE125B1B1D85D3C24636B3590E1642D9F21B166C0C6CD99C9C6087A1224A0C44\" , \"representative\" : \"nano_3o7uzba8b9e1wqu5ziwpruteyrs3scyqr761x7ke6w1xctohxfh5du75qgaj\" , \"balance\" : \"218195000000000000000000000000\" , \"link\" : \"0000000000000000000000000000000000000000000000000000000000000000\" , \"link_as_account\" : \"nano_1111111111111111111111111111111111111111111111111111hifc8npp\" , \"signature\" : \"B1BD285235C612C5A141FA61793D7C6C762D3F104A85102DED5FBD6B4514971C4D044ACD3EC8C06A9495D8E83B6941B54F8DABA825ADF799412ED9E2C86D7A0C\" , \"work\" : \"05bb28cd8acbe71d\" } } } } Optional \"contents\" Boolean, true by default. Disable contents for each block Optional \"json_block\" version 19.0+ Default \"false\". If \"true\", \"contents\" will contain a JSON subtree instead of a JSON string. Optional \"representatives\" Boolean, false by default. Returns list of votes representatives & its weights for each block Request: { \"action\" : \"confirmation_info\" , \"json_block\" : \"true\" , \"root\" : \"F8BA8CBE61C679231EB06FA03A0CD7CFBE68746396CBBA169BD9E12725682B44\" , \"representatives\" : \"true\" } Response: { \"announcements\" : \"5\" , \"last_winner\" : \"B94C505029F04BC057A0486ADA8BD07981B4A8736AE6581F2E98C6D18498146F\" , \"total_tally\" : \"51145880360792646375807054724596663794\" , \"blocks\" : { \"B94C505029F04BC057A0486ADA8BD07981B4A8736AE6581F2E98C6D18498146F\" : { \"tally\" : \"51145880360792646375807054724596663794\" , \"contents\" : { \"type\" : \"state\" , \"account\" : \"nano_3fihmbtuod33s4nrbqfczhk9zy9ddqimwjshzg4c3857es8c9631i5rg6h9p\" , \"previous\" : \"EE125B1B1D85D3C24636B3590E1642D9F21B166C0C6CD99C9C6087A1224A0C44\" , \"representative\" : \"nano_3o7uzba8b9e1wqu5ziwpruteyrs3scyqr761x7ke6w1xctohxfh5du75qgaj\" , \"balance\" : \"218195000000000000000000000000\" , \"link\" : \"0000000000000000000000000000000000000000000000000000000000000000\" , \"link_as_account\" : \"nano_1111111111111111111111111111111111111111111111111111hifc8npp\" , \"signature\" : \"B1BD285235C612C5A141FA61793D7C6C762D3F104A85102DED5FBD6B4514971C4D044ACD3EC8C06A9495D8E83B6941B54F8DABA825ADF799412ED9E2C86D7A0C\" , \"work\" : \"05bb28cd8acbe71d\" }, \"representatives\" : { \"nano_3pczxuorp48td8645bs3m6c3xotxd3idskrenmi65rbrga5zmkemzhwkaznh\" : \"12617828599372664613607727105312358589\" , \"nano_1stofnrxuz3cai7ze75o174bpm7scwj9jn3nxsn8ntzg784jf1gzn1jjdkou\" : \"5953738757270291536911559258663615240\" , ... \"nano_3i4n5n6c6xssapbdtkdoutm88c5zjmatc5tc77xyzdkpef8akid9errcpjnx\" : \"0\" } } } }","title":"confirmation_info"},{"location":"commands/rpc-protocol/#confirmation_quorum","text":"version 16.0+ Returns information about node elections settings & observed network state: delta tally required to rollback block, percentage of online weight for delta, minimum online weight to confirm block, currently observed online total weight, known peers total weight Request: { \"action\" : \"confirmation_quorum\" } Response: { \"quorum_delta\" : \"41469707173777717318245825935516662250\" , \"online_weight_quorum_percent\" : \"50\" , \"online_weight_minimum\" : \"60000000000000000000000000000000000000\" , \"online_stake_total\" : \"82939414347555434636491651871033324568\" , \"peers_stake_total\" : \"69026910610720098597176027400951402360\" , \"peers_stake_required\" : \"60000000000000000000000000000000000000\" } Optional \"peer_details\" version 17.0+ Boolean, false by default. If true, add account/ip/rep weight for each peer considered in the summation of peers_stake_total . Response field \"peers_stake_required\" version 19.0+ The effective stake needed from directly connected peers for quorum. Per v19, this field is computed as max(quorum_delta, online_weight_minimum) . If peers_stake_total is lower than this value, the node will not mark blocks as confirmed.","title":"confirmation_quorum"},{"location":"commands/rpc-protocol/#database_txn_tracker","text":"v19.0+ Debug purposes only This call is for internal diagnostics/debug purposes only. Do not rely on this interface being stable and do not use in a production system. Returns a list of open database transactions which are equal or greater than the min_read_time or min_write_time for reads and read-writes respectively. Request: { \"action\" : \"database_txn_tracker\" , \"min_read_time\" : \"1000\" , \"min_write_time\" : \"0\" } Response on Windows/Debug: { \"txn_tracking\" : [ { \"thread\" : \"Blck processing\" , // Which t hread held t he transa c t io n \"time_held_open\" : \"2\" , // Seco n ds t he transa c t io n has curre ntl y bee n held ope n f or \"write\" : \"true\" , // I f true i t is a wri te lock , o t herwise false . \"stacktrace\" : [ { \"name\" : \"nano::mdb_store::tx_begin_write\" , \"address\" : \"00007FF7142C5F86\" , \"source_file\" : \"c:\\\\users\\\\wesley\\\\documents\\\\raiblocks\\\\nano\\\\node\\\\lmdb.cpp\" , \"source_line\" : \"825\" }, { \"name\" : \"nano::block_processor::process_batch\" , \"address\" : \"00007FF714121EEA\" , \"source_file\" : \"c:\\\\users\\\\wesley\\\\documents\\\\raiblocks\\\\nano\\\\node\\\\blockprocessor.cpp\" , \"source_line\" : \"243\" }, { \"name\" : \"nano::block_processor::process_blocks\" , \"address\" : \"00007FF71411F8A6\" , \"source_file\" : \"c:\\\\users\\\\wesley\\\\documents\\\\raiblocks\\\\nano\\\\node\\\\blockprocessor.cpp\" , \"source_line\" : \"103\" }, ... ] } ... // o t her t hreads ] }","title":"database_txn_tracker"},{"location":"commands/rpc-protocol/#delegators","text":"version 8.0+ Returns a list of pairs of delegator names given account a representative and its balance Request: { \"action\" : \"delegators\" , \"account\" : \"nano_1111111111111111111111111111111111111111111111111117353trpda\" } Response: { \"delegators\" : { \"nano_13bqhi1cdqq8yb9szneoc38qk899d58i5rcrgdk5mkdm86hekpoez3zxw5sd\" : \"500000000000000000000000000000000000\" , \"nano_17k6ug685154an8gri9whhe5kb5z1mf5w6y39gokc1657sh95fegm8ht1zpn\" : \"961647970820730000000000000000000000\" } }","title":"delegators"},{"location":"commands/rpc-protocol/#delegators_count","text":"version 8.0+ Get number of delegators for a specific representative account Request: { \"action\" : \"delegators_count\" , \"account\" : \"nano_1111111111111111111111111111111111111111111111111117353trpda\" } Response: { \"count\" : \"2\" }","title":"delegators_count"},{"location":"commands/rpc-protocol/#deterministic_key","text":"Derive deterministic keypair from seed based on index Request: { \"action\" : \"deterministic_key\" , \"seed\" : \"0000000000000000000000000000000000000000000000000000000000000000\" , \"index\" : \"0\" } Response: { \"private\" : \"9F0E444C69F77A49BD0BE89DB92C38FE713E0963165CCA12FAF5712D7657120F\" , \"public\" : \"C008B814A7D269A1FA3C6528B19201A24D797912DB9996FF02A1FF356E45552B\" , \"account\" : \"nano_3i1aq1cchnmbn9x5rsbap8b15akfh7wj7pwskuzi7ahz8oq6cobd99d4r3b7\" }","title":"deterministic_key"},{"location":"commands/rpc-protocol/#epoch_upgrade","text":"enable_control required, version 20.0+ Debug purposes only This call is for internal diagnostics/debug purposes only. Do not rely on this interface being stable and do not use in a production system. Upgrade network to new epoch with epoch signer private key Dangerous RPC calls controlled by enable_control This RPC command/option requires enable_control to be enabled within the RPC config file. Enabling this means that anyone with access to the RPC port could potentially access wallet funds , stop the node from running and take other dangerous actions. Use caution when enabling this option, especially with external RPC access available. For more details see the Node Security page . Request: { \"action\" : \"epoch_upgrade\" , \"epoch\" : \"1\" , \"key\" : \"0000000000000000000000000000000000000000000000000000000000000000\" } Response: { \"started\" : \"1\" } Optional \"count\" Number. Determines limit of number of accounts to upgrade. Optional \"threads\" version 21.0+ Number. Determines limit of work threads to use for concurrent upgrade processes (useful with multiple work peers or high work peer latency).","title":"epoch_upgrade"},{"location":"commands/rpc-protocol/#frontier_count","text":"Reports the number of accounts in the ledger Request: { \"action\" : \"frontier_count\" } Response: { \"count\" : \"920471\" }","title":"frontier_count"},{"location":"commands/rpc-protocol/#frontiers","text":"Returns a list of pairs of account and block hash representing the head block starting at account up to count Request: { \"action\" : \"frontiers\" , \"account\" : \"nano_1111111111111111111111111111111111111111111111111111hifc8npp\" , \"count\" : \"1\" } Response: { \"frontiers\" : { \"nano_3e3j5tkog48pnny9dmfzj1r16pg8t1e76dz5tmac6iq689wyjfpi00000000\" : \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\" } }","title":"frontiers"},{"location":"commands/rpc-protocol/#keepalive","text":"enable_control required Tells the node to send a keepalive packet to address : port Dangerous RPC calls controlled by enable_control This RPC command/option requires enable_control to be enabled within the RPC config file. Enabling this means that anyone with access to the RPC port could potentially access wallet funds , stop the node from running and take other dangerous actions. Use caution when enabling this option, especially with external RPC access available. For more details see the Node Security page . Request: { \"action\" : \"keepalive\" , \"address\" : \"::ffff:192.169.0.1\" , \"port\" : \"1024\" } Response: { \"started\" : \"1\" }","title":"keepalive"},{"location":"commands/rpc-protocol/#key_create","text":"Generates an adhoc random keypair Request: { \"action\" : \"key_create\" } Response: { \"private\" : \"781186FB9EF17DB6E3D1056550D9FAE5D5BBADA6A6BC370E4CBB938B1DC71DA3\" , \"public\" : \"3068BB1CA04525BB0E416C485FE6A67FD52540227D267CC8B6E8DA958A7FA039\" , \"account\" : \"nano_1e5aqegc1jb7qe964u4adzmcezyo6o146zb8hm6dft8tkp79za3sxwjym5rx\" }","title":"key_create"},{"location":"commands/rpc-protocol/#key_expand","text":"Derive public key and account number from private key Request: { \"action\" : \"key_expand\" , \"key\" : \"781186FB9EF17DB6E3D1056550D9FAE5D5BBADA6A6BC370E4CBB938B1DC71DA3\" } Response: { \"private\" : \"781186FB9EF17DB6E3D1056550D9FAE5D5BBADA6A6BC370E4CBB938B1DC71DA3\" , \"public\" : \"3068BB1CA04525BB0E416C485FE6A67FD52540227D267CC8B6E8DA958A7FA039\" , \"account\" : \"nano_1e5aqegc1jb7qe964u4adzmcezyo6o146zb8hm6dft8tkp79za3sxwjym5rx\" }","title":"key_expand"},{"location":"commands/rpc-protocol/#ledger","text":"enable_control required, version 9.0+ Returns frontier, open block, change representative block, balance, last modified timestamp from local database & block count starting at account up to count Dangerous RPC calls controlled by enable_control This RPC command/option requires enable_control to be enabled within the RPC config file. Enabling this means that anyone with access to the RPC port could potentially access wallet funds , stop the node from running and take other dangerous actions. Use caution when enabling this option, especially with external RPC access available. For more details see the Node Security page . Includes unconfirmed blocks This call may return results that include unconfirmed blocks, so it should not be used in any processes or integrations requiring only details from blocks confirmed by the network. Request: { \"action\" : \"ledger\" , \"account\" : \"nano_1111111111111111111111111111111111111111111111111111hifc8npp\" , \"count\" : \"1\" } Response: { \"accounts\" : { \"nano_11119gbh8hb4hj1duf7fdtfyf5s75okzxdgupgpgm1bj78ex3kgy7frt3s9n\" : { \"frontier\" : \"E71AF3E9DD86BBD8B4620EFA63E065B34D358CFC091ACB4E103B965F95783321\" , \"open_block\" : \"643B77F1ECEFBDBE1CC909872964C1DBBE23A6149BD3CEF2B50B76044659B60F\" , \"representative_block\" : \"643B77F1ECEFBDBE1CC909872964C1DBBE23A6149BD3CEF2B50B76044659B60F\" , \"balance\" : \"0\" , \"modified_timestamp\" : \"1511476234\" , \"block_count\" : \"2\" } } } Optional \"representative\", \"weight\", \"pending\" Booleans, false by default. Additionally returns representative, voting weight, pending balance for each account Request: { \"action\" : \"ledger\" , \"account\" : \"nano_1111111111111111111111111111111111111111111111111111hifc8npp\" , \"count\" : \"1\" , \"representative\" : \"true\" , \"weight\" : \"true\" , \"pending\" : \"true\" } Response: { \"accounts\" : { \"nano_11119gbh8hb4hj1duf7fdtfyf5s75okzxdgupgpgm1bj78ex3kgy7frt3s9n\" : { \"frontier\" : \"E71AF3E9DD86BBD8B4620EFA63E065B34D358CFC091ACB4E103B965F95783321\" , \"open_block\" : \"643B77F1ECEFBDBE1CC909872964C1DBBE23A6149BD3CEF2B50B76044659B60F\" , \"representative_block\" : \"643B77F1ECEFBDBE1CC909872964C1DBBE23A6149BD3CEF2B50B76044659B60F\" , \"balance\" : \"0\" , \"modified_timestamp\" : \"1511476234\" , \"block_count\" : \"2\" , \"representative\" : \"nano_1anrzcuwe64rwxzcco8dkhpyxpi8kd7zsjc1oeimpc3ppca4mrjtwnqposrs\" , \"weight\" : \"0\" , \"pending\" : \"0\" } } } Optional \"modified_since\" version 11.0+ UNIX timestamp (number), 0 by default. Return only accounts modified in local database after specific timestamp Optional \"sorting\" Boolean, false by default. Additional sorting accounts in descending order NOTE: The \"count\" option is ignored if \"sorting\" is specified Optional \"threshold\" version 19.0+ Number (128 bit, decimal), default 0. Return only accounts with balance above threshold . If pending is also given, the number compared with the threshold is the sum of account balance and pending balance.","title":"ledger"},{"location":"commands/rpc-protocol/#node_id","text":"enable_control required, version 17.0+ Debug purposes only This call is for internal diagnostics/debug purposes only. Do not rely on this interface being stable and do not use in a production system. Derive private key, public key and node ID number with checksum (similar to account representation). \"as_account\" field is deprecated version 20.0 will generate the node_id with node_ prefix, earlier versions will generate with nano_ prefix Dangerous RPC calls controlled by enable_control This RPC command/option requires enable_control to be enabled within the RPC config file. Enabling this means that anyone with access to the RPC port could potentially access wallet funds , stop the node from running and take other dangerous actions. Use caution when enabling this option, especially with external RPC access available. For more details see the Node Security page . Request: { \"action\" : \"node_id\" } Response: { \"private\" : \"2AD75C9DC20EA497E41722290C4DC966ECC4D6C75CAA4E447961F918FD73D8C7\" , \"public\" : \"78B11E1777B8E7DF9090004376C3EDE008E84680A497C0805F68CA5928626E1C\" , \"as_account\" : \"nano_1y7j5rdqhg99uyab1145gu3yur1ax35a3b6qr417yt8cd6n86uiw3d4whty3\" , \"node_id\" : \"node_1y7j5rdqhg99uyab1145gu3yur1ax35a3b6qr417yt8cd6n86uiw3d4whty3\" }","title":"node_id"},{"location":"commands/rpc-protocol/#node_id_delete","text":"enable_control required, version 17.0+ Debug purposes only This call is for internal diagnostics/debug purposes only. Do not rely on this interface being stable and do not use in a production system. Removing node ID (restart required to take effect) Dangerous RPC calls controlled by enable_control This RPC command/option requires enable_control to be enabled within the RPC config file. Enabling this means that anyone with access to the RPC port could potentially access wallet funds , stop the node from running and take other dangerous actions. Use caution when enabling this option, especially with external RPC access available. For more details see the Node Security page . Request: { \"action\" : \"node_id_delete\" } Response: { \"deprecated\" : \"1\" }","title":"node_id_delete"},{"location":"commands/rpc-protocol/#peers","text":"Returns a list of pairs of online peer IPv6:port and its node protocol network version Request: { \"action\" : \"peers\" } Response version 8.0+: { \"peers\" : { \"[::ffff:172.17.0.1]:32841\" : \"16\" } } Response before version 8.0: { \"peers\" : [ \"[::ffff:172.17.0.1]:32841\" ] } Optional \"peer_details\" version 18.0+ Boolean, false by default. Returns a list of peers IPv6:port with its node protocol network version and node ID. The node ID is random and is not a Nano address. type returned in version 19.0+ as either tcp (preferred) or udp (fallback) used for peering with that node. version 20.0 will generate the node_id with node_ prefix, earlier versions will generate with nano_ prefix Response: { \"peers\" : { \"[::ffff:172.17.0.1]:32841\" : { \"protocol_version\" : \"16\" , \"node_id\" : \"node_1y7j5rdqhg99uyab1145gu3yur1ax35a3b6qr417yt8cd6n86uiw3d4whty3\" , \"type\" : \"udp\" } } }","title":"peers"},{"location":"commands/rpc-protocol/#pending","text":"Returns a list of block hashes which have not yet been received by this account. Optional include_only_confirmed recommended By default this will return blocks not in active elections but unconfirmed (e.g., block was received but node was restarted, election was dropped, new ledger with reset confirmation height). To avoid potential issues related to these situations setting the include_only_confirmed = true is recommended for most use cases. Request: { \"action\" : \"pending\" , \"account\" : \"nano_1111111111111111111111111111111111111111111111111117353trpda\" , \"count\" : \"1\" } Response: { \"blocks\" : [ \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\" ] } Optional \"count\" Number. Determines limit of number of blocks to return. Optional \"threshold\" version 8.0+ Number (128 bit, decimal). Returns a list of pending block hashes with amount more or equal to threshold Request: { \"action\" : \"pending\" , \"account\" : \"nano_1111111111111111111111111111111111111111111111111117353trpda\" , \"count\" : \"1\" , \"threshold\" : \"1000000000000000000000000\" } Response: { \"blocks\" : { \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\" : \"6000000000000000000000000000000\" } } Optional \"source\" version 9.0+ Boolean, false by default. Returns a list of pending block hashes with amount and source accounts Request: { \"action\" : \"pending\" , \"account\" : \"nano_1111111111111111111111111111111111111111111111111117353trpda\" , \"count\" : \"1\" , \"source\" : \"true\" } Response: { \"blocks\" : { \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\" : { \"amount\" : \"6000000000000000000000000000000\" , \"source\" : \"nano_3dcfozsmekr1tr9skf1oa5wbgmxt81qepfdnt7zicq5x3hk65fg4fqj58mbr\" } } } Optional \"include_active\" version 15.0+ Boolean, false by default. Include active blocks without finished confirmations Request: { \"action\" : \"pending\" , \"account\" : \"nano_1111111111111111111111111111111111111111111111111117353trpda\" , \"count\" : \"1\" , \"include_active\" : \"true\" } Optional \"min_version\" version 15.0+ Boolean, false by default. Returns the minimum version (epoch) of a block which can pocket this pending block. Optional \"sorting\" Boolean, false by default. Additionally sorts the blocks by their amounts in descending order. version 22.0+ If used with \"count\" returns the absolute sorted values. version 19.0+ If used with \"count\" only sorts relative to the first pending entries found up to count so not necessarily the ones with the largest pending balance. Optional \"include_only_confirmed\" version 19.0+ Boolean, false by default. Only returns block which have their confirmation height set or are undergoing confirmation height processing.","title":"pending"},{"location":"commands/rpc-protocol/#pending_exists","text":"version 8.0+ Check whether block is pending by hash Request: { \"action\" : \"pending_exists\" , \"hash\" : \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\" } Response: { \"exists\" : \"1\" } Optional \"include_active\" version 15.0+ Boolean, false by default. Include active blocks without finished confirmations Request: { \"action\" : \"pending_exists\" , \"hash\" : \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\" , \"include_active\" : \"true\" } Optional \"include_only_confirmed\" version 19.0+ Boolean, false by default. Only returns hashes which have their confirmation height set or are undergoing confirmation height processing.","title":"pending_exists"},{"location":"commands/rpc-protocol/#process","text":"Publish block to the network. Using the optional json_block is recommended since v19.0. Since v20.0, blocks are watched for confirmation by default (see optional watch_work ). Including subtype in process RPC calls highly recommended In order to avoid potential incorrect sends including the optional subtype parameter on all process RPC calls is highly recommended . In the next version of the RPC this parameter will be required. Request: { \"action\" : \"process\" , \"json_block\" : \"true\" , \"subtype\" : \"send\" , \"block\" : { \"type\" : \"state\" , \"account\" : \"nano_1qato4k7z3spc8gq1zyd8xeqfbzsoxwo36a45ozbrxcatut7up8ohyardu1z\" , \"previous\" : \"6CDDA48608C7843A0AC1122BDD46D9E20E21190986B19EAC23E7F33F2E6A6766\" , \"representative\" : \"nano_3pczxuorp48td8645bs3m6c3xotxd3idskrenmi65rbrga5zmkemzhwkaznh\" , \"balance\" : \"40200000001000000000000000000000000\" , \"link\" : \"87434F8041869A01C8F6F263B87972D7BA443A72E0A97D7A3FD0CCC2358FD6F9\" , \"link_as_account\" : \"nano_33t5by1653nt196hfwm5q3wq7oxtaix97r7bhox5zn8eratrzoqsny49ftsd\" , \"signature\" : \"A5DB164F6B81648F914E49CAB533900C389FAAD64FBB24F6902F9261312B29F730D07E9BCCD21D918301419B4E05B181637CF8419ED4DCBF8EF2539EB2467F07\" , \"work\" : \"000bc55b014e807d\" } } Response: { \"hash\" : \"E2FB233EF4554077A7BF1AA85851D5BF0B36965D2B0FB504B2BC778AB89917D3\" } Optional \"force\" version 13.1+ Boolean, false by default. Manually forcing fork resolution if processed block is not accepted as fork Optional \"subtype\" version 18.0+ String, empty by default. Additional check for state blocks subtype, i.e. prevent accidental sending to incorrect accounts instead of receiving pending blocks. Options: send - account balance is reduced receive - account balance is increased open - first block on account with account balance initially set higher than 0 change - account balance is unchanged, representative field value changed to valid public address epoch - block signed with epoch signer private key (does not allow balance or representative changes) Optional \"json_block\" version 19.0+ Default \"false\". If \"true\", \"block\" must contain a JSON subtree instead of a JSON string. Optional \"watch_work\" version 20.0+ Default \"true\". If \"true\", block will be placed on watch for confirmation, with equivalent functionality to in-wallet transactions using send , receive and account_representative_set , including republishing and rework if confirmation is delayed (default is 5 seconds, set by work_watcher_period config entry) and if active_difficulty is higher than the block's PoW difficulty.","title":"process"},{"location":"commands/rpc-protocol/#representatives","text":"Returns a list of pairs of representative and its voting weight Request: { \"action\" : \"representatives\" } Response: { \"representatives\" : { \"nano_1111111111111111111111111111111111111111111111111117353trpda\" : \"3822372327060170000000000000000000000\" , \"nano_1111111111111111111111111111111111111111111111111awsq94gtecn\" : \"30999999999999999999999999000000\" , \"nano_114nk4rwjctu6n6tr6g6ps61g1w3hdpjxfas4xj1tq6i8jyomc5d858xr1xi\" : \"0\" } } Optional \"count\" version 9.0+ Number. Returns a list of pairs of representative and its voting weight up to count Optional \"sorting\" version 9.0+ Boolean, false by default. Additional sorting representatives in descending order NOTE: The \"count\" option is ignored if \"sorting\" is specified","title":"representatives"},{"location":"commands/rpc-protocol/#representatives_online","text":"version 18.0+ Returns a list of online representative accounts that have voted recently Request: { \"action\" : \"representatives_online\" } Response: { \"representatives\" : [ \"nano_1111111111111111111111111111111111111111111111111117353trpda\" , \"nano_1111111111111111111111111111111111111111111111111awsq94gtecn\" , \"nano_114nk4rwjctu6n6tr6g6ps61g1w3hdpjxfas4xj1tq6i8jyomc5d858xr1xi\" ] } versions 11.2\u201317.1 Returns a list of pairs of online representative accounts that have voted recently and empty strings Response: { \"representatives\" : { \"nano_1111111111111111111111111111111111111111111111111117353trpda\" : \"\" , \"nano_1111111111111111111111111111111111111111111111111awsq94gtecn\" : \"\" , \"nano_114nk4rwjctu6n6tr6g6ps61g1w3hdpjxfas4xj1tq6i8jyomc5d858xr1xi\" : \"\" } } Optional \"weight\" version 17.0+ Boolean, false by default. Returns voting weight for each representative. Response: { \"representatives\" : { \"nano_114nk4rwjctu6n6tr6g6ps61g1w3hdpjxfas4xj1tq6i8jyomc5d858xr1xi\" : { \"weight\" : \"150462654614686936429917024683496890\" } } }","title":"representatives_online"},{"location":"commands/rpc-protocol/#republish","text":"Rebroadcast blocks starting at hash to the network Request: { \"action\" : \"republish\" , \"hash\" : \"991CF190094C00F0B68E2E5F75F6BEE95A2E0BD93CEAA4A6734DB9F19B728948\" } Response: { \"success\" : \"\" , \"blocks\" : [ \"991CF190094C00F0B68E2E5F75F6BEE95A2E0BD93CEAA4A6734DB9F19B728948\" , \"A170D51B94E00371ACE76E35AC81DC9405D5D04D4CEBC399AEACE07AE05DD293\" ] } Optional \"sources\" version 8.0+ Boolean, false by default. Additionally rebroadcast source chain blocks for receive/open up to sources depth Request: { \"action\" : \"republish\" , \"hash\" : \"90D0C16AC92DD35814E84BFBCC739A039615D0A42A76EF44ADAEF1D99E9F8A35\" , \"count\" : \"1\" , \"sources\" : \"2\" } Response: { \"blocks\" : [ \"991CF190094C00F0B68E2E5F75F6BEE95A2E0BD93CEAA4A6734DB9F19B728948\" , \"A170D51B94E00371ACE76E35AC81DC9405D5D04D4CEBC399AEACE07AE05DD293\" , \"90D0C16AC92DD35814E84BFBCC739A039615D0A42A76EF44ADAEF1D99E9F8A35\" ] } Optional \"destinations\" version 8.0+ Boolean, false by default. Additionally rebroadcast destination chain blocks from receive up to destinations depth Request: { \"action\" : \"republish\" , \"hash\" : \"A170D51B94E00371ACE76E35AC81DC9405D5D04D4CEBC399AEACE07AE05DD293\" , \"count\" : \"1\" , \"destinations\" : \"2\" } Response: { \"blocks\" : [ \"A170D51B94E00371ACE76E35AC81DC9405D5D04D4CEBC399AEACE07AE05DD293\" , \"90D0C16AC92DD35814E84BFBCC739A039615D0A42A76EF44ADAEF1D99E9F8A35\" , \"18563C814A54535B7C12BF76A0E23291BA3769536634AB90AD0305776A533E8E\" ] }","title":"republish"},{"location":"commands/rpc-protocol/#sign","text":"version 18.0+ Signing provided block with private key or key of account from wallet . Using the optional json_block is recommended since v19.0. Request with private key: { \"action\" : \"sign\" , \"json_block\" : \"true\" , \"key\" : \"1D3759BB2CA187A66875D3B8497624159A576FD315E07F702B99B92BC59FC14A\" , \"block\" : { \"type\" : \"state\" , \"account\" : \"nano_1qato4k7z3spc8gq1zyd8xeqfbzsoxwo36a45ozbrxcatut7up8ohyardu1z\" , \"previous\" : \"6CDDA48608C7843A0AC1122BDD46D9E20E21190986B19EAC23E7F33F2E6A6766\" , \"representative\" : \"nano_3pczxuorp48td8645bs3m6c3xotxd3idskrenmi65rbrga5zmkemzhwkaznh\" , \"balance\" : \"40200000001000000000000000000000000\" , \"link\" : \"87434F8041869A01C8F6F263B87972D7BA443A72E0A97D7A3FD0CCC2358FD6F9\" , \"link_as_account\" : \"nano_33t5by1653nt196hfwm5q3wq7oxtaix97r7bhox5zn8eratrzoqsny49ftsd\" , \"signature\" : \"A5DB164F6B81648F914E49CAB533900C389FAAD64FBB24F6902F9261312B29F730D07E9BCCD21D918301419B4E05B181637CF8419ED4DCBF8EF2539EB2467F07\" , \"work\" : \"000bc55b014e807d\" } } Request with account from wallet: { \"action\" : \"sign\" , \"json_block\" : \"true\" , \"wallet\" : \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\" , \"account\" : \"nano_18ky5chy5ws89oi46ki4zjy6x5ezpmj98zg6icwke9bmuy99nosieyqf8c1h\" , \"block\" : { \"type\" : \"state\" , \"account\" : \"nano_1qato4k7z3spc8gq1zyd8xeqfbzsoxwo36a45ozbrxcatut7up8ohyardu1z\" , \"previous\" : \"6CDDA48608C7843A0AC1122BDD46D9E20E21190986B19EAC23E7F33F2E6A6766\" , \"representative\" : \"nano_3pczxuorp48td8645bs3m6c3xotxd3idskrenmi65rbrga5zmkemzhwkaznh\" , \"balance\" : \"40200000001000000000000000000000000\" , \"link\" : \"87434F8041869A01C8F6F263B87972D7BA443A72E0A97D7A3FD0CCC2358FD6F9\" , \"link_as_account\" : \"nano_33t5by1653nt196hfwm5q3wq7oxtaix97r7bhox5zn8eratrzoqsny49ftsd\" , \"signature\" : \"A5DB164F6B81648F914E49CAB533900C389FAAD64FBB24F6902F9261312B29F730D07E9BCCD21D918301419B4E05B181637CF8419ED4DCBF8EF2539EB2467F07\" , \"work\" : \"000bc55b014e807d\" } } Response: { \"signature\" : \"2A71F3877033F5966735F260E906BFCB7FA82CDD543BCD1224F180F85A96FC26CB3F0E4180E662332A0DFE4EE6A0F798A71C401011E635604E532383EC08C70D\" , \"block\" : { \"type\" : \"state\" , \"account\" : \"nano_1qato4k7z3spc8gq1zyd8xeqfbzsoxwo36a45ozbrxcatut7up8ohyardu1z\" , \"previous\" : \"6CDDA48608C7843A0AC1122BDD46D9E20E21190986B19EAC23E7F33F2E6A6766\" , \"representative\" : \"nano_3pczxuorp48td8645bs3m6c3xotxd3idskrenmi65rbrga5zmkemzhwkaznh\" , \"balance\" : \"40200000001000000000000000000000000\" , \"link\" : \"87434F8041869A01C8F6F263B87972D7BA443A72E0A97D7A3FD0CCC2358FD6F9\" , \"link_as_account\" : \"nano_33t5by1653nt196hfwm5q3wq7oxtaix97r7bhox5zn8eratrzoqsny49ftsd\" , \"signature\" : \"2A71F3877033F5966735F260E906BFCB7FA82CDD543BCD1224F180F85A96FC26CB3F0E4180E662332A0DFE4EE6A0F798A71C401011E635604E532383EC08C70D\" , \"work\" : \"000bc55b014e807d\" } } Optional \"json_block\" version 19.0+ Default \"false\". If \"true\", the input \"block\" must contain a JSON subtree instead of a JSON string. In addition, the response block will be a JSON subtree. Optional sign block hash Requires configuration changes. Set \"rpc.enable_sign_hash\" to \"true\" Request: { \"action\" : \"sign\" , \"hash\" : \"E2FB233EF4554077A7BF1AA85851D5BF0B36965D2B0FB504B2BC778AB89917D3\" } Response: { \"signature\" : \"2A71F3877033F5966735F260E906BFCB7FA82CDD543BCD1224F180F85A96FC26CB3F0E4180E662332A0DFE4EE6A0F798A71C401011E635604E532383EC08C70D\" }","title":"sign"},{"location":"commands/rpc-protocol/#stats","text":"version 12.2+ For configuration and other details, please see Statistics from RPC Request counters: { \"action\" : \"stats\" , \"type\" : \"counters\" } Counters response: { \"type\" : \"counters\" , \"created\" : \"2018.03.29 01:46:36\" , \"entries\" : [ { \"time\" : \"01:46:36\" , \"type\" : \"traffic_tcp\" , \"detail\" : \"all\" , \"dir\" : \"in\" , \"value\" : \"3122792\" }, { \"time\" : \"01:46:36\" , \"type\" : \"traffic_tcp\" , \"detail\" : \"all\" , \"dir\" : \"out\" , \"value\" : \"203184\" } ... ] } version 18.0+ also returns \"stat_duration_seconds\": the number of seconds since startup or since the last \"stats_clear\" call Request samples: { \"action\" : \"stats\" , \"type\" : \"samples\" } Samples response: { \"type\" : \"samples\" , \"created\" : \"2018.03.29 01:47:08\" , \"entries\" : [ { \"time\" : \"01:47:04\" , \"type\" : \"traffic_tcp\" , \"detail\" : \"all\" , \"dir\" : \"in\" , \"value\" : \"59480\" }, { \"time\" : \"01:47:05\" , \"type\" : \"traffic_tcp\" , \"detail\" : \"all\" , \"dir\" : \"in\" , \"value\" : \"44496\" } ... ] } version 18.0+ NOTE: This call is for debug purposes only and is unstable as returned objects may be frequently changed. Request objects: { \"action\" : \"stats\" , \"type\" : \"objects\" } Objects response: { \"node\" : { \"ledger\" : { \"bootstrap_weights\" : { \"count\" : \"125\" , \"size\" : \"7000\" } }, \"peers\" : { \"peers\" : { \"count\" : \"38\" , \"size\" : \"7296\" }, \"attempts\" : { \"count\" : \"95\" , \"size\" : \"3800\" }, }, ... } } version 22.0+ NOTE: This call is for debug purposes only and is unstable as returned objects may be frequently changed and will be different depending on the ledger backend. Request database: { \"action\" : \"stats\" , \"type\" : \"database\" } Database response: LMDB: { \"branch_pages\" : \"0\" , \"depth\" : \"1\" , \"entries\" : \"11\" , \"leaf_pages\" : \"1\" , \"overflow_pages\" : \"0\" , \"page_size\" : \"4096\" } RocksDB: { \"cur-size-all-mem-tables\" : \"74063072\" , \"size-all-mem-tables\" : \"487744504\" , \"estimate-table-readers-mem\" : \"113431016\" , \"estimate-live-data-size\" : \"17756425993\" , \"compaction-pending\" : \"0\" , \"estimate-num-keys\" : \"81835964\" , \"estimate-pending-compaction-bytes\" : \"0\" , \"total-sst-files-size\" : \"20350606013\" , \"block-cache-capacity\" : \"318767104\" , \"block-cache-usage\" : \"150310696\" }","title":"stats"},{"location":"commands/rpc-protocol/#stats_clear","text":"version 18.0+ Clears all collected statistics. The \"stat_duration_seconds\" value in the \"stats\" action is also reset. Request: { \"action\" : \"stats_clear\" } Response: { \"success\" : \"\" }","title":"stats_clear"},{"location":"commands/rpc-protocol/#stop","text":"enable_control required Method to safely shutdown node Dangerous RPC calls controlled by enable_control This RPC command/option requires enable_control to be enabled within the RPC config file. Enabling this means that anyone with access to the RPC port could potentially access wallet funds , stop the node from running and take other dangerous actions. Use caution when enabling this option, especially with external RPC access available. For more details see the Node Security page . Request: { \"action\" : \"stop\" } Response: { \"success\" : \"\" }","title":"stop"},{"location":"commands/rpc-protocol/#successors","text":"Returns a list of block hashes in the account chain starting at block up to count (direction from open block up to frontier, from older blocks to newer). Will list all blocks up to frontier (latest block) of this chain when count is set to \"-1\". The requested block hash is included in the answer. Request: { \"action\" : \"successors\" , \"block\" : \"991CF190094C00F0B68E2E5F75F6BEE95A2E0BD93CEAA4A6734DB9F19B728948\" , \"count\" : \"1\" } Response: { \"blocks\" : [ \"991CF190094C00F0B68E2E5F75F6BEE95A2E0BD93CEAA4A6734DB9F19B728948\" ] } Optional \"offset\" version 18.0+ Number, 0 by default. Return the account chain block hashes offset by the specified number of blocks Optional \"reverse\" version 18.0+ Boolean, false by default. Returns a consecutive list of block hashes in the account chain starting at block back to count (direction from frontier back to open block, from newer blocks to older). Equal to chain","title":"successors"},{"location":"commands/rpc-protocol/#telemetry","text":"version 21.0+ Return metrics from other nodes on the network. By default, returns a summarized view of the whole network. See below for details on obtaining local telemetry data. Networking - node telemetry contains more detailed information on the protocol implementation of telemetry. Request: { \"action\" : \"telemetry\" } Response: { \"block_count\" : \"5777903\" , \"cemented_count\" : \"688819\" , \"unchecked_count\" : \"443468\" , \"account_count\" : \"620750\" , \"bandwidth_cap\" : \"1572864\" , \"peer_count\" : \"32\" , \"protocol_version\" : \"18\" , \"uptime\" : \"556896\" , \"genesis_block\" : \"F824C697633FAB78B703D75189B7A7E18DA438A2ED5FFE7495F02F681CD56D41\" , \"major_version\" : \"21\" , \"minor_version\" : \"0\" , \"patch_version\" : \"0\" , \"pre_release_version\" : \"0\" , \"maker\" : \"0\" , \"timestamp\" : \"1587055945990\" , \"active_difficulty\" : \"ffffffcdbf40aa45\" } This contains a summarized view of the network with 10% of lower/upper bound results removed to reduce the effect of outliers. Returned values are calculated as follows: Field Name Response details block_count average count of blocks in ledger (including unconfirmed) cemented_count average count of blocks cemented in ledger (only confirmed) unchecked_count average count of unchecked blocks account_count average count of accounts in ledger bandwidth_cap 0 = unlimited; the mode is chosen if there is more than 1 common result otherwise the results are averaged (excluding 0 ) peer_count average count of peers nodes are connected to *_version mode (most common) of (protocol, major, minor, patch, pre_release) versions uptime average number of seconds since the UTC epoch at the point where the response is sent from the peer genesis_block mode (most common) of genesis block hashes maker mode (most common), meant for third party node software implementing the protocol so that it can be distinguished, 0 = Nano Foundation, 1 = Nano Foundation pruned node timestamp number of milliseconds since the UTC epoch at the point where the response is sent from the peer active_difficulty average of the current network difficulty, see active_difficulty \"network_current\" This only returns values which have been cached by the ongoing polling of peer metric data. Each response is cached for 60 seconds on the main network and 15 seconds on beta; a few additional seconds are added on for response delays. Optional \"raw\" When setting raw to true metrics from all nodes are displayed. It additionally contains signature , node_id , address and port from each peer. Request: { \"action\" : \"telemetry\" , \"raw\" : \"true\" } Response: { \"metrics\" : [ { \"block_count\" : \"5777903\" , ... \"node_id\" : \"node_1cmi8difuruopgzpnb4ybrnnj5rproxwuwe5mad7ucbsekakiwn37qqg1zo5\" , \"signature\" : \"5F8DEE5F895D53E122FDEB4B1B4118A41F9DDB818C6B299B09DF59131AF9F201BB7057769423F6B0C868B57509177B54D5D2C731405FE607527F5E2B6B2E290F\" , \"address\" : \"::ffff:152.89.106.89\" , \"port\" : \"54000\" }, { \"block_count\" : \"5777902\" , ... \"node_id\" : \"node_3ipxdjrha3rfg9h3spiz5jkprw8kdj7bph9fir51kf6pmryzznsyhakqznk3\" , \"signature\" : \"D691B855D9EC70EA6320DE609EB379EB706845433E034AD22721E8F91BF3A26156F40CCB2E98653F1E63D4CE5F10F530A835DE1B154D1213464E3B9BB9BE4908\" , \"address\" : \"::ffff:95.216.205.215\" , \"port\" : \"54006\" } ... ] } Optional \"address\" & \"port\" Get metrics from a specific peer. It accepts both ipv4 and ipv6 addresses { \"action\" : \"telemetry\" , \"address\" : \"246.125.123.456\" , \"port\" : \"7075\" } Requesting telemetry data from the local node Metrics for the local node can be requested using the peering port and any loopback address 127.0.0.1 , ::1 or [::1]","title":"telemetry"},{"location":"commands/rpc-protocol/#validate_account_number","text":"Check whether account is a valid account number using checksum Request: { \"action\" : \"validate_account_number\" , \"account\" : \"nano_1111111111111111111111111111111111111111111111111117353trpda\" } Response: { \"valid\" : \"1\" }","title":"validate_account_number"},{"location":"commands/rpc-protocol/#version","text":"Returns version information for RPC, Store, Protocol (network), Node (Major & Minor version). Since version 20.0 also returns the Network label and identifier (hash of the genesis open block), and Build Info. Since version 21.0 also returns Database backend information. RPC Version always returns \"1\" as of 01/11/2018 Request: { \"action\" : \"version\" } Response: { \"rpc_version\" : \"1\" , \"store_version\" : \"14\" , \"protocol_version\" : \"17\" , \"node_vendor\" : \"Nano 20.0\" , \"store_vendor\" : \"LMDB 0.9.23\" , // si n ce V 21.0 \"network\" : \"live\" , // si n ce v 20.0 \"network_identifier\" : \"991CF190094C00F0B68E2E5F75F6BEE95A2E0BD93CEAA4A6734DB9F19B728948\" , // si n ce v 20.0 \"build_info\" : \"Build Info <git hash> \\\"<compiler> version \\\" \\\"<compiler version string>\\\" \\\"BOOST <boost version>\\\" BUILT \\\"<build date>\\\"\" // si n ce v 20.0 }","title":"version"},{"location":"commands/rpc-protocol/#unchecked","text":"version 8.0+ Returns a list of pairs of unchecked block hashes and their json representation up to count . Using the optional json_block is recommended since v20.0. Request: { \"action\" : \"unchecked\" , \"json_block\" : \"true\" , \"count\" : \"1\" , } Response: { \"blocks\" : { \"87434F8041869A01C8F6F263B87972D7BA443A72E0A97D7A3FD0CCC2358FD6F9\" : { \"type\" : \"state\" , \"account\" : \"nano_1ipx847tk8o46pwxt5qjdbncjqcbwcc1rrmqnkztrfjy5k7z4imsrata9est\" , \"previous\" : \"CE898C131AAEE25E05362F247760F8A3ACF34A9796A5AE0D9204E86B0637965E\" , \"representative\" : \"nano_1stofnrxuz3cai7ze75o174bpm7scwj9jn3nxsn8ntzg784jf1gzn1jjdkou\" , \"balance\" : \"5606157000000000000000000000000000000\" , \"link\" : \"5D1AA8A45F8736519D707FCB375976A7F9AF795091021D7E9C7548D6F45DD8D5\" , \"link_as_account\" : \"nano_1qato4k7z3spc8gq1zyd8xeqfbzsoxwo36a45ozbrxcatut7up8ohyardu1z\" , \"signature\" : \"82D41BC16F313E4B2243D14DFFA2FB04679C540C2095FEE7EAE0F2F26880AD56DD48D87A7CC5DD760C5B2D76EE2C205506AA557BF00B60D8DEE312EC7343A501\" , \"work\" : \"8a142e07a10996d5\" } } }","title":"unchecked"},{"location":"commands/rpc-protocol/#unchecked_clear","text":"enable_control required, version 8.0+ Clear unchecked synchronizing blocks Dangerous RPC calls controlled by enable_control This RPC command/option requires enable_control to be enabled within the RPC config file. Enabling this means that anyone with access to the RPC port could potentially access wallet funds , stop the node from running and take other dangerous actions. Use caution when enabling this option, especially with external RPC access available. For more details see the Node Security page . Request: { \"action\" : \"unchecked_clear\" } Response: { \"success\" : \"\" }","title":"unchecked_clear"},{"location":"commands/rpc-protocol/#unchecked_get","text":"version 8.0+ Retrieves a json representation of unchecked synchronizing block by hash . Using the optional json_block is recommended since v19.0. Request: { \"action\" : \"unchecked_get\" , \"json_block\" : \"true\" , \"hash\" : \"19BF0C268C2D9AED1A8C02E40961B67EA56B1681DE274CD0C50F3DD972F0655C\" } Response: { \"modified_timestamp\" : \"1565856525\" , \"contents\" : { \"type\" : \"state\" , \"account\" : \"nano_1hmqzugsmsn4jxtzo5yrm4rsysftkh9343363hctgrjch1984d8ey9zoyqex\" , \"previous\" : \"009C587914611E83EE7F75BD9C000C430C720D0364D032E84F37678D7D012911\" , \"representative\" : \"nano_1stofnrxuz3cai7ze75o174bpm7scwj9jn3nxsn8ntzg784jf1gzn1jjdkou\" , \"balance\" : \"189012679592109992600249228\" , \"link\" : \"0000000000000000000000000000000000000000000000000000000000000000\" , \"link_as_account\" : \"nano_1111111111111111111111111111111111111111111111111111hifc8npp\" , \"signature\" : \"845C8660750895843C013CE33E31B80EF0A7A69E52DDAF74A5F1BDFAA9A52E4D9EA2C3BE1AB0BD5790FCC1AD9B7A3D2F4B44EECE4279A8184D414A30A1B4620F\" , \"work\" : \"0dfb32653e189699\" } } Optional \"json_block\" version 19.0+ Default \"false\". If \"true\", \"contents\" will contain a JSON subtree instead of a JSON string.","title":"unchecked_get"},{"location":"commands/rpc-protocol/#unchecked_keys","text":"version 8.0+ Retrieves unchecked database keys, blocks hashes & a json representations of unchecked pending blocks starting from key up to count . Using the optional json_block is recommended since v19.0. Request: { \"action\" : \"unchecked_keys\" , \"json_block\" : \"true\" , \"key\" : \"19BF0C268C2D9AED1A8C02E40961B67EA56B1681DE274CD0C50F3DD972F0655C\" , \"count\" : \"1\" } Response: { \"unchecked\" : [ { \"key\" : \"19BF0C268C2D9AED1A8C02E40961B67EA56B1681DE274CD0C50F3DD972F0655C\" , \"hash\" : \"A1A8558CBABD3F7C1D70F8CB882355F2EF688E7F30F5FDBD0204CAE157885056\" , \"modified_timestamp\" : \"1565856744\" , \"contents\" : { \"type\" : \"state\" , \"account\" : \"nano_1hmqzugsmsn4jxtzo5yrm4rsysftkh9343363hctgrjch1984d8ey9zoyqex\" , \"previous\" : \"19BF0C268C2D9AED1A8C02E40961B67EA56B1681DE274CD0C50F3DD972F0655C\" , \"representative\" : \"nano_1stofnrxuz3cai7ze75o174bpm7scwj9jn3nxsn8ntzg784jf1gzn1jjdkou\" , \"balance\" : \"189012679592109992600249226\" , \"link\" : \"0000000000000000000000000000000000000000000000000000000000000000\" , \"link_as_account\" : \"nano_1111111111111111111111111111111111111111111111111111hifc8npp\" , \"signature\" : \"FF5D49925AD3C8705E6EEDD993E8C4120E6107D7F1CB53B287773448DEA0B1D32918E67804248FC83609F0D93401D833DFA33127F21B6CD02F75D6E31A00450A\" , \"work\" : \"8193ddf00947e694\" } } ] } Optional \"json_block\" version 19.0+ Default \"false\". If \"true\", \"contents\" will contain a JSON subtree instead of a JSON string.","title":"unchecked_keys"},{"location":"commands/rpc-protocol/#unopened","text":"enable_control required, version 19.0+ Returns the total pending balance for unopened accounts in the local database, starting at account (optional) up to count (optional), sorted by account number. Notes: By default excludes the burn account. Dangerous RPC calls controlled by enable_control This RPC command/option requires enable_control to be enabled within the RPC config file. Enabling this means that anyone with access to the RPC port could potentially access wallet funds , stop the node from running and take other dangerous actions. Use caution when enabling this option, especially with external RPC access available. For more details see the Node Security page . Request: { \"action\" : \"unopened\" , \"account\" : \"nano_1111111111111111111111111111111111111111111111111111hifc8npp\" , \"count\" : \"1\" } Response: { \"accounts\" : { \"nano_1111111111111111111111111111111111111111111111111111hifc8npp\" : \"207034077034226183413773082289554618448\" } } Optional \"threshold\" Number (128 bit, decimal), default 0. Return only accounts with total pending balance above threshold .","title":"unopened"},{"location":"commands/rpc-protocol/#uptime","text":"version 18.0+ Return node uptime in seconds Request: { \"action\" : \"uptime\" } Response: { \"seconds\" : \"6000\" }","title":"uptime"},{"location":"commands/rpc-protocol/#work_cancel","text":"enable_control required Stop generating work for block Dangerous RPC calls controlled by enable_control This RPC command/option requires enable_control to be enabled within the RPC config file. Enabling this means that anyone with access to the RPC port could potentially access wallet funds , stop the node from running and take other dangerous actions. Use caution when enabling this option, especially with external RPC access available. For more details see the Node Security page . Request: { \"action\" : \"work_cancel\" , \"hash\" : \"718CC2121C3E641059BC1C2CFC45666C99E8AE922F7A807B7D07B62C995D79E2\" } Response: { }","title":"work_cancel"},{"location":"commands/rpc-protocol/#work_generate","text":"enable_control required Generates work for block. hash is the frontier of the account or in the case of an open block, the public key representation of the account which can be found with account_key . Dangerous RPC calls controlled by enable_control This RPC command/option requires enable_control to be enabled within the RPC config file. Enabling this means that anyone with access to the RPC port could potentially access wallet funds , stop the node from running and take other dangerous actions. Use caution when enabling this option, especially with external RPC access available. For more details see the Node Security page . Request: { \"action\" : \"work_generate\" , \"hash\" : \"718CC2121C3E641059BC1C2CFC45666C99E8AE922F7A807B7D07B62C995D79E2\" } Response: { \"work\" : \"2b3d689bbcb21dca\" , \"difficulty\" : \"fffffff93c41ec94\" , // o f t he resul t i n g work \"multiplier\" : \"1.182623871097636\" , // si n ce v 19.0 , calcula te d fr om de fault base di ff icul t y \"hash\" : \"718CC2121C3E641059BC1C2CFC45666C99E8AE922F7A807B7D07B62C995D79E2\" // si n ce v 20.0 } Optional \"use_peers\" version 14.0+ Boolean, false by default. If the optional use_peers parameter is set to true , then the node will query its work peers (if it has any). Without this parameter, the node will only generate work locally. Optional \"difficulty\" version 19.0+ Difficulty value (16 hexadecimal digits string, 64 bit). Uses difficulty value to generate work. Defaults to the network base difficulty. Optional \"multiplier\" version 20.0+ Multiplier from base difficulty (positive number). Uses equivalent difficulty as multiplier from base difficulty to generate work. Note: overrides the difficulty parameter. Optional \"account\" version 20.0+ A valid Nano account. If provided and use_peers is set to true , this information will be relayed to work peers. Optional \"version\" version 21.0+ Work version string. Currently \"work_1\" is the default and only valid option. Optional \"block\" version 21.0+ A valid Nano block (string or JSON). Using the optional json_block is recommended. If provided and difficulty or multiplier are both not given, RPC processor tries to calculate the appropriate difficulty threshold based on ledger data. Note: block should be the one where the resulting work value will be used, not the previous block. Optional \"json_block\" version 21.0+ Default \"false\". If \"true\", block in the request should contain a JSON subtree instead of a JSON string.","title":"work_generate"},{"location":"commands/rpc-protocol/#work_peer_add","text":"enable_control required, version 8.0+ Add specific IP address and port as work peer for node until restart Dangerous RPC calls controlled by enable_control This RPC command/option requires enable_control to be enabled within the RPC config file. Enabling this means that anyone with access to the RPC port could potentially access wallet funds , stop the node from running and take other dangerous actions. Use caution when enabling this option, especially with external RPC access available. For more details see the Node Security page . Request: { \"action\" : \"work_peer_add\" , \"address\" : \"::ffff:172.17.0.1\" , \"port\" : \"7076\" } Response: { \"success\" : \"\" }","title":"work_peer_add"},{"location":"commands/rpc-protocol/#work_peers","text":"enable_control required, version 8.0+ Dangerous RPC calls controlled by enable_control This RPC command/option requires enable_control to be enabled within the RPC config file. Enabling this means that anyone with access to the RPC port could potentially access wallet funds , stop the node from running and take other dangerous actions. Use caution when enabling this option, especially with external RPC access available. For more details see the Node Security page . Request: { \"action\" : \"work_peers\" } Response: { \"work_peers\" : [ \"::ffff:172.17.0.1:7076\" ] }","title":"work_peers"},{"location":"commands/rpc-protocol/#work_peers_clear","text":"enable_control required, version 8.0+ Clear work peers node list until restart Dangerous RPC calls controlled by enable_control This RPC command/option requires enable_control to be enabled within the RPC config file. Enabling this means that anyone with access to the RPC port could potentially access wallet funds , stop the node from running and take other dangerous actions. Use caution when enabling this option, especially with external RPC access available. For more details see the Node Security page . Request: { \"action\" : \"work_peers_clear\" } Response: { \"success\" : \"\" }","title":"work_peers_clear"},{"location":"commands/rpc-protocol/#work_validate","text":"Check whether work is valid for block. Provides two values: valid_all is true if the work is valid at the current network difficulty (work can be used for any block). valid_receive is true if the work is valid for use in a receive block. Read the details below when using this RPC in V21 . Semantics change in V21.0 In V21.0, when the optional difficulty is not given, valid is no longer included in the response. Use the new response fields \"valid_all\" and \"valid_receive\" taking into account the subtype of the block using this work value: valid_all validates at the current network difficulty. As soon as the node processes the first epoch_2 block , this difficulty is increased. valid_receive is completely accurate only once the epoch_2 upgrade is finished. Until the upgrade is finished, it is only accurate if the account where this work will be used is already upgraded. The upgrade status of an account can be obtained from account_info . The account is upgraded if \"account_version\" is \"2\" . Request: { \"action\" : \"work_validate\" , \"work\" : \"2bf29ef00786a6bc\" , \"hash\" : \"718CC2121C3E641059BC1C2CFC45666C99E8AE922F7A807B7D07B62C995D79E2\" } Response since v21.0: { \"valid_all\" : \"1\" , \"valid_receive\" : \"1\" , \"difficulty\" : \"fffffff93c41ec94\" , \"multiplier\" : \"1.182623871097636\" // calcula te d fr om t he de fault base di ff icul t y } Response up to v20.0 { \"valid\" : \"1\" , \"difficulty\" : \"fffffff93c41ec94\" , // si n ce v 19.0 \"multiplier\" : \"9.4609\" // si n ce v 19.0 } Optional \"difficulty\" version 19.0+ Difficulty value (16 hexadecimal digits string, 64 bit). Uses difficulty value to validate work. Defaults to the network base difficulty. Response includes extra field valid signifying validity at the given difficulty. Request with given \"difficulty\" { \"action\" : \"work_validate\" , \"difficulty\" : \"ffffffffffffffff\" , \"work\" : \"2bf29ef00786a6bc\" , \"hash\" : \"718CC2121C3E641059BC1C2CFC45666C99E8AE922F7A807B7D07B62C995D79E2\" } Response with given \"difficulty: { \"valid\" : \"0\" , \"valid_all\" : \"1\" , // si n ce v 21.0 \"valid_receive\" : \"1\" , // si n ce v 21.0 \"difficulty\" : \"fffffff93c41ec94\" , \"multiplier\" : \"1.182623871097636\" } Optional \"multiplier\" version 20.0+ Multiplier from base difficulty (positive number). Uses equivalent difficulty as multiplier from base difficulty to validate work. Note: overrides the difficulty parameter. Optional \"version\" version 21.0+ Work version string. Currently \"work_1\" is the default and only valid option.","title":"work_validate"},{"location":"commands/rpc-protocol/#wallet-rpcs","text":"For development and testing only Below are RPC commands that interact with the built-in, QT-based node wallet. This wallet is only recommended for development and testing. For production integrations, setting up custom External Management processes is required.","title":"Wallet RPCs"},{"location":"commands/rpc-protocol/#account_create","text":"enable_control required Creates a new account, insert next deterministic key in wallet Dangerous RPC calls controlled by enable_control This RPC command/option requires enable_control to be enabled within the RPC config file. Enabling this means that anyone with access to the RPC port could potentially access wallet funds , stop the node from running and take other dangerous actions. Use caution when enabling this option, especially with external RPC access available. For more details see the Node Security page . Request: { \"action\" : \"account_create\" , \"wallet\" : \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\" } Response: { \"account\" : \"nano_3e3j5tkog48pnny9dmfzj1r16pg8t1e76dz5tmac6iq689wyjfpi00000000\" } Optional \"index\" version 18.0+ unset by default. Indicates which index to create account for starting with 0 Request: { \"action\" : \"account_create\" , \"wallet\" : \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\" , \"index\" : \"1\" } Optional \"work\" version 9.0+ Boolean, true by default. Setting false disables work generation after creating account Request: { \"action\" : \"account_create\" , \"wallet\" : \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\" , \"work\" : \"false\" }","title":"account_create"},{"location":"commands/rpc-protocol/#account_list","text":"Lists all the accounts inside wallet Request: { \"action\" : \"account_list\" , \"wallet\" : \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\" } Response: { \"accounts\" : [ \"nano_3e3j5tkog48pnny9dmfzj1r16pg8t1e76dz5tmac6iq689wyjfpi00000000\" ] }","title":"account_list"},{"location":"commands/rpc-protocol/#account_move","text":"enable_control required Moves accounts from source to wallet Dangerous RPC calls controlled by enable_control This RPC command/option requires enable_control to be enabled within the RPC config file. Enabling this means that anyone with access to the RPC port could potentially access wallet funds , stop the node from running and take other dangerous actions. Use caution when enabling this option, especially with external RPC access available. For more details see the Node Security page . Request: { \"action\" : \"account_move\" , \"wallet\" : \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\" , \"source\" : \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\" , \"accounts\" : [ \"nano_3e3j5tkog48pnny9dmfzj1r16pg8t1e76dz5tmac6iq689wyjfpi00000000\" ] } Response: { \"moved\" : \"1\" }","title":"account_move"},{"location":"commands/rpc-protocol/#account_remove","text":"enable_control required Remove account from wallet Dangerous RPC calls controlled by enable_control This RPC command/option requires enable_control to be enabled within the RPC config file. Enabling this means that anyone with access to the RPC port could potentially access wallet funds , stop the node from running and take other dangerous actions. Use caution when enabling this option, especially with external RPC access available. For more details see the Node Security page . Request: { \"action\" : \"account_remove\" , \"wallet\" : \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\" , \"account\" : \"nano_39a73oy5ungrhxy5z5oao1xso4zo7dmgpjd4u74xcrx3r1w6rtazuouw6qfi\" } Response: { \"removed\" : \"1\" }","title":"account_remove"},{"location":"commands/rpc-protocol/#account_representative_set","text":"enable_control required Sets the representative for account in wallet Dangerous RPC calls controlled by enable_control This RPC command/option requires enable_control to be enabled within the RPC config file. Enabling this means that anyone with access to the RPC port could potentially access wallet funds , stop the node from running and take other dangerous actions. Use caution when enabling this option, especially with external RPC access available. For more details see the Node Security page . Request: { \"action\" : \"account_representative_set\" , \"wallet\" : \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\" , \"account\" : \"nano_39a73oy5ungrhxy5z5oao1xso4zo7dmgpjd4u74xcrx3r1w6rtazuouw6qfi\" , \"representative\" : \"nano_16u1uufyoig8777y6r8iqjtrw8sg8maqrm36zzcm95jmbd9i9aj5i8abr8u5\" } Response: { \"block\" : \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\" } Optional \"work\" version 9.0+ Work value (16 hexadecimal digits string, 64 bit). Uses work value for block from external source and disables work precaching for this account. Not using this field re-enables work precaching.","title":"account_representative_set"},{"location":"commands/rpc-protocol/#accounts_create","text":"enable_control required, version 9.0+ Creates new accounts, insert next deterministic keys in wallet up to count Dangerous RPC calls controlled by enable_control This RPC command/option requires enable_control to be enabled within the RPC config file. Enabling this means that anyone with access to the RPC port could potentially access wallet funds , stop the node from running and take other dangerous actions. Use caution when enabling this option, especially with external RPC access available. For more details see the Node Security page . Request: { \"action\" : \"accounts_create\" , \"wallet\" : \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\" , \"count\" : \"2\" } Response: { \"accounts\" : [ \"nano_3e3j5tkog48pnny9dmfzj1r16pg8t1e76dz5tmac6iq689wyjfpi00000000\" , \"nano_1e5aqegc1jb7qe964u4adzmcezyo6o146zb8hm6dft8tkp79za3s00000000\" ] } Optional enabling work generation version 11.2+ Boolean, false by default. Enables work generation after creating accounts Request: { \"action\" : \"accounts_create\" , \"wallet\" : \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\" , \"count\" : \"2\" , \"work\" : \"true\" } Note: Before version 11.2 work generation was enabled by default, if you want to disable work generation for previous versions, use \"work\": \"false\"","title":"accounts_create"},{"location":"commands/rpc-protocol/#block_create-optional-wallet","text":"See block_create Node RPC command above","title":"block_create (optional wallet)"},{"location":"commands/rpc-protocol/#password_change","text":"enable_control required Changes the password for wallet to password Dangerous RPC calls controlled by enable_control This RPC command/option requires enable_control to be enabled within the RPC config file. Enabling this means that anyone with access to the RPC port could potentially access wallet funds , stop the node from running and take other dangerous actions. Use caution when enabling this option, especially with external RPC access available. For more details see the Node Security page . Request: { \"action\" : \"password_change\" , \"wallet\" : \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\" , \"password\" : \"test\" } Response: { \"changed\" : \"1\" }","title":"password_change"},{"location":"commands/rpc-protocol/#password_enter","text":"Enters the password in to wallet to unlock it Request: { \"action\" : \"password_enter\" , \"wallet\" : \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\" , \"password\" : \"test\" } Response: { \"valid\" : \"1\" }","title":"password_enter"},{"location":"commands/rpc-protocol/#password_valid","text":"Checks whether the password entered for wallet is valid Request: { \"action\" : \"password_valid\" , \"wallet\" : \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\" } Response: { \"valid\" : \"1\" }","title":"password_valid"},{"location":"commands/rpc-protocol/#receive","text":"enable_control required Receive pending block for account in wallet . If receiving the block opens the account, sets the account representative to a wallet representative . Before v21, the representative is set to the account itself. Dangerous RPC calls controlled by enable_control This RPC command/option requires enable_control to be enabled within the RPC config file. Enabling this means that anyone with access to the RPC port could potentially access wallet funds , stop the node from running and take other dangerous actions. Use caution when enabling this option, especially with external RPC access available. For more details see the Node Security page . Request: { \"action\" : \"receive\" , \"wallet\" : \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\" , \"account\" : \"nano_3e3j5tkog48pnny9dmfzj1r16pg8t1e76dz5tmac6iq689wyjfpi00000000\" , \"block\" : \"53EAA25CE28FA0E6D55EA9704B32604A736966255948594D55CBB05267CECD48\" } Response: { \"block\" : \"EE5286AB32F580AB65FD84A69E107C69FBEB571DEC4D99297E19E3FA5529547B\" } Optional \"work\" version 9.0+ Work value (16 hexadecimal digits string, 64 bit). Uses work value for block from external source and disables work precaching for this account. Not using this field re-enables work precaching.","title":"receive"},{"location":"commands/rpc-protocol/#receive_minimum","text":"enable_control required, version 8.0+ Returns receive minimum for node wallet Dangerous RPC calls controlled by enable_control This RPC command/option requires enable_control to be enabled within the RPC config file. Enabling this means that anyone with access to the RPC port could potentially access wallet funds , stop the node from running and take other dangerous actions. Use caution when enabling this option, especially with external RPC access available. For more details see the Node Security page . Request: { \"action\" : \"receive_minimum\" } Response: { \"amount\" : \"1000000000000000000000000\" }","title":"receive_minimum"},{"location":"commands/rpc-protocol/#receive_minimum_set","text":"enable_control required, version 8.0+ Set amount as new receive minimum for node wallet until restart Dangerous RPC calls controlled by enable_control This RPC command/option requires enable_control to be enabled within the RPC config file. Enabling this means that anyone with access to the RPC port could potentially access wallet funds , stop the node from running and take other dangerous actions. Use caution when enabling this option, especially with external RPC access available. For more details see the Node Security page . Request: { \"action\" : \"receive_minimum_set\" , \"amount\" : \"1000000000000000000000000000000\" } Response: { \"success\" : \"\" }","title":"receive_minimum_set"},{"location":"commands/rpc-protocol/#search_pending","text":"enable_control required Tells the node to look for pending blocks for any account in wallet Dangerous RPC calls controlled by enable_control This RPC command/option requires enable_control to be enabled within the RPC config file. Enabling this means that anyone with access to the RPC port could potentially access wallet funds , stop the node from running and take other dangerous actions. Use caution when enabling this option, especially with external RPC access available. For more details see the Node Security page . Request: { \"action\" : \"search_pending\" , \"wallet\" : \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\" } Response: { \"started\" : \"1\" }","title":"search_pending"},{"location":"commands/rpc-protocol/#search_pending_all","text":"enable_control required, version 8.0+ Tells the node to look for pending blocks for any account in all available wallets Dangerous RPC calls controlled by enable_control This RPC command/option requires enable_control to be enabled within the RPC config file. Enabling this means that anyone with access to the RPC port could potentially access wallet funds , stop the node from running and take other dangerous actions. Use caution when enabling this option, especially with external RPC access available. For more details see the Node Security page . Request: { \"action\" : \"search_pending_all\" } Response: { \"success\" : \"\" }","title":"search_pending_all"},{"location":"commands/rpc-protocol/#send","text":"enable_control required Send amount from source in wallet to destination Dangerous RPC calls controlled by enable_control This RPC command/option requires enable_control to be enabled within the RPC config file. Enabling this means that anyone with access to the RPC port could potentially access wallet funds , stop the node from running and take other dangerous actions. Use caution when enabling this option, especially with external RPC access available. For more details see the Node Security page . Use of id option is highly recommended Integrations using the node wallet must ensure idempotency for transactions and this can be done externally if preferred. Using the id field provides this option internally and is highly recommended for all node wallet uses. Request: { \"action\" : \"send\" , \"wallet\" : \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\" , \"source\" : \"nano_3e3j5tkog48pnny9dmfzj1r16pg8t1e76dz5tmac6iq689wyjfpi00000000\" , \"destination\" : \"nano_3e3j5tkog48pnny9dmfzj1r16pg8t1e76dz5tmac6iq689wyjfpi00000000\" , \"amount\" : \"1000000\" , \"id\" : \"your-unique-id\" } Response: { \"block\" : \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\" } Proof of Work is precomputed for one transaction in the background when you are using the node wallet to track accounts. If it has been a while since your last transaction it will send instantly, the next one will need to wait for Proof of Work to be generated. If the request times out, then the send may or may not have gone through. If you want to the ability to retry a failed send, all send calls must specify the id parameter as follows Highly recommended \"id\" version 10.0+ You can (and should) specify a unique id for each spend to provide idempotency . That means that if you call send two times with the same id, the second request won't send any additional Nano, and will return the first block instead. The id can be any string. This may be a required parameter in the future. If you accidentally reuse an id, the send will not go through (it will be seen as a duplicate request), so make sure your ids are unique! They must be unique per node, and are not segregated per wallet. Using the same id for requests with different parameters (wallet, source, destination, and amount) is undefined behavior and may result in an error in the future. Request: { \"action\" : \"send\" , \"wallet\" : \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\" , \"source\" : \"nano_3e3j5tkog48pnny9dmfzj1r16pg8t1e76dz5tmac6iq689wyjfpi00000000\" , \"destination\" : \"nano_3e3j5tkog48pnny9dmfzj1r16pg8t1e76dz5tmac6iq689wyjfpi00000000\" , \"amount\" : \"1000000\" , \"id\" : \"7081e2b8fec9146e\" } Response: { \"block\" : \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\" } Sending the request again will yield the same block, and will not affect the ledger. Optional \"work\" version 9.0+ Work value (16 hexadecimal digits string, 64 bit). Uses work value for block from external source and disables work precaching for this account. Not using this field re-enables work precaching. Request: { \"action\" : \"send\" , \"wallet\" : \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\" , \"source\" : \"nano_3e3j5tkog48pnny9dmfzj1r16pg8t1e76dz5tmac6iq689wyjfpi00000000\" , \"destination\" : \"nano_3e3j5tkog48pnny9dmfzj1r16pg8t1e76dz5tmac6iq689wyjfpi00000000\" , \"amount\" : \"1000000\" , \"work\" : \"2bf29ef00786a6bc\" }","title":"send"},{"location":"commands/rpc-protocol/#sign-optional-wallet","text":"See sign Node RPC command above","title":"sign (optional wallet)"},{"location":"commands/rpc-protocol/#wallet_add","text":"enable_control required Add an adhoc private key key to wallet Dangerous RPC calls controlled by enable_control This RPC command/option requires enable_control to be enabled within the RPC config file. Enabling this means that anyone with access to the RPC port could potentially access wallet funds , stop the node from running and take other dangerous actions. Use caution when enabling this option, especially with external RPC access available. For more details see the Node Security page . Request: { \"action\" : \"wallet_add\" , \"wallet\" : \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\" , \"key\" : \"34F0A37AAD20F4A260F0A5B3CB3D7FB50673212263E58A380BC10474BB039CE4\" } Response: { \"account\" : \"nano_3e3j5tkog48pnny9dmfzj1r16pg8t1e76dz5tmac6iq689wyjfpi00000000\" } Optional disabling work generation version 9.0+ Boolean, false by default. Disables work generation after adding account Request: { \"action\" : \"wallet_add\" , \"wallet\" : \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\" , \"key\" : \"34F0A37AAD20F4A260F0A5B3CB3D7FB50673212263E58A380BC10474BB039CE4\" , \"work\" : \"false\" }","title":"wallet_add"},{"location":"commands/rpc-protocol/#wallet_add_watch","text":"enable_control required, version 11.0+ Add watch-only accounts to wallet Dangerous RPC calls controlled by enable_control This RPC command/option requires enable_control to be enabled within the RPC config file. Enabling this means that anyone with access to the RPC port could potentially access wallet funds , stop the node from running and take other dangerous actions. Use caution when enabling this option, especially with external RPC access available. For more details see the Node Security page . Request: { \"action\" : \"wallet_add_watch\" , \"wallet\" : \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\" , \"accounts\" : [ \"nano_3e3j5tkog48pnny9dmfzj1r16pg8t1e76dz5tmac6iq689wyjfpi00000000\" , \"nano_111111111111111111111111111111111111111111111111111000000000\" ] } Response: { \"success\" : \"\" }","title":"wallet_add_watch"},{"location":"commands/rpc-protocol/#wallet_balances","text":"Returns how many raw is owned and how many have not yet been received by all accounts in wallet Includes unconfirmed blocks This call may return results that include unconfirmed blocks, so it should not be used in any processes or integrations requiring only details from blocks confirmed by the network. Request: { \"action\" : \"wallet_balances\" , \"wallet\" : \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\" } Response: { \"balances\" : { \"nano_3e3j5tkog48pnny9dmfzj1r16pg8t1e76dz5tmac6iq689wyjfpi00000000\" : { \"balance\" : \"10000\" , \"pending\" : \"10000\" } } } Optional \"threshold\" version 9.0+ Number (128 bit, decimal). Returns wallet accounts balances more or equal to threshold","title":"wallet_balances"},{"location":"commands/rpc-protocol/#wallet_change_seed","text":"enable_control required Changes seed for wallet to seed . Notes: Clear all deterministic accounts in wallet! To restore account from new seed use RPC accounts_create . last_restored_account and restored_count fields in response returned since version 19.0+ Dangerous RPC calls controlled by enable_control This RPC command/option requires enable_control to be enabled within the RPC config file. Enabling this means that anyone with access to the RPC port could potentially access wallet funds , stop the node from running and take other dangerous actions. Use caution when enabling this option, especially with external RPC access available. For more details see the Node Security page . Request: { \"action\" : \"wallet_change_seed\" , \"wallet\" : \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\" , \"seed\" : \"74F2B37AAD20F4A260F0A5B3CB3D7FB51673212263E58A380BC10474BB039CEE\" } Response: { \"success\" : \"\" , \"last_restored_account\" : \"nano_1mhdfre3zczr86mp44jd3xft1g1jg66jwkjtjqixmh6eajfexxti7nxcot9c\" , \"restored_count\" : \"1\" } Optional \"count\" version 18.0+ Number, 0 by default. Manually set count of accounts to restore from seed","title":"wallet_change_seed"},{"location":"commands/rpc-protocol/#wallet_contains","text":"Check whether wallet contains account Request: { \"action\" : \"wallet_contains\" , \"wallet\" : \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\" , \"account\" : \"nano_3e3j5tkog48pnny9dmfzj1r16pg8t1e76dz5tmac6iq689wyjfpi00000000\" } Response: { \"exists\" : \"1\" }","title":"wallet_contains"},{"location":"commands/rpc-protocol/#wallet_create","text":"enable_control required Creates a new random wallet id Dangerous RPC calls controlled by enable_control This RPC command/option requires enable_control to be enabled within the RPC config file. Enabling this means that anyone with access to the RPC port could potentially access wallet funds , stop the node from running and take other dangerous actions. Use caution when enabling this option, especially with external RPC access available. For more details see the Node Security page . Request: { \"action\" : \"wallet_create\" } Response: { \"wallet\" : \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\" } Optional \"seed\" version 18.0+ Seed value (64 hexadecimal digits string, 256 bit). Changes seed for a new wallet to seed , returning last restored account from given seed & restored count","title":"wallet_create"},{"location":"commands/rpc-protocol/#wallet_destroy","text":"enable_control required Destroys wallet and all contained accounts Dangerous RPC calls controlled by enable_control This RPC command/option requires enable_control to be enabled within the RPC config file. Enabling this means that anyone with access to the RPC port could potentially access wallet funds , stop the node from running and take other dangerous actions. Use caution when enabling this option, especially with external RPC access available. For more details see the Node Security page . Request: { \"action\" : \"wallet_destroy\" , \"wallet\" : \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\" } Response: { \"destroyed\" : \"1\" }","title":"wallet_destroy"},{"location":"commands/rpc-protocol/#wallet_export","text":"Return a json representation of wallet Request: { \"action\" : \"wallet_export\" , \"wallet\" : \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\" } Response: { \"json\" : \"{\\\"0000000000000000000000000000000000000000000000000000000000000000\\\": \\\"0000000000000000000000000000000000000000000000000000000000000001\\\"}\" }","title":"wallet_export"},{"location":"commands/rpc-protocol/#wallet_frontiers","text":"Returns a list of pairs of account and block hash representing the head block starting for accounts from wallet Request: { \"action\" : \"wallet_frontiers\" , \"wallet\" : \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\" } Response: { \"frontiers\" : { \"nano_3e3j5tkog48pnny9dmfzj1r16pg8t1e76dz5tmac6iq689wyjfpi00000000\" : \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\" } }","title":"wallet_frontiers"},{"location":"commands/rpc-protocol/#wallet_history","text":"version 18.0+ Reports send/receive information for accounts in wallet. Change blocks are skipped, open blocks will appear as receive. Response will start with most recent blocks according to local ledger. Includes unconfirmed blocks This call may return results that include unconfirmed blocks, so it should not be used in any processes or integrations requiring only details from blocks confirmed by the network. Request: { \"action\" : \"wallet_history\" , \"wallet\" : \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\" } Response: { \"history\" : [ { \"type\" : \"send\" , \"account\" : \"nano_1qato4k7z3spc8gq1zyd8xeqfbzsoxwo36a45ozbrxcatut7up8ohyardu1z\" , \"amount\" : \"30000000000000000000000000000000000\" , \"block_account\" : \"nano_1ipx847tk8o46pwxt5qjdbncjqcbwcc1rrmqnkztrfjy5k7z4imsrata9est\" , \"hash\" : \"87434F8041869A01C8F6F263B87972D7BA443A72E0A97D7A3FD0CCC2358FD6F9\" , \"local_timestamp\" : \"1527698508\" }, { \"type\" : \"send\" , \"account\" : \"nano_38ztgpejb7yrm7rr586nenkn597s3a1sqiy3m3uyqjicht7kzuhnihdk6zpz\" , \"amount\" : \"40000000000000000000000000000000000\" , \"block_account\" : \"nano_1ipx847tk8o46pwxt5qjdbncjqcbwcc1rrmqnkztrfjy5k7z4imsrata9est\" , \"hash\" : \"CE898C131AAEE25E05362F247760F8A3ACF34A9796A5AE0D9204E86B0637965E\" , \"local_timestamp\" : \"1527698492\" } ] } Optional \"modified_since\" UNIX timestamp (number), 0 by default. Return only accounts modified in local database after specific timestamp","title":"wallet_history"},{"location":"commands/rpc-protocol/#wallet_info","text":"version 15.0+ Returns the sum of all accounts balances in wallet , number of accounts in wallet, number of deterministic & adhoc (non-deterministic) accounts, deterministic index (index of last account derived from seed. Equal to deterministic accounts number if no accounts were removed) Includes unconfirmed blocks This call may return results that include unconfirmed blocks, so it should not be used in any processes or integrations requiring only details from blocks confirmed by the network. Request: { \"action\" : \"wallet_info\" , \"wallet\" : \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\" } Response: { \"balance\" : \"10000\" , \"pending\" : \"10000\" , \"accounts_count\" : \"3\" , \"adhoc_count\" : \"1\" , \"deterministic_count\" : \"2\" , \"deterministic_index\" : \"2\" }","title":"wallet_info"},{"location":"commands/rpc-protocol/#wallet_ledger","text":"enable_control required, version 11.0+ Returns frontier, open block, change representative block, balance, last modified timestamp from local database & block count for accounts from wallet Includes unconfirmed blocks This call may return results that include unconfirmed blocks, so it should not be used in any processes or integrations requiring only details from blocks confirmed by the network. Dangerous RPC calls controlled by enable_control This RPC command/option requires enable_control to be enabled within the RPC config file. Enabling this means that anyone with access to the RPC port could potentially access wallet funds , stop the node from running and take other dangerous actions. Use caution when enabling this option, especially with external RPC access available. For more details see the Node Security page . Request: { \"action\" : \"wallet_ledger\" , \"wallet\" : \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\" } Response: { \"accounts\" : { \"nano_11119gbh8hb4hj1duf7fdtfyf5s75okzxdgupgpgm1bj78ex3kgy7frt3s9n\" : { \"frontier\" : \"E71AF3E9DD86BBD8B4620EFA63E065B34D358CFC091ACB4E103B965F95783321\" , \"open_block\" : \"643B77F1ECEFBDBE1CC909872964C1DBBE23A6149BD3CEF2B50B76044659B60F\" , \"representative_block\" : \"643B77F1ECEFBDBE1CC909872964C1DBBE23A6149BD3CEF2B50B76044659B60F\" , \"balance\" : \"0\" , \"modified_timestamp\" : \"1511476234\" , \"block_count\" : \"2\" } } } Optional \"representative\", \"weight\", \"pending\" Booleans, false by default. Additionally returns representative, voting weight, pending balance for each account Request: { \"action\" : \"wallet_ledger\" , \"wallet\" : \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\" , \"representative\" : \"true\" , \"weight\" : \"true\" , \"pending\" : \"true\" } Response: { \"accounts\" : { \"nano_11119gbh8hb4hj1duf7fdtfyf5s75okzxdgupgpgm1bj78ex3kgy7frt3s9n\" : { \"frontier\" : \"E71AF3E9DD86BBD8B4620EFA63E065B34D358CFC091ACB4E103B965F95783321\" , \"open_block\" : \"643B77F1ECEFBDBE1CC909872964C1DBBE23A6149BD3CEF2B50B76044659B60F\" , \"representative_block\" : \"643B77F1ECEFBDBE1CC909872964C1DBBE23A6149BD3CEF2B50B76044659B60F\" , \"balance\" : \"0\" , \"modified_timestamp\" : \"1511476234\" , \"block_count\" : \"2\" , \"representative\" : \"nano_1anrzcuwe64rwxzcco8dkhpyxpi8kd7zsjc1oeimpc3ppca4mrjtwnqposrs\" , \"weight\" : \"0\" , \"pending\" : \"0\" } } } Optional \"modified_since\" UNIX timestamp (number), 0 by default. Return only accounts modified in local database after specific timestamp","title":"wallet_ledger"},{"location":"commands/rpc-protocol/#wallet_lock","text":"enable_control required, version 9.0+ Locks wallet Dangerous RPC calls controlled by enable_control This RPC command/option requires enable_control to be enabled within the RPC config file. Enabling this means that anyone with access to the RPC port could potentially access wallet funds , stop the node from running and take other dangerous actions. Use caution when enabling this option, especially with external RPC access available. For more details see the Node Security page . Request: { \"action\" : \"wallet_lock\" , \"wallet\" : \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\" } Response: { \"locked\" : \"1\" }","title":"wallet_lock"},{"location":"commands/rpc-protocol/#wallet_locked","text":"Checks whether wallet is locked Request: { \"action\" : \"wallet_locked\" , \"wallet\" : \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\" } Response: { \"locked\" : \"0\" }","title":"wallet_locked"},{"location":"commands/rpc-protocol/#wallet_pending","text":"enable_control required, version 8.0+ Returns a list of block hashes which have not yet been received by accounts in this wallet Dangerous RPC calls controlled by enable_control This RPC command/option requires enable_control to be enabled within the RPC config file. Enabling this means that anyone with access to the RPC port could potentially access wallet funds , stop the node from running and take other dangerous actions. Use caution when enabling this option, especially with external RPC access available. For more details see the Node Security page . Request: { \"action\" : \"wallet_pending\" , \"wallet\" : \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\" , \"count\" : \"1\" } Response: { \"blocks\" : { \"nano_1111111111111111111111111111111111111111111111111117353trpda\" : [ \"142A538F36833D1CC78B94E11C766F75818F8B940771335C6C1B8AB880C5BB1D\" ], \"nano_3t6k35gi95xu6tergt6p69ck76ogmitsa8mnijtpxm9fkcm736xtoncuohr3\" : [ \"4C1FEEF0BEA7F50BE35489A1233FE002B212DEA554B55B1B470D78BD8F210C74\" ] } } Optional \"threshold\" Number (128 bit, decimal). Returns a list of pending block hashes with amount more or equal to threshold Request: { \"action\" : \"wallet_pending\" , \"wallet\" : \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\" , \"count\" : \"1\" , \"threshold\" : \"1000000000000000000000000\" } Response: { \"blocks\" : { \"nano_1111111111111111111111111111111111111111111111111117353trpda\" : { \"142A538F36833D1CC78B94E11C766F75818F8B940771335C6C1B8AB880C5BB1D\" : \"6000000000000000000000000000000\" }, \"nano_3t6k35gi95xu6tergt6p69ck76ogmitsa8mnijtpxm9fkcm736xtoncuohr3\" : { \"4C1FEEF0BEA7F50BE35489A1233FE002B212DEA554B55B1B470D78BD8F210C74\" : \"106370018000000000000000000000000\" } } } Optional \"source\" version 9.0+ Boolean, false by default. Returns a list of pending block hashes with amount and source accounts Request: { \"action\" : \"wallet_pending\" , \"wallet\" : \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\" , \"count\" : \"1\" , \"source\" : \"true\" } Response: { \"blocks\" : { \"nano_1111111111111111111111111111111111111111111111111117353trpda\" : { \"142A538F36833D1CC78B94E11C766F75818F8B940771335C6C1B8AB880C5BB1D\" : { \"amount\" : \"6000000000000000000000000000000\" , \"source\" : \"nano_3dcfozsmekr1tr9skf1oa5wbgmxt81qepfdnt7zicq5x3hk65fg4fqj58mbr\" } }, \"nano_3t6k35gi95xu6tergt6p69ck76ogmitsa8mnijtpxm9fkcm736xtoncuohr3\" : { \"4C1FEEF0BEA7F50BE35489A1233FE002B212DEA554B55B1B470D78BD8F210C74\" : { \"amount\" : \"106370018000000000000000000000000\" , \"source\" : \"nano_13ezf4od79h1tgj9aiu4djzcmmguendtjfuhwfukhuucboua8cpoihmh8byo\" } } } } Optional \"include_active\" version 15.0+ Boolean, false by default. Include active blocks without finished confirmations Request: { \"action\" : \"wallet_pending\" , \"wallet\" : \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\" , \"count\" : \"1\" , \"include_active\" : \"true\" } Optional \"min_version\" version 15.0+ Boolean, false by default. Returns the minimum version (epoch) of a block which can pocket this pending block. Optional \"include_only_confirmed\" version 19.0+ Boolean, false by default. Only returns block which have their confirmation height set or are undergoing confirmation height processing.","title":"wallet_pending"},{"location":"commands/rpc-protocol/#wallet_representative","text":"Returns the default representative for wallet Request: { \"action\" : \"wallet_representative\" , \"wallet\" : \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\" } Response: { \"representative\" : \"nano_3e3j5tkog48pnny9dmfzj1r16pg8t1e76dz5tmac6iq689wyjfpi00000000\" }","title":"wallet_representative"},{"location":"commands/rpc-protocol/#wallet_representative_set","text":"enable_control required Sets the default representative for wallet (used only for new accounts, already existing accounts use already set representatives) Dangerous RPC calls controlled by enable_control This RPC command/option requires enable_control to be enabled within the RPC config file. Enabling this means that anyone with access to the RPC port could potentially access wallet funds , stop the node from running and take other dangerous actions. Use caution when enabling this option, especially with external RPC access available. For more details see the Node Security page . Request: { \"action\" : \"wallet_representative_set\" , \"wallet\" : \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\" , \"representative\" : \"nano_3e3j5tkog48pnny9dmfzj1r16pg8t1e76dz5tmac6iq689wyjfpi00000000\" } Response: { \"set\" : \"1\" } Optional \"update_existing_accounts\" version 18.0+ Boolean, false by default. Change representative for existing accounts in wallet. May require a lot of time to complete for large wallets due to work generation for change type state blocks","title":"wallet_representative_set"},{"location":"commands/rpc-protocol/#wallet_republish","text":"enable_control required, version 8.0+ Rebroadcast blocks for accounts from wallet starting at frontier down to count to the network Dangerous RPC calls controlled by enable_control This RPC command/option requires enable_control to be enabled within the RPC config file. Enabling this means that anyone with access to the RPC port could potentially access wallet funds , stop the node from running and take other dangerous actions. Use caution when enabling this option, especially with external RPC access available. For more details see the Node Security page . Request: { \"action\" : \"wallet_republish\" , \"wallet\" : \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\" , \"count\" : \"2\" } Response: { \"blocks\" : [ \"991CF190094C00F0B68E2E5F75F6BEE95A2E0BD93CEAA4A6734DB9F19B728948\" , \"A170D51B94E00371ACE76E35AC81DC9405D5D04D4CEBC399AEACE07AE05DD293\" , \"90D0C16AC92DD35814E84BFBCC739A039615D0A42A76EF44ADAEF1D99E9F8A35\" ] }","title":"wallet_republish"},{"location":"commands/rpc-protocol/#wallet_work_get","text":"enable_control required, version 8.0+ Returns a list of pairs of account and work from wallet Dangerous RPC calls controlled by enable_control This RPC command/option requires enable_control to be enabled within the RPC config file. Enabling this means that anyone with access to the RPC port could potentially access wallet funds , stop the node from running and take other dangerous actions. Use caution when enabling this option, especially with external RPC access available. For more details see the Node Security page . Request: { \"action\" : \"wallet_work_get\" , \"wallet\" : \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\" } Response: { \"works\" : { \"nano_1111111111111111111111111111111111111111111111111111hifc8npp\" : \"432e5cf728c90f4f\" } }","title":"wallet_work_get"},{"location":"commands/rpc-protocol/#work_get","text":"enable_control required, version 8.0+ Retrieves work for account in wallet Dangerous RPC calls controlled by enable_control This RPC command/option requires enable_control to be enabled within the RPC config file. Enabling this means that anyone with access to the RPC port could potentially access wallet funds , stop the node from running and take other dangerous actions. Use caution when enabling this option, especially with external RPC access available. For more details see the Node Security page . Request: { \"action\" : \"work_get\" , \"wallet\" : \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\" , \"account\" : \"nano_1111111111111111111111111111111111111111111111111111hifc8npp\" } Response: { \"work\" : \"432e5cf728c90f4f\" }","title":"work_get"},{"location":"commands/rpc-protocol/#work_set","text":"enable_control required, version 8.0+ Set work for account in wallet Dangerous RPC calls controlled by enable_control This RPC command/option requires enable_control to be enabled within the RPC config file. Enabling this means that anyone with access to the RPC port could potentially access wallet funds , stop the node from running and take other dangerous actions. Use caution when enabling this option, especially with external RPC access available. For more details see the Node Security page . Request: { \"action\" : \"work_set\" , \"wallet\" : \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\" , \"account\" : \"nano_1111111111111111111111111111111111111111111111111111hifc8npp\" , \"work\" : \"0000000000000000\" } Response: { \"success\" : \"\" }","title":"work_set"},{"location":"commands/rpc-protocol/#unit-conversion-rpcs","text":"","title":"Unit Conversion RPCs"},{"location":"commands/rpc-protocol/#krai_from_raw","text":"Divide a raw amount down by the krai ratio. Request: { \"action\" : \"krai_from_raw\" , \"amount\" : \"1000000000000000000000000000\" } Response: { \"amount\" : \"1\" }","title":"krai_from_raw"},{"location":"commands/rpc-protocol/#krai_to_raw","text":"Multiply an krai amount by the krai ratio. Request: { \"action\" : \"krai_to_raw\" , \"amount\" : \"1\" } Response: { \"amount\" : \"1000000000000000000000000000\" }","title":"krai_to_raw"},{"location":"commands/rpc-protocol/#mrai_from_raw","text":"Divide a raw amount down by the Mrai ratio. Request: { \"action\" : \"mrai_from_raw\" , \"amount\" : \"1000000000000000000000000000000\" } Response: { \"amount\" : \"1\" }","title":"mrai_from_raw"},{"location":"commands/rpc-protocol/#mrai_to_raw","text":"Multiply an Mrai amount by the Mrai ratio. Request: { \"action\" : \"mrai_to_raw\" , \"amount\" : \"1\" } Response: { \"amount\" : \"1000000000000000000000000000000\" }","title":"mrai_to_raw"},{"location":"commands/rpc-protocol/#rai_from_raw","text":"Divide a raw amount down by the rai ratio. Request: { \"action\" : \"rai_from_raw\" , \"amount\" : \"1000000000000000000000000\" } Response: { \"amount\" : \"1\" }","title":"rai_from_raw"},{"location":"commands/rpc-protocol/#rai_to_raw","text":"Multiply an rai amount by the rai ratio. Request: { \"action\" : \"rai_to_raw\" , \"amount\" : \"1\" } Response: { \"amount\" : \"1000000000000000000000000\" }","title":"rai_to_raw"},{"location":"commands/rpc-protocol/#deprecated-rpcs","text":"","title":"Deprecated RPCs"},{"location":"commands/rpc-protocol/#history","text":"Deprecated : please use account_history instead. It provides a head option which is identical to the history hash option.","title":"history"},{"location":"commands/rpc-protocol/#removed-rpcs","text":"","title":"Removed RPCs"},{"location":"commands/rpc-protocol/#removed-in-v22","text":"","title":"Removed in v22"},{"location":"commands/rpc-protocol/#block_count_type","text":"Reports the number of blocks in the ledger by type (send, receive, open, change, state with version) Request: { \"action\" : \"block_count_type\" } Response: { \"send\" : \"5016664\" , \"receive\" : \"4081228\" , \"open\" : \"546457\" , \"change\" : \"24193\" , \"state_v0\" : \"4216537\" , \"state_v1\" : \"10653709\" , \"state\" : \"14870246\" }","title":"block_count_type"},{"location":"commands/rpc-protocol/#payment_begin","text":"Begin a new payment session. Searches wallet for an account that's marked as available and has a 0 balance. If one is found, the account number is returned and is marked as unavailable. If no account is found, a new account is created, placed in the wallet, and returned. Request: { \"action\" : \"payment_begin\" , \"wallet\" : \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\" } Response: { \"account\" : \"nano_3e3j5tkog48pnny9dmfzj1r16pg8t1e76dz5tmac6iq689wyjfpi00000000\" }","title":"payment_begin"},{"location":"commands/rpc-protocol/#payment_end","text":"End a payment session. Marks the account as available for use in a payment session. Request: { \"action\" : \"payment_end\" , \"account\" : \"nano_3e3j5tkog48pnny9dmfzj1r16pg8t1e76dz5tmac6iq689wyjfpi00000000\" , \"wallet\" : \"FFFD1BAEC8EC20814BBB9059B393051AAA8380F9B5A2E6B2489A277D81789EEE\" } Response: { }","title":"payment_end"},{"location":"commands/rpc-protocol/#payment_init","text":"Marks all accounts in wallet as available for being used as a payment session. Request: { \"action\" : \"payment_init\" , \"wallet\" : \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\" } Response: { \"status\" : \"Ready\" }","title":"payment_init"},{"location":"commands/rpc-protocol/#payment_wait","text":"Wait for payment of 'amount' to arrive in 'account' or until 'timeout' milliseconds have elapsed. Request: { \"action\" : \"payment_wait\" , \"account\" : \"nano_3e3j5tkog48pnny9dmfzj1r16pg8t1e76dz5tmac6iq689wyjfpi00000000\" , \"amount\" : \"1\" , \"timeout\" : \"1000\" } Response: { \"deprecated\" : \"1\" , \"status\" : \"success\" }","title":"payment_wait"},{"location":"integration-guides/advanced/","text":"Advanced Integrations \u00b6 Cold Wallets \u00b6 When security of funds is critical, it is a best practice to split your balance between multiple wallets: One or more hot wallets to handle daily user deposits/withdraws. One or more cold wallets to securely store Nano in an offline environment. Important A cold wallet manages private keys that have never been on a network-enabled computer. This guide extends the concepts covered in External Private Key Management . It is advised that you read that section before continuing. Note Operations done on the hot, online, insecure computer will be prefaced with (HOT) . Operations done on the cold, offline, secure computer will be prefaced with (COLD) . Both the hot and cold computers need to have the nano_node software installed. The hot nano_node needs to be synced with the network; the cold nano_node by definition should not be synced as it never connects to the internet . Cold Wallet Workflow The typical work flow for a cold wallet is as follows: (HOT) Gather account and transaction data. Transfer this data using an offline method (e.g. via USB stick) to the (COLD) secure offline computer. (COLD) Verify Head Block hash. (COLD) Generate and Sign new transaction data. Transfer the signed transaction back to the (HOT) insecure online-computer. (HOT) Publish the signed transaction to the Nano Network. sequenceDiagram participant Network participant HOT participant COLD HOT->>Network: Get Data Network->>HOT: Data Response HOT-->>COLD: Offline Transfer COLD-->>COLD: Verify COLD-->>COLD: Generate & Sign COLD-->>HOT: Return Signed HOT->>Network: Publish Signed Note over COLD,HOT: Cold/Hot Wallet transfers are done <br />offline using USB Stick or similar. Private Key Management \u00b6 The process for external private key management in a cold wallet is very similar to external private key management for a hot wallet. The primary difference is that all signing commands (and thus information containing your private key) are isolated to a clean computer with no network connection. (HOT) Account Information \u00b6 Get account information by the account_info RPC Command: Request Example curl -d '{ \"action\": \"account_info\", \"representative\": \"true\", \"account\": \"nano_3qb1qckpady6njewfotrdrcgakrgbfh7ytqfrd9r8txsx7d91b9pu6z1ixrg\" }' http://127.0.0.1:7076 Success Response { \"frontier\" : \"DC8EC06D1F32F97BD69BF59E3297563BD23779F72176A4FF553CFF52309C337E\" , \"open_block\" : \"2E1F5AD4BD2C840FD9DC3929ECE9EE6D0B4A8C870E45EDA11048DE91EC409165\" , \"representative_block\" : \"DC8EC06D1F32F97BD69BF59E3297563BD23779F72176A4FF553CFF52309C337E\" , \"balance\" : \"8900000000000000000000000\" , \"modified_timestamp\" : \"1524812177\" , \"block_count\" : \"105\" , \"representative\" : \"nano_3rropjiqfxpmrrkooej4qtmm1pueu36f9ghinpho4esfdor8785a455d16nf\" } (HOT) Balance Validation (Part 1) \u00b6 We should always assume the (HOT) computer has been compromised, so cannot trust the balance returned by account_info . We must obtain the headblock's transaction data and independently confirm the block's hash on our (COLD) offline computer. On the (HOT) online computer, this information can be obtained by the block_info RPC Command. Request Format curl -d '{ \"action\": \"block_info\", \"hash\": \"{{HEADBLOCK}}\" }' http://127.0.0.1:7076 Request Example curl -d '{ \"action\": \"block_info\", \"hash\": \"DC8EC06D1F32F97BD69BF59E3297563BD23779F72176A4FF553CFF52309C337E\" }' http://127.0.0.1:7076 Success Response { \"block_account\" : \"nano_3qb1qckpady6njewfotrdrcgakrgbfh7ytqfrd9r8txsx7d91b9pu6z1ixrg\" , \"amount\" : \"100000000000000000000000\" , \"balance\" : \"8900000000000000000000000\" , \"height\" : \"105\" , \"local_timestamp\" : \"0\" , \"contents\" : \"{\\n \\\"type\\\": \\\"state\\\",\\n \\\"account\\\": \\\"nano_3qb1qckpady6njewfotrdrcgakrgbfh7ytqfrd9r8txsx7d91b9pu6z1ixrg\\\",\\n \\\"previous\\\": \\\"829C33C4E1F41F24F50AB6AF8D0893F484E7078F0FA05F8F56CB69223E8EEE77\\\",\\n \\\"representative\\\": \\\"nano_3rropjiqfxpmrrkooej4qtmm1pueu36f9ghinpho4esfdor8785a455d16nf\\\",\\n \\\"balance\\\": \\\"8900000000000000000000000\\\",\\n \\\"link\\\": \\\"616349D5A5EBA49A73324EF29044B65E13644EC182FFC1ACA4371F897EFF22AA\\\",\\n \\\"link_as_account\\\": \\\"nano_1rd5b9ctdtx6mbsm6mqkk34deqimej9e51qzr8pcafrzj7zhyaockuye93sk\\\",\\n \\\"signature\\\": \\\"5058A5A1D371CE367D88DB232D398B33DF15FF95D84206986848F4165FFD9FB009B99D9DC6E90D2A3D96C639C7772497C6D6FFB8A67143AE9BB07DC49EB72401\\\",\\n \\\"work\\\": \\\"5621a5a58ef8964a\\\"\\n }\\n\" } Info Below are a few important points to remember: Contents are returned as a stringified JSON object. The type of the block is \"state\" . This guide only covers on how to trustlessly process \"state\" blocks on an offline computer. Transfer the response over to the (COLD) computer. (COLD) Balance Validation (Part 2) \u00b6 On the (COLD) computer, we need to verify the block hash using the block_hash RPC Command.. This allows us to create a safe transaction referencing the reported head block's balance. Request Format curl -d '{ \"action\": \"block_hash\", \"block\": \"<CONTENTS>\" }' http://127.0.0.1:7076 Request Example curl -d '{ \"action\": \"block_hash\", \"block\": \"{\\n \\\"type\\\": \\\"state\\\",\\n \\\"account\\\": \\\"nano_3qb1qckpady6njewfotrdrcgakrgbfh7ytqfrd9r8txsx7d91b9pu6z1ixrg\\\",\\n \\\"previous\\\": \\\"829C33C4E1F41F24F50AB6AF8D0893F484E7078F0FA05F8F56CB69223E8EEE77\\\",\\n \\\"representative\\\": \\\"nano_3rropjiqfxpmrrkooej4qtmm1pueu36f9ghinpho4esfdor8785a455d16nf\\\",\\n \\\"balance\\\": \\\"8900000000000000000000000\\\",\\n \\\"link\\\": \\\"616349D5A5EBA49A73324EF29044B65E13644EC182FFC1ACA4371F897EFF22AA\\\",\\n \\\"link_as_account\\\": \\\"nano_1rd5b9ctdtx6mbsm6mqkk34deqimej9e51qzr8pcafrzj7zhyaockuye93sk\\\",\\n \\\"signature\\\": \\\"5058A5A1D371CE367D88DB232D398B33DF15FF95D84206986848F4165FFD9FB009B99D9DC6E90D2A3D96C639C7772497C6D6FFB8A67143AE9BB07DC49EB72401\\\",\\n \\\"work\\\": \\\"5621a5a58ef8964a\\\"\\n }\\n\" }' http://127.0.0.1:7076 Success Response { \"hash\" : \"DC8EC06D1F32F97BD69BF59E3297563BD23779F72176A4FF553CFF52309C337E\" } Using the responded hash on the (COLD) computer guarentees that the transaction we are about to create on the (COLD) computer will have a safe, expected outcome. Important Lets consider the following scenarios where malicious software on the (HOT) computer modifies data: You are creating a send transaction. Malicious software alters the balance field of the head block to be lower than it actually is in an attempt to get you to send too much Nano to the destination address. This alters the block's hash, but the malicious software could report the honest headblock's hash. By independently computing the headblock's hash on the (COLD) computer, the generated transaction would be rejected by the network since the previous field references a non-existent block which is certainly not the headblock of your account. Use the responded hash for the previous field in your new transaction. When computing final account balance, compute it relative to the balance field of the headblock on the (COLD) computer. Complete the rest of the block creation as described in section External Private Key Management . Once the block is created and signed on the (COLD) computer, transfer the contents over to the (HOT) computer. From the (HOT) computer, run the process RPC command to broadcast the signed transaction to the network. HTTP callback \u00b6 Send JSON POST requests with every confirmed block to callback server configured for the node. Multiple notifications for blocks Depending on the node setup and sync status, multiple confirmation notifications for the same block hash may be sent by a single tracking mechanism. In order to prevent potential issues, integrations must track these block hashes externally to the node and prevent any unwanted actions based on multiple notifications. Configuration For details on configuring the HTTP callback within a node, see the HTTP callback section of Running a Node Configuration . Example Callback { \"account\" : \"nano_1ipx847tk8o46pwxt5qjdbncjqcbwcc1rrmqnkztrfjy5k7z4imsrata9est\" , \"hash\" : \"B785D56473DE6330AC9A2071F19BD44BCAF1DE5C200A826B4BBCC85E588620FB\" , \"block\" : \"{\\n \\\"type\\\": \\\"state\\\",\\n \\\"account\\\": \\\"nano_1ipx847tk8o46pwxt5qjdbncjqcbwcc1rrmqnkztrfjy5k7z4imsrata9est\\\",\\n \\\"previous\\\": \\\"82D68AE43E3E04CBBF9ED150999A347C2ABBE74B38D6E506C18DF7B1994E06C2\\\",\\n \\\"representative\\\": \\\"nano_1stofnrxuz3cai7ze75o174bpm7scwj9jn3nxsn8ntzg784jf1gzn1jjdkou\\\",\\n \\\"balance\\\": \\\"5256159500000000000000000000000000000\\\",\\n \\\"link\\\": \\\"8B95FEB05496327471F4729F0B0919E1994F9116FD213F44C76F696B7ECD386A\\\",\\n \\\"link_as_account\\\": \\\"nano_34woztr7b7jkgjrzawnz3e6jmresbyajfzb39x4eguubffzetg5c96f3s16p\\\",\\n \\\"signature\\\": \\\"FBE5CC5491B54FE9CD8C48312A7A6D3945835FD97F4526571E9BED50E407A27ED8FB0E4AA0BF67E2831B8DB32A74E686A62BF4EC162E8FBB6E665196135C050B\\\",\\n \\\"work\\\": \\\"824ca671ce7067ac\\\"\\n }\\n\" , \"amount\" : \"2500000000000000000000000000000\" } Send state blocks have special fields \"is_send\" & \"subtype\" { \"account\" : \"nano_1ipx847tk8o46pwxt5qjdbncjqcbwcc1rrmqnkztrfjy5k7z4imsrata9est\" , \"hash\" : \"82D68AE43E3E04CBBF9ED150999A347C2ABBE74B38D6E506C18DF7B1994E06C2\" , \"block\" : \"{\\n \\\"type\\\": \\\"state\\\",\\n \\\"account\\\": \\\"nano_1ipx847tk8o46pwxt5qjdbncjqcbwcc1rrmqnkztrfjy5k7z4imsrata9est\\\",\\n \\\"previous\\\": \\\"BE716FE4E21E0DC923ED67543601090A17547474CBA6D6F4B3FD6C113775860F\\\",\\n \\\"representative\\\": \\\"nano_1stofnrxuz3cai7ze75o174bpm7scwj9jn3nxsn8ntzg784jf1gzn1jjdkou\\\",\\n \\\"balance\\\": \\\"5256157000000000000000000000000000000\\\",\\n \\\"link\\\": \\\"5D1AA8A45F8736519D707FCB375976A7F9AF795091021D7E9C7548D6F45DD8D5\\\",\\n \\\"link_as_account\\\": \\\"nano_1qato4k7z3spc8gq1zyd8xeqfbzsoxwo36a45ozbrxcatut7up8ohyardu1z\\\",\\n \\\"signature\\\": \\\"5AF10D3DDD0E3D7A0EF18670560D194C35A519943150650BBBE0CBDB2A47A1E41817DA69112F996A9898E11F1D79EF51C041BD57C1686B81E7F9DFCCFFBAB000\\\",\\n \\\"work\\\": \\\"13ae0ea3e2af9004\\\"\\n }\\n\" , \"amount\" : \"90000000000000000000000000000000000\" , \"is_send\" : \"true\" , \"subtype\" : \"send\" } Warning It is recommended to fetch the block using the hash provided in the callback rather than trust this data is valid, and check that data instead, since a malicious 3 rd party can also make a fake callback request to your endpoint. Running Nano as a service \u00b6 There are 3 different ways to enable RPC for the node: In process rpc.enable = true rpc.child_process.enable = false (default, V19.0+) Child process V19.0+ only rpc.enable = true rpc.child_process.enable = true rpc.child_process.rpc_path = [path to nano_rpc] ipc.tcp.enable = true ipc.tcp.port = process.ipc_port of config-rpc.toml Out of node process V19.0+ only rpc.enable = false rpc.child_process.enable = false node.ipc.tcp.enable = true node.ipc.tcp.port == process.ipc_port of config-rpc.toml The choice depends on the setup and security that you want. The easiest way is to use RPC in_process according to configuration Launch nano_node in test mode ./nano_node --daemon --network=test Check if RPC is enabled with curl (use different terminal or session) curl -g -d '{ \"action\": \"block_count\" }' '[::1]:7076' Tip If you get curl: (7) Couldn't connect to server , replace [::1]:7076 with 127.0.0.1:7076 . To stop node, use curl -g -d '{ \"action\": \"stop\" }' '[::1]:7076' Launch nano_node as a service with systemd sudo touch /etc/systemd/system/nano_node.service sudo chmod 664 /etc/systemd/system/nano_node.service sudo nano /etc/systemd/system/nano_node.service Paste your specific user, group, path settings (example) [Unit] Description=Nano node service After=network.target [Service] ExecStart=/path_to_nano_node/nano_node --daemon Restart=on-failure User=username Group=groupname [Install] WantedBy=multi-user.target Start nano_node service sudo service nano_node start Enable at startup sudo systemctl enable nano_node Tip To manage node, use RPC commands or CLI Known issues \u00b6 Error initiating bootstrap ... Too many open files Increase max open files limit. Edit /etc/security/limits.conf & add * soft nofile 65535 * hard nofile 65535 root soft nofile 65535 root hard nofile 65535 Then restart session & nano_node service. Check changes with ulimit -n","title":"Advanced"},{"location":"integration-guides/advanced/#advanced-integrations","text":"","title":"Advanced Integrations"},{"location":"integration-guides/advanced/#cold-wallets","text":"When security of funds is critical, it is a best practice to split your balance between multiple wallets: One or more hot wallets to handle daily user deposits/withdraws. One or more cold wallets to securely store Nano in an offline environment. Important A cold wallet manages private keys that have never been on a network-enabled computer. This guide extends the concepts covered in External Private Key Management . It is advised that you read that section before continuing. Note Operations done on the hot, online, insecure computer will be prefaced with (HOT) . Operations done on the cold, offline, secure computer will be prefaced with (COLD) . Both the hot and cold computers need to have the nano_node software installed. The hot nano_node needs to be synced with the network; the cold nano_node by definition should not be synced as it never connects to the internet . Cold Wallet Workflow The typical work flow for a cold wallet is as follows: (HOT) Gather account and transaction data. Transfer this data using an offline method (e.g. via USB stick) to the (COLD) secure offline computer. (COLD) Verify Head Block hash. (COLD) Generate and Sign new transaction data. Transfer the signed transaction back to the (HOT) insecure online-computer. (HOT) Publish the signed transaction to the Nano Network. sequenceDiagram participant Network participant HOT participant COLD HOT->>Network: Get Data Network->>HOT: Data Response HOT-->>COLD: Offline Transfer COLD-->>COLD: Verify COLD-->>COLD: Generate & Sign COLD-->>HOT: Return Signed HOT->>Network: Publish Signed Note over COLD,HOT: Cold/Hot Wallet transfers are done <br />offline using USB Stick or similar.","title":"Cold Wallets"},{"location":"integration-guides/advanced/#private-key-management","text":"The process for external private key management in a cold wallet is very similar to external private key management for a hot wallet. The primary difference is that all signing commands (and thus information containing your private key) are isolated to a clean computer with no network connection.","title":"Private Key Management"},{"location":"integration-guides/advanced/#hot-account-information","text":"Get account information by the account_info RPC Command:","title":"(HOT) Account Information"},{"location":"integration-guides/advanced/#hot-balance-validation-part-1","text":"We should always assume the (HOT) computer has been compromised, so cannot trust the balance returned by account_info . We must obtain the headblock's transaction data and independently confirm the block's hash on our (COLD) offline computer. On the (HOT) online computer, this information can be obtained by the block_info RPC Command.","title":"(HOT) Balance Validation (Part 1)"},{"location":"integration-guides/advanced/#cold-balance-validation-part-2","text":"On the (COLD) computer, we need to verify the block hash using the block_hash RPC Command.. This allows us to create a safe transaction referencing the reported head block's balance.","title":"(COLD) Balance Validation (Part 2)"},{"location":"integration-guides/advanced/#http-callback","text":"Send JSON POST requests with every confirmed block to callback server configured for the node. Multiple notifications for blocks Depending on the node setup and sync status, multiple confirmation notifications for the same block hash may be sent by a single tracking mechanism. In order to prevent potential issues, integrations must track these block hashes externally to the node and prevent any unwanted actions based on multiple notifications. Configuration For details on configuring the HTTP callback within a node, see the HTTP callback section of Running a Node Configuration . Example Callback { \"account\" : \"nano_1ipx847tk8o46pwxt5qjdbncjqcbwcc1rrmqnkztrfjy5k7z4imsrata9est\" , \"hash\" : \"B785D56473DE6330AC9A2071F19BD44BCAF1DE5C200A826B4BBCC85E588620FB\" , \"block\" : \"{\\n \\\"type\\\": \\\"state\\\",\\n \\\"account\\\": \\\"nano_1ipx847tk8o46pwxt5qjdbncjqcbwcc1rrmqnkztrfjy5k7z4imsrata9est\\\",\\n \\\"previous\\\": \\\"82D68AE43E3E04CBBF9ED150999A347C2ABBE74B38D6E506C18DF7B1994E06C2\\\",\\n \\\"representative\\\": \\\"nano_1stofnrxuz3cai7ze75o174bpm7scwj9jn3nxsn8ntzg784jf1gzn1jjdkou\\\",\\n \\\"balance\\\": \\\"5256159500000000000000000000000000000\\\",\\n \\\"link\\\": \\\"8B95FEB05496327471F4729F0B0919E1994F9116FD213F44C76F696B7ECD386A\\\",\\n \\\"link_as_account\\\": \\\"nano_34woztr7b7jkgjrzawnz3e6jmresbyajfzb39x4eguubffzetg5c96f3s16p\\\",\\n \\\"signature\\\": \\\"FBE5CC5491B54FE9CD8C48312A7A6D3945835FD97F4526571E9BED50E407A27ED8FB0E4AA0BF67E2831B8DB32A74E686A62BF4EC162E8FBB6E665196135C050B\\\",\\n \\\"work\\\": \\\"824ca671ce7067ac\\\"\\n }\\n\" , \"amount\" : \"2500000000000000000000000000000\" } Send state blocks have special fields \"is_send\" & \"subtype\" { \"account\" : \"nano_1ipx847tk8o46pwxt5qjdbncjqcbwcc1rrmqnkztrfjy5k7z4imsrata9est\" , \"hash\" : \"82D68AE43E3E04CBBF9ED150999A347C2ABBE74B38D6E506C18DF7B1994E06C2\" , \"block\" : \"{\\n \\\"type\\\": \\\"state\\\",\\n \\\"account\\\": \\\"nano_1ipx847tk8o46pwxt5qjdbncjqcbwcc1rrmqnkztrfjy5k7z4imsrata9est\\\",\\n \\\"previous\\\": \\\"BE716FE4E21E0DC923ED67543601090A17547474CBA6D6F4B3FD6C113775860F\\\",\\n \\\"representative\\\": \\\"nano_1stofnrxuz3cai7ze75o174bpm7scwj9jn3nxsn8ntzg784jf1gzn1jjdkou\\\",\\n \\\"balance\\\": \\\"5256157000000000000000000000000000000\\\",\\n \\\"link\\\": \\\"5D1AA8A45F8736519D707FCB375976A7F9AF795091021D7E9C7548D6F45DD8D5\\\",\\n \\\"link_as_account\\\": \\\"nano_1qato4k7z3spc8gq1zyd8xeqfbzsoxwo36a45ozbrxcatut7up8ohyardu1z\\\",\\n \\\"signature\\\": \\\"5AF10D3DDD0E3D7A0EF18670560D194C35A519943150650BBBE0CBDB2A47A1E41817DA69112F996A9898E11F1D79EF51C041BD57C1686B81E7F9DFCCFFBAB000\\\",\\n \\\"work\\\": \\\"13ae0ea3e2af9004\\\"\\n }\\n\" , \"amount\" : \"90000000000000000000000000000000000\" , \"is_send\" : \"true\" , \"subtype\" : \"send\" } Warning It is recommended to fetch the block using the hash provided in the callback rather than trust this data is valid, and check that data instead, since a malicious 3 rd party can also make a fake callback request to your endpoint.","title":"HTTP callback"},{"location":"integration-guides/advanced/#running-nano-as-a-service","text":"There are 3 different ways to enable RPC for the node: In process rpc.enable = true rpc.child_process.enable = false (default, V19.0+) Child process V19.0+ only rpc.enable = true rpc.child_process.enable = true rpc.child_process.rpc_path = [path to nano_rpc] ipc.tcp.enable = true ipc.tcp.port = process.ipc_port of config-rpc.toml Out of node process V19.0+ only rpc.enable = false rpc.child_process.enable = false node.ipc.tcp.enable = true node.ipc.tcp.port == process.ipc_port of config-rpc.toml The choice depends on the setup and security that you want. The easiest way is to use RPC in_process according to configuration Launch nano_node in test mode ./nano_node --daemon --network=test Check if RPC is enabled with curl (use different terminal or session) curl -g -d '{ \"action\": \"block_count\" }' '[::1]:7076' Tip If you get curl: (7) Couldn't connect to server , replace [::1]:7076 with 127.0.0.1:7076 . To stop node, use curl -g -d '{ \"action\": \"stop\" }' '[::1]:7076' Launch nano_node as a service with systemd sudo touch /etc/systemd/system/nano_node.service sudo chmod 664 /etc/systemd/system/nano_node.service sudo nano /etc/systemd/system/nano_node.service Paste your specific user, group, path settings (example) [Unit] Description=Nano node service After=network.target [Service] ExecStart=/path_to_nano_node/nano_node --daemon Restart=on-failure User=username Group=groupname [Install] WantedBy=multi-user.target Start nano_node service sudo service nano_node start Enable at startup sudo systemctl enable nano_node Tip To manage node, use RPC commands or CLI","title":"Running Nano as a service"},{"location":"integration-guides/advanced/#known-issues","text":"Error initiating bootstrap ... Too many open files Increase max open files limit. Edit /etc/security/limits.conf & add * soft nofile 65535 * hard nofile 65535 root soft nofile 65535 root hard nofile 65535 Then restart session & nano_node service. Check changes with ulimit -n","title":"Known issues"},{"location":"integration-guides/block-confirmation-tracking/","text":"Block Confirmation Tracking \u00b6 Guide based on node V19.0 The recommendations below are based on node V19.0 and node versions earlier may not have all these options available. All integrations should upgrade their nodes to make use of easier block confirmation procedures detailed here. A primary function of any integration is to track confirmation of blocks on the network and the node provides both proactive notifications and options to request confirmation status on individual blocks. This combination allows building of robust systems for monitoring the status of any blocks of interest. Notifications and fallback requests both recommended Due to notification methods not guaranteeing delivery of every block confirmed, it is recommended that manual requests for confirmation status be implemented as a fallback option. Both these types of methods are outlined below. Receiving notifications of confirmation \u00b6 The recommended method for receiving notifications is via WebSockets through the confirmation topic . This method involves sending a subscribe command to start receiving notifications every time a block is confirmed by the network. It is recommended that the confirmation_type filtering options are not used for this purpose, to make it less likely to miss a notification. Setup process Update your WebSocket configuration Connect to the WebSocket at the configured endpoint Send a subscription request for all confirmations including the ack option and validate the subscription request was successful Listen for block confirmation notifications from the WebSocket As confirmations are received they can be parsed and handled as necessary. All operations handling notifications from the node on block confirmation should be idempotent as multiple notifications for the same block hash can occur. Multiple notifications for blocks Depending on the node setup and sync status, multiple confirmation notifications for the same block hash may be sent by a single tracking mechanism. In order to prevent potential issues, integrations must track these block hashes externally to the node and prevent any unwanted actions based on multiple notifications. Requesting block confirmation status \u00b6 In the event confirmation notifications are not received from the WebSocket in an expected timeframe, the block_info RPC can be called on a specific block hash. The confirmed field will indicate whether the block has been confirmed. Typical confirmation times on the main network during low-traffic periods are within a few seconds, so a delay of 5 seconds before requesting block information is recommended. If confirmation has still not been seen on the block, the block_confirm RPC can be called. This will cause the following: If the block is confirmed, it will trigger a notification through the WebSocket and HTTP Callbacks, and the block hash will also appear in the confirmation_history RPC (recommended for debug purposes only). If the block is not in active elections, it will start an election which should result in confirmation and related notifications. If the block is already in active elections, it will not have an effect and confirmation should eventually occur along with related notifications. Once block_confirm is called, a notification of confirmation through the WebSocket should be expected and if not received, then calling block_info RPC to check for confirmation again can be done. Escalation of potential delays in confirmation can be done after this point in external systems as necessary. Account frontier confirmation status \u00b6 For some systems the starting point for checking block status may be the account, such as when a user views their account. The following process is recommended when the account is known and the confirmation status of the frontier block is desired. Call account_info RPC to get current frontier hash Call block_info for the frontier hash and check if confirmed = true If the block is not confirmed, you can follow a similar process outlined in the Requesting block confirmation status section above for requesting block confirmation and re-checking confirmation status before escalating in external systems.","title":"Block Confirmation Tracking"},{"location":"integration-guides/block-confirmation-tracking/#block-confirmation-tracking","text":"Guide based on node V19.0 The recommendations below are based on node V19.0 and node versions earlier may not have all these options available. All integrations should upgrade their nodes to make use of easier block confirmation procedures detailed here. A primary function of any integration is to track confirmation of blocks on the network and the node provides both proactive notifications and options to request confirmation status on individual blocks. This combination allows building of robust systems for monitoring the status of any blocks of interest. Notifications and fallback requests both recommended Due to notification methods not guaranteeing delivery of every block confirmed, it is recommended that manual requests for confirmation status be implemented as a fallback option. Both these types of methods are outlined below.","title":"Block Confirmation Tracking"},{"location":"integration-guides/block-confirmation-tracking/#receiving-notifications-of-confirmation","text":"The recommended method for receiving notifications is via WebSockets through the confirmation topic . This method involves sending a subscribe command to start receiving notifications every time a block is confirmed by the network. It is recommended that the confirmation_type filtering options are not used for this purpose, to make it less likely to miss a notification. Setup process Update your WebSocket configuration Connect to the WebSocket at the configured endpoint Send a subscription request for all confirmations including the ack option and validate the subscription request was successful Listen for block confirmation notifications from the WebSocket As confirmations are received they can be parsed and handled as necessary. All operations handling notifications from the node on block confirmation should be idempotent as multiple notifications for the same block hash can occur. Multiple notifications for blocks Depending on the node setup and sync status, multiple confirmation notifications for the same block hash may be sent by a single tracking mechanism. In order to prevent potential issues, integrations must track these block hashes externally to the node and prevent any unwanted actions based on multiple notifications.","title":"Receiving notifications of confirmation"},{"location":"integration-guides/block-confirmation-tracking/#requesting-block-confirmation-status","text":"In the event confirmation notifications are not received from the WebSocket in an expected timeframe, the block_info RPC can be called on a specific block hash. The confirmed field will indicate whether the block has been confirmed. Typical confirmation times on the main network during low-traffic periods are within a few seconds, so a delay of 5 seconds before requesting block information is recommended. If confirmation has still not been seen on the block, the block_confirm RPC can be called. This will cause the following: If the block is confirmed, it will trigger a notification through the WebSocket and HTTP Callbacks, and the block hash will also appear in the confirmation_history RPC (recommended for debug purposes only). If the block is not in active elections, it will start an election which should result in confirmation and related notifications. If the block is already in active elections, it will not have an effect and confirmation should eventually occur along with related notifications. Once block_confirm is called, a notification of confirmation through the WebSocket should be expected and if not received, then calling block_info RPC to check for confirmation again can be done. Escalation of potential delays in confirmation can be done after this point in external systems as necessary.","title":"Requesting block confirmation status"},{"location":"integration-guides/block-confirmation-tracking/#account-frontier-confirmation-status","text":"For some systems the starting point for checking block status may be the account, such as when a user views their account. The following process is recommended when the account is known and the confirmation status of the frontier block is desired. Call account_info RPC to get current frontier hash Call block_info for the frontier hash and check if confirmed = true If the block is not confirmed, you can follow a similar process outlined in the Requesting block confirmation status section above for requesting block confirmation and re-checking confirmation status before escalating in external systems.","title":"Account frontier confirmation status"},{"location":"integration-guides/build-options/","text":"Build Options \u00b6 Only Official Builds Supported The fastest and most recommended method of installation is through Docker management Only official release builds are recommended and supported for use on the main network Builds created from git should be done using the available release tags ( V21.2 etc.) Official release builds \u00b6 Each release cycle official builds of the node for Linux, MacOS and Windows are generated and linked to from the related GitHub Release : OS Download link/command Verification Universal Linux https://repo.nano.org/live/binaries/nano-node-V21.2-Linux.tar.bz2 SHA256 Checksum Debian http://repo.nano.org/live/binaries/nano-node-V21.2-Linux.deb SHA256 Checksum macOS https://repo.nano.org/live/binaries/nano-node-V21.2-Darwin.dmg SHA256 Checksum Windows (exe) https://repo.nano.org/live/binaries/nano-node-V21.2-win64.exe SHA256 Checksum Windows (zip) https://repo.nano.org/live/binaries/nano-node-V21.2-win64.zip SHA256 Checksum Docker docker pull nanocurrency/nano:V21.2 or docker pull nanocurrency/nano:latest See Pulling the Docker Image for more details. RHEL/CentOS rpm sudo rpm -iUvh https://repo.nano.org/live/binaries/nanocurrency-21.2-21.el7.x86_64.rpm This installs nano_node and nano_rpc to /usr/bin . SHA256 Checksum Known Issue V20: Peers stake reporting inaccurate (Windows only) Issue: For Windows builds only, when calling confirmation_quorum RPC the peers_stake_total amount returned may be inaccurate, returning a range from the correct full peer stake amount down to 0. Solution: A solution to the issue has been found and as this is a reporting issue only, the fix will be included in the next released version. For those manually building the node, patching the fix pull request onto the V20.0 tag can resolve the issue now. Or alternatively, building on the V20.0 tag with RelWithDebInfo option, see Build Instructions for Windows . Known Issue V19+: macOS 'Too many open files' Issue: The following error can be seen when attempting to run a full node on macOS using the built-in Qt wallet or other GUI-based wallets: \"Exception while running wallet: open: Too many open files\". This is due to macOS having a very low default file descriptor limit and V19.0 uses more of them after the move to TCP. Solution: For now a workaround is needed to increase the limit. The method depends on the specific macOS version, but some people had success with the recipe in https://superuser.com/a/1171028 . Beta builds \u00b6 Each beta release cycle official beta builds of the node for Linux, MacOS and Windows are released, along with Docker images. Go to the Beta Network page for more details. Other sources The beta node can be also be installed for RHEL/CentOS rpm: sudo yum-config-manager --add-repo https://repo.nano.org/nanocurrency-beta.repo sudo yum install nanocurrency-beta This installs nano_node-beta to bin. Test builds \u00b6 Each Release Candidate (RC) or final release build can be used on the public test network for general integration and node upgrade testing. Go to the Test Network page for more details about Docker, binaries configuration, etc., or see the Test network section below for manual build details. Nano Directory \u00b6 Contents \u00b6 The Nano directory contains: wallets file ( wallets.ldb ), log files , optional config files, ledger file (data.ldb) and related lock files. Protect wallet and backup files The built-in node wallet is for use in development and testing only. Those using it should take care in protecting access to the wallets.ldb file and backup files, whether encrypted or not, for added security. Locations \u00b6 OS Location Windows C: \\U sers \\< user> \\A ppData \\L ocal \\N ano \\ macOS /Users/<user>/Library/Nano/ Linux /home/<user>/Nano/ Moving directory locations Some users desire to change the blockchain download location. A solution is available for the no gui nano_node (see https://github.com/nanocurrency/nano-node/issues/79 ), but no concrete solution is available for the GUI client. However, a workaround can be acheived via the use of symbolic links. Below is a short tutorial for Windows builds: Rename/delete the Nano directory in your appdata Local directory (if you haven't run the wallet yet, skip this step). This is necessary because the command to create a symbolic link in windows will fail if the the input directory already exists. Decide on where you want to store the blockchain and create a symbolic link. The command is (in an administrative command-prompt): mklink /d \"C:\\Users\\<user>\\AppData\\Local\\Nano\\\" \"E:\\Some\\Other\\Directory\" . This command creates a symbolic link for a directory ( /d ) that 'redirects' all requests for files/directories in the Local\\Nano directory to the Other\\Directory . This means that a file created in the input directory will actually be in the output directory (on the other disk). Verify it works. Create a file in your Nano directory in your appdata, and you should see it appear in the directory you linked it to (and vice-versa). If you have old wallets or a partially-downloaded blockchain, copy them back into the local directory. Start the wallet. General Build Instructions \u00b6 Unsupported configuration This documentation is intended only for developers of the Nano Node software, and will not result in a supported configuration. End-users are advised to use releases. The fastest and most recommended method of installation is through Docker . Running node as a service . To manage a node, use RPC commands or the CLI . Requirements Required Source Boost 1.69+ extracted to [boost.src] (OR bash nano-node/util/build_prep/bootstrap_boost.sh -m ) (wallet) Qt 5.x open source edition extracted to [qt.src] Nano node source in [nano-node.src] Required build tools (macOS) XCode >= 7.3 (Windows) Visual Studio 2015 (Windows) NSIS package builder (*nix) Clang >= 3.5 or GCC >= 5 CMake Boost \u00b6 Option 1 Inside nano-node directory run: bash util/build_prep/bootstrap_boost.sh -m This will build the required Boost libraries at /usr/local/boost/ . Option 2 Inside [boost.src] run: ./bootstrap.sh --with-libraries = filesystem,log,program_options,system,thread ./b2 --prefix =[ boost ] --build-dir =[ boost.build ] link = static install If on Windows: an additional b2 option address-model=64 for x64 builds should be included. QT Wallet \u00b6 In [qt.build] execute: [ qt.src ] /configure -shared -opensource -nomake examples -nomake tests -confirm-license -prefix [ qt ] make make install If on Windows: use nmake instead of make . Node \u00b6 CMake variables Format: cmake -D VARNAME=VARVALUE BOOST_ROOT=\\[boost\\] ( /usr/local/boost/ if bootstrapped) CMAKE_BUILD_TYPE=Release (default) ACTIVE_NETWORK=nano_live_network (default) Qt5_DIR=[qt]lib/cmake/Qt5 (to build GUI wallet) NANO_GUI=ON (to build GUI wallet) ENABLE_AVX2=ON , optional PERMUTE_WITH_GATHER=ON , optional PERMUTE_WITH_SHUFFLES=ON (for CPU with AXV2 support, choose fastest method for your CPU with https://github.com/sneves/blake2-avx2/ ) CRYPTOPP_CUSTOM=ON (more conservative building of Crypto++ for wider range of systems) NANO_SIMD_OPTIMIZATIONS=OFF (Enable CPU-specific SIMD optimization: SSE/AVX or NEON, e.g.) NANO_SECURE_RPC=ON (to build node with TLS) NANO_WARN_TO_ERR=ON ( v20.0+ turn compiler warnings into errors on Linux/Mac) NANO_TIMED_LOCKS=50 ( v20.0+ when the number of milliseconds a mutex is held is equal or greater than this output a stacktrace, 0 disables.) NANO_STACKTRACE_BACKTRACE=ON ( v20.0+ use a different configuration of Boost backtrace in stacktraces, attempting to display filenames, function names and line numbers. Needs libbacktrace to be installed. Some workarounds may be necessary depending on system and configuration. Use CLI --debug_stacktrace to get an example output.) CI_BUILD=TRUE ( v20.0+ if enabled, uses environment variable TRAVIS_TAG (required) to modify the locally reported node version; example TRAVIS_TAG=\"My Nano Node v20\" ) NANO_ROCKSDB=ON ( v20.0+ NOTE: RocksDB support is still in experimental stages and should not be used in production systems. To build the node with RocksDB click here for more details) NANO_ASIO_HANDLER_TRACKING=10 (Output asio diagnostics for any completion handlers which have taken longer than this in milliseconds. For more information see the description of the PR #2681 ) NANO_FUZZER_TEST=ON (Build the fuzz tests, not available on Windows) Build Node git submodule update --init --recursive Generate with cmake then build with your compiler (*nix) to build node without GUI execute: make nano_node (*nix) to build wallet with GUI execute: make nano_wallet (*nix) to build rpc for child/out of process execute: make nano_rpc Building a package (macOS) cpack -G \"DragNDrop\" (Windows) cpack -G \"NSIS\" (*nix) cpack -G \"TBZ2\" Testing the Node In order to run the tests, the corresponding CMake variable must be set: -D NANO_TEST=ON . With this variable set, make will also build test files, and will produce core_test , rpc_test , load_test and slow_test binaries, which can be executed such as ./core_test . See more details in Testing Beta Network Participation More information can be found on the Beta Network page To run a node on the beta network, set CMake variable: -DACTIVE_NETWORK=nano_beta_network Test Network Participation More information can be found on the Test Network page To run a node on the test network, set CMake variable: -DACTIVE_NETWORK=nano_test_network Debian/Ubuntu Dependencies \u00b6 These instructions are for the following systems: Ubuntu 16.04 LTS Server Ubuntu 16.10+ Debian 8 Jessie (Debian 8 requires Cmake 3.4+) Debian 9 Stretch Install dependencies sudo apt-get update && sudo apt-get upgrade sudo apt-get install git cmake g++ curl wget Follow the build instructions . CentOS 7 Dependencies \u00b6 Requirements GCC compiler version 4.9+ or other compiler with C++14 language support (default Centos 7 compilers are outdated) Cmake 3.4+ Install dependencies sudo yum check-update sudo yum install git libstdc++-static curl wget Configure repository with modern GCC sudo yum install centos-release-scl sudo yum install devtoolset-7-gcc* scl enable devtoolset-7 bash Modern Cmake wget https://cmake.org/files/v3.12/cmake-3.12.1.tar.gz tar zxvf cmake-3.12.1.tar.gz && cd cmake-3.12.1 ./bootstrap --prefix = /usr/local make -j $( nproc ) sudo make install cd .. Follow the build instructions . Arch Linux Dependencies \u00b6 Install dependencies pacman -Syu pacman -S base-devel git gcc cmake curl wget Follow the build instructions . Build Instructions - Debian, CentOS, Arch Linux \u00b6 Unsupported configuration This documentation is intended only for developers of the Nano Node software, and will not result in a supported configuration. End-users are advised to use releases. The fastest and most recommended method of installation is through Docker . Running node as a service . To manage a node, use RPC commands or the CLI . Node \u00b6 git clone --branch V21.2 --recursive https://github.com/nanocurrency/nano-node.git nano_build cd nano_build export BOOST_ROOT = ` pwd ` /../boost_build bash util/build_prep/bootstrap_boost.sh -m cmake -G \"Unix Makefiles\" . make nano_node cp nano_node ../nano_node && cd .. && ./nano_node --diagnostics Build Instructions - macOS \u00b6 Unsupported configuration This documentation is intended only for developers of the Nano Node software, and will not result in a supported configuration. End-users are advised to use releases. The fastest and most recommended method of installation is through Docker . Running node as a service . To manage a node, use RPC commands or the CLI . git clone --branch V21.2 --recursive https://github.com/nanocurrency/nano-node.git nano_build cd nano_build export BOOST_ROOT = ` pwd ` /../boost_build bash util/build_prep/bootstrap_boost.sh -m cmake -G \"Unix Makefiles\" . make nano_node cp nano_node ../nano_node && cd .. && ./nano_node --diagnostics Build Instructions - Windows \u00b6 Unsupported configuration This documentation is intended only for developers of the Nano Node software, and will not result in a supported configuration. End-users are advised to use releases. The fastest and most recommended method of installation is through Docker . Running node as a service . To manage a node, use RPC commands or the CLI . Dependencies \u00b6 Boost 1.69+ for your build env Qt 5.9.5+ 64-bit (open source version) appropriate for your build env Git for Windows git_bash CMake Visual Studio 2017 Community (or higher edition, if you have a valid license. eg. Professional or Enterprise) Select Desktop development with C++ Select the latest Windows 10 SDK Setup \u00b6 Download Source Using git_bash: git clone --branch V21.1 --recursive https://github.com/nanocurrency/nano-node cd nano-node Create a build directory inside nano-node (makes for easier cleaning of build) Using git_bash: mkdir build cd build * Note: all subsequent commands should be run within this \"build\" directory. Get redistributables Using Powershell: Invoke-WebRequest -Uri https://aka.ms/vs/15/release/vc_redist.x64.exe -OutFile . \\v c_redist.x64.exe Generate the build configuration. Using 64 Native Tools Command Prompt: Replace %CONFIGURATION% with one of the following: Release , RelWithDebInfo , Debug Replace %NETWORK% with one of the following: nano_beta_network , nano_live_network , nano_test_network Ensure the Qt, Boost, and Windows SDK paths match your installation. cmake -DNANO_GUI = ON -DCMAKE_BUILD_TYPE = %CONFIGURATION% -DACTIVE_NETWORK = %NETWORK% -DQt5_DIR = \"C:\\Qt\\5.9.5\\msvc2017_64\\lib\\cmake\\Qt5\" -DNANO_SIMD_OPTIMIZATIONS = TRUE -DBoost_COMPILER = \"-vc141\" -DBOOST_ROOT = \"C:/local/boost_1_69_0\" -DBOOST_LIBRARYDIR = \"C:/local/boost_1_69_0/lib64-msvc-14.1\" -G \"Visual Studio 15 2017 Win64\" -DIPHLPAPI_LIBRARY = \"C:/Program Files (x86)/Windows Kits/10/Lib/10.0.17763.0/um/x64/iphlpapi.lib\" -DWINSOCK2_LIBRARY = \"C:/Program Files (x86)/Windows Kits/10/Lib/10.0.17763.0/um/x64/WS2_32.lib\" .. \\. Build \u00b6 Open nano-node.sln in Visual Studio Build the configuration specified in the previous step Alternative using 64 Native Tools Command Prompt: cmake --build . --target ALL_BUILD --config %CONFIGURATION% -- /m:%NUMBER_OF_PROCESSORS% Package up binaries \u00b6 Using 64 Native Tools Command Prompt: Replace %CONFIGURATION% with the build configuration specified in previous step Replace %GENERATOR% with NSIS (if installed) or ZIP cpack -G %GENERATOR% -C %CONFIGURATION% Testing \u00b6 A number of tests binaries can be built when the -DNANO_TEST CMake variable is set to ON . core_test - Tests the majority of protocol, node and network functionality. slow_test - Tests which operate on a large amount of data and may take a while. Not currently tested by CI. rpc_test - Tests all RPC commands load_test - Launches many nodes and RPC servers, checking sending/receiving blocks with simultaneous calls. Use ./load_test --help to see the available options Running Tests \u00b6 To run all tests in a binary just launch it: ./core_test To check a specific subset of tests, gtest filtering can be used (with optional wildcards): ./core_test --gtest_filter = confirmation_height.single ./rpc_test --gtest_filter = rpc.* To run tests multiple times: ./core_test --gtest_repeat = 10 If running on a debugger, add the argument --gtest_break_on_failure break at the moment a test fails. Environment variables to customize tests \u00b6 TEST_KEEP_TMPDIRS=1 - Setting this to anything will prevent the tests deleting any files it creates, useful for debugging log files. TEST_USE_ROCKSDB=1 - Use the RocksDB ledger backend for the tests instead of LMDB. The tests must be built with RocksDB support. TEST_BASE_PORT=26000 - The base port used in tests, the range of ports used in this case would be 26000 - 26199. This is useful if wanting to run multiple tests at once without port conflicts, the default base port used is 24000. Sanitizers \u00b6 3 different CMake sanitizer options are supported: NANO_ASAN_INT , NANO_TSAN and NANO_ASAN . They cannot be used in conjunction with each other. Thread Sanitizer \u00b6 Use -DNANO_TSAN=ON as an extra CMake option. The following environment variable should also be set: export TSAN_OPTIONS=\"suppressions=../tsan_suppressions\" tsan_suppressions should be a path to the file in the root nano directory. This suppresses many errors relating to the mdb and rocksdb libraries. Address Sanitizer \u00b6 Use the CMake variable -DNANO_ASAN=ON or -DNANO_ASAN_INT=ON before running an executable. Valgrind \u00b6 Valgrind can be used to find other issues such as memory leaks. A valgrind suppressions file is provided to remove some warnings. Valgrind can be run as follows (there are many options available): valgrind --leak-check = full --track-origins = yes --suppressions = ../valgrind.supp ./core_test","title":"Build Options"},{"location":"integration-guides/build-options/#build-options","text":"Only Official Builds Supported The fastest and most recommended method of installation is through Docker management Only official release builds are recommended and supported for use on the main network Builds created from git should be done using the available release tags ( V21.2 etc.)","title":"Build Options"},{"location":"integration-guides/build-options/#official-release-builds","text":"Each release cycle official builds of the node for Linux, MacOS and Windows are generated and linked to from the related GitHub Release : OS Download link/command Verification Universal Linux https://repo.nano.org/live/binaries/nano-node-V21.2-Linux.tar.bz2 SHA256 Checksum Debian http://repo.nano.org/live/binaries/nano-node-V21.2-Linux.deb SHA256 Checksum macOS https://repo.nano.org/live/binaries/nano-node-V21.2-Darwin.dmg SHA256 Checksum Windows (exe) https://repo.nano.org/live/binaries/nano-node-V21.2-win64.exe SHA256 Checksum Windows (zip) https://repo.nano.org/live/binaries/nano-node-V21.2-win64.zip SHA256 Checksum Docker docker pull nanocurrency/nano:V21.2 or docker pull nanocurrency/nano:latest See Pulling the Docker Image for more details. RHEL/CentOS rpm sudo rpm -iUvh https://repo.nano.org/live/binaries/nanocurrency-21.2-21.el7.x86_64.rpm This installs nano_node and nano_rpc to /usr/bin . SHA256 Checksum Known Issue V20: Peers stake reporting inaccurate (Windows only) Issue: For Windows builds only, when calling confirmation_quorum RPC the peers_stake_total amount returned may be inaccurate, returning a range from the correct full peer stake amount down to 0. Solution: A solution to the issue has been found and as this is a reporting issue only, the fix will be included in the next released version. For those manually building the node, patching the fix pull request onto the V20.0 tag can resolve the issue now. Or alternatively, building on the V20.0 tag with RelWithDebInfo option, see Build Instructions for Windows . Known Issue V19+: macOS 'Too many open files' Issue: The following error can be seen when attempting to run a full node on macOS using the built-in Qt wallet or other GUI-based wallets: \"Exception while running wallet: open: Too many open files\". This is due to macOS having a very low default file descriptor limit and V19.0 uses more of them after the move to TCP. Solution: For now a workaround is needed to increase the limit. The method depends on the specific macOS version, but some people had success with the recipe in https://superuser.com/a/1171028 .","title":"Official release builds"},{"location":"integration-guides/build-options/#beta-builds","text":"Each beta release cycle official beta builds of the node for Linux, MacOS and Windows are released, along with Docker images. Go to the Beta Network page for more details. Other sources The beta node can be also be installed for RHEL/CentOS rpm: sudo yum-config-manager --add-repo https://repo.nano.org/nanocurrency-beta.repo sudo yum install nanocurrency-beta This installs nano_node-beta to bin.","title":"Beta builds"},{"location":"integration-guides/build-options/#test-builds","text":"Each Release Candidate (RC) or final release build can be used on the public test network for general integration and node upgrade testing. Go to the Test Network page for more details about Docker, binaries configuration, etc., or see the Test network section below for manual build details.","title":"Test builds"},{"location":"integration-guides/build-options/#nano-directory","text":"","title":"Nano Directory"},{"location":"integration-guides/build-options/#contents","text":"The Nano directory contains: wallets file ( wallets.ldb ), log files , optional config files, ledger file (data.ldb) and related lock files. Protect wallet and backup files The built-in node wallet is for use in development and testing only. Those using it should take care in protecting access to the wallets.ldb file and backup files, whether encrypted or not, for added security.","title":"Contents"},{"location":"integration-guides/build-options/#locations","text":"OS Location Windows C: \\U sers \\< user> \\A ppData \\L ocal \\N ano \\ macOS /Users/<user>/Library/Nano/ Linux /home/<user>/Nano/ Moving directory locations Some users desire to change the blockchain download location. A solution is available for the no gui nano_node (see https://github.com/nanocurrency/nano-node/issues/79 ), but no concrete solution is available for the GUI client. However, a workaround can be acheived via the use of symbolic links. Below is a short tutorial for Windows builds: Rename/delete the Nano directory in your appdata Local directory (if you haven't run the wallet yet, skip this step). This is necessary because the command to create a symbolic link in windows will fail if the the input directory already exists. Decide on where you want to store the blockchain and create a symbolic link. The command is (in an administrative command-prompt): mklink /d \"C:\\Users\\<user>\\AppData\\Local\\Nano\\\" \"E:\\Some\\Other\\Directory\" . This command creates a symbolic link for a directory ( /d ) that 'redirects' all requests for files/directories in the Local\\Nano directory to the Other\\Directory . This means that a file created in the input directory will actually be in the output directory (on the other disk). Verify it works. Create a file in your Nano directory in your appdata, and you should see it appear in the directory you linked it to (and vice-versa). If you have old wallets or a partially-downloaded blockchain, copy them back into the local directory. Start the wallet.","title":"Locations"},{"location":"integration-guides/build-options/#general-build-instructions","text":"Unsupported configuration This documentation is intended only for developers of the Nano Node software, and will not result in a supported configuration. End-users are advised to use releases. The fastest and most recommended method of installation is through Docker . Running node as a service . To manage a node, use RPC commands or the CLI . Requirements Required Source Boost 1.69+ extracted to [boost.src] (OR bash nano-node/util/build_prep/bootstrap_boost.sh -m ) (wallet) Qt 5.x open source edition extracted to [qt.src] Nano node source in [nano-node.src] Required build tools (macOS) XCode >= 7.3 (Windows) Visual Studio 2015 (Windows) NSIS package builder (*nix) Clang >= 3.5 or GCC >= 5 CMake","title":"General Build Instructions"},{"location":"integration-guides/build-options/#boost","text":"Option 1 Inside nano-node directory run: bash util/build_prep/bootstrap_boost.sh -m This will build the required Boost libraries at /usr/local/boost/ . Option 2 Inside [boost.src] run: ./bootstrap.sh --with-libraries = filesystem,log,program_options,system,thread ./b2 --prefix =[ boost ] --build-dir =[ boost.build ] link = static install If on Windows: an additional b2 option address-model=64 for x64 builds should be included.","title":"Boost"},{"location":"integration-guides/build-options/#qt-wallet","text":"In [qt.build] execute: [ qt.src ] /configure -shared -opensource -nomake examples -nomake tests -confirm-license -prefix [ qt ] make make install If on Windows: use nmake instead of make .","title":"QT Wallet"},{"location":"integration-guides/build-options/#node","text":"CMake variables Format: cmake -D VARNAME=VARVALUE BOOST_ROOT=\\[boost\\] ( /usr/local/boost/ if bootstrapped) CMAKE_BUILD_TYPE=Release (default) ACTIVE_NETWORK=nano_live_network (default) Qt5_DIR=[qt]lib/cmake/Qt5 (to build GUI wallet) NANO_GUI=ON (to build GUI wallet) ENABLE_AVX2=ON , optional PERMUTE_WITH_GATHER=ON , optional PERMUTE_WITH_SHUFFLES=ON (for CPU with AXV2 support, choose fastest method for your CPU with https://github.com/sneves/blake2-avx2/ ) CRYPTOPP_CUSTOM=ON (more conservative building of Crypto++ for wider range of systems) NANO_SIMD_OPTIMIZATIONS=OFF (Enable CPU-specific SIMD optimization: SSE/AVX or NEON, e.g.) NANO_SECURE_RPC=ON (to build node with TLS) NANO_WARN_TO_ERR=ON ( v20.0+ turn compiler warnings into errors on Linux/Mac) NANO_TIMED_LOCKS=50 ( v20.0+ when the number of milliseconds a mutex is held is equal or greater than this output a stacktrace, 0 disables.) NANO_STACKTRACE_BACKTRACE=ON ( v20.0+ use a different configuration of Boost backtrace in stacktraces, attempting to display filenames, function names and line numbers. Needs libbacktrace to be installed. Some workarounds may be necessary depending on system and configuration. Use CLI --debug_stacktrace to get an example output.) CI_BUILD=TRUE ( v20.0+ if enabled, uses environment variable TRAVIS_TAG (required) to modify the locally reported node version; example TRAVIS_TAG=\"My Nano Node v20\" ) NANO_ROCKSDB=ON ( v20.0+ NOTE: RocksDB support is still in experimental stages and should not be used in production systems. To build the node with RocksDB click here for more details) NANO_ASIO_HANDLER_TRACKING=10 (Output asio diagnostics for any completion handlers which have taken longer than this in milliseconds. For more information see the description of the PR #2681 ) NANO_FUZZER_TEST=ON (Build the fuzz tests, not available on Windows) Build Node git submodule update --init --recursive Generate with cmake then build with your compiler (*nix) to build node without GUI execute: make nano_node (*nix) to build wallet with GUI execute: make nano_wallet (*nix) to build rpc for child/out of process execute: make nano_rpc Building a package (macOS) cpack -G \"DragNDrop\" (Windows) cpack -G \"NSIS\" (*nix) cpack -G \"TBZ2\" Testing the Node In order to run the tests, the corresponding CMake variable must be set: -D NANO_TEST=ON . With this variable set, make will also build test files, and will produce core_test , rpc_test , load_test and slow_test binaries, which can be executed such as ./core_test . See more details in Testing Beta Network Participation More information can be found on the Beta Network page To run a node on the beta network, set CMake variable: -DACTIVE_NETWORK=nano_beta_network Test Network Participation More information can be found on the Test Network page To run a node on the test network, set CMake variable: -DACTIVE_NETWORK=nano_test_network","title":"Node"},{"location":"integration-guides/build-options/#debianubuntu-dependencies","text":"These instructions are for the following systems: Ubuntu 16.04 LTS Server Ubuntu 16.10+ Debian 8 Jessie (Debian 8 requires Cmake 3.4+) Debian 9 Stretch Install dependencies sudo apt-get update && sudo apt-get upgrade sudo apt-get install git cmake g++ curl wget Follow the build instructions .","title":"Debian/Ubuntu Dependencies"},{"location":"integration-guides/build-options/#centos-7-dependencies","text":"Requirements GCC compiler version 4.9+ or other compiler with C++14 language support (default Centos 7 compilers are outdated) Cmake 3.4+ Install dependencies sudo yum check-update sudo yum install git libstdc++-static curl wget Configure repository with modern GCC sudo yum install centos-release-scl sudo yum install devtoolset-7-gcc* scl enable devtoolset-7 bash Modern Cmake wget https://cmake.org/files/v3.12/cmake-3.12.1.tar.gz tar zxvf cmake-3.12.1.tar.gz && cd cmake-3.12.1 ./bootstrap --prefix = /usr/local make -j $( nproc ) sudo make install cd .. Follow the build instructions .","title":"CentOS 7 Dependencies"},{"location":"integration-guides/build-options/#arch-linux-dependencies","text":"Install dependencies pacman -Syu pacman -S base-devel git gcc cmake curl wget Follow the build instructions .","title":"Arch Linux Dependencies"},{"location":"integration-guides/build-options/#build-instructions-debian-centos-arch-linux","text":"Unsupported configuration This documentation is intended only for developers of the Nano Node software, and will not result in a supported configuration. End-users are advised to use releases. The fastest and most recommended method of installation is through Docker . Running node as a service . To manage a node, use RPC commands or the CLI .","title":"Build Instructions - Debian, CentOS, Arch Linux"},{"location":"integration-guides/build-options/#node_1","text":"git clone --branch V21.2 --recursive https://github.com/nanocurrency/nano-node.git nano_build cd nano_build export BOOST_ROOT = ` pwd ` /../boost_build bash util/build_prep/bootstrap_boost.sh -m cmake -G \"Unix Makefiles\" . make nano_node cp nano_node ../nano_node && cd .. && ./nano_node --diagnostics","title":"Node"},{"location":"integration-guides/build-options/#build-instructions-macos","text":"Unsupported configuration This documentation is intended only for developers of the Nano Node software, and will not result in a supported configuration. End-users are advised to use releases. The fastest and most recommended method of installation is through Docker . Running node as a service . To manage a node, use RPC commands or the CLI . git clone --branch V21.2 --recursive https://github.com/nanocurrency/nano-node.git nano_build cd nano_build export BOOST_ROOT = ` pwd ` /../boost_build bash util/build_prep/bootstrap_boost.sh -m cmake -G \"Unix Makefiles\" . make nano_node cp nano_node ../nano_node && cd .. && ./nano_node --diagnostics","title":"Build Instructions - macOS"},{"location":"integration-guides/build-options/#build-instructions-windows","text":"Unsupported configuration This documentation is intended only for developers of the Nano Node software, and will not result in a supported configuration. End-users are advised to use releases. The fastest and most recommended method of installation is through Docker . Running node as a service . To manage a node, use RPC commands or the CLI .","title":"Build Instructions - Windows"},{"location":"integration-guides/build-options/#dependencies","text":"Boost 1.69+ for your build env Qt 5.9.5+ 64-bit (open source version) appropriate for your build env Git for Windows git_bash CMake Visual Studio 2017 Community (or higher edition, if you have a valid license. eg. Professional or Enterprise) Select Desktop development with C++ Select the latest Windows 10 SDK","title":"Dependencies"},{"location":"integration-guides/build-options/#setup","text":"Download Source Using git_bash: git clone --branch V21.1 --recursive https://github.com/nanocurrency/nano-node cd nano-node Create a build directory inside nano-node (makes for easier cleaning of build) Using git_bash: mkdir build cd build * Note: all subsequent commands should be run within this \"build\" directory. Get redistributables Using Powershell: Invoke-WebRequest -Uri https://aka.ms/vs/15/release/vc_redist.x64.exe -OutFile . \\v c_redist.x64.exe Generate the build configuration. Using 64 Native Tools Command Prompt: Replace %CONFIGURATION% with one of the following: Release , RelWithDebInfo , Debug Replace %NETWORK% with one of the following: nano_beta_network , nano_live_network , nano_test_network Ensure the Qt, Boost, and Windows SDK paths match your installation. cmake -DNANO_GUI = ON -DCMAKE_BUILD_TYPE = %CONFIGURATION% -DACTIVE_NETWORK = %NETWORK% -DQt5_DIR = \"C:\\Qt\\5.9.5\\msvc2017_64\\lib\\cmake\\Qt5\" -DNANO_SIMD_OPTIMIZATIONS = TRUE -DBoost_COMPILER = \"-vc141\" -DBOOST_ROOT = \"C:/local/boost_1_69_0\" -DBOOST_LIBRARYDIR = \"C:/local/boost_1_69_0/lib64-msvc-14.1\" -G \"Visual Studio 15 2017 Win64\" -DIPHLPAPI_LIBRARY = \"C:/Program Files (x86)/Windows Kits/10/Lib/10.0.17763.0/um/x64/iphlpapi.lib\" -DWINSOCK2_LIBRARY = \"C:/Program Files (x86)/Windows Kits/10/Lib/10.0.17763.0/um/x64/WS2_32.lib\" .. \\.","title":"Setup"},{"location":"integration-guides/build-options/#build","text":"Open nano-node.sln in Visual Studio Build the configuration specified in the previous step Alternative using 64 Native Tools Command Prompt: cmake --build . --target ALL_BUILD --config %CONFIGURATION% -- /m:%NUMBER_OF_PROCESSORS%","title":"Build"},{"location":"integration-guides/build-options/#package-up-binaries","text":"Using 64 Native Tools Command Prompt: Replace %CONFIGURATION% with the build configuration specified in previous step Replace %GENERATOR% with NSIS (if installed) or ZIP cpack -G %GENERATOR% -C %CONFIGURATION%","title":"Package up binaries"},{"location":"integration-guides/build-options/#testing","text":"A number of tests binaries can be built when the -DNANO_TEST CMake variable is set to ON . core_test - Tests the majority of protocol, node and network functionality. slow_test - Tests which operate on a large amount of data and may take a while. Not currently tested by CI. rpc_test - Tests all RPC commands load_test - Launches many nodes and RPC servers, checking sending/receiving blocks with simultaneous calls. Use ./load_test --help to see the available options","title":"Testing"},{"location":"integration-guides/build-options/#running-tests","text":"To run all tests in a binary just launch it: ./core_test To check a specific subset of tests, gtest filtering can be used (with optional wildcards): ./core_test --gtest_filter = confirmation_height.single ./rpc_test --gtest_filter = rpc.* To run tests multiple times: ./core_test --gtest_repeat = 10 If running on a debugger, add the argument --gtest_break_on_failure break at the moment a test fails.","title":"Running Tests"},{"location":"integration-guides/build-options/#environment-variables-to-customize-tests","text":"TEST_KEEP_TMPDIRS=1 - Setting this to anything will prevent the tests deleting any files it creates, useful for debugging log files. TEST_USE_ROCKSDB=1 - Use the RocksDB ledger backend for the tests instead of LMDB. The tests must be built with RocksDB support. TEST_BASE_PORT=26000 - The base port used in tests, the range of ports used in this case would be 26000 - 26199. This is useful if wanting to run multiple tests at once without port conflicts, the default base port used is 24000.","title":"Environment variables to customize tests"},{"location":"integration-guides/build-options/#sanitizers","text":"3 different CMake sanitizer options are supported: NANO_ASAN_INT , NANO_TSAN and NANO_ASAN . They cannot be used in conjunction with each other.","title":"Sanitizers"},{"location":"integration-guides/build-options/#thread-sanitizer","text":"Use -DNANO_TSAN=ON as an extra CMake option. The following environment variable should also be set: export TSAN_OPTIONS=\"suppressions=../tsan_suppressions\" tsan_suppressions should be a path to the file in the root nano directory. This suppresses many errors relating to the mdb and rocksdb libraries.","title":"Thread Sanitizer"},{"location":"integration-guides/build-options/#address-sanitizer","text":"Use the CMake variable -DNANO_ASAN=ON or -DNANO_ASAN_INT=ON before running an executable.","title":"Address Sanitizer"},{"location":"integration-guides/build-options/#valgrind","text":"Valgrind can be used to find other issues such as memory leaks. A valgrind suppressions file is provided to remove some warnings. Valgrind can be run as follows (there are many options available): valgrind --leak-check = full --track-origins = yes --suppressions = ../valgrind.supp ./core_test","title":"Valgrind"},{"location":"integration-guides/ipc-integration/","text":"IPC Integration \u00b6 The node manages communications using an IPC interface with v1 introduced in V18 (see IPC v1 Details ) and upgraded to v2 in V21 to include more robust options. This latest version supports the original RPC v1 endpoint and introduces RPC v2 for completion in future release, along with an authentication system for more granular control of permissioned calls. Configuration These configuration options are set in the config-node.toml file . IPC is configured in the node.ipc.tcp and node.ipc.local sections: [node.ipc.local] # If enabled, certain unsafe RPCs can be used. Not recommended for production systems. # type:bool #allow_unsafe = false # Enable or disable IPC via local domain socket. # type:bool #enable = false # Timeout for requests. # type:seconds #io_timeout = 15 # Path to the local domain socket. # type:string #path = \"/tmp/nano\" [node.ipc.tcp] # Enable or disable IPC via TCP server. # type:bool #enable = false # Timeout for requests. # type:seconds #io_timeout = 15 # Server listening port. # type:uint16 #port = 7077 IPC request/response format \u00b6 A client must make requests using the following framing format: REQUEST ::= HEADER PAYLOAD HEADER ::= u8('N') ENCODING u8(0) u8(0) ENCODING ::= u8(1) PAYLOAD ::= <encoding specific> Four encodings currently exist: 1: legacy RPC [ since v18.0 ] 2: legacy RPC allowing unsafe operations if node is configured so [ since v19.0 ] 3: flatbuffers [ since v21.0 ] 4: json over flatbuffers [ since v21.0 ] The encoding is followed by two reserved zero-bytes. These allow for future extensions, such as versioning and extended headers. Note that the framing format does not include a length field - this is optionally placed in the respective payloads. The reason is that some encodings might want to be \"streamy\", sending responses in chunks, or end with a sentinel. LEGACY_RPC_PAYLOAD ::= be32(length) JSON request LEGACY_RPC_RESPONSE ::= be32(length) JSON response In short, JSON requests and responses are 32-bit big-endian length-prefixed. RPC Gateway \u00b6 The RPC gateway automatically translates between Flatbuffers and JSON messages over HTTP. The request and response is standard JSON. Examples require TLS support The examples below assumes the node is compiled with TLS support. If not, replace https with http. If using TLS with a self-signed certificate, add --insecure to curl commands. Making calls without a message envelope \u00b6 A message envelope is a way to tell the server which message type is sent, as well as other information such as credentials. For HTTP clients, it's convenient to send messages without an envelope. They do so by appending the message name (using uppercase CamelCase) to the path: POST to https://www.example.com:7076/api/v2/AccountWeight { \"account\": \"nano_3t6k35gi95xu6tergt6p69ck76ogmitsa8mnijtpxm9fkcm736xtoncuohr3\" } The RPC 1.0 action field is thus not necessary. The response message is always wrapped in an envelope. JSON clients use the message property to access the message: { \"time\" : 1579736914615 , \"message_type\" : \"AccountWeightResponse\" , \"message\" : { \"voting_weight\" : \"668657804547735335568510480612620716\" } } The message_type is always Error if a call fails: { \"time\" : 1579737134595 , \"message_type\" : \"Error\" , \"message\" : { \"code\" : 3 , \"message\" : \"Access denied\" } } The time property is milliseconds since unix epoch when the message was produced on the server. Relation to the WebSocket response structure The message and time properties of the response envelope is exactly the same as in WebSockets . Instead of message_type , WebSockets use topic . This structure should help simplify clients using both HTTP and WebSockets. Headers When calling without an envelope, credentials and a correlation id can still be set using an HTTP header: curl --header \"Nano-Api-Key:mywalletuser\" ... The correlation header is Nano-Correlation-Id, which can be an arbitrary string. This is usually not useful for request/response JSON clients, but may be valuable if responses from RPCs and WebSocket subscriptions are dealt with in a common message handler on the client. Making calls with message envelopes \u00b6 If the message name is missing from the path, an envelope will be expected which tells the node about the message type. POST to https://www.example.com:7076/api/v2 { \"message_type\" : \"AccountWeight\" , \"message\" : { \"account\" : \"nano_3t6k35gi95xu6tergt6p69ck76ogmitsa8mnijtpxm9fkcm736xtoncuohr3\" } } The above is similar to using the \"action\" property in RPC 1.0. The main difference is that the message itself is always placed in a \"message\" property. The envelope allows additional information to be sent, such as credentials: POST to https://www.example.com:7076/api/v2 { \"credentials\" : \"mywalletuser\" , \"message_type\" : \"AccountWeight\" , \"message\" : { \"account\" : \"nano_3t6k35gi95xu6tergt6p69ck76ogmitsa8mnijtpxm9fkcm736xtoncuohr3\" } } Large requests While somewhat less convenient, the envelope approach is desirable for very large requests, because the node doesn't need to copy the message into an envelope. Flatbuffers mapping \u00b6 Here's the corresponding message definitions for the AccountWeight request and response types: /** Returns the voting weight for the given account */ table AccountWeight { /** A nano_ address */ account: string (required); } /** Response to AccountWeight */ table AccountWeightResponse { /** Voting weight as a decimal number*/ voting_weight: string (required); } Parsing errors \u00b6 Any problems with the JSON request will be reported with error details: { \"message_type\" : \"Error\" , \"message\" : { \"code\" : 1 , \"message\" : \"Invalid message format: 3: 2: error: required field is missing: account in AccountWeight\" } } IPC Authorization \u00b6 Work in progress Permission settings is a work in progress, and their exact definition and defaults will be part of RPC 2.0 in a future node release. With IPC 2.0, the Nano node offers an authorization system. The configuration is done in config-access.toml by defining users and optional roles. Permissions are then assigned to these. The node only checks for permissions, never roles. This way, you can freely structure roles and users the way that suits your situation. There is also a default user with limited default permissions, currently only allowed to use the AccountWeight and IsAlive calls. This is used when no credentials are given. The permissions of the default user can also be changed in the configuration file. Credentials: IPC clients set the credentials in the message envelope HTTP(S) clients either use a message envelope or the HTTP Header Nano-Api-Key Layered security highly recommended While permissions enable node operators to pick what functionality to expose to which users, it is still highly recommended that layered security is used. For instance, a wallet backend should expose only required functionality to clients. The backend can then communicate with the node with credentials for additional security. Call example \u00b6 curl --header \"Nano-Api-Key:mywalletuser\" --insecure -d \\ '{ \"account\": \"nano_3t6k35gi95xu6tergt6p69ck76ogmitsa8mnijtpxm9fkcm736xtoncuohr3\"}' \\ https://www.example.com:7076/api/v2/AccountWeight This uses HTTPS (which the node supports through a build option), and the --insecure is there because the node's certificate in this example is self-signed. Using an envelope instead of the AccountWeight endpoint: { \"credentials\" : \"mywalletuser\" , \"message_type\" : \"AccountWeight\" , \"message\" : { \"account\" : \"nano_3t6k35gi95xu6tergt6p69ck76ogmitsa8mnijtpxm9fkcm736xtoncuohr3\" } } POST the above to https://www.example.com:7076/api/v2 Configuration examples \u00b6 For testing IPC without caring about permissions, this gives access to everything: [[user]] allow = \"unrestricted\" A more elaborate sample: Work in progress Permission settings is a work in progress, and their exact definition and defaults will be part of RPC 2.0 in a future node release. [[role]] id = \"service_admin\" allow = \"api_service_register, api_service_stop\" [[user]] # User id's are typically randomly generated strings which # matches the credentials in API requests. id = \"user-2bb818ee-6424-4750-8bdb-db23bab7bc57\" # Inherit all the permissions from these roles roles = \"service_admin\" # Add additional permissions for this specific user allow = \"wallet_seed_change, api_topic_confirmation\" # A list of specific permissions can be denied as well deny = \"api_account_weight\" [[user]] id = \"history-viewer-e3cf8a09-bd74-4ef2-9b84-e14f3db2bb4b\" # Add specific permission for this user allow = \"api_account_info, api_account_history\" # Do not inherit any default permissions. This is useful # for making users with a explicit set of minimum permissions. # The default user can also be set to bare. That way, a node can be # exposed with a limited set of default permissions. bare = true Reload config \u00b6 The access file can be reloaded without restarting the node or wallet. For the node: killall -SIGHUP nano_node (actual syntax depends on OS) IPC V1 Details \u00b6 As of v18, the Nano node exposes a low level IPC interface over which multiple future APIs can be marshalled. Currently, the IPC interface supports the legacy RPC JSON format. The HTTP based RPC server is still available. Because the only IPC encoding is currently \"legacy RPC\", RPC config options like \"enable_control\" still apply. Transports TCP and unix domain sockets are supported. Named pipes and shared memory may be supported in future releases. IPC clients A NodeJS client is available at https://github.com/meltingice/nano-ipc-js A Python client is being developed at https://github.com/guilhermelawless/nano-ipc-py","title":"IPC Integration"},{"location":"integration-guides/ipc-integration/#ipc-integration","text":"The node manages communications using an IPC interface with v1 introduced in V18 (see IPC v1 Details ) and upgraded to v2 in V21 to include more robust options. This latest version supports the original RPC v1 endpoint and introduces RPC v2 for completion in future release, along with an authentication system for more granular control of permissioned calls. Configuration These configuration options are set in the config-node.toml file . IPC is configured in the node.ipc.tcp and node.ipc.local sections: [node.ipc.local] # If enabled, certain unsafe RPCs can be used. Not recommended for production systems. # type:bool #allow_unsafe = false # Enable or disable IPC via local domain socket. # type:bool #enable = false # Timeout for requests. # type:seconds #io_timeout = 15 # Path to the local domain socket. # type:string #path = \"/tmp/nano\" [node.ipc.tcp] # Enable or disable IPC via TCP server. # type:bool #enable = false # Timeout for requests. # type:seconds #io_timeout = 15 # Server listening port. # type:uint16 #port = 7077","title":"IPC Integration"},{"location":"integration-guides/ipc-integration/#ipc-requestresponse-format","text":"A client must make requests using the following framing format: REQUEST ::= HEADER PAYLOAD HEADER ::= u8('N') ENCODING u8(0) u8(0) ENCODING ::= u8(1) PAYLOAD ::= <encoding specific> Four encodings currently exist: 1: legacy RPC [ since v18.0 ] 2: legacy RPC allowing unsafe operations if node is configured so [ since v19.0 ] 3: flatbuffers [ since v21.0 ] 4: json over flatbuffers [ since v21.0 ] The encoding is followed by two reserved zero-bytes. These allow for future extensions, such as versioning and extended headers. Note that the framing format does not include a length field - this is optionally placed in the respective payloads. The reason is that some encodings might want to be \"streamy\", sending responses in chunks, or end with a sentinel. LEGACY_RPC_PAYLOAD ::= be32(length) JSON request LEGACY_RPC_RESPONSE ::= be32(length) JSON response In short, JSON requests and responses are 32-bit big-endian length-prefixed.","title":"IPC request/response format"},{"location":"integration-guides/ipc-integration/#rpc-gateway","text":"The RPC gateway automatically translates between Flatbuffers and JSON messages over HTTP. The request and response is standard JSON. Examples require TLS support The examples below assumes the node is compiled with TLS support. If not, replace https with http. If using TLS with a self-signed certificate, add --insecure to curl commands.","title":"RPC Gateway"},{"location":"integration-guides/ipc-integration/#making-calls-without-a-message-envelope","text":"A message envelope is a way to tell the server which message type is sent, as well as other information such as credentials. For HTTP clients, it's convenient to send messages without an envelope. They do so by appending the message name (using uppercase CamelCase) to the path: POST to https://www.example.com:7076/api/v2/AccountWeight { \"account\": \"nano_3t6k35gi95xu6tergt6p69ck76ogmitsa8mnijtpxm9fkcm736xtoncuohr3\" } The RPC 1.0 action field is thus not necessary. The response message is always wrapped in an envelope. JSON clients use the message property to access the message: { \"time\" : 1579736914615 , \"message_type\" : \"AccountWeightResponse\" , \"message\" : { \"voting_weight\" : \"668657804547735335568510480612620716\" } } The message_type is always Error if a call fails: { \"time\" : 1579737134595 , \"message_type\" : \"Error\" , \"message\" : { \"code\" : 3 , \"message\" : \"Access denied\" } } The time property is milliseconds since unix epoch when the message was produced on the server. Relation to the WebSocket response structure The message and time properties of the response envelope is exactly the same as in WebSockets . Instead of message_type , WebSockets use topic . This structure should help simplify clients using both HTTP and WebSockets. Headers When calling without an envelope, credentials and a correlation id can still be set using an HTTP header: curl --header \"Nano-Api-Key:mywalletuser\" ... The correlation header is Nano-Correlation-Id, which can be an arbitrary string. This is usually not useful for request/response JSON clients, but may be valuable if responses from RPCs and WebSocket subscriptions are dealt with in a common message handler on the client.","title":"Making calls without a message envelope"},{"location":"integration-guides/ipc-integration/#making-calls-with-message-envelopes","text":"If the message name is missing from the path, an envelope will be expected which tells the node about the message type. POST to https://www.example.com:7076/api/v2 { \"message_type\" : \"AccountWeight\" , \"message\" : { \"account\" : \"nano_3t6k35gi95xu6tergt6p69ck76ogmitsa8mnijtpxm9fkcm736xtoncuohr3\" } } The above is similar to using the \"action\" property in RPC 1.0. The main difference is that the message itself is always placed in a \"message\" property. The envelope allows additional information to be sent, such as credentials: POST to https://www.example.com:7076/api/v2 { \"credentials\" : \"mywalletuser\" , \"message_type\" : \"AccountWeight\" , \"message\" : { \"account\" : \"nano_3t6k35gi95xu6tergt6p69ck76ogmitsa8mnijtpxm9fkcm736xtoncuohr3\" } } Large requests While somewhat less convenient, the envelope approach is desirable for very large requests, because the node doesn't need to copy the message into an envelope.","title":"Making calls with message envelopes"},{"location":"integration-guides/ipc-integration/#flatbuffers-mapping","text":"Here's the corresponding message definitions for the AccountWeight request and response types: /** Returns the voting weight for the given account */ table AccountWeight { /** A nano_ address */ account: string (required); } /** Response to AccountWeight */ table AccountWeightResponse { /** Voting weight as a decimal number*/ voting_weight: string (required); }","title":"Flatbuffers mapping"},{"location":"integration-guides/ipc-integration/#parsing-errors","text":"Any problems with the JSON request will be reported with error details: { \"message_type\" : \"Error\" , \"message\" : { \"code\" : 1 , \"message\" : \"Invalid message format: 3: 2: error: required field is missing: account in AccountWeight\" } }","title":"Parsing errors"},{"location":"integration-guides/ipc-integration/#ipc-authorization","text":"Work in progress Permission settings is a work in progress, and their exact definition and defaults will be part of RPC 2.0 in a future node release. With IPC 2.0, the Nano node offers an authorization system. The configuration is done in config-access.toml by defining users and optional roles. Permissions are then assigned to these. The node only checks for permissions, never roles. This way, you can freely structure roles and users the way that suits your situation. There is also a default user with limited default permissions, currently only allowed to use the AccountWeight and IsAlive calls. This is used when no credentials are given. The permissions of the default user can also be changed in the configuration file. Credentials: IPC clients set the credentials in the message envelope HTTP(S) clients either use a message envelope or the HTTP Header Nano-Api-Key Layered security highly recommended While permissions enable node operators to pick what functionality to expose to which users, it is still highly recommended that layered security is used. For instance, a wallet backend should expose only required functionality to clients. The backend can then communicate with the node with credentials for additional security.","title":"IPC Authorization"},{"location":"integration-guides/ipc-integration/#call-example","text":"curl --header \"Nano-Api-Key:mywalletuser\" --insecure -d \\ '{ \"account\": \"nano_3t6k35gi95xu6tergt6p69ck76ogmitsa8mnijtpxm9fkcm736xtoncuohr3\"}' \\ https://www.example.com:7076/api/v2/AccountWeight This uses HTTPS (which the node supports through a build option), and the --insecure is there because the node's certificate in this example is self-signed. Using an envelope instead of the AccountWeight endpoint: { \"credentials\" : \"mywalletuser\" , \"message_type\" : \"AccountWeight\" , \"message\" : { \"account\" : \"nano_3t6k35gi95xu6tergt6p69ck76ogmitsa8mnijtpxm9fkcm736xtoncuohr3\" } } POST the above to https://www.example.com:7076/api/v2","title":"Call example"},{"location":"integration-guides/ipc-integration/#configuration-examples","text":"For testing IPC without caring about permissions, this gives access to everything: [[user]] allow = \"unrestricted\" A more elaborate sample: Work in progress Permission settings is a work in progress, and their exact definition and defaults will be part of RPC 2.0 in a future node release. [[role]] id = \"service_admin\" allow = \"api_service_register, api_service_stop\" [[user]] # User id's are typically randomly generated strings which # matches the credentials in API requests. id = \"user-2bb818ee-6424-4750-8bdb-db23bab7bc57\" # Inherit all the permissions from these roles roles = \"service_admin\" # Add additional permissions for this specific user allow = \"wallet_seed_change, api_topic_confirmation\" # A list of specific permissions can be denied as well deny = \"api_account_weight\" [[user]] id = \"history-viewer-e3cf8a09-bd74-4ef2-9b84-e14f3db2bb4b\" # Add specific permission for this user allow = \"api_account_info, api_account_history\" # Do not inherit any default permissions. This is useful # for making users with a explicit set of minimum permissions. # The default user can also be set to bare. That way, a node can be # exposed with a limited set of default permissions. bare = true","title":"Configuration examples"},{"location":"integration-guides/ipc-integration/#reload-config","text":"The access file can be reloaded without restarting the node or wallet. For the node: killall -SIGHUP nano_node (actual syntax depends on OS)","title":"Reload config"},{"location":"integration-guides/ipc-integration/#ipc-v1-details","text":"As of v18, the Nano node exposes a low level IPC interface over which multiple future APIs can be marshalled. Currently, the IPC interface supports the legacy RPC JSON format. The HTTP based RPC server is still available. Because the only IPC encoding is currently \"legacy RPC\", RPC config options like \"enable_control\" still apply. Transports TCP and unix domain sockets are supported. Named pipes and shared memory may be supported in future releases. IPC clients A NodeJS client is available at https://github.com/meltingice/nano-ipc-js A Python client is being developed at https://github.com/guilhermelawless/nano-ipc-py","title":"IPC V1 Details"},{"location":"integration-guides/key-management/","text":"Key Management \u00b6 Seeds \u00b6 Hex Seed \u00b6 Nano's private key(s) have been traditionally derived from a 64 character, uppercase hexadecimal string (0-9A-F). This is currently the more popular form of seed supported by a variety of services and wallets. Additional details available in The Basics guide . Mnemonic Seed \u00b6 Nano's private key(s) from mnemonic derivation follows the BIP 39 / 44 standard. Only hardened paths are defined. Nano's coin-type is 165' (0x800000a5) 44'/165'/0' derives the first private key, 44'/165'/1' derives the second private key, and so on. The BIP39 seed modifier \"ed25519 seed\" is used which makes wallets compatible with each other. This was chosen due to it being used by the Ledger Nano implementation. Demo Examples \u00b6 External libraries, review before using The linked resources below contain code dealing with private key management and/or execution of transactions. The Nano Foundation does not control this code, does not endorse it and is not responsible for its use. Use of this code requires review and is at your own discretion. https://github.com/roosmaa/nano-bip39-demo https://github.com/joltwallet/bip-mnemonic Implementations \u00b6 https://github.com/numsu/nanocurrency-web-js Test Vectors \u00b6 Given 24-Word Mnemonic: edge defense waste choose enrich upon flee junk siren film clown finish luggage leader kid quick brick print evidence swap drill paddle truly occur Given Passphrase: some password Derived BIP39 Seed: 0dc285fde768f7ff29b66ce7252d56ed92fe003b605907f7a4f683c3dc8586d34a914d3c71fc099bb38ee4a59e5b081a3497b7a323e90cc68f67b5837690310c Derived Private Key for 44'/165'/0' : 3be4fc2ef3f3b7374e6fc4fb6e7bb153f8a2998b3b3dab50853eabe128024143 Derived Public key: 5b65b0e8173ee0802c2c3e6c9080d1a16b06de1176c938a924f58670904e82c4 Derived Address: nano_1pu7p5n3ghq1i1p4rhmek41f5add1uh34xpb94nkbxe8g4a6x1p69emk8y1d External Management \u00b6 For larger, more robust systems, external private key management is recommended. In this setup, the node operator generates and stores private keys in an external database and only queries the nano_node to: Find pending blocks for an account Sign transactions given a private key. More advanced systems may choose to implement signing themselves. Broadcast the signed transaction to the network. Note WALLET_IDs are not used for External Private Key Management since private keys are not stored in the nano_node. Much of this section builds off of the Blocks Specifications documentation. External accounting systems \u00b6 In order to properly implement accounting systems external to the Nano node the following best practices should be put into place, which ensure only fully confirmed blocks are used for external tracking of credits, debits, etc. Confirmation and idempotency The details below expand on this, but the two most important pieces of any integration are: Always confirm blocks - make sure to follow the block confirmation tracking recommendations so you are always taking action from confirmed blocks Guarantee idempotency - whenever you take action from a block confirmation, it must be idempotent so you don't take the action again if the same block hash is seen through confirmation tracking Block confirmation procedures \u00b6 Before crediting funds to an account internally based on a deposit on the network, the block sending the funds must be confirmed. This is done by verifying the network has reached quorum on the block. Details of the recommended verification process can be found in the block confirmation tracking guide . Tracking confirmed balances \u00b6 External accounting systems that track balances arriving to the node must track hashes of blocks that have been received in order to guarantee idempotency. Once confirmation of a block has been validated, the block hash should be recorded for the account along with any credits, debits or other related information. Any attempts to credit or debit accounts external to the node should check that no previous conflicting or duplicate activity was already recorded for that same block hash. Transaction order and correctness \u00b6 If you are creating a batch of transactions for a single account, which can be a mix of sending and receiving funds, there is no need to wait for the confirmation of blocks in that account to create the next transaction. As long as a transaction is valid, it will be confirmed by the network. The transactions that follow it can only be confirmed if the previous transactions are valid. However, you must always wait for the confirmation of pending blocks before creating the corresponding receive transaction, to ensure it will be confirmed. Always wait for confirmation of transactions that you did not create yourself. Expanding Private Keys \u00b6 A Nano private key is a 256-bit piece of data produced from a cryptographically secure random number generator. Secure Private Keys Generating private keys from an insecure source may result in loss of funds. Be sure to backup any generated private key; if lost the funds in the account will become inaccessible. Step 1: Generate secure private key The bash command below generates a valid private key from a cryptographically secure random number generator. Always use a cryptographically secure processes for generating any private keys. Command Example cat /dev/urandom | tr -dc '0-9A-F' | head -c ${ 1 :- 64 } Success Result 781186FB9EF17DB6E3D1056550D9FAE5D5BBADA6A6BC370E4CBB938B1DC71DA3 Step 2: Expand private key From the private key, a public key can be derived, and the public key can be translated into a Nano Address using the key_expand RPC command. Request Example curl -d '{ \"action\": \"key_expand\", \"key\": \"781186FB9EF17DB6E3D1056550D9FAE5D5BBADA6A6BC370E4CBB938B1DC71DA3\" }' http://127.0.0.1:7076 Success Response { \"private\" : \"781186FB9EF17DB6E3D1056550D9FAE5D5BBADA6A6BC370E4CBB938B1DC71DA3\" , \"public\" : \"3068BB1CA04525BB0E416C485FE6A67FD52540227D267CC8B6E8DA958A7FA039\" , \"account\" : \"nano_1e5aqegc1jb7qe964u4adzmcezyo6o146zb8hm6dft8tkp79za3sxwjym5rx\" } Creating Transactions \u00b6 Using external keys, transactions are generated in two steps: creation and broadcast. This section will be more heavy on example rather than precise specifications. Send Transaction \u00b6 Step 1: Get Account Info To send funds to an account, first call the account_info RPC command to gather necessary account information to craft your transaction. Setting \"representative\": \"true\" makes the nano_node also return the account's representative address, a necessary piece of data for creating a transaction. Request Example curl -d '{ \"action\": \"account_info\", \"representative\": \"true\", \"account\": \"nano_1e5aqegc1jb7qe964u4adzmcezyo6o146zb8hm6dft8tkp79za3sxwjym5rx\" }' http://127.0.0.1:7076 Success Response { \"frontier\" : \"92BA74A7D6DC7557F3EDA95ADC6341D51AC777A0A6FF0688A5C492AB2B2CB40D\" , \"open_block\" : \"B292BFFAAE9013BE630B31144EF15205E986940080687C0441CCFE6EAB67FE53\" , \"representative_block\" : \"B292BFFAAE9013BE630B31144EF15205E986940080687C0441CCFE6EAB67FE53\" , \"balance\" : \"4618869000000000000000000000000\" , \"modified_timestamp\" : \"1524626644\" , \"block_count\" : \"4\" , \"representative\" : \"nano_1stofnrxuz3cai7ze75o174bpm7scwj9jn3nxsn8ntzg784jf1gzn1jjdkou\" } Step 2: Build block_create request Using details from the account_info call response, along with other information, we can create the block_create RPC request. For more details on values, see the Blocks Specifications documentation. Field Value \"json_block\" always \"true\" , so that the output is JSON-formatted \"type\" always the constant \"state\" \"previous\" \"frontier\" from account_info response \"account\" \"account\" address used in the account_info call above that the block will be created for \"representative\" \"representative\" address returned in the account_info call \"balance\" balance of the account in raw raw after this transaction is completed (decreased if sending, increased if receiving). In this example, we will send 1 nano nano ( 10^{30} raw 10^{30} raw ) to address nano_1q3hqecaw15cjt7thbtxu3pbzr1eihtzzpzxguoc37bj1wc5ffoh7w74gi6p . \"link\" destination address the funds will move between \"key\" account's private key Request Example curl -d '{ \"action\": \"block_create\", \"json_block\": \"true\", \"type\": \"state\", \"previous\": \"92BA74A7D6DC7557F3EDA95ADC6341D51AC777A0A6FF0688A5C492AB2B2CB40D\", \"account\": \"nano_1e5aqegc1jb7qe964u4adzmcezyo6o146zb8hm6dft8tkp79za3sxwjym5rx\", \"representative\": \"nano_1stofnrxuz3cai7ze75o174bpm7scwj9jn3nxsn8ntzg784jf1gzn1jjdkou\", \"balance\": \"3618869000000000000000000000000\", \"link\": \"nano_1q3hqecaw15cjt7thbtxu3pbzr1eihtzzpzxguoc37bj1wc5ffoh7w74gi6p\", \"key\": \"781186FB9EF17DB6E3D1056550D9FAE5D5BBADA6A6BC370E4CBB938B1DC71DA3\" }' http://127.0.0.1:7076 Success Response { \"hash\" : \"8DB5C07E0E62E9DFE8558CB9BD654A115B02245B38CD369753CECE36DAD13C05\" , \"block\" : { \"type\" : \"state\" , \"account\" : \"nano_1e5aqegc1jb7qe964u4adzmcezyo6o146zb8hm6dft8tkp79za3sxwjym5rx\" , \"previous\" : \"92BA74A7D6DC7557F3EDA95ADC6341D51AC777A0A6FF0688A5C492AB2B2CB40D\" , \"representative\" : \"nano_1stofnrxuz3cai7ze75o174bpm7scwj9jn3nxsn8ntzg784jf1gzn1jjdkou\" , \"balance\" : \"3618869000000000000000000000000\" , \"link\" : \"5C2FBB148E006A8E8BA7A75DD86C9FE00C83F5FFDBFD76EAA09531071436B6AF\" , \"link_as_account\" : \"nano_1q3hqecaw15cjt7thbtxu3pbzr1eihtzzpzxguoc37bj1wc5ffoh7w74gi6p\" , \"signature\" : \"79240D56231EF1885F354473733AF158DC6DA50E53836179565A20C0BE89D473ED3FF8CD11545FF0ED162A0B2C4626FD6BF84518568F8BB965A4884C7C32C205\" , \"work\" : \"fbffed7c73b61367\" } } Additional details The option json_block , available since V19.0, makes the RPC call return a non-stringified version of the block, which is easier to parse and always recommended. block_create RPC commands generally take longer than other RPC commands because the nano_node has to generate the Proof-of-Work for the transaction. The response block data is already properly formatted to include in the process RPC command. The nano_node creating and signing this transaction has no concept of what the transaction amount is, nor network state; all the nano_node knows is that it is creating a block whose previous block on the account chain has hash 92BA74A7D6DC7557F3EDA95ADC6341D51AC777A0A6FF0688A5C492AB2B2CB40D results in the account having a balance of 3618869000000000000000000000000 . If the account's balance at block hash 92BA74A7D6DC7557F3EDA95ADC6341D51AC777A0A6FF0688A5C492AB2B2CB40D was actually 5618869000000000000000000000000 , then 2 nano nano would have been sent to nano_1q3hqecaw15cjt7thbtxu3pbzr1eihtzzpzxguoc37bj1wc5ffoh7w74gi6p . What if I receive funds on my account and then broadcast the above crafted send? Would this result in me sending excess funds to the recipient? If you followed this guide, then the answer is \"no\". When you issued the account_info RPC command, you received the account's balance at a specific blockhash on its account-chain. In your crafted transaction, you specify that hash in the \"previous\" field. If funds were signed into your account, the headblock on your account-chain would change. Since your send no longer refers to the headblock on your account-chain when broadcasted, the network would reject your transaction. Warning Since only the resulting balance is recorded, the transaction amount is interpreted as the difference in balance from the previous block on the account-chain and the newly created block. For this reason, it is crucial that you obtain the current account balance and headblock in the same atomic account_info RPC command. When not following this guide closely, the following inappropriate sequence of events could lead to erroneous amounts sent to a recipient. An account's balance, say 5 nano nano , was obtained using the account_balance . This balance is valid as of hypothetical BLOCK_A . By another process you control, a receive ( BLOCK_B ) was signed and broadcasted into your account-chain (race-condition). Lets say this receive increased the funds on the account chain by 10 nano nano , resulting in a final balance 15 nano nano . The account's frontier block is obtained by the accounts_frontiers RPC command, returning the hash of BLOCK_B . Other transaction metadata is obtained by other RPC commands. With the collected data, if a send transaction was created for 3 nano nano , the final balance would be computed as 5 - 3 5 - 3 , or 2 nano nano . When this is broadcasted, since it is referring to the current head block on the account, BLOCK_B , the network would accept it. But, because the balance as of BLOCK_B was actually 15 nano nano , this would result in 12 nano nano being sent to the recipient. For this reason, only populate transaction data source from a single account_info RPC call . Step 3: Broadcast the transaction As a result of the command above, the nano_node will return a signed, but not yet broadcasted transaction. Broadcasting of the signed transaction is covered in the Broadcasting Transactions section. Receive Transaction \u00b6 Manually receiving first block The very first transaction on an account-chain, which is always a receive, is slightly special and deserves its own section First Receive Transaction . Step 1: Get Account Info Receiving funds is very similar to sending funds outlined in the previous section, starting with calling account_info to get block details for the account frontier. The scenario below pretends that our previous example of a send transaction was not broadcast and confirmed on the network because the starting account_info details are identical. Request Example curl -d '{ \"action\": \"account_info\", \"representative\": \"true\", \"account\": \"nano_1e5aqegc1jb7qe964u4adzmcezyo6o146zb8hm6dft8tkp79za3sxwjym5rx\" }' http://127.0.0.1:7076 Success Response { \"frontier\" : \"92BA74A7D6DC7557F3EDA95ADC6341D51AC777A0A6FF0688A5C492AB2B2CB40D\" , \"open_block\" : \"B292BFFAAE9013BE630B31144EF15205E986940080687C0441CCFE6EAB67FE53\" , \"representative_block\" : \"B292BFFAAE9013BE630B31144EF15205E986940080687C0441CCFE6EAB67FE53\" , \"balance\" : \"4618869000000000000000000000000\" , \"modified_timestamp\" : \"1524626644\" , \"block_count\" : \"4\" , \"representative\" : \"nano_1stofnrxuz3cai7ze75o174bpm7scwj9jn3nxsn8ntzg784jf1gzn1jjdkou\" } Step 2: Build block_create request Using details from the account_info call response, along with other information, we can create the block_create RPC request. The two differences between the send transaction are the \"link\" and \"balance\" fields. For more details on values, see the Blocks Specifications documentation. Field Value \"json_block\" always \"true\" , so that the output is JSON-formatted \"type\" always the constant \"state\" \"previous\" \"frontier\" from account_info response, or 0 if first block on new account \"account\" \"account\" address used in the account_info call above that the block will be created for \"representative\" \"representative\" address returned in the account_info call \"balance\" balance of the account in raw raw after this transaction is completed (decreased if sending, increased if receiving). In this example, we will receive 7 nano nano ( 7 \\times 10^{30} raw 7 \\times 10^{30} raw ) based on the assumed details of the block the \"link\" hash refers to (block contents not shown in this example). \"link\" block hash of its paired send transaction, assumed to be a 7 nano nano send from block hash CBC911F57B6827649423C92C88C0C56637A4274FF019E77E24D61D12B5338783 \"key\" account's private key Request Example curl -d '{ \"action\": \"block_create\", \"json_block\": \"true\", \"type\": \"state\", \"previous\": \"92BA74A7D6DC7557F3EDA95ADC6341D51AC777A0A6FF0688A5C492AB2B2CB40D\", \"account\": \"nano_1e5aqegc1jb7qe964u4adzmcezyo6o146zb8hm6dft8tkp79za3sxwjym5rx\", \"representative\": \"nano_1stofnrxuz3cai7ze75o174bpm7scwj9jn3nxsn8ntzg784jf1gzn1jjdkou\", \"balance\": \"11618869000000000000000000000000\", \"link\": \"CBC911F57B6827649423C92C88C0C56637A4274FF019E77E24D61D12B5338783\", \"key\": \"781186FB9EF17DB6E3D1056550D9FAE5D5BBADA6A6BC370E4CBB938B1DC71DA3\" }' http://127.0.0.1:7076 Success Response { \"hash\" : \"350D145570578A36D3D5ADE58DC7465F4CAAF257DD55BD93055FF826057E2CDD\" , \"block\" : { \"type\" : \"state\" , \"account\" : \"nano_1e5aqegc1jb7qe964u4adzmcezyo6o146zb8hm6dft8tkp79za3sxwjym5rx\" , \"previous\" : \"92BA74A7D6DC7557F3EDA95ADC6341D51AC777A0A6FF0688A5C492AB2B2CB40D\" , \"representative\" : \"nano_1stofnrxuz3cai7ze75o174bpm7scwj9jn3nxsn8ntzg784jf1gzn1jjdkou\" , \"balance\" : \"11618869000000000000000000000000\" , \"link\" : \"CBC911F57B6827649423C92C88C0C56637A4274FF019E77E24D61D12B5338783\" , \"link_as_account\" : \"nano_3kyb49tqpt39ekc49kbej51ecsjqnimnzw1swxz4boix4ctm93w517umuiw8\" , \"signature\" : \"EEFFE1EFCCC8F2F6F2F1B79B80ABE855939DD9D6341323186494ADEE775DAADB3B6A6A07A85511F2185F6E739C4A54F1454436E22255A542ED879FD04FEED001\" , \"work\" : \"c5cf86de24b24419\" } } Additional details Here the follow scenario occurs: Previous balance was 4618869000000000000000000000000 raw raw Increased our balance by 7000000000000000000000000000000 raw raw Final balance becomes 11618869000000000000000000000000 raw raw Step 3: Broadcast the transaction As a result of the command above, the nano_node will return a signed, but not yet broadcasted transaction. Broadcasting of the signed transaction is covered in the Broadcasting Transactions section. First Receive Transaction \u00b6 The first transaction of an account is crafted in a slightly different way. To open an account, you must have sent some funds to it with a Send Transaction from another account. The funds will be pending on the receiving account. If you already know the hash of the pending transaction, you can skip Step 1. Step 1: Obtain the pending transaction block hash Start with obtaining a list of pending transactions in your unopened account. Limit the response to the highest value transaction by using a combination of sorting and count . Request Example curl -d '{ \"action\": \"pending\", \"account\": \"nano_1rawdji18mmcu9psd6h87qath4ta7iqfy8i4rqi89sfdwtbcxn57jm9k3q11\", \"count\": \"1\", \"sorting\": \"true\", \"include_only_confirmed\": \"true\" }' http://127.0.0.1:7076 Success Response { \"blocks\" : { \"5B2DA492506339C0459867AA1DA1E7EDAAC4344342FAB0848F43B46D248C8E99\" : \"100\" } } Step 2: Build block_create request Using the block hash and raw transaction amount from the pending call response, along with other information, we can create the block_create RPC request. The only difference between the normal receive transactions is the \"previous\" field. For more details on values, see the Blocks Specifications documentation. Field Value \"json_block\" always \"true\" , so that the output is JSON-formatted \"type\" always the constant \"state\" \"previous\" always the constant \"0\" as this request is for the first block of the account \"account\" \"account\" address used in the account_info call above that the block will be created for \"representative\" \"representative\" the account address to use as representative for your account. Choose a reliable, trustworthy representative. \"balance\" balance of the account in raw raw after this transaction is completed. In this example, we will receive 100\\ raw 100\\ raw , based on the assumed details from the \"pending\" response above. \"link\" block hash of its paired send transaction, in this case assumed to be the block 5B2DA492506339C0459867AA1DA1E7EDAAC4344342FAB0848F43B46D248C8E99 \"key\" account's private key Request Example curl -d '{ \"action\": \"block_create\", \"json_block\": \"true\", \"type\": \"state\", \"previous\": \"0\", \"account\": \"nano_1rawdji18mmcu9psd6h87qath4ta7iqfy8i4rqi89sfdwtbcxn57jm9k3q11\", \"representative\": \"nano_1stofnrxuz3cai7ze75o174bpm7scwj9jn3nxsn8ntzg784jf1gzn1jjdkou\", \"balance\": \"100\", \"link\": \"5B2DA492506339C0459867AA1DA1E7EDAAC4344342FAB0848F43B46D248C8E99\", \"key\": \"0ED82E6990A16E7AD2375AB5D54BEAABF6C676D09BEC74D9295FCAE35439F694\" }' http://127.0.0.1:7076 Success Response { \"hash\" : \"ED3BE5340CC9D62964B5A5F84375A06078CBEDC45FB5FA2926985D6E27D803BB\" , \"block\" : { \"type\" : \"state\" , \"account\" : \"nano_1rawdji18mmcu9psd6h87qath4ta7iqfy8i4rqi89sfdwtbcxn57jm9k3q11\" , \"previous\" : \"0000000000000000000000000000000000000000000000000000000000000000\" , \"representative\" : \"nano_1stofnrxuz3cai7ze75o174bpm7scwj9jn3nxsn8ntzg784jf1gzn1jjdkou\" , \"balance\" : \"100\" , \"link\" : \"5B2DA492506339C0459867AA1DA1E7EDAAC4344342FAB0848F43B46D248C8E99\" , \"link_as_account\" : \"nano_1psfnkb71rssr34sisxc5piyhufcrit68iqtp44ayixnfnkas5nsiuy58za7\" , \"signature\" : \"903991714A55954D15C91DB75CAE2FBF1DD1A2D6DA5524AA2870F76B50A8FE8B4E3FBB53E46B9E82638104AAB3CFA71CFC36B7D676B3D6CAE84725D04E4C360F\" , \"work\" : \"08d09dc3405d9441\" } } Step 3: Broadcast the transaction As a result of the command above, the nano_node will return a signed, but not yet broadcasted transaction. Broadcasting of the signed transaction is covered in the Broadcasting Transactions section. Broadcasting Transactions \u00b6 Broadcast using process RPC command Common to all of these transactions is the need to broadcast the completed block to the network. This is achieved by the process RPC command which accepts the block as stringified JSON data. If you followed the previous examples, you used the option json_block for RPC block_create , which allows you use the non-stringified version, as long as you include the same option in this RPC call. A successful broadcast will return the broadcasted block's hash. Including subtype in process RPC calls highly recommended In order to avoid potential incorrect sends including the optional subtype parameter on all process RPC calls is highly recommended . In the next version of the RPC this parameter will be required. Request Example curl -d '{ \"action\": \"process\", \"json_block\": \"true\", \"subtype\": \"open\", \"block\": { \"type\": \"state\", \"account\": \"nano_1rawdji18mmcu9psd6h87qath4ta7iqfy8i4rqi89sfdwtbcxn57jm9k3q11\", \"previous\": \"0000000000000000000000000000000000000000000000000000000000000000\", \"representative\": \"nano_1stofnrxuz3cai7ze75o174bpm7scwj9jn3nxsn8ntzg784jf1gzn1jjdkou\", \"balance\": \"100\", \"link\": \"5B2DA492506339C0459867AA1DA1E7EDAAC4344342FAB0848F43B46D248C8E99\", \"link_as_account\": \"nano_1psfnkb71rssr34sisxc5piyhufcrit68iqtp44ayixnfnkas5nsiuy58za7\", \"signature\": \"903991714A55954D15C91DB75CAE2FBF1DD1A2D6DA5524AA2870F76B50A8FE8B4E3FBB53E46B9E82638104AAB3CFA71CFC36B7D676B3D6CAE84725D04E4C360F\", \"work\": \"08d09dc3405d9441\" } }' http://127.0.0.1:7076 Success Response { \"hash\" : \"42A723D2B60462BF7C9A003FE9A70057D3A6355CA5F1D0A57581000000000000\" } Block watching and re-work Since V20.0, blocks processed using process are placed under observation by the node for re-broadcasting and re-generation of work under certain conditions. If you wish to disable this feature, add \"watch_work\": \"false\" to the process RPC command. If a block is not confirmed within a certain amount of time (configuration option work_watcher_period , default 5 seconds), an automatic re-generation of a higher difficulty proof-of-work may take place. Re-generation only takes place when the network is unable to confirm transactions quickly (commonly referred as the network being saturated ) and the higher difficulty proof-of-work is used to help prioritize the block higher in the processing queue of other nodes. Configuration option max_work_generate_multiplier can be used to limit how much effort should be spent in re-generating the proof-of-work. The target proof-of-work difficulty threshold is obtained internally as the minimum between active_difficulty and max_work_generate_multiplier (converted to difficulty). With a new, higher difficulty proof-of-work, the block will get higher confirmation priority across the network. When a transaction does not confirm If a transaction is taking too long to confirm, you may call the process RPC command with the same block data with no risk. If for some reason a transaction fails to properly broadcast, subsequent transactions on the account-chain after that transaction will not be accepted by the network since the \"previous\" field in the transaction data refers to a non-existant block. If this situation occurs, rebroadcasting the missing transaction(s) will make the subsequent blocks valid in the network's ledger. Rebroadcasting blocks for an account-chain The following command rebroadcasts all hashes on an account-chain starting at block hash provided: Request Example curl -d '{ \"action\": \"republish\", \"hash\": \"48006BF3146C18CAD3A53A957BF64EF7C57820B21FCCE373FA637559DA260358\" }' http://127.0.0.1:7076 Internal Management \u00b6 The nano_node software has a built-in private-key manager that is suitable for smaller operations (<1000 accounts). External Key Management allows more powerful and robust systems at the cost of additional complexity. External Key Management is recommended for larger operations. Creating a Wallet \u00b6 To create an account, you first must create a wallet to hold the seed that will subsequently create the account. Request Example curl -d '{ \"action\": \"wallet_create\" }' http://127.0.0.1:7076 Success Response { \"wallet\" : \"E3E67B1B3FFA46F606240F1D0B964873D42E9C6D0B7A0BF376A2E128541CC446\" } The nano_node responds with the WALLET_ID. If you lose your WALLET_ID, it can only be recovered via a CLI command. To reiterate, the WALLET_ID is not a seed . The seed can be extracted for backup in Backing Up Seed . Many of the RPC commands in this guide require the WALLET_ID. Recovering WALLET_ID \u00b6 If you lose your WALLET_ID, you can print out all your WALLET_IDs and public addresses in those wallets with the --wallet_list CLI command as follows: Command Format docker exec ${ NANO_NAME } nano_node --wallet_list Success Response Wallet_ID : E3E67B1B3FFA46F606240F1D0B964873D42E9C6D0B7A0BF376A2E128541CC446 nano_16odwi933gpzmkgdcy9tt5zef5ka3jcfubc97fwypsokg7sji4mb9n6qtbme Wallet_ID : DB0711484E35A4C75230D898853A86BFAFE9F87FCE99C83A4C2668C39607DD4B In this example, the nano_node's internal private-key management system contains two wallets, each with a different 256-bit seed. The first wallet has a single account and the second wallet has zero accounts. Account creation will be covered later. Backing Up Seed \u00b6 The following command will print the seed for a given wallet to stdout. Replace ${WALLET_ID} with the WALLET_ID that you would like to display the seed of. Command Format docker exec ${ NANO_NAME :- nano_node_1 } nano_node --wallet_decrypt_unsafe --wallet ${ WALLET_ID } Success Response Seed : D56143E7561D71C1AF4D563C6AF79EECE93E82479818AD8ED88BED1AAE8BE4E5 Pub : nano_16odwi933gpzmkgdcy9tt5zef5ka3jcfubc97fwypsokg7sji4mb9n6qtbme Prv : 1F6FEB5D1E05C10B904E1112F430C3FA93ACC7067206B63AD155199501794E3E Info The nano_node responds with three pieces of information: The seed of the wallet (back this up). The pairing public address The private key (deterministically derived from seed) of accounts within the wallet. Additional notes: If you change the seed in a wallet, future created accounts will be derived from that seed. Changing seeds on a wallet that already has accounts can cause accidental loss of funds from improper seed or private key backup. It is recommended to always create a new wallet when restoring a seed. Error Response Wallet doesn't exist Warning If anyone has access to the seed, they can freely access funds, so keep this very secure. Since the above command prints to stdout, it is recommended to wipe stdout afterwards using: clear && printf '\\e[3J' Restoring/Changing Seed \u00b6 Warning Only change the seed of a wallet that contains no accounts. Changing the seed of a wallet that already has accounts may lead to a false sense of security: accounts are generated by the seed that is currently in the wallet. Generating accounts, then switching the seed and backing up the new seed does not backup the previously generated accounts. Request Format curl -d '{ \"action\": \"wallet_change_seed\", \"wallet\": \"<WALLET_ID>\", \"seed\": \"<SEED>\" }' http://127.0.0.1:7076 Request Example curl -d '{ \"action\":\"wallet_change_seed\", \"wallet\":\"DB0711484E35A4C75230D898853A86BFAFE9F87FCE99C83A4C2668C39607DD4B\", \"seed\":\"D56143E7561D71C1AF4D563C6AF79EECE93E82479818AD8ED88BED1AAE8BE4E5\" }' http://127.0.0.1:7076 Success Response { \"success\" : \"\" } Error Response Response if the wallet_id isn't found in nano_node: { \"error\" : \"Wallet not found\" } Response if the seed field contains non-hexidecimal values or is too long: { \"error\" : \"Bad seed\" } Warning If the hexidecimal seed represents less than 256 bits, the seed will be 0-padded on the left to become 256 bits. Account Create \u00b6 After creating a wallet, it's corresponding WALLET_ID, and backing up the seed (not the wallet_id) , the wallet can be populated with accounts. To create a new account in a wallet use the account_create RPC command: Request Format curl -d '{ \"action\": \"account_create\", \"wallet\": \"<WALLET_ID>\" }' http://127.0.0.1:7076 Success Response { \"account\" : \"nano_16odwi933gpzmkgdcy9tt5zef5ka3jcfubc97fwypsokg7sji4mb9n6qtbme\" } Error Response { \"error\" : \"Wallet not found\" } Bulk Account Create \u00b6 To generate many accounts in bulk, it is more efficient to create them all at once using the accounts_create RPC command: Request Format curl -d '{ \"action\": \"accounts_create\", \"wallet\": \"<WALLET_ID>\", \"count\": \"<NUM_ACCOUNTS>\" }' http://127.0.0.1:7076 Request Example curl -d '{ \"action\": \"accounts_create\", \"wallet\": \"DB0711484E35A4C75230D898853A86BFAFE9F87FCE99C83A4C2668C39607DD4B\", \"count\":\"5\" }' http://127.0.0.1:7076 Success Response { \"accounts\" : [ \"nano_35kgi43t5hgi64715qnppmz1yb6re1igfcrkfx4ppirkqpfmecnpd1mdmafu\" , \"nano_3t13y6b7h93yn9hehn8p6yqx1yqzrxxs33drhzep8huhymwxamn15pba75oj\" , \"nano_11exxzfoosai96w7gnrjrn7m6i8bodch37ib8jgxsm5k96na6e1wda8np881\" , \"nano_3xbsso8pkemwatwdnkcyn1bfcmrb8dpcg3pit9zqxj9mkxa6ifiankff6m9x\" , \"nano_1q5gpy46moe1csj8md8oq3x57sxqmwskk8mmr7c63q1yebnjcsxg1yib19kn\" ] } Receiving Funds \u00b6 As long as the nano_node is synced and unlocked (nano_node locking is not covered in this guide), nano_node automatically creates and signs receive transactions for all accounts in the wallet's internal private-key management system. Tip In the event that a receive is not automatically generated, it can be manually generated using the receive RPC command. Semi-Manual Receiving Funds \u00b6 If the nano_node does not automatically sign in a pending transaction, transactions can be manually signed in. The easiest way is to explicitly command the nano_node to check all of the accounts in all of its wallets for pending blocks. Request Example curl -d '{ \"action\": \"search_pending_all\" }' http://127.0.0.1:7076 Success Response { \"success\" : \"\" } Note As the number of accounts in a nano_node grows, this command becomes increasingly computationally expensive. Sending funds \u00b6 The send RPC command sends funds from an account in the specified wallet to a destination address. Request Format curl -d '{ \"action\": \"send\", \"wallet\": \"<WALLET_ID>\", \"source\": \"<SOURCE_ADDRESS>\", \"destination\": \"<DESTINATION_ADDRESS>\", \"amount\": \"1000000\", \"id\": \"7081e2b8fec9146e\" }' http://127.0.0.1:7076 Field Description wallet WALLET_ID containing the source address source Address you control starting with \"nano_\" destination Destination address starting with \"nano_\" amount Amount to send in raw id Any string Important The \"id\" field is a safety mechanism that prevents issuing a transaction multiple times by repeating the RPC command. If a transaction is successful, any subsequent send RPC commands with the same identifier will be ignored by the nano_node. If the request times out, then the send may or may not have gone through. Most exchange \"double withdraw\" issues are caused by naive error-handling routines which re-issue the send request without the \"id\" parameter. The \"id\" field is local to your nano_node instance and does not offer protection when sent to different instances of nano_node that manage the same seed. As previously mentioned, having a seed loaded in multiple online nano_node is strongly discouraged. If managing more than 1000 accounts, building a separate system for managing keys and accounts externally is recommended Below is a sample command to send 1 nano nano from nano_3e3j5tkog48pnny9dmfzj1r16pg8t1e76dz5tmac6iq689wyjfpi00000000 to nano_16odwi933gpzmkgdcy9tt5zef5ka3jcfubc97fwypsokg7sji4mb9n6qtbme . Request Example curl -d '{ \"action\": \"send\", \"wallet\": \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\", \"source\": \"nano_3e3j5tkog48pnny9dmfzj1r16pg8t1e76dz5tmac6iq689wyjfpi00000000\", \"destination\": \"nano_16odwi933gpzmkgdcy9tt5zef5ka3jcfubc97fwypsokg7sji4mb9n6qtbme\", \"amount\": \"1000000000000000000000000000000\", \"id\": \"7081e2b8fec9146e\" }' http://127.0.0.1:7076 Success Response { \"block\" : \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\" } On success, the nano_node returns the hash of the transaction's block. Republishing Transactions \u00b6 It may take a few seconds for the transaction to appear on the Nano Network. If the transaction fails to appear, you may call the republish RPC command with the oldest missing transaction's hash. Account-chains must be continuous and unbroken . If for some reason a transaction fails to properly broadcast, subsequent transactions on the account-chain will not be accepted by the network since the \"previous\" field in the transaction data refers to a block unknown to to other nodes on the network. Tip Republishing the missing transaction(s) will make all the subsequent blocks valid in the network's ledger. Republishing does not create new transactions. The following command rebroadcasts all hashes on an acccount-chain starting at block with hash ${BLOCK_HASH} : Request Example curl -d '{ \"action\": \"republish\", \"hash\": \"AF9C1D46AAE66CC8F827904ED02D4B3D95AA98B1FF058352BA6B670BEFD40231\" }' http://127.0.0.1:7076 Success Response { \"success\" : \"\" , \"blocks\" : [ \"AF9C1D46AAE66CC8F827904ED02D4B3D95AA98B1FF058352BA6B670BEFD40231\" , \"C9A111580A21F3E63F2283DAF6450D5178BFAC2A6C38E09B76EEA9CE37EC9CE0\" ] } On success, the nano_node returns the hashes of all republished blocks.","title":"Key Management"},{"location":"integration-guides/key-management/#key-management","text":"","title":"Key Management"},{"location":"integration-guides/key-management/#seeds","text":"","title":"Seeds"},{"location":"integration-guides/key-management/#hex-seed","text":"Nano's private key(s) have been traditionally derived from a 64 character, uppercase hexadecimal string (0-9A-F). This is currently the more popular form of seed supported by a variety of services and wallets. Additional details available in The Basics guide .","title":"Hex Seed"},{"location":"integration-guides/key-management/#mnemonic-seed","text":"Nano's private key(s) from mnemonic derivation follows the BIP 39 / 44 standard. Only hardened paths are defined. Nano's coin-type is 165' (0x800000a5) 44'/165'/0' derives the first private key, 44'/165'/1' derives the second private key, and so on. The BIP39 seed modifier \"ed25519 seed\" is used which makes wallets compatible with each other. This was chosen due to it being used by the Ledger Nano implementation.","title":"Mnemonic Seed"},{"location":"integration-guides/key-management/#demo-examples","text":"External libraries, review before using The linked resources below contain code dealing with private key management and/or execution of transactions. The Nano Foundation does not control this code, does not endorse it and is not responsible for its use. Use of this code requires review and is at your own discretion. https://github.com/roosmaa/nano-bip39-demo https://github.com/joltwallet/bip-mnemonic","title":"Demo Examples"},{"location":"integration-guides/key-management/#implementations","text":"https://github.com/numsu/nanocurrency-web-js","title":"Implementations"},{"location":"integration-guides/key-management/#test-vectors","text":"Given 24-Word Mnemonic: edge defense waste choose enrich upon flee junk siren film clown finish luggage leader kid quick brick print evidence swap drill paddle truly occur Given Passphrase: some password Derived BIP39 Seed: 0dc285fde768f7ff29b66ce7252d56ed92fe003b605907f7a4f683c3dc8586d34a914d3c71fc099bb38ee4a59e5b081a3497b7a323e90cc68f67b5837690310c Derived Private Key for 44'/165'/0' : 3be4fc2ef3f3b7374e6fc4fb6e7bb153f8a2998b3b3dab50853eabe128024143 Derived Public key: 5b65b0e8173ee0802c2c3e6c9080d1a16b06de1176c938a924f58670904e82c4 Derived Address: nano_1pu7p5n3ghq1i1p4rhmek41f5add1uh34xpb94nkbxe8g4a6x1p69emk8y1d","title":"Test Vectors"},{"location":"integration-guides/key-management/#external-management","text":"For larger, more robust systems, external private key management is recommended. In this setup, the node operator generates and stores private keys in an external database and only queries the nano_node to: Find pending blocks for an account Sign transactions given a private key. More advanced systems may choose to implement signing themselves. Broadcast the signed transaction to the network. Note WALLET_IDs are not used for External Private Key Management since private keys are not stored in the nano_node. Much of this section builds off of the Blocks Specifications documentation.","title":"External Management"},{"location":"integration-guides/key-management/#external-accounting-systems","text":"In order to properly implement accounting systems external to the Nano node the following best practices should be put into place, which ensure only fully confirmed blocks are used for external tracking of credits, debits, etc. Confirmation and idempotency The details below expand on this, but the two most important pieces of any integration are: Always confirm blocks - make sure to follow the block confirmation tracking recommendations so you are always taking action from confirmed blocks Guarantee idempotency - whenever you take action from a block confirmation, it must be idempotent so you don't take the action again if the same block hash is seen through confirmation tracking","title":"External accounting systems"},{"location":"integration-guides/key-management/#block-confirmation-procedures","text":"Before crediting funds to an account internally based on a deposit on the network, the block sending the funds must be confirmed. This is done by verifying the network has reached quorum on the block. Details of the recommended verification process can be found in the block confirmation tracking guide .","title":"Block confirmation procedures"},{"location":"integration-guides/key-management/#tracking-confirmed-balances","text":"External accounting systems that track balances arriving to the node must track hashes of blocks that have been received in order to guarantee idempotency. Once confirmation of a block has been validated, the block hash should be recorded for the account along with any credits, debits or other related information. Any attempts to credit or debit accounts external to the node should check that no previous conflicting or duplicate activity was already recorded for that same block hash.","title":"Tracking confirmed balances"},{"location":"integration-guides/key-management/#transaction-order-and-correctness","text":"If you are creating a batch of transactions for a single account, which can be a mix of sending and receiving funds, there is no need to wait for the confirmation of blocks in that account to create the next transaction. As long as a transaction is valid, it will be confirmed by the network. The transactions that follow it can only be confirmed if the previous transactions are valid. However, you must always wait for the confirmation of pending blocks before creating the corresponding receive transaction, to ensure it will be confirmed. Always wait for confirmation of transactions that you did not create yourself.","title":"Transaction order and correctness"},{"location":"integration-guides/key-management/#expanding-private-keys","text":"A Nano private key is a 256-bit piece of data produced from a cryptographically secure random number generator. Secure Private Keys Generating private keys from an insecure source may result in loss of funds. Be sure to backup any generated private key; if lost the funds in the account will become inaccessible. Step 1: Generate secure private key The bash command below generates a valid private key from a cryptographically secure random number generator. Always use a cryptographically secure processes for generating any private keys.","title":"Expanding Private Keys"},{"location":"integration-guides/key-management/#creating-transactions","text":"Using external keys, transactions are generated in two steps: creation and broadcast. This section will be more heavy on example rather than precise specifications.","title":"Creating Transactions"},{"location":"integration-guides/key-management/#send-transaction","text":"Step 1: Get Account Info To send funds to an account, first call the account_info RPC command to gather necessary account information to craft your transaction. Setting \"representative\": \"true\" makes the nano_node also return the account's representative address, a necessary piece of data for creating a transaction.","title":"Send Transaction"},{"location":"integration-guides/key-management/#receive-transaction","text":"Manually receiving first block The very first transaction on an account-chain, which is always a receive, is slightly special and deserves its own section First Receive Transaction . Step 1: Get Account Info Receiving funds is very similar to sending funds outlined in the previous section, starting with calling account_info to get block details for the account frontier. The scenario below pretends that our previous example of a send transaction was not broadcast and confirmed on the network because the starting account_info details are identical.","title":"Receive Transaction"},{"location":"integration-guides/key-management/#first-receive-transaction","text":"The first transaction of an account is crafted in a slightly different way. To open an account, you must have sent some funds to it with a Send Transaction from another account. The funds will be pending on the receiving account. If you already know the hash of the pending transaction, you can skip Step 1. Step 1: Obtain the pending transaction block hash Start with obtaining a list of pending transactions in your unopened account. Limit the response to the highest value transaction by using a combination of sorting and count .","title":"First Receive Transaction"},{"location":"integration-guides/key-management/#broadcasting-transactions","text":"Broadcast using process RPC command Common to all of these transactions is the need to broadcast the completed block to the network. This is achieved by the process RPC command which accepts the block as stringified JSON data. If you followed the previous examples, you used the option json_block for RPC block_create , which allows you use the non-stringified version, as long as you include the same option in this RPC call. A successful broadcast will return the broadcasted block's hash. Including subtype in process RPC calls highly recommended In order to avoid potential incorrect sends including the optional subtype parameter on all process RPC calls is highly recommended . In the next version of the RPC this parameter will be required.","title":"Broadcasting Transactions"},{"location":"integration-guides/key-management/#internal-management","text":"The nano_node software has a built-in private-key manager that is suitable for smaller operations (<1000 accounts). External Key Management allows more powerful and robust systems at the cost of additional complexity. External Key Management is recommended for larger operations.","title":"Internal Management"},{"location":"integration-guides/key-management/#creating-a-wallet","text":"To create an account, you first must create a wallet to hold the seed that will subsequently create the account.","title":"Creating a Wallet"},{"location":"integration-guides/key-management/#recovering-wallet_id","text":"If you lose your WALLET_ID, you can print out all your WALLET_IDs and public addresses in those wallets with the --wallet_list CLI command as follows:","title":"Recovering WALLET_ID"},{"location":"integration-guides/key-management/#backing-up-seed","text":"The following command will print the seed for a given wallet to stdout. Replace ${WALLET_ID} with the WALLET_ID that you would like to display the seed of.","title":"Backing Up Seed"},{"location":"integration-guides/key-management/#restoringchanging-seed","text":"Warning Only change the seed of a wallet that contains no accounts. Changing the seed of a wallet that already has accounts may lead to a false sense of security: accounts are generated by the seed that is currently in the wallet. Generating accounts, then switching the seed and backing up the new seed does not backup the previously generated accounts.","title":"Restoring/Changing Seed"},{"location":"integration-guides/key-management/#account-create","text":"After creating a wallet, it's corresponding WALLET_ID, and backing up the seed (not the wallet_id) , the wallet can be populated with accounts. To create a new account in a wallet use the account_create RPC command:","title":"Account Create"},{"location":"integration-guides/key-management/#bulk-account-create","text":"To generate many accounts in bulk, it is more efficient to create them all at once using the accounts_create RPC command:","title":"Bulk Account Create"},{"location":"integration-guides/key-management/#receiving-funds","text":"As long as the nano_node is synced and unlocked (nano_node locking is not covered in this guide), nano_node automatically creates and signs receive transactions for all accounts in the wallet's internal private-key management system. Tip In the event that a receive is not automatically generated, it can be manually generated using the receive RPC command.","title":"Receiving Funds"},{"location":"integration-guides/key-management/#semi-manual-receiving-funds","text":"If the nano_node does not automatically sign in a pending transaction, transactions can be manually signed in. The easiest way is to explicitly command the nano_node to check all of the accounts in all of its wallets for pending blocks.","title":"Semi-Manual Receiving Funds"},{"location":"integration-guides/key-management/#sending-funds","text":"The send RPC command sends funds from an account in the specified wallet to a destination address.","title":"Sending funds"},{"location":"integration-guides/key-management/#republishing-transactions","text":"It may take a few seconds for the transaction to appear on the Nano Network. If the transaction fails to appear, you may call the republish RPC command with the oldest missing transaction's hash. Account-chains must be continuous and unbroken . If for some reason a transaction fails to properly broadcast, subsequent transactions on the account-chain will not be accepted by the network since the \"previous\" field in the transaction data refers to a block unknown to to other nodes on the network. Tip Republishing the missing transaction(s) will make all the subsequent blocks valid in the network's ledger. Republishing does not create new transactions. The following command rebroadcasts all hashes on an acccount-chain starting at block with hash ${BLOCK_HASH} :","title":"Republishing Transactions"},{"location":"integration-guides/the-basics/","text":"The Basics \u00b6 Block Lattice Design \u00b6 Nano's ledger is built on a data-structure called a \"Block Lattice.\" Every account (private/public key pair) has their own blockchain (account-chain). Only the holder of the private key may sign and publish blocks to their own account-chain. Each block represents a transaction. Action Description Send Send funds from users account to another account Receive Receive funds from a given \"Send\" transaction The system is akin to writing (send) and cashing (receive) a Cashier's Check. There are a few things to consider about transactions: The receiving account does not have to be online during the Send transaction. The transaction will stay as pending indefinitely until a Receive transaction is created. Once funds are sent, they cannot be revoked by the sender. Representatives \u00b6 The Nano Network achieves consensus using the unique Open Representative Voting (ORV) model. In this setup, representatives (accounts where nano_node with the private keys are running 24/7) vote on transactions. Info Below are some helpful things to remember about Nano's representatives and consensus: A representative's voting power is directly proportional to the amount of funds delegated to that account by other users of the protocol. An account's representative has no bearing on its transactions or nano_node operation. Choosing a representative with good uptime that is also a unique entity (to prevent sybil attacks) helps maintain high Nano network security. If an account's representative goes offline, the account's funds are no longer used to help secure the network; however, the account is unaffected. Anyone that runs a full-time node may be a representative and be delegated voting weight from other users of the protocol. An account can freely change its representative anytime within any transaction or explicitly by publishing a block which only changes the representative (sends no funds), which most wallets support. Account, Key, Seed and Wallet IDs \u00b6 When dealing with the various IDs in the node it is important to understand the function and implication of each one. Similar IDs, Different Functions There are several things that can have a similar form but may have very different functions, and mixing them up can result in loss of funds. Use caution when handling them. Wallet ID \u00b6 This is a series of 32 random bytes of data and is not the seed . It is used in several RPC actions and command line options for the node. It is a purely local UUID that is a reference to a block of data about a specific wallet (set of seed/private keys/info about them) in your node's local database file. The reason this is necessary is because we want to store information about each account in a wallet: whether it's been used, what its account is so we don't have to generate it every time, its balance, etc. Also, so we can hold ad hoc accounts, which are accounts that are not derived from the seed. This identifier is only useful in conjunction with your node's database file and it will not recover funds if that database is lost or corrupted . This is the value that you get back when using the wallet_create etc RPC commands, and what the node expects for RPC commands with a \"wallet\" field as input. Seed \u00b6 This is a series of 32 random bytes of data, usually represented as a 64 character, uppercase hexadecimal string (0-9A-F). This value is used to derive account private keys for accounts by combining it with an index and then putting that into the following hash function where || means concatenation and i is a 32-bit big-endian unsigned integer: PrivK[i] = blake2b(outLen = 32, input = seed || i) Private keys are derived deterministically from the seed, which means that as long as you put the same seed and index into the derivation function, you will get the same resulting private key every time. Therefore, knowing just the seed allows you to be able to access all the derived private keys from index 0 to 2^{32} - 1 2^{32} - 1 (because the index value is a unsigned 32-bit integer). Wallet implementations will commonly start from index 0 and increment it by 1 each time you create a new account so that recovering accounts is as easy as importing the seed and then repeating this account creation process. It should be noted that Nano reference wallet is using described Blake2b private keys derivation path. However some implementations can use BIP44 deterministic wallets and mnemonic seed producing different private keys for given seed and indices. Additionally 24-word mnemonic can be derived from a Nano 64 length hex seed as entropy with clear notice for users that this is not BIP44 seed/entropy. Code samples Python deterministic key: import hashlib seed = b \" \\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01 \" # \"0000000000000000000000000000000000000000000000000000000000000001\" index = 0x00000001 . to_bytes ( 4 , 'big' ) # 1 blake2b_state = hashlib . blake2b ( digest_size = 32 ) blake2b_state . update ( seed + index ) # where `+` means concatenation, not sum: https://docs.python.org/3/library/hashlib.html#hashlib.hash.update # code line above is equal to `blake2b_state.update(seed); blake2b_state.update(index)` PrivK = blake2b_state . digest () print ( blake2b_state . hexdigest () . upper ()) # \"1495F2D49159CC2EAAAA97EBB42346418E1268AFF16D7FCA90E6BAD6D0965520\" Mnemonic words for Blake2b Nano seed using Bitcoinjs : const bip39 = require ( 'bip39' ) const mnemonic = bip39 . entropyToMnemonic ( '0000000000000000000000000000000000000000000000000000000000000001' ) // => abandon abandon abandon abandon abandon abandon abandon abandon abandon abandon abandon abandon abandon abandon abandon abandon abandon abandon abandon abandon abandon abandon abandon diesel bip39 . mnemonicToEntropy ( mnemonic ) // => '0000000000000000000000000000000000000000000000000000000000000001' Account private key \u00b6 This is also a 32 byte value, usually represented as a 64 character, uppercase hexadecimal string(0-9A-F). It can either be random (an ad-hoc key ) or derived from a seed, as described above. This is what represents control of a specific account on the ledger. If you know or can know the private key of someone's account, you can transact as if you own that account. Account public key \u00b6 This is also a 32 byte value, usually represented as a 64 character, uppercase hexadecimal string (0-9A-F). It is derived from an account private key by using the ED25519 curve using Blake2b-512 as the hash function (instead of SHA-512). Usually account public keys will not be passed around in this form, rather the below address is used. Account public address \u00b6 This is what you think of as someone's Nano address: it's a string that starts with nano_ (previously xrb_ ), then has 52 characters which are the account public key but encoded with a specific base32 encoding algorithm to prevent human transcription errors by limiting ambiguity between different characters (no O and 0 for example). Then the final 8 characters are Blake2b-40 checksum of the account public key to aid in discovering typos, also encoded with the same base32 scheme (5 bytes). So for address nano_1anrzcuwe64rwxzcco8dkhpyxpi8kd7zsjc1oeimpc3ppca4mrjtwnqposrs : Prefix Encoded Account Public Key Checksum nano_ 1anrzcuwe64rwxzcco8dkhpyxpi8kd7zsjc1oeimpc3ppca4mrjt wnqposrs For basic address validation, the following regular expression can be used: ^(nano|xrb)_[13]{1}[13456789abcdefghijkmnopqrstuwxyz]{59}$ . Validation of the checksum is also recommended, depending on the integration. Prefixes: nano_ vs. xrb_ As of V19.0 the Nano node only returns nano_ addresses in all actions , but prior versions returned xrb_ addresses. These prefixes are interchangeable \u2014 everything after the _ remains the same. If you have an issue using one or the other prefix with any exchange or service, you can safely switch between nano_ and xrb_ prefixes as needed \u2014 they both represent the same account owned by your private key or seed. Units \u00b6 Nano can be represented using more than one unit of measurement. While the most common unit is the nano nano , the smallest unit is the raw raw . Below is the formula for converting between raw raw and nano nano . 1 nano = 10^{30} raw 1 nano = 10^{30} raw Important All RPC commands expect units to be represented as raw raw . Always keep units in integer raw raw amounts to prevent any floating-point error or unit confusion. Depending on your implementation language, you may require a big number library to perform arithmetic directly on raw raw . See Distribution and Units page for more details on units. Because final balances are recorded rather than transaction amounts, API calls must be done carefully to avoid loss of funds. Incorrect arithmetic or use of fields may change an intended receive to a send to a non-existent address. Blocks Specifications \u00b6 All new transactions on the Nano Protocol are communicated via blocks. The account's entire state, including the balance after each transaction, is recorded in every block. Transaction amounts are interpreted as the difference in balance between consecutive blocks. If an account balance decreases, the transaction that caused the decrease is considered a send. Similarly, if an account balance increases, the transaction that caused the increase is considered a receive. Important Because final balances are recorded rather than transaction amounts, API calls must be done carefully to avoid sending erroneous amounts. Block Format \u00b6 Because each block contains the current state of the account, the \"type\" of the block is always \"state\" . The following table presents the anatomy of a block, along with the format used within RPC calls for building blocks, and the serialized, binary representation: Key RPC Format Serialized Description type string - \"state\" account string 32 bytes This account's nano_ address previous 64 hex-char string 32 bytes Previous head block on account; 0 if open block representative string 32 bytes Representative nano_ address balance decimal string 16 bytes Resulting balance (in raw ) link - 32 bytes Multipurpose field - see link table below signature 128 hex-char string 64 bytes ED25519+Blake2b 512-bit signature work 16 hex-char string 8 bytes Proof of Work Nonce Depending on the action each transaction intends to perform, the \"link\" field will have a different value for block_create RPC command: Action RPC Format Description Change string Must be \"0\" Send string Destination \"nano_\" address Receive 64 hex-char string Pairing block's hash (block sending funds) Note Any transaction may also simultaneously change the representative. The above description of the \"Change\" action is for creating a block with an explicit representative change where no funds are transferred (balance is not changed). In the completed, signed transaction json, the \"link\" field is always hexadecimal. The first block on an account must be receiving funds (cannot be an explicit representative change). The first block is often referred to as \"opening the account\". Self-Signed Blocks \u00b6 If you choose to implement your own signing, the order of data (in bytes) to hash prior to signing is as follows. All values are binary representations No ASCII/UTF-8 strings. Order of data: block preamble (32-Bytes, value 0x6 ) account (32-Bytes) previous (32-Bytes) representative (32-Bytes) balance (16-Bytes) link (32-Bytes) The digital signing algorithm (which internally applies another Blake2b hashing) is applied on the resulting digest. Private/public key usage Make sure that your private key uses the correct partnering public key while signing as using an incorrect public key may leak information about your private key. Creating Blocks \u00b6 For details on how to create individual blocks for sending from, receiving to, opening or changing representatives for an account, please see the Creating Transactions section. URI and QR Code Standards \u00b6 Note: amount values should always be in RAW. Note: Please use nano:// for deep links Send to an address \u00b6 nano:nano_<encoded address>[?][amount=<raw amount>][&][label=<label>][&][message=<message>] Just the address nano:nano_3wm37qz19zhei7nzscjcopbrbnnachs4p1gnwo5oroi3qonw6inwgoeuufdp Address and an amount (as RAW) nano:nano_3wm37qz19zhei7nzscjcopbrbnnachs4p1gnwo5oroi3qonw6inwgoeuufdp?amount=1000 Address and a label nano:nano_3wm37qz19zhei7nzscjcopbrbnnachs4p1gnwo5oroi3qonw6inwgoeuufdp?label=Developers%20Fund%20Address Send to an address with amount, label and message nano:nano_3wm37qz19zhei7nzscjcopbrbnnachs4p1gnwo5oroi3qonw6inwgoeuufdp?amount=10&label=Developers%20Fund&message=Donate%20Now Representative change \u00b6 nanorep:nano_<encoded address>[?][label=<label>][&][message=<message>] Change to representative with label and message nanorep:nano_1stofnrxuz3cai7ze75o174bpm7scwj9jn3nxsn8ntzg784jf1gzn1jjdkou?label=Official%20Rep%202&message=Thank%20you%20for%20changing%20your%20representative%21 Private Key Import \u00b6 nanokey:<encoded private key>[?][label=<label>][&][message=<message>] Seed Import \u00b6 nanoseed:<encoded seed>[?][label=<label>][&][message=<message>][&][lastindex=<index>] Process a JSON blob block \u00b6 (to be sent as the block argument to the RPC call process ) nanoblock:<blob>","title":"The Basics"},{"location":"integration-guides/the-basics/#the-basics","text":"","title":"The Basics"},{"location":"integration-guides/the-basics/#block-lattice-design","text":"Nano's ledger is built on a data-structure called a \"Block Lattice.\" Every account (private/public key pair) has their own blockchain (account-chain). Only the holder of the private key may sign and publish blocks to their own account-chain. Each block represents a transaction. Action Description Send Send funds from users account to another account Receive Receive funds from a given \"Send\" transaction The system is akin to writing (send) and cashing (receive) a Cashier's Check. There are a few things to consider about transactions: The receiving account does not have to be online during the Send transaction. The transaction will stay as pending indefinitely until a Receive transaction is created. Once funds are sent, they cannot be revoked by the sender.","title":"Block Lattice Design"},{"location":"integration-guides/the-basics/#representatives","text":"The Nano Network achieves consensus using the unique Open Representative Voting (ORV) model. In this setup, representatives (accounts where nano_node with the private keys are running 24/7) vote on transactions. Info Below are some helpful things to remember about Nano's representatives and consensus: A representative's voting power is directly proportional to the amount of funds delegated to that account by other users of the protocol. An account's representative has no bearing on its transactions or nano_node operation. Choosing a representative with good uptime that is also a unique entity (to prevent sybil attacks) helps maintain high Nano network security. If an account's representative goes offline, the account's funds are no longer used to help secure the network; however, the account is unaffected. Anyone that runs a full-time node may be a representative and be delegated voting weight from other users of the protocol. An account can freely change its representative anytime within any transaction or explicitly by publishing a block which only changes the representative (sends no funds), which most wallets support.","title":"Representatives"},{"location":"integration-guides/the-basics/#account-key-seed-and-wallet-ids","text":"When dealing with the various IDs in the node it is important to understand the function and implication of each one. Similar IDs, Different Functions There are several things that can have a similar form but may have very different functions, and mixing them up can result in loss of funds. Use caution when handling them.","title":"Account, Key, Seed and Wallet IDs"},{"location":"integration-guides/the-basics/#wallet-id","text":"This is a series of 32 random bytes of data and is not the seed . It is used in several RPC actions and command line options for the node. It is a purely local UUID that is a reference to a block of data about a specific wallet (set of seed/private keys/info about them) in your node's local database file. The reason this is necessary is because we want to store information about each account in a wallet: whether it's been used, what its account is so we don't have to generate it every time, its balance, etc. Also, so we can hold ad hoc accounts, which are accounts that are not derived from the seed. This identifier is only useful in conjunction with your node's database file and it will not recover funds if that database is lost or corrupted . This is the value that you get back when using the wallet_create etc RPC commands, and what the node expects for RPC commands with a \"wallet\" field as input.","title":"Wallet ID"},{"location":"integration-guides/the-basics/#seed","text":"This is a series of 32 random bytes of data, usually represented as a 64 character, uppercase hexadecimal string (0-9A-F). This value is used to derive account private keys for accounts by combining it with an index and then putting that into the following hash function where || means concatenation and i is a 32-bit big-endian unsigned integer: PrivK[i] = blake2b(outLen = 32, input = seed || i) Private keys are derived deterministically from the seed, which means that as long as you put the same seed and index into the derivation function, you will get the same resulting private key every time. Therefore, knowing just the seed allows you to be able to access all the derived private keys from index 0 to 2^{32} - 1 2^{32} - 1 (because the index value is a unsigned 32-bit integer). Wallet implementations will commonly start from index 0 and increment it by 1 each time you create a new account so that recovering accounts is as easy as importing the seed and then repeating this account creation process. It should be noted that Nano reference wallet is using described Blake2b private keys derivation path. However some implementations can use BIP44 deterministic wallets and mnemonic seed producing different private keys for given seed and indices. Additionally 24-word mnemonic can be derived from a Nano 64 length hex seed as entropy with clear notice for users that this is not BIP44 seed/entropy. Code samples Python deterministic key: import hashlib seed = b \" \\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01 \" # \"0000000000000000000000000000000000000000000000000000000000000001\" index = 0x00000001 . to_bytes ( 4 , 'big' ) # 1 blake2b_state = hashlib . blake2b ( digest_size = 32 ) blake2b_state . update ( seed + index ) # where `+` means concatenation, not sum: https://docs.python.org/3/library/hashlib.html#hashlib.hash.update # code line above is equal to `blake2b_state.update(seed); blake2b_state.update(index)` PrivK = blake2b_state . digest () print ( blake2b_state . hexdigest () . upper ()) # \"1495F2D49159CC2EAAAA97EBB42346418E1268AFF16D7FCA90E6BAD6D0965520\" Mnemonic words for Blake2b Nano seed using Bitcoinjs : const bip39 = require ( 'bip39' ) const mnemonic = bip39 . entropyToMnemonic ( '0000000000000000000000000000000000000000000000000000000000000001' ) // => abandon abandon abandon abandon abandon abandon abandon abandon abandon abandon abandon abandon abandon abandon abandon abandon abandon abandon abandon abandon abandon abandon abandon diesel bip39 . mnemonicToEntropy ( mnemonic ) // => '0000000000000000000000000000000000000000000000000000000000000001'","title":"Seed"},{"location":"integration-guides/the-basics/#account-private-key","text":"This is also a 32 byte value, usually represented as a 64 character, uppercase hexadecimal string(0-9A-F). It can either be random (an ad-hoc key ) or derived from a seed, as described above. This is what represents control of a specific account on the ledger. If you know or can know the private key of someone's account, you can transact as if you own that account.","title":"Account private key"},{"location":"integration-guides/the-basics/#account-public-key","text":"This is also a 32 byte value, usually represented as a 64 character, uppercase hexadecimal string (0-9A-F). It is derived from an account private key by using the ED25519 curve using Blake2b-512 as the hash function (instead of SHA-512). Usually account public keys will not be passed around in this form, rather the below address is used.","title":"Account public key"},{"location":"integration-guides/the-basics/#account-public-address","text":"This is what you think of as someone's Nano address: it's a string that starts with nano_ (previously xrb_ ), then has 52 characters which are the account public key but encoded with a specific base32 encoding algorithm to prevent human transcription errors by limiting ambiguity between different characters (no O and 0 for example). Then the final 8 characters are Blake2b-40 checksum of the account public key to aid in discovering typos, also encoded with the same base32 scheme (5 bytes). So for address nano_1anrzcuwe64rwxzcco8dkhpyxpi8kd7zsjc1oeimpc3ppca4mrjtwnqposrs : Prefix Encoded Account Public Key Checksum nano_ 1anrzcuwe64rwxzcco8dkhpyxpi8kd7zsjc1oeimpc3ppca4mrjt wnqposrs For basic address validation, the following regular expression can be used: ^(nano|xrb)_[13]{1}[13456789abcdefghijkmnopqrstuwxyz]{59}$ . Validation of the checksum is also recommended, depending on the integration. Prefixes: nano_ vs. xrb_ As of V19.0 the Nano node only returns nano_ addresses in all actions , but prior versions returned xrb_ addresses. These prefixes are interchangeable \u2014 everything after the _ remains the same. If you have an issue using one or the other prefix with any exchange or service, you can safely switch between nano_ and xrb_ prefixes as needed \u2014 they both represent the same account owned by your private key or seed.","title":"Account public address"},{"location":"integration-guides/the-basics/#units","text":"Nano can be represented using more than one unit of measurement. While the most common unit is the nano nano , the smallest unit is the raw raw . Below is the formula for converting between raw raw and nano nano . 1 nano = 10^{30} raw 1 nano = 10^{30} raw Important All RPC commands expect units to be represented as raw raw . Always keep units in integer raw raw amounts to prevent any floating-point error or unit confusion. Depending on your implementation language, you may require a big number library to perform arithmetic directly on raw raw . See Distribution and Units page for more details on units. Because final balances are recorded rather than transaction amounts, API calls must be done carefully to avoid loss of funds. Incorrect arithmetic or use of fields may change an intended receive to a send to a non-existent address.","title":"Units"},{"location":"integration-guides/the-basics/#blocks-specifications","text":"All new transactions on the Nano Protocol are communicated via blocks. The account's entire state, including the balance after each transaction, is recorded in every block. Transaction amounts are interpreted as the difference in balance between consecutive blocks. If an account balance decreases, the transaction that caused the decrease is considered a send. Similarly, if an account balance increases, the transaction that caused the increase is considered a receive. Important Because final balances are recorded rather than transaction amounts, API calls must be done carefully to avoid sending erroneous amounts.","title":"Blocks Specifications"},{"location":"integration-guides/the-basics/#block-format","text":"Because each block contains the current state of the account, the \"type\" of the block is always \"state\" . The following table presents the anatomy of a block, along with the format used within RPC calls for building blocks, and the serialized, binary representation: Key RPC Format Serialized Description type string - \"state\" account string 32 bytes This account's nano_ address previous 64 hex-char string 32 bytes Previous head block on account; 0 if open block representative string 32 bytes Representative nano_ address balance decimal string 16 bytes Resulting balance (in raw ) link - 32 bytes Multipurpose field - see link table below signature 128 hex-char string 64 bytes ED25519+Blake2b 512-bit signature work 16 hex-char string 8 bytes Proof of Work Nonce Depending on the action each transaction intends to perform, the \"link\" field will have a different value for block_create RPC command: Action RPC Format Description Change string Must be \"0\" Send string Destination \"nano_\" address Receive 64 hex-char string Pairing block's hash (block sending funds) Note Any transaction may also simultaneously change the representative. The above description of the \"Change\" action is for creating a block with an explicit representative change where no funds are transferred (balance is not changed). In the completed, signed transaction json, the \"link\" field is always hexadecimal. The first block on an account must be receiving funds (cannot be an explicit representative change). The first block is often referred to as \"opening the account\".","title":"Block Format"},{"location":"integration-guides/the-basics/#self-signed-blocks","text":"If you choose to implement your own signing, the order of data (in bytes) to hash prior to signing is as follows. All values are binary representations No ASCII/UTF-8 strings. Order of data: block preamble (32-Bytes, value 0x6 ) account (32-Bytes) previous (32-Bytes) representative (32-Bytes) balance (16-Bytes) link (32-Bytes) The digital signing algorithm (which internally applies another Blake2b hashing) is applied on the resulting digest. Private/public key usage Make sure that your private key uses the correct partnering public key while signing as using an incorrect public key may leak information about your private key.","title":"Self-Signed Blocks"},{"location":"integration-guides/the-basics/#creating-blocks","text":"For details on how to create individual blocks for sending from, receiving to, opening or changing representatives for an account, please see the Creating Transactions section.","title":"Creating Blocks"},{"location":"integration-guides/the-basics/#uri-and-qr-code-standards","text":"Note: amount values should always be in RAW. Note: Please use nano:// for deep links","title":"URI and QR Code Standards"},{"location":"integration-guides/the-basics/#send-to-an-address","text":"nano:nano_<encoded address>[?][amount=<raw amount>][&][label=<label>][&][message=<message>] Just the address nano:nano_3wm37qz19zhei7nzscjcopbrbnnachs4p1gnwo5oroi3qonw6inwgoeuufdp Address and an amount (as RAW) nano:nano_3wm37qz19zhei7nzscjcopbrbnnachs4p1gnwo5oroi3qonw6inwgoeuufdp?amount=1000 Address and a label nano:nano_3wm37qz19zhei7nzscjcopbrbnnachs4p1gnwo5oroi3qonw6inwgoeuufdp?label=Developers%20Fund%20Address Send to an address with amount, label and message nano:nano_3wm37qz19zhei7nzscjcopbrbnnachs4p1gnwo5oroi3qonw6inwgoeuufdp?amount=10&label=Developers%20Fund&message=Donate%20Now","title":"Send to an address"},{"location":"integration-guides/the-basics/#representative-change","text":"nanorep:nano_<encoded address>[?][label=<label>][&][message=<message>] Change to representative with label and message nanorep:nano_1stofnrxuz3cai7ze75o174bpm7scwj9jn3nxsn8ntzg784jf1gzn1jjdkou?label=Official%20Rep%202&message=Thank%20you%20for%20changing%20your%20representative%21","title":"Representative change"},{"location":"integration-guides/the-basics/#private-key-import","text":"nanokey:<encoded private key>[?][label=<label>][&][message=<message>]","title":"Private Key Import"},{"location":"integration-guides/the-basics/#seed-import","text":"nanoseed:<encoded seed>[?][label=<label>][&][message=<message>][&][lastindex=<index>]","title":"Seed Import"},{"location":"integration-guides/the-basics/#process-a-json-blob-block","text":"(to be sent as the block argument to the RPC call process ) nanoblock:<blob>","title":"Process a JSON blob block"},{"location":"integration-guides/websockets/","text":"WebSockets \u00b6 Available in version 19.0+ only. When upgrading from version 18 or earlier, the node performs a confirmation height upgrade. During this process, the WebSocket notifications may include confirmations for old blocks. Services must handle duplicate notifications, as well as missed blocks as WebSockets do not provide guaranteed delivery. Reasons for missed blocks include intermittent network issues and internal containers (in the node or clients) reaching capacity. Multiple notifications for blocks Depending on the node setup and sync status, multiple confirmation notifications for the same block hash may be sent by a single tracking mechanism. In order to prevent potential issues, integrations must track these block hashes externally to the node and prevent any unwanted actions based on multiple notifications. The Nano node offers notification of confirmed blocks over WebSockets. This offers higher throughput over the HTTP callback, and uses a single ingoing connection instead of an outgoing connection for every block. The HTTP callback is still available and both mechanisms can be used at the same time. Example clients \u00b6 Sample clients are available: Node.js: https://github.com/cryptocode/nano-websocket-sample-nodejs Python: https://github.com/guilhermelawless/nano-websocket-sample-py Configuration \u00b6 These configuration options are set in the config-node.toml file . [node.websocket] # WebSocket server bind address. # type:string,ip address = \"::1\" # Enable or disable WebSocket server. # type:bool enable = true # WebSocket server listening port. # type:uint16 port = 7078 With the above configuration, localhost clients should connect to ws://[::1]:7078 . Configuration for use with Docker Set the WebSocket server bind address to ::ffff:0.0.0.0 instead, and configure the container to map port 7078 accordingly. Review Managing the Container to ensure the websocket is not exposed externally. Acknowledgement \u00b6 All WebSocket actions can optionally request an acknowledgement. The following is an example for the subscribe action. { \"action\" : \"subscribe\" , \"topic\" : \"confirmation\" , \"ack\" : true , \"id\" : \"<optional unique id>\" } If the action succeeds, the following message will be sent back (note that no message ordering is guaranteed): { \"ack\" : \"subscribe\" , \"time\" : \"<milliseconds since epoch>\" , \"id\" : \"<optional unique id>\" } Update \u00b6 Some subscriptions can be updated without requiring unsubscribing and re-subscribing to the same topic. A typical message is the following: { \"action\" : \"update\" , \"topic\" : \"confirmation\" , \"options\" : { ... } } Updatable filter options are mentioned in the examples below. Keepalive \u00b6 This action is available since v20.0 Keepalive allows checking the liveliness of the websocket without refreshing it or changing a subscription. Use the format: { \"action\" : \"ping\" } The expected response is: { \"ack\" : \"pong\" , \"time\" : \"<milliseconds since epoch>\" } Subscribe/Unsubscribe \u00b6 To receive notifications through the websocket you must subscribe to the specific topic and a standard subscription without filters looks like this: { \"action\" : \"subscribe\" , \"topic\" : \"confirmation\" } Unsubscribing also has the format: To unsubscribe: { \"action\" : \"unsubscribe\" , \"topic\" : \"confirmation\" } Optional Filters Some topics support filters as well. Details of the subscription filter options for each topic are included in examples below. Note Note that, if empty options are supplied (see examples below), an empty filter will be used and nothing will be broadcasted. Available Topics \u00b6 Confirmations \u00b6 Multiple notifications for blocks Depending on the node setup and sync status, multiple confirmation notifications for the same block hash may be sent by a single tracking mechanism. In order to prevent potential issues, integrations must track these block hashes externally to the node and prevent any unwanted actions based on multiple notifications. Subscribing To subscribe to all confirmed blocks: { \"action\" : \"subscribe\" , \"topic\" : \"confirmation\" } Filtering options Confirmation types The node classifies block confirmations into the following categories: Active quorum : a block is confirmed through voting (including block_confirm RPC if block is previously unconfirmed) Active confirmation height : a block which is confirmed as a dependent election from a successor through voting (or by block_confirm RPC if the block is already confirmed) Inactive : a block that is not in active elections is implicitly confirmed by a successor. By default, the node emits all confirmations to WebSocket clients. However, the following filtering option is available: { \"action\" : \"subscribe\" , \"topic\" : \"confirmation\" , \"options\" : { \"confirmation_type\" : \"<type>\" } } The most common values for confirmation_type are all (default), active and inactive . If more fine-grained filtering is needed, active can be replaced with active_quorum or active_confirmation_height per the definitions above. Accounts Filters for confirmation can be used to subscribe only to selected accounts. Once filters are given, blocks from accounts that do not match the options are not broadcasted. Legacy blocks never broadcasted Note that legacy blocks are never broadcasted if filters are given, even if they match the accounts. { \"action\" : \"subscribe\" , \"topic\" : \"confirmation\" , \"options\" : { \"all_local_accounts\" : true , \"accounts\" : [ \"nano_16c4ush661bbn2hxc6iqrunwoyqt95in4hmw6uw7tk37yfyi77s7dyxaw8ce\" , \"nano_3dmtrrws3pocycmbqwawk6xs7446qxa36fcncush4s1pejk16ksbmakis32c\" ] } } When all_local_accounts is set to true , blocks that mention accounts in any wallet will be broadcasted. accounts is a list of additional accounts to subscribe to. Both prefixes are supported. Updating the list of accounts version 21.0+ The list of accounts for which blocks are broadcasted can be updated (see Update ): { \"action\" : \"update\" , \"topic\" : \"confirmation\" , \"options\" : { \"accounts_add\" : [ ... // addi t io nal accou nts t o tra ck ], \"accounts_del\" : [ ... // accou nts t o remove fr om tra cki n g ] } } Note that this can result in an empty filter. Response Options Type field Confirmations sent through WebSockets, whether filtering is used or not, contains a confirmation_type field with values active_quorum , active_confirmation_height or inactive . Block content inclusion By setting include_block to false , the block content will not be present. Default is true . Because account filtering needs block content to function, setting this flag to false is currently incompatible with account filtering. This restriction may be lifted in future releases. { \"action\" : \"subscribe\" , \"topic\" : \"confirmation\" , \"options\" : { \"include_block\" : \"false\" , } } Election info Details about the election leading to the confirmation can be obtained by setting the include_election_info option to true: { \"action\" : \"subscribe\" , \"topic\" : \"confirmation\" , \"options\" : { \"include_election_info\" : \"true\" } } Including the election info option results in the following fields being included: election duration in milliseconds end of election time as milliseconds since epoch weight tally in raw unit the confirmation request_count ( version 20.0+ ) number of blocks and voters ( version 21.0+ ) Sample Results Differences from the HTTP callback The \"block\" contains JSON instead of an escaped string. This makes parsing easier. The JSON received by the client contains a topic, event time (milliseconds since epoch) and the message itself. Subtype is part of block (if it's a state block) There is no \"is_send\" property since \"subtype\" signifies the intent for state blocks. A confirmation type is added, which can be filtered. { \"topic\" : \"confirmation\" , \"time\" : \"1564935350664\" , \"message\" : { \"account\" : \"nano_1tgkjkq9r96zd3pkr7edj8e4qbu3wr3ps6ettzse8hmoa37nurua7faupjhc\" , \"amount\" : \"15621963968634827029081574961\" , \"hash\" : \"0E889F83E28152A70E87B92D846CA3D8966F3AEEC65E11B25F7B4E6760C57CA3\" , \"confirmation_type\" : \"active_quorum\" , \"election_info\" : { \"duration\" : \"546\" , \"time\" : \"1564935348219\" , \"tally\" : \"42535295865117307936387010521258262528\" , \"request_count\" : \"1\" , // si n ce V 20.0 \"blocks\" : \"1\" , // si n ce V 21.0 \"voters\" : \"52\" // si n ce V 21.0 }, \"block\" : { \"type\" : \"state\" , \"account\" : \"nano_1tgkjkq9r96zd3pkr7edj8e4qbu3wr3ps6ettzse8hmoa37nurua7faupjhc\" , \"previous\" : \"4E9003ABD469D1F58A70518234016797FA654B494A2627B8583052629A91689E\" , \"representative\" : \"nano_3rw4un6ys57hrb39sy1qx8qy5wukst1iiponztrz9qiz6qqa55kxzx4491or\" , \"balance\" : \"0\" , \"link\" : \"3098F4C0D1D8BD889AF078CDFF81E982B8EFA6D6D8FAE954CF0CDC7A256C3F8B\" , \"link_as_account\" : \"nano_1e6rym1f5p7xj4fh1y8fzy1ym1orxymffp9tx7cey58whakprhwdzuk533th\" , \"signature\" : \"D5C332587B1A4DEA35B6F03B0A9BEB45C5BBE582060B0252C313CF411F72478721F8E7DA83A779BA5006D571266F32BDE34C1447247F417F8F12101D3ADAF705\" , \"work\" : \"c950fc037d61e372\" , \"subtype\" : \"send\" } } } Votes \u00b6 Experimental, unfinished This subscription is experimental and not all votes are broadcasted. The message format might change in the future. Subscribing To subscribe to all votes notifications: { \"action\" : \"subscribe\" , \"topic\" : \"vote\" } Filtering options The following filtering options can be combined. Representatives Used to subscribe only to votes from selected representatives. Once filters are given, votes from representatives that do not match the options are not broadcasted. If the result is an empty filter (for example, all given accounts are invalid), then the filter is not used. A message is logged in the node logs when this happens. { \"action\" : \"subscribe\" , \"topic\" : \"vote\" , \"options\" : { \"representatives\" : [ \"nano_16c4ush661bbn2hxc6iqrunwoyqt95in4hmw6uw7tk37yfyi77s7dyxaw8ce\" , \"nano_3dmtrrws3pocycmbqwawk6xs7446qxa36fcncush4s1pejk16ksbmakis32c\" ] } } Vote type Votes are one of three types: replay , if this exact vote had been seen before vote , if it is the first time the vote has been seen indeterminate , when it cannot be determined due to a lack of an associated election By default only vote type votes are broadcasted, and the others are filtered. To disable these filters set include_replays to true and/or include_indeterminate to true . { \"action\" : \"subscribe\" , \"topic\" : \"vote\" , \"options\" : { \"include_replays\" : \"true\" , \"include_indeterminate\" : \"true\" } } Sample Results { \"topic\" : \"vote\" , \"time\" : \"1554995525343\" , \"message\" : { \"account\" : \"nano_1n5aisgwmq1oibg8c7aerrubboccp3mfcjgm8jaas1fwhxmcndaf4jrt75fy\" , \"signature\" : \"1950700796914893705657789944906107642480343124305202910152471520450456881722545967829502369630995363643731706156278026749554294222131169148120786048025353\" , \"sequence\" : \"855471574\" , \"blocks\" : [ \"6FB9DE5D7908DEB8A2EA391AEA95041587CBF3420EF8A606F1489FECEE75C869\" ], \"type\" : \"replay\" // si n ce V 21.0 , ca n be vo te /replay/i n de ter mi nate } } Stopped elections \u00b6 If an election is stopped for any reason, the corresponding block hash is sent on the \"stopped_election\" topic. Reasons for stopping elections include low priority elections being dropped due to processing queue capacity being reached, and forced processing via process RPC when there's a fork. Subscribing To subscribe to all stopped elections notifications: { \"action\" : \"subscribe\" , \"topic\" : \"stopped_election\" } Filtering options No filters are currently available for the stopped_election topic. Sample Results { \"topic\" : \"stopped_election\" , \"time\" : \"1560437195533\" , \"message\" : { \"hash\" : \"FA6D344ECAB2C5E1C04E62B2BC6EE072938DD47530AB26E0D5A9A384302FBEB3\" } } Active difficulty \u00b6 Subscribing To subscribe to all active difficulty notifications: { \"action\" : \"subscribe\" , \"topic\" : \"active_difficulty\" } Filtering options No filters are currently available for the active_difficulty topic. Sample Results { \"topic\" : \"active_difficulty\" , \"time\" : \"1561661736065\" , \"message\" : { \"multiplier\" : \"1.5\" , \"network_current\" : \"fffffffaaaaaaaab\" , \"network_minimum\" : \"fffffff800000000\" , \"network_receive_current\" : \"fffffff07c1f07c2\" , // si n ce V 21.2 \"network_receive_minimum\" : \"fffffe0000000000\" // si n ce V 21.2 } } Proof of work \u00b6 This subscription is available since v20.0 Subscribing To subscribe to PoW generation notifications: { \"action\" : \"subscribe\" , \"topic\" : \"work\" } Filtering options No filters are currently available for the work topic. Sample Results Successful work generation: { \"success\" : \"true\" , \"reason\" : \"\" , \"duration\" : \"306\" , \"request\" : { \"hash\" : \"3ECE2684044C0EAF2CA6B1C72F11AFC5B5A75C00CFF993FB17B6E75F78ABF175\" , \"difficulty\" : \"ffffff999999999a\" , \"multiplier\" : \"10.000000000009095\" , \"version\" : \"work_1\" // si n ce V 21.0 }, \"result\" : { \"source\" : \"192.168.1.101:7000\" , \"work\" : \"4352c6e222703c57\" , \"difficulty\" : \"ffffffd2ca03b921\" , \"multiplier\" : \"22.649415016750655\" }, \"bad_peers\" : \"\" } Work generation cancelled with one bad peer (unresponsive or provided invalid work): { \"success\" : \"false\" , \"reason\" : \"cancelled\" , \"duration\" : \"539\" , \"request\" : { \"hash\" : \"3ECE2684044C0EAF2CA6B1C72F11AFC5B5A75C00CFF993FB17B6E75F78ABF175\" , \"difficulty\" : \"ffffff999999999a\" , \"multiplier\" : \"10.000000000009095\" }, \"bad_peers\" : [ \"192.168.1.101:7000\" ] } Notes: The duration is in milliseconds If work generation fails, the notification is similar to the work cancelled notification, except \"reason\": \"failure\" When work generation is done locally it will show \"source\": \"local\" Node telemetry \u00b6 This subscription is available since v21.0 Subscribing To subscribe to telemetry response notifications from other nodes on the network : { \"action\" : \"subscribe\" , \"topic\" : \"telemetry\" } Filtering options No filters are currently available for the telemetry topic. Sample Results { \"topic\" : \"telemetry\" , \"time\" : \"1594654710305\" , \"message\" : { \"block_count\" : \"51571901\" , \"cemented_count\" : \"51571901\" , \"unchecked_count\" : \"0\" , \"account_count\" : \"1376750\" , \"bandwidth_cap\" : \"10485760\" , \"peer_count\" : \"261\" , \"protocol_version\" : \"18\" , \"uptime\" : \"1223618\" , \"genesis_block\" : \"991CF190094C00F0B68E2E5F75F6BEE95A2E0BD93CEAA4A6734DB9F19B728948\" , \"major_version\" : \"21\" , \"minor_version\" : \"0\" , \"patch_version\" : \"0\" , \"pre_release_version\" : \"0\" , \"maker\" : \"0\" , \"timestamp\" : \"1594654710521\" , \"active_difficulty\" : \"ffffffc000000000\" , \"node_id\" : \"node_3cczh431wuh5gg64jen6a658xewpx7eiyfqn7f8gpdcfp786s7xdb51kr1rp\" , \"signature\" : \"C9429FBC069F15E9AE552FB80500B4BA0F0CF2E25DD6C6D2018FA1D96DC4353A75E4A86872E54E7B2BFF06526719076E792DA3C83F1B2FD40244804EAC324C00\" , \"address\" : \"::ffff:139.180.168.194\" , \"port\" : \"7075\" } } See the telemetry RPC command which gives more information about the message response. New unconfirmed blocks \u00b6 This subscription is available since v21.0 These blocks are not confirmed Blocks received through this websocket should not be used for tracking confirmations, as they are unconfirmed and could be replaced by a conflicting block. Read the confirmation tracking guide for more details. Subscribing To subscribe to node telemetry response notifications: { \"action\" : \"subscribe\" , \"topic\" : \"new_unconfirmed_block\" } Filtering options No filters are currently available for the new_unconfirmed_block topic. Sample Results { \"topic\" : \"new_unconfirmed_block\" , \"time\" : \"1587109495082\" , \"message\" : { \"type\" : \"state\" , \"account\" : \"nano_1unw379kgu1iub1caswn5khfk4b6tzinku8ww7uds9z7nwubj3dgt6yzjpiw\" , \"previous\" : \"A01B96AFE86DC82FECD13F8C3A4F1AC779DCDAF60166F94F1A2CD3987F4609F0\" , \"representative\" : \"nano_1stofnrxuz3cai7ze75o174bpm7scwj9jn3nxsn8ntzg784jf1gzn1jjdkou\" , \"balance\" : \"2345399869764044123018481994\" , \"link\" : \"E0049F6D5D5661A714D8928D287285A0105B07720661F8C8B1FC8EE5B15FC067\" , \"link_as_account\" : \"nano_3r16mxpotom3nwcfj6nf73sada1ide5q63m3z56d5z6gwprozi59ocyuoxc1\" , \"signature\" : \"7BDD77BE14552263F9AF5130229A3BBB9038EE4B9C29E66D3D58280EF43B7FAF2DBC7070BD9CA39C844B7068E3AF40B04CE1D5CEEEA142C8FE20EE091A3C320E\" , \"work\" : \"8ebdd4aa0bf1263e\" , \"subtype\" : \"receive\" } } Bootstrap \u00b6 This subscription is available since v21.0 Subscribing To subscribe to bootstrap attempts start/exit notifications: { \"action\" : \"subscribe\" , \"topic\" : \"bootstrap\" } Filtering options No filters are currently available for the bootstrap topic. Sample Results { \"topic\" : \"bootstrap\" , \"time\" : \"1561661740065\" , \"message\" : { \"reason\" : \"started\" , \"id\" : \"C9FF2347C4DF512A7F6B514CC4A0F79A\" , \"mode\" : \"legacy\" } } { \"topic\" : \"bootstrap\" , \"time\" : \"1561661740565\" , \"message\" : { \"reason\" : \"exited\" , \"id\" : \"C9FF2347C4DF512A7F6B514CC4A0F79A\" , \"mode\" : \"legacy\" , \"total_blocks\" : \"1000000\" , \"duration\" : \"500\" } } Notes: The duration is in seconds","title":"WebSockets"},{"location":"integration-guides/websockets/#websockets","text":"Available in version 19.0+ only. When upgrading from version 18 or earlier, the node performs a confirmation height upgrade. During this process, the WebSocket notifications may include confirmations for old blocks. Services must handle duplicate notifications, as well as missed blocks as WebSockets do not provide guaranteed delivery. Reasons for missed blocks include intermittent network issues and internal containers (in the node or clients) reaching capacity. Multiple notifications for blocks Depending on the node setup and sync status, multiple confirmation notifications for the same block hash may be sent by a single tracking mechanism. In order to prevent potential issues, integrations must track these block hashes externally to the node and prevent any unwanted actions based on multiple notifications. The Nano node offers notification of confirmed blocks over WebSockets. This offers higher throughput over the HTTP callback, and uses a single ingoing connection instead of an outgoing connection for every block. The HTTP callback is still available and both mechanisms can be used at the same time.","title":"WebSockets"},{"location":"integration-guides/websockets/#example-clients","text":"Sample clients are available: Node.js: https://github.com/cryptocode/nano-websocket-sample-nodejs Python: https://github.com/guilhermelawless/nano-websocket-sample-py","title":"Example clients"},{"location":"integration-guides/websockets/#configuration","text":"These configuration options are set in the config-node.toml file . [node.websocket] # WebSocket server bind address. # type:string,ip address = \"::1\" # Enable or disable WebSocket server. # type:bool enable = true # WebSocket server listening port. # type:uint16 port = 7078 With the above configuration, localhost clients should connect to ws://[::1]:7078 . Configuration for use with Docker Set the WebSocket server bind address to ::ffff:0.0.0.0 instead, and configure the container to map port 7078 accordingly. Review Managing the Container to ensure the websocket is not exposed externally.","title":"Configuration"},{"location":"integration-guides/websockets/#acknowledgement","text":"All WebSocket actions can optionally request an acknowledgement. The following is an example for the subscribe action. { \"action\" : \"subscribe\" , \"topic\" : \"confirmation\" , \"ack\" : true , \"id\" : \"<optional unique id>\" } If the action succeeds, the following message will be sent back (note that no message ordering is guaranteed): { \"ack\" : \"subscribe\" , \"time\" : \"<milliseconds since epoch>\" , \"id\" : \"<optional unique id>\" }","title":"Acknowledgement"},{"location":"integration-guides/websockets/#update","text":"Some subscriptions can be updated without requiring unsubscribing and re-subscribing to the same topic. A typical message is the following: { \"action\" : \"update\" , \"topic\" : \"confirmation\" , \"options\" : { ... } } Updatable filter options are mentioned in the examples below.","title":"Update"},{"location":"integration-guides/websockets/#keepalive","text":"This action is available since v20.0 Keepalive allows checking the liveliness of the websocket without refreshing it or changing a subscription. Use the format: { \"action\" : \"ping\" } The expected response is: { \"ack\" : \"pong\" , \"time\" : \"<milliseconds since epoch>\" }","title":"Keepalive"},{"location":"integration-guides/websockets/#subscribeunsubscribe","text":"To receive notifications through the websocket you must subscribe to the specific topic and a standard subscription without filters looks like this: { \"action\" : \"subscribe\" , \"topic\" : \"confirmation\" } Unsubscribing also has the format: To unsubscribe: { \"action\" : \"unsubscribe\" , \"topic\" : \"confirmation\" } Optional Filters Some topics support filters as well. Details of the subscription filter options for each topic are included in examples below. Note Note that, if empty options are supplied (see examples below), an empty filter will be used and nothing will be broadcasted.","title":"Subscribe/Unsubscribe"},{"location":"integration-guides/websockets/#available-topics","text":"","title":"Available Topics"},{"location":"integration-guides/websockets/#confirmations","text":"Multiple notifications for blocks Depending on the node setup and sync status, multiple confirmation notifications for the same block hash may be sent by a single tracking mechanism. In order to prevent potential issues, integrations must track these block hashes externally to the node and prevent any unwanted actions based on multiple notifications.","title":"Confirmations"},{"location":"integration-guides/websockets/#votes","text":"Experimental, unfinished This subscription is experimental and not all votes are broadcasted. The message format might change in the future.","title":"Votes"},{"location":"integration-guides/websockets/#stopped-elections","text":"If an election is stopped for any reason, the corresponding block hash is sent on the \"stopped_election\" topic. Reasons for stopping elections include low priority elections being dropped due to processing queue capacity being reached, and forced processing via process RPC when there's a fork.","title":"Stopped elections"},{"location":"integration-guides/websockets/#active-difficulty","text":"","title":"Active difficulty"},{"location":"integration-guides/websockets/#proof-of-work","text":"This subscription is available since v20.0","title":"Proof of work"},{"location":"integration-guides/websockets/#node-telemetry","text":"This subscription is available since v21.0","title":"Node telemetry"},{"location":"integration-guides/websockets/#new-unconfirmed-blocks","text":"This subscription is available since v21.0 These blocks are not confirmed Blocks received through this websocket should not be used for tracking confirmations, as they are unconfirmed and could be replaced by a conflicting block. Read the confirmation tracking guide for more details.","title":"New unconfirmed blocks"},{"location":"integration-guides/websockets/#bootstrap","text":"This subscription is available since v21.0","title":"Bootstrap"},{"location":"integration-guides/work-generation/","text":"Some sections of this page target node version 21 or higher Every block published to the network, whether a send, receive or representative change block, requires a small, valid Proof-of-Work to be completed above a minimum difficulty floor (threshold). As of V21 this threshold is different for different block types: send and change blocks require a higher threshold, while receive blocks are lower. This work value is not used in consensus, but instead is one of the first pieces of data used to validate blocks on the network and is a key component of maintaining consistent quality of service on the network. System considerations \u00b6 The following configuration options should be taken into careful consideration when planning work generation resources for services integrating with Nano. These options should be combined to provide the best separation of resources between node participation on network vs. work generation needs. Representatives should avoid heavy RPC use and work generation Supporting the network by running a representative is recommended for many services, however it is not recommended that voting nodes are used for heavy RPC or work generation activities. Wherever possible, integrations should utilize separate machines for their integration nodes and consensus-producing, voting nodes. CPU vs. GPU \u00b6 As GPUs provide faster and more energy efficient work generation than CPUs, and reduce RPC delays during heavy usage periods, they are preferred for any setups able to utilize them. In cases where the node is running on the same machine where work generation is done, GPUs are highly recommended to avoid performance impacts to the node that relying CPU cores can cause. Choosing a machine \u00b6 Using a separate machine to manage work generation is recommended where possible. The machine running the node should have a minimum of dedicated resources to keep in sync with the network and any potential interruption due to work generation activities should be avoided. Note that this separation introduces latency, so efforts should be done to keep that to a minimum including running machines in the same region or cluster, avoiding routing work requests through external edge networks, etc. Software for work generation \u00b6 Although the node can be configured to generate work directly, there are plans to separate work generation from the node into its own application and process. To help prepare for this future architecturs the preferred setup today is to use the Nano Work Server for work generation. Number of work peers \u00b6 To provide a more robust and redundant work generation setup, multiple work peers can be used. Any node configured with multiple peers will make requests serially from the list of work peers until a successful response is received. Disable local CPU work generation Since using the same CPU resources the node relies on for work generation can cause performance issues, local CPU work generation should be turned off by setting node.work_threads = 0 when using work peers. Recommended configurations \u00b6 Below are common, recommended configurations for planning work generation needs. Based on the considerations outlined above, the following general rules apply when planning resources: GPU-based work generation is recommended wherever reasonable Running the Nano Work Server is preferred, regardless of machine or CPU/GPU decisions CPU-based work generation on the same machine the node is running is not recommended Heavy RPC, regular work generation \u00b6 Services with heavy RPC calls and work generation can benefit from ensuring dedicated resources exist for each process separately. To maximize performance a separate machine running the Nano Work Server with a GPU attached is recommended: Setup a machine separate from the node with GPU attached Install the Nano Work Server Setup a service to start and monitor the work server process using the GPU option --gpu <PLATFORM:DEVICE> and run nano-work-server --help for additional options and details Configure the machine running the node to allow traffic over TCP from the work generation machine's IP address Add the work machine IP address as a work peer in the node's config-node.toml file CPU for lower generation levels For services with heavier RPC usage but less work generation needs excluding the GPU in the above example and relying on the CPU resources of the separate machine is also an option. This can be done by setting node.work_threads to the appropriate thread count for your needs. Make sure to benchmark the machine performance to plan for any potential spikes, as CPU generation is slower. Light RPC, regular work generation \u00b6 Services where RPC usage is lighter but regular work generation is needed could move work generation to the same machine if a GPU is used: Install the Nano Work Server on the same machine as the node Setup a service to start and monitor the work server process with options for using the GPU - --gpu <PLATFORM:DEVICE:THREADS> is required, run nano-work-server --help for additional options and details Configure the node to prevent local CPU work generation by setting node.work_threads = 0 Node work generation option A less preferred alternative to setting up, running and monitoring the Nano Work Server is to use the node itself to generate work. This should only be done with an attached GPU by setting up and enabling OpenCL with opencl.enable = true and adusting opencl.device and opencl.platform to match your setup. Practical guides \u00b6 Work generated using the node, incl. work peers \u00b6 graph TD A{Block signing<br> location?} A -->|in the node| B[<a href='/commands/rpc-protocol/#block_create'><b>RPC block_create</b></a><br>no <i>&quotwork&quot</i>] A -->|not in the node| C_1(Create and sign <b>block</b>) B -->block((block)) C_1 -->|block| C_2[<a href='/commands/rpc-protocol/#work_generate'><b>RPC work_generate</b></a><br><i>&quotblock&quot: </i><b>block</b>] C_2 -->|work| C_3(Use <b>work</b> in <b>block</b>) C_3 -->block block -->D[<a href='/commands/rpc-protocol/#process'><b>RPC process</b></a><br><i>&quotwatch_work&quot: &quottrue&quot</i>] Work generated without using the node \u00b6 Lower thresholds for receive blocks Receive blocks benefit from a lower work threshold. In the following guide, replace uses of network_minimum and network_current with network_receive_minimum and network_receive_current , respectively, to benefit from the lower threshold. graph TD M{Access to a node?} -->|yes| N[active_difficulty <a href='/commands/rpc-protocol/#active_difficulty'><b>RPC</b></a> or <a href='/integration-guides/websockets/#active-difficulty'><b>WS</b></a>] M --> |no| O_1(<a href='/protocol-design/networking/#node-telemetry'><b>Telemetry</b></a>) N -->P_1(Generate work at<br><b>network_minimum</b> difficulty) O_1 -->O_2((active<br>difficulty)) P_1 -->|work| P_2(Use <b>work</b> in block) P_2 -->P_3((block)) P_3 -->P_4[<a href='/commands/rpc-protocol/#process'><b>RPC process</b></a><br><i>&quotwatch_work&quot: &quotfalse&quot</i>] P_4 -->P_5(<a href='/integration-guides/block-confirmation-tracking/'>Track block confirmation</a>) P_5 -->P_6{Block unconfirmed<br>after 5 seconds?} P_6 -->P_7[active_difficulty <a href='/commands/rpc-protocol/#active_difficulty'><b>RPC</b></a> or <a href='/integration-guides/websockets/#active-difficulty'><b>WS</b></a>] P_7 -->P_8{Block difficulty less<br>than <b>network_current</b> ?} P_8 -->|yes| P_9(Generate work at<br><b>network_current</b> difficulty) P_8 -->|no| P_6 P_9 -->|updated_work| P_10(Use <b>updated_work</b> in <b>block</b>) P_10 -->P_4 Node Configuration \u00b6 The following configuration options can be changed in node-config.toml . For more information on the location of this file, and general information on the configuration of the node, see the Configuration page. opencl.enable \u00b6 When GPU acceleration is enabled, the CPU is also used by default Make sure to set node.work_threads to 0 when using the GPU To enable GPU acceleration for work generation, set this option to true . Other fields may need to be changed if you have multiple OpenCL-enabled platforms and devices. node.work_threads \u00b6 Recommended value: node.work_threads = 0 Determines the number of local CPU threads to used for work generation. While enabled by default, it is recommended to turn off local CPU work generation. Set to 0 to turn off local CPU work generation. node.work_peers \u00b6 Used when offloading work generation to another node or service. Format must be ipv6, preceded by ::ffff: if ipv4. Hostnames are supported since v21. Calls are made to the address:port designated using the standard RPC format work_generate . Example: [node] work_peers = [ \"example.work-peer.org:7000\" , \"::ffff:192.168.1.25:7076\" ] node.max_work_generate_multiplier \u00b6 Sets a limit on the generation difficulty. Multiplier is based off the base difficulty threshold . If the node is setup as a work peer itself, requests for work higher than this limit are ignored. Default value is 64 . Benchmarks \u00b6 Benchmark commands \u00b6 Nano Work Server The Nano Work Server is the preferred approach for benchmarking and includes an example . Node RPC Setup and run a node with RPC enabled, control enabled, and the desired configuration including work peers. Use the script from blake2b-pow-bench . Node local work generation Note that these commands do not use the configuration of the node. Prefer using the alternative above for that purpose, such as changing the number of threads for CPU work generation, or using work peers. CPU with all available threads: nano_node --debug_profile_generate [--difficulty fffffff800000000] [--multiplier 1.0] GPU acceleration: nano_node --debug_opencl --platform=0 --device=0 [--difficulty fffffff800000000] [--multiplier 1.0] The command will trigger continual work generation, so let it run until a sufficient sample size of times are generated (at least 100 instances). Compute the average of these times which are the number of microseconds it took to generate each sample. Example benchmarks \u00b6 Below are work generation benchmarks from a variety of consumer-grade CPUs and GPUs. All values are presented in # work/second generated . See the difficulty thresholds section below for details about values required for different epoch versions and block types. Device Epoch v1 All Blocks Epoch v2 Send/Change Blocks Epoch v2 Receive Blocks Nvidia GTX 1080 26.24 3.32 203.42 Nvidia Tesla P100 (Google Cloud) 29.28 3.63 220.35 Nvidia RTX 2080 Ti 47.27 5.48 357.23 Nvidia Tesla V100 (Google Cloud) 57.48 7.25 420.33 AMD R9 290 14.57 1.92 94.47 AMD RX Vega 64 30.77 3.79 232.56 AMD Vega 8 @1750MHz 3.45 0.55 23.81 AMD R7-4800U @2.8GHz AVX2 0.64 0.06 3.70 AMD R5-3600 @4.07GHz 0.59 0.09 3.51 AMD R9-3900X @3.97GHz AVX2 1.97 0.26 15.64 Intel Core i7 6700 @3.7GHz AVX2 0.65 0.07 5.25 Work calculation details \u00b6 Work equation \u00b6 The \"work\" field in transactions contains a 64-bit nonce found using the blake2b hash function . The nonce satisfies the following equations depending on block height: Block Height 1 The first block on an account-chain doesn't have a previous (head) block, so the account public key is used ( || means concatenation): blake2b(\\text{nonce} || \\text{public_key}) \\ge \\text{threshold} blake2b(\\text{nonce} || \\text{public_key}) \\ge \\text{threshold} Block Height 2 and up Once an account has an existing block the previous block hash is used for all blocks going forward: blake2b(\\text{nonce} || \\text{prev_block_hash}) \\ge \\text{threshold} blake2b(\\text{nonce} || \\text{prev_block_hash}) \\ge \\text{threshold} Difficulty thresholds \u00b6 The mainnet's base difficulty threshold is currently fffffff800000000 for all send or change blocks and fffffe0000000000 for all receive blocks. These split difficulties were set as part of the network upgrade to increase difficulty completed at the end of August 2020. Previous difficulty levels are outlined below as well for historical reference, but currently the epoch v2 thresholds are required when publishing new blocks to the network: Epoch version Block Type Difficulty Threshold 1 All ffffffc000000000 2 Send or change fffffff800000000 2 Receive fffffe0000000000 For a block to be valid, its work field must satisfy the above work equations using this value for threshold. Nodes also prioritize the order in which they confirm transactions based on how far above this threshold the work value is. This only happens in case of saturation. Due to prioritization, it may be desirable to generate work further above the threshold to guarantee faster processing by the network. To assist integrations with managing these work difficulty levels, nodes monitor the trend of difficulty seen on unconfirmed blocks, and expose that value via the active_difficulty RPC. Development node wallet behavior The developer wallet included with the node is configured to pre-cache work at the base threshold and monitor any blocks it publishes to the network for confirmation. If they are not confirmed within 5 seconds, the difficulty on that block will be compared against the active difficulty seen on the network. If the block has a lower work value than the network, then new work generation is requested at the higher level. Difficulty management for external integrations For services aiming to ensure the highest priority on their transactions, the confirmation of published blocks should be monitored by their integration and work levels compared against active difficulty in a similar fashion to the development wallet mentioned above. If work is left at base difficulty there could be delays in the transactions being processed during heavy network usage times. Configure max work generate multiplier Due to the possibility of network work levels increasing beyond the capabilities of certain work generation setups, the config option node.max_work_generate_multiplier can be used to limit how high a work value will be requested at. All setups, whether using the developer wallet or an external integration, should implement an appropriate limit which defaults to 64x in V20. Pre-caching \u00b6 Work for an account can be pre-cached and saved for immediate use on an account as long as it was based on the current frontier block at the time of use. Although this customization must be made externally to the node, it can help level out potential spikes in work generation, especially useful with wallet implementations. To accomplish this, after a block is published for an account (whatever type of block), note the hash of that block and use it in a RPC work_generate call. Note that you may require setting \u201cuse_peers\u201d: \u201ctrue\u201d . Upon receiving a response, store its value in your database for later use for that account. Note that after a new block is published for the account, that value will no longer be a valid PoW. Pre-caching when next block type is unknown With V21+ the work difficulty thresholds were split by block type. For many integrations, such as wallet providers, the context of what type of block will be generated next for an account is unknown. The recommendation for these cases is to generate difficulty at the higher threshold of a send/change block to ensure delays are avoided and the best user experience is available when using wallets. Utilizing lower work when batching For services that process receiving their pending transactions in bulk the lower work threshold of receive blocks can be taken advantage of. In doing so, the difficulty is 64x lower than a send/change block, but the difficulty will be normalized for proper prioritization if published during heavy network load times. Difficulty multiplier \u00b6 Relative difficulty, or difficulty multiplier, describes how much more value a PoW has compared to another. In the node this is typically used to compare against the base threshold, often in relation to rework being performed or validated for proper priotizing of transactions. This value is available as part of the active_difficulty RPC, but can also be obtained with the following expression: \\frac{(2^{64} - \\text{base_difficulty})}{(2^{64} - \\text{work_difficulty})} \\frac{(2^{64} - \\text{base_difficulty})}{(2^{64} - \\text{work_difficulty})} In the inverse direction, in order to get the equivalent difficulty for a certain multiplier, the following expression can be used. 2^{64} - \\frac{2^{64} - \\text{base_difficulty}}{\\text{multiplier}} 2^{64} - \\frac{2^{64} - \\text{base_difficulty}}{\\text{multiplier}} Code Snippets Python def to_multiplier ( difficulty : int , base_difficulty ) -> float : return float (( 1 << 64 ) - base_difficulty ) / float (( 1 << 64 ) - difficulty ) def from_multiplier ( multiplier : float , base_difficulty : int = NANO_DIFFICULTY ) -> int : return int (( 1 << 64 ) - (( 1 << 64 ) - base_difficulty ) / multiplier ) Rust fn to_multiplier ( difficulty : u64 , base_difficulty : u64 ) -> f64 { ( base_difficulty . wrapping_neg () as f64 ) / ( difficulty . wrapping_neg () as f64 ) } fn from_multiplier ( multiplier : f64 , base_difficulty : u64 ) -> u64 { ((( base_difficulty . wrapping_neg () as f64 ) / multiplier ) as u64 ). wrapping_neg () } C++ double to_multiplier ( uint64_t const difficulty , uint64_t const base_difficulty ) { return static_cast < double > ( - base_difficulty ) / ( - difficulty ); } uint64_t from_multiplier ( double const multiplier , uint64_t const base_difficulty ) { return ( - static_cast < uint64_t > (( - base_difficulty ) / multiplier )); }","title":"Work Generation"},{"location":"integration-guides/work-generation/#system-considerations","text":"The following configuration options should be taken into careful consideration when planning work generation resources for services integrating with Nano. These options should be combined to provide the best separation of resources between node participation on network vs. work generation needs. Representatives should avoid heavy RPC use and work generation Supporting the network by running a representative is recommended for many services, however it is not recommended that voting nodes are used for heavy RPC or work generation activities. Wherever possible, integrations should utilize separate machines for their integration nodes and consensus-producing, voting nodes.","title":"System considerations"},{"location":"integration-guides/work-generation/#cpu-vs-gpu","text":"As GPUs provide faster and more energy efficient work generation than CPUs, and reduce RPC delays during heavy usage periods, they are preferred for any setups able to utilize them. In cases where the node is running on the same machine where work generation is done, GPUs are highly recommended to avoid performance impacts to the node that relying CPU cores can cause.","title":"CPU vs. GPU"},{"location":"integration-guides/work-generation/#choosing-a-machine","text":"Using a separate machine to manage work generation is recommended where possible. The machine running the node should have a minimum of dedicated resources to keep in sync with the network and any potential interruption due to work generation activities should be avoided. Note that this separation introduces latency, so efforts should be done to keep that to a minimum including running machines in the same region or cluster, avoiding routing work requests through external edge networks, etc.","title":"Choosing a machine"},{"location":"integration-guides/work-generation/#software-for-work-generation","text":"Although the node can be configured to generate work directly, there are plans to separate work generation from the node into its own application and process. To help prepare for this future architecturs the preferred setup today is to use the Nano Work Server for work generation.","title":"Software for work generation"},{"location":"integration-guides/work-generation/#number-of-work-peers","text":"To provide a more robust and redundant work generation setup, multiple work peers can be used. Any node configured with multiple peers will make requests serially from the list of work peers until a successful response is received. Disable local CPU work generation Since using the same CPU resources the node relies on for work generation can cause performance issues, local CPU work generation should be turned off by setting node.work_threads = 0 when using work peers.","title":"Number of work peers"},{"location":"integration-guides/work-generation/#recommended-configurations","text":"Below are common, recommended configurations for planning work generation needs. Based on the considerations outlined above, the following general rules apply when planning resources: GPU-based work generation is recommended wherever reasonable Running the Nano Work Server is preferred, regardless of machine or CPU/GPU decisions CPU-based work generation on the same machine the node is running is not recommended","title":"Recommended configurations"},{"location":"integration-guides/work-generation/#heavy-rpc-regular-work-generation","text":"Services with heavy RPC calls and work generation can benefit from ensuring dedicated resources exist for each process separately. To maximize performance a separate machine running the Nano Work Server with a GPU attached is recommended: Setup a machine separate from the node with GPU attached Install the Nano Work Server Setup a service to start and monitor the work server process using the GPU option --gpu <PLATFORM:DEVICE> and run nano-work-server --help for additional options and details Configure the machine running the node to allow traffic over TCP from the work generation machine's IP address Add the work machine IP address as a work peer in the node's config-node.toml file CPU for lower generation levels For services with heavier RPC usage but less work generation needs excluding the GPU in the above example and relying on the CPU resources of the separate machine is also an option. This can be done by setting node.work_threads to the appropriate thread count for your needs. Make sure to benchmark the machine performance to plan for any potential spikes, as CPU generation is slower.","title":"Heavy RPC, regular work generation"},{"location":"integration-guides/work-generation/#light-rpc-regular-work-generation","text":"Services where RPC usage is lighter but regular work generation is needed could move work generation to the same machine if a GPU is used: Install the Nano Work Server on the same machine as the node Setup a service to start and monitor the work server process with options for using the GPU - --gpu <PLATFORM:DEVICE:THREADS> is required, run nano-work-server --help for additional options and details Configure the node to prevent local CPU work generation by setting node.work_threads = 0 Node work generation option A less preferred alternative to setting up, running and monitoring the Nano Work Server is to use the node itself to generate work. This should only be done with an attached GPU by setting up and enabling OpenCL with opencl.enable = true and adusting opencl.device and opencl.platform to match your setup.","title":"Light RPC, regular work generation"},{"location":"integration-guides/work-generation/#practical-guides","text":"","title":"Practical guides"},{"location":"integration-guides/work-generation/#work-generated-using-the-node-incl-work-peers","text":"graph TD A{Block signing<br> location?} A -->|in the node| B[<a href='/commands/rpc-protocol/#block_create'><b>RPC block_create</b></a><br>no <i>&quotwork&quot</i>] A -->|not in the node| C_1(Create and sign <b>block</b>) B -->block((block)) C_1 -->|block| C_2[<a href='/commands/rpc-protocol/#work_generate'><b>RPC work_generate</b></a><br><i>&quotblock&quot: </i><b>block</b>] C_2 -->|work| C_3(Use <b>work</b> in <b>block</b>) C_3 -->block block -->D[<a href='/commands/rpc-protocol/#process'><b>RPC process</b></a><br><i>&quotwatch_work&quot: &quottrue&quot</i>]","title":"Work generated using the node, incl. work peers"},{"location":"integration-guides/work-generation/#work-generated-without-using-the-node","text":"Lower thresholds for receive blocks Receive blocks benefit from a lower work threshold. In the following guide, replace uses of network_minimum and network_current with network_receive_minimum and network_receive_current , respectively, to benefit from the lower threshold. graph TD M{Access to a node?} -->|yes| N[active_difficulty <a href='/commands/rpc-protocol/#active_difficulty'><b>RPC</b></a> or <a href='/integration-guides/websockets/#active-difficulty'><b>WS</b></a>] M --> |no| O_1(<a href='/protocol-design/networking/#node-telemetry'><b>Telemetry</b></a>) N -->P_1(Generate work at<br><b>network_minimum</b> difficulty) O_1 -->O_2((active<br>difficulty)) P_1 -->|work| P_2(Use <b>work</b> in block) P_2 -->P_3((block)) P_3 -->P_4[<a href='/commands/rpc-protocol/#process'><b>RPC process</b></a><br><i>&quotwatch_work&quot: &quotfalse&quot</i>] P_4 -->P_5(<a href='/integration-guides/block-confirmation-tracking/'>Track block confirmation</a>) P_5 -->P_6{Block unconfirmed<br>after 5 seconds?} P_6 -->P_7[active_difficulty <a href='/commands/rpc-protocol/#active_difficulty'><b>RPC</b></a> or <a href='/integration-guides/websockets/#active-difficulty'><b>WS</b></a>] P_7 -->P_8{Block difficulty less<br>than <b>network_current</b> ?} P_8 -->|yes| P_9(Generate work at<br><b>network_current</b> difficulty) P_8 -->|no| P_6 P_9 -->|updated_work| P_10(Use <b>updated_work</b> in <b>block</b>) P_10 -->P_4","title":"Work generated without using the node"},{"location":"integration-guides/work-generation/#node-configuration","text":"The following configuration options can be changed in node-config.toml . For more information on the location of this file, and general information on the configuration of the node, see the Configuration page.","title":"Node Configuration"},{"location":"integration-guides/work-generation/#openclenable","text":"When GPU acceleration is enabled, the CPU is also used by default Make sure to set node.work_threads to 0 when using the GPU To enable GPU acceleration for work generation, set this option to true . Other fields may need to be changed if you have multiple OpenCL-enabled platforms and devices.","title":"opencl.enable"},{"location":"integration-guides/work-generation/#nodework_threads","text":"Recommended value: node.work_threads = 0 Determines the number of local CPU threads to used for work generation. While enabled by default, it is recommended to turn off local CPU work generation. Set to 0 to turn off local CPU work generation.","title":"node.work_threads"},{"location":"integration-guides/work-generation/#nodework_peers","text":"Used when offloading work generation to another node or service. Format must be ipv6, preceded by ::ffff: if ipv4. Hostnames are supported since v21. Calls are made to the address:port designated using the standard RPC format work_generate . Example: [node] work_peers = [ \"example.work-peer.org:7000\" , \"::ffff:192.168.1.25:7076\" ]","title":"node.work_peers"},{"location":"integration-guides/work-generation/#nodemax_work_generate_multiplier","text":"Sets a limit on the generation difficulty. Multiplier is based off the base difficulty threshold . If the node is setup as a work peer itself, requests for work higher than this limit are ignored. Default value is 64 .","title":"node.max_work_generate_multiplier"},{"location":"integration-guides/work-generation/#benchmarks","text":"","title":"Benchmarks"},{"location":"integration-guides/work-generation/#benchmark-commands","text":"Nano Work Server The Nano Work Server is the preferred approach for benchmarking and includes an example . Node RPC Setup and run a node with RPC enabled, control enabled, and the desired configuration including work peers. Use the script from blake2b-pow-bench . Node local work generation Note that these commands do not use the configuration of the node. Prefer using the alternative above for that purpose, such as changing the number of threads for CPU work generation, or using work peers. CPU with all available threads: nano_node --debug_profile_generate [--difficulty fffffff800000000] [--multiplier 1.0] GPU acceleration: nano_node --debug_opencl --platform=0 --device=0 [--difficulty fffffff800000000] [--multiplier 1.0] The command will trigger continual work generation, so let it run until a sufficient sample size of times are generated (at least 100 instances). Compute the average of these times which are the number of microseconds it took to generate each sample.","title":"Benchmark commands"},{"location":"integration-guides/work-generation/#example-benchmarks","text":"Below are work generation benchmarks from a variety of consumer-grade CPUs and GPUs. All values are presented in # work/second generated . See the difficulty thresholds section below for details about values required for different epoch versions and block types. Device Epoch v1 All Blocks Epoch v2 Send/Change Blocks Epoch v2 Receive Blocks Nvidia GTX 1080 26.24 3.32 203.42 Nvidia Tesla P100 (Google Cloud) 29.28 3.63 220.35 Nvidia RTX 2080 Ti 47.27 5.48 357.23 Nvidia Tesla V100 (Google Cloud) 57.48 7.25 420.33 AMD R9 290 14.57 1.92 94.47 AMD RX Vega 64 30.77 3.79 232.56 AMD Vega 8 @1750MHz 3.45 0.55 23.81 AMD R7-4800U @2.8GHz AVX2 0.64 0.06 3.70 AMD R5-3600 @4.07GHz 0.59 0.09 3.51 AMD R9-3900X @3.97GHz AVX2 1.97 0.26 15.64 Intel Core i7 6700 @3.7GHz AVX2 0.65 0.07 5.25","title":"Example benchmarks"},{"location":"integration-guides/work-generation/#work-calculation-details","text":"","title":"Work calculation details"},{"location":"integration-guides/work-generation/#work-equation","text":"The \"work\" field in transactions contains a 64-bit nonce found using the blake2b hash function . The nonce satisfies the following equations depending on block height: Block Height 1 The first block on an account-chain doesn't have a previous (head) block, so the account public key is used ( || means concatenation): blake2b(\\text{nonce} || \\text{public_key}) \\ge \\text{threshold} blake2b(\\text{nonce} || \\text{public_key}) \\ge \\text{threshold} Block Height 2 and up Once an account has an existing block the previous block hash is used for all blocks going forward: blake2b(\\text{nonce} || \\text{prev_block_hash}) \\ge \\text{threshold} blake2b(\\text{nonce} || \\text{prev_block_hash}) \\ge \\text{threshold}","title":"Work equation"},{"location":"integration-guides/work-generation/#difficulty-thresholds","text":"The mainnet's base difficulty threshold is currently fffffff800000000 for all send or change blocks and fffffe0000000000 for all receive blocks. These split difficulties were set as part of the network upgrade to increase difficulty completed at the end of August 2020. Previous difficulty levels are outlined below as well for historical reference, but currently the epoch v2 thresholds are required when publishing new blocks to the network: Epoch version Block Type Difficulty Threshold 1 All ffffffc000000000 2 Send or change fffffff800000000 2 Receive fffffe0000000000 For a block to be valid, its work field must satisfy the above work equations using this value for threshold. Nodes also prioritize the order in which they confirm transactions based on how far above this threshold the work value is. This only happens in case of saturation. Due to prioritization, it may be desirable to generate work further above the threshold to guarantee faster processing by the network. To assist integrations with managing these work difficulty levels, nodes monitor the trend of difficulty seen on unconfirmed blocks, and expose that value via the active_difficulty RPC. Development node wallet behavior The developer wallet included with the node is configured to pre-cache work at the base threshold and monitor any blocks it publishes to the network for confirmation. If they are not confirmed within 5 seconds, the difficulty on that block will be compared against the active difficulty seen on the network. If the block has a lower work value than the network, then new work generation is requested at the higher level. Difficulty management for external integrations For services aiming to ensure the highest priority on their transactions, the confirmation of published blocks should be monitored by their integration and work levels compared against active difficulty in a similar fashion to the development wallet mentioned above. If work is left at base difficulty there could be delays in the transactions being processed during heavy network usage times. Configure max work generate multiplier Due to the possibility of network work levels increasing beyond the capabilities of certain work generation setups, the config option node.max_work_generate_multiplier can be used to limit how high a work value will be requested at. All setups, whether using the developer wallet or an external integration, should implement an appropriate limit which defaults to 64x in V20.","title":"Difficulty thresholds"},{"location":"integration-guides/work-generation/#pre-caching","text":"Work for an account can be pre-cached and saved for immediate use on an account as long as it was based on the current frontier block at the time of use. Although this customization must be made externally to the node, it can help level out potential spikes in work generation, especially useful with wallet implementations. To accomplish this, after a block is published for an account (whatever type of block), note the hash of that block and use it in a RPC work_generate call. Note that you may require setting \u201cuse_peers\u201d: \u201ctrue\u201d . Upon receiving a response, store its value in your database for later use for that account. Note that after a new block is published for the account, that value will no longer be a valid PoW. Pre-caching when next block type is unknown With V21+ the work difficulty thresholds were split by block type. For many integrations, such as wallet providers, the context of what type of block will be generated next for an account is unknown. The recommendation for these cases is to generate difficulty at the higher threshold of a send/change block to ensure delays are avoided and the best user experience is available when using wallets. Utilizing lower work when batching For services that process receiving their pending transactions in bulk the lower work threshold of receive blocks can be taken advantage of. In doing so, the difficulty is 64x lower than a send/change block, but the difficulty will be normalized for proper prioritization if published during heavy network load times.","title":"Pre-caching"},{"location":"integration-guides/work-generation/#difficulty-multiplier","text":"Relative difficulty, or difficulty multiplier, describes how much more value a PoW has compared to another. In the node this is typically used to compare against the base threshold, often in relation to rework being performed or validated for proper priotizing of transactions. This value is available as part of the active_difficulty RPC, but can also be obtained with the following expression: \\frac{(2^{64} - \\text{base_difficulty})}{(2^{64} - \\text{work_difficulty})} \\frac{(2^{64} - \\text{base_difficulty})}{(2^{64} - \\text{work_difficulty})} In the inverse direction, in order to get the equivalent difficulty for a certain multiplier, the following expression can be used. 2^{64} - \\frac{2^{64} - \\text{base_difficulty}}{\\text{multiplier}} 2^{64} - \\frac{2^{64} - \\text{base_difficulty}}{\\text{multiplier}} Code Snippets Python def to_multiplier ( difficulty : int , base_difficulty ) -> float : return float (( 1 << 64 ) - base_difficulty ) / float (( 1 << 64 ) - difficulty ) def from_multiplier ( multiplier : float , base_difficulty : int = NANO_DIFFICULTY ) -> int : return int (( 1 << 64 ) - (( 1 << 64 ) - base_difficulty ) / multiplier ) Rust fn to_multiplier ( difficulty : u64 , base_difficulty : u64 ) -> f64 { ( base_difficulty . wrapping_neg () as f64 ) / ( difficulty . wrapping_neg () as f64 ) } fn from_multiplier ( multiplier : f64 , base_difficulty : u64 ) -> u64 { ((( base_difficulty . wrapping_neg () as f64 ) / multiplier ) as u64 ). wrapping_neg () } C++ double to_multiplier ( uint64_t const difficulty , uint64_t const base_difficulty ) { return static_cast < double > ( - base_difficulty ) / ( - difficulty ); } uint64_t from_multiplier ( double const multiplier , uint64_t const base_difficulty ) { return ( - static_cast < uint64_t > (( - base_difficulty ) / multiplier )); }","title":"Difficulty multiplier"},{"location":"node-implementation/blocks/","text":"Node Implementation - Blocks \u00b6 Part of work in progress Living Whitepaper This page is part of the Living Whitepaper revisions currently underway to replace the original static whitepaper. These efforts include the Protocol Design and Node Implementation sections of the docs, which will cover and expand on details and topics covered in the original whitepaper . See the bottom of the page for related whitepaper sections and other related details. Some of the sections and headers on this page may be in draft form or just suggestions/framework for later consideration. If you are interested in helping with revisions please connect with us on the #documentation channel on our Discord server . Block publishing and propagation \u00b6 Nodes use a modified gossip protocol for message distribution that enables quick distribution of blocks and votes across the network while distributing the load required to propagate messages across multiple nodes rather than each node having to respond to requests from every other node. Prioritization of messages are focused on the Principal Representative nodes that make up the core consensus mechanism where they receive blocks and votes directly from other nodes and then messages are spread to the rest of the network via gossiping. Blocks are initially broadcast and propagated across the network to different types of nodes based on the blocks status. Some basic rules are listed below: Nodes initially publish new blocks on the live network to all Principal Representatives they can connect to and a subset of Non Principal Representative nodes. When a node processes a new block that is not a known fork, or is a known fork and the block becomes the new winner on an election, nodes will republish that block to sqrt(peers) . On average, this gossiping results in blocks arriving multiple times at each node. To help reduce node resource usage, there are duplicate block filters in place to prevent reprocessing of the same blocks.","title":"Blocks"},{"location":"node-implementation/blocks/#node-implementation-blocks","text":"Part of work in progress Living Whitepaper This page is part of the Living Whitepaper revisions currently underway to replace the original static whitepaper. These efforts include the Protocol Design and Node Implementation sections of the docs, which will cover and expand on details and topics covered in the original whitepaper . See the bottom of the page for related whitepaper sections and other related details. Some of the sections and headers on this page may be in draft form or just suggestions/framework for later consideration. If you are interested in helping with revisions please connect with us on the #documentation channel on our Discord server .","title":"Node Implementation - Blocks"},{"location":"node-implementation/blocks/#block-publishing-and-propagation","text":"Nodes use a modified gossip protocol for message distribution that enables quick distribution of blocks and votes across the network while distributing the load required to propagate messages across multiple nodes rather than each node having to respond to requests from every other node. Prioritization of messages are focused on the Principal Representative nodes that make up the core consensus mechanism where they receive blocks and votes directly from other nodes and then messages are spread to the rest of the network via gossiping. Blocks are initially broadcast and propagated across the network to different types of nodes based on the blocks status. Some basic rules are listed below: Nodes initially publish new blocks on the live network to all Principal Representatives they can connect to and a subset of Non Principal Representative nodes. When a node processes a new block that is not a known fork, or is a known fork and the block becomes the new winner on an election, nodes will republish that block to sqrt(peers) . On average, this gossiping results in blocks arriving multiple times at each node. To help reduce node resource usage, there are duplicate block filters in place to prevent reprocessing of the same blocks.","title":"Block publishing and propagation"},{"location":"node-implementation/components/","text":"Node Implementation - Components \u00b6 Part of work in progress Living Whitepaper This page is part of the Living Whitepaper revisions currently underway to replace the original static whitepaper. These efforts include the Protocol Design and Node Implementation sections of the docs, which will cover and expand on details and topics covered in the original whitepaper . See the bottom of the page for related whitepaper sections and other related details. Some of the sections and headers on this page may be in draft form or just suggestions/framework for later consideration. If you are interested in helping with revisions please connect with us on the #documentation channel on our Discord server . Overview (diagram) \u00b6 Node \u00b6 Ledger \u00b6 Node wallet (dev only) \u00b6 Work generation \u00b6 Communications \u00b6 RPC server \u00b6 IPC \u00b6 CLI \u00b6 WebSockets \u00b6 Existing whitepaper sections related to this page: Implementation","title":"Components"},{"location":"node-implementation/components/#node-implementation-components","text":"Part of work in progress Living Whitepaper This page is part of the Living Whitepaper revisions currently underway to replace the original static whitepaper. These efforts include the Protocol Design and Node Implementation sections of the docs, which will cover and expand on details and topics covered in the original whitepaper . See the bottom of the page for related whitepaper sections and other related details. Some of the sections and headers on this page may be in draft form or just suggestions/framework for later consideration. If you are interested in helping with revisions please connect with us on the #documentation channel on our Discord server .","title":"Node Implementation - Components"},{"location":"node-implementation/components/#overview-diagram","text":"","title":"Overview (diagram)"},{"location":"node-implementation/components/#node","text":"","title":"Node"},{"location":"node-implementation/components/#ledger","text":"","title":"Ledger"},{"location":"node-implementation/components/#node-wallet-dev-only","text":"","title":"Node wallet (dev only)"},{"location":"node-implementation/components/#work-generation","text":"","title":"Work generation"},{"location":"node-implementation/components/#communications","text":"","title":"Communications"},{"location":"node-implementation/components/#rpc-server","text":"","title":"RPC server"},{"location":"node-implementation/components/#ipc","text":"","title":"IPC"},{"location":"node-implementation/components/#cli","text":"","title":"CLI"},{"location":"node-implementation/components/#websockets","text":"Existing whitepaper sections related to this page: Implementation","title":"WebSockets"},{"location":"node-implementation/contributing/","text":"Contributing code to the Nano node \u00b6 About the code base \u00b6 Nano is written in C++17 and supports Linux, macOS and Windows. Libraries We use Boost to help us write efficient cross platform code, including the async IO library for networking (asio). Make sure you have the correct Boost version installed. Submodules Name Details cryptopp Provides the implementation for random number generator, SipHash, AES and other cryptographic schemes. phc\u2011winner\u2011argon2 When encrypting with AES, the password first goes through key derivation, and argon2 is our hash of choice for doing that. lmdb The database library used for the ledger and wallet, with local patches for Windows. This is a very fast and portable key/value store with ordered keys. It is extremely resilient to crashes in the program, OS, and power-downs without corruption. rocksdb This database library can be used for the ledger. Provides better file IO and reduced ledger size. miniupnp This library is used to do port mapping if the gateway supports it. cpptoml This library is used for rpc, wallet and node configuration files flatbuffers A (de)serialization library for sending binary messages over IPC instead of plain-text JSON gtest A unit testing library, only used in development environments Qt Wallet To build the GUI, set the NANO_GUI flag in cmake. The desktop wallet uses Qt5, but without the MOC compiler. Hence, you cannot use the signals and slots mechanism. The majority of the Qt wallet code resides in the qt subproject, while the QApplication startup code resides in nano_wallet . Using CMake CMake is used to generate build files and project files for various IDE's. Please familiarize yourself with basic cmake usage, such as how to change cache variables via the command line, ccmake or CMake GUI. This is much more convenient that editing the CMakeLists.txt file directly. Find out more about building in Integration Guides Build Options . Testing \u00b6 Add tests If you add new functionality, adding unit tests to avoid regressions in the future is required. The easiest way to get started writing your first test is to base it off one of the existing tests. You'll find these in the core_test & rpc_test directories. There is also slow_test & load_test directories but these are not commonly modified. Make sure the NANO_TEST cache variable in cmake is set. Run tests before creating a pull request Please run the tests before submitting a PR. Go to the build directory and run the core_test binary. GitHub collaboration \u00b6 Communication is the key to working together efficiently. A good way to get in touch with the developers is to join the #development channel on Discord . If you have an idea of an improvement or new feature, consider discussing it first with the team, either on Discord, or by adding an issue. Maybe someone is already working on it, or have suggestions on how to improve on the idea. Security Vulnerability Disclosure Do NOT discuss potential security vulnerabilities on the issue tracker, public forums or open discussion channels If you discover a bug you believe to pose a security risk to the Nano network, please contact bugs@nano.org with a proof of concept with full details of the bug including: Repository of the bug High-level summary Detailed description Steps to reproduce Supporting material/references The potential security impact of the bug Code Process \u00b6 Fork and do all your work on a branch \u00b6 Nano prefers the standard GitHub workflow. You create a fork of the Nano repository, make branches for features/issues, and commit and push these. Create pull requests \u00b6 Before: Branch out of the develop branch. The master branch is only updated on new releases. Review your code locally. Have you followed the guidelines in this document? Run tests. Did you consider adding a test case for your feature? Run ASAN and TSAN to detect memory or threading bugs Commit and push your fork Create pull request on the upstream repository: Make sure you add a description that clearly describes the purpose of the PR. If the PR solves one or more issues, please reference these in the description. After: Check that CI completes successfully. If not, fix the problem and push an update. Respond to comments and reviews in a timely fashion. Resolve conflicts \u00b6 If time passes between your pull request (PR) submission and the team accepting it, merge conflicts may occur due to activity on develop, such as merging other PR's before yours. In order for your PR to be accepted, you must resolve these conflicts. The preferred process is to rebase your changes, resolve any conflicts, and push your changes again. 2 3 Check out your branch git fetch upstream git rebase upstream/develop Resolve conflicts in your favorite editor git add {filename} git rebase --continue Commit and push your branch Consider squashing or amending commits In the review process, you're likely to get feedback. You'll commit and push more changes, get more feedback, etc. This can lead to a messy git history, and can make stuff like bisecting harder. Once your PR is OK'ed, please squash the commits into a one. 4 Note that you can also update the last commit with git commit --amend . Say your last commit had a typo. Instead of committing and having to squash it later, simply commit with amend and push the branch. Code standard \u00b6 Formatting \u00b6 clang-format is used to enforce most of the formatting rules, such as: Tabs for indentation. Open braces go on new lines. Space before open parenthesis. Space after comma. Please run ci/clang-format-all.sh on *nix systems before pushing your code to ensure that the formatting is good. If you want to do formatting from the IDE, chances are there's a plugin available. Visual studio for instance provides a way to automatically format on saving. The definition file .clang-format is located in the project root directory. Make sure you set up your editor to use tabs. Use tabs for indentation, and spaces for alignment 5 . That way, you can use any tab size you want in your favorite editor, but the code will still look good for people with different settings. Coding guidelines \u00b6 Use auto type inference for local variables if it's clear from the context what the type will be. Use your best judgement, sometimes adding explicit types can increase readability 1 Handle exceptions, including IO exceptions for file and network operations. Be liberal with debug_assert . Use asserts to check invariants, not potential runtime errors, which should be handled gracefully. debug_assert has an advantage over normal assert as it will always print out the stacktrace of the current thread when it hits. Debug asserts are for detecting bugs, not error handling. There is also release_assert which is similar to debug_assert but also hits in a release build. When there is unexpected behaviour and no suitable way to recover it can be used to halt program execution. Be liberal with logger.always_log or logger.try_log statements, except in performance critical paths. Add comments to explain complex and subtle situations, but avoid comments that reiterates what the code already says. Use RAII and C++11 smart pointers to manage memory and other resources. Performance and scalabiliy considerations \u00b6 When making changes, think about performance and scalability. Pick good data structures and think about algorithmic complexity. For small data sets, std::vector should be your to-go container, as a linear scan through contiguous memory is often faster than any alternative due to memory being read in cache lines. Nested loops yield quadratic behavior - is there an alternative? A typical example is removing an inner lookup loop with an unordered set/map to improve lookup performance to O(1). Make sure your change doesn't conflict with the scalability characteristics described in the white paper. Security \u00b6 Your code will be reviewed with security in mind, but please do your part before creating a pull request: Familiarize yourself with best practices for writing secure C++ code. In particular: Consult https://wiki.sei.cmu.edu/confluence/display/cplusplus Avoid using ANSI C functions. Many of these are prone to buffer overruns. Avoid using C strings and direct buffer manipulation. Use static and dynamic analysis tools, such as valgrind, XCode instrumentation, linters and sanitizers. These tools are also great for debugging crashes and performance problems. General tips for contributors \u00b6 Read the white paper Peruse the code and don't be shy about asking questions if there are parts you don't understand. Make sure you understand the GitHub workflow. Participate in the community by reading and replying to GitHub issues, Reddit posts and tweets. This gives you a great insight into the pain points that exists with the software. [WIP] Developer starter pack \u00b6 Items include: Windows/MacOS/Linux C++17 compiler Boost Git CMake This guide is designed to give an overall structure of the core Nano Protocol codebase to help new developers get a better understanding of the different areas and how they interoperate. Due to the rapid changing nature of the protocol it\u2019s possible some of the features are moved to different places or have changed entirely. Working on the protocol requires a very multi-disciplined and wide area of knowledge, none of it is particularly mandatory to get started but a good C++ understanding will help prevent being too overwhelmed initially: Modern C++ knowledge (up to C++17) including multithreading primitives (mutex, condition variables, atomics) & templates, Boost (asio & beast), RocksDB, LMDB, FlatBuffers, JSON-RPC, IPC, networking communication (ip/tcp, message passing, broadcasting algorithms), QT, signal handling, PKI cryptography, git & cross-platform development. The main Nano projects are located inside the /nano subdirectory. Executable binaries (all have nano_ prefix) \u00b6 All executable projects have a main function inside entry.cpp nano_node \u2013 The standard way to start a node. There are 2 source files in here, entry.cpp and daemon.cpp . nano_daemon::daemon::run() is always called so is a good place to put a breakpoint if there are any issues during node operation (especially errors when launching initially). nano_rpc \u2013 This executable does not need to be run explicitly unless out of process RPC is selected. https://docs.nano.org/integration-guides/advanced/?h=+nano_rpc#running-nano-as-a-service Because this project is quite small it is all done inside the entry.cpp file and is probably an easier starting point template should anything else need to be moved out of process in the future. nano_wallet \u2013 This essentially does the same as nano_node but doesn\u2019t support all CLI commands and has a graphical user interface for the wallet. Tests The googletest (gtest) framework is used to validate a variety of functionality in the node, we do not currently use gmock in the codebase. Executables core_test \u2013 This is where the majority of tests should go. If there is any new functionality added or something has changed, it more often than not should have a test here! Any new core areas should have their own separate test file to encapsulate the logic. ipc_flatbuffers_test \u2013 This actually doesn\u2019t use the gtest library and has its own main file which just contains a simple example of using flatbuffers. load_test \u2013 This creates a dynamic number of nodes, sends blocks from 1 of the nodes (primary) and waits until all other nodes have the same number of blocks. This does not normally need to be modified but is run as part CI at the end. rpc_test \u2013 All RPC tests go here. There is some boilerplate to follow which creates an ipc_server for the node which mimics out of process rpc commands communicating with it. Care must be taken when creating write transactions as they are not allowed on io-threads ( https://github.com/nanocurrency/nano-node/pull/1264 ). To make sure this is adhered to when calling the RPC commands, there is an RAII object scoped_io_thread_name_change which changes the current thread (normally the main one) to be io , and restores it when the object goes out of scope. For instance ... scoped_thread_name_io.reset (); node.process (state_block); scoped_thread_name_io.renew (); slow_test \u2013 Any core tests which are not suitable for CI because they take a long time (> a few seconds) should go here. There is a desire to make this file run once per night, but until then should be periodically run by developers. Helper test_common \u2013 This is a helper library which contains test specific (not node related) things which can be used by all test projects. This project should not have a node dependency. Anything which does should be put into nano/node/testing.cpp . Fuzzer The fuzzer uses libfuzzer which inputs arbitrary data continuously trying to find catch edge cases missed in traditional testing on specific examples. This is not currently supported on Windows. The executables are found in fuzzer_test/*. The node must be built with the CMake option -DNANO_FUZZER_TEST=ON , this does not require that NANO_TEST be set. Currently there are 3 executables built: fuzz_bignum, fuzz_buffer, fuzz_endpoint_parsing. Notes: There aren\u2019t currently tests for specific CLIs so it\u2019s recommended to abstract the functionality so that it can be tested in core_test . Bootstrapping There are 2 bootstrapping methods, legacy and lazy. See https://medium.com/nanocurrency/nano-explainer-lazy-bootstrapping-6f091e1eae8c for more information. node/bootstrap/boostrap_attempt.hpp contains the base class definition for bootstrap attempts. Legacy node/bootstrap/boostrap_legacy.cpp Legacy bootstrapping works by requesting frontiers periodically (every 5 minutes) from a random selection of peers, this is done in nano::node::ongoing_bootstrap () . bootstrap_frontier.cpp contains the frontier req client and server. A frontier_req message is send from frontier_req_client to get a list of frontiers from a peer\u2019s frontier_req_server starting at frontier_req.start which is done as accounts_begin (transaction, current + 1); . The accounts are sorted by their hash. Lazy node/bootstrap/boostrap_lazy.hpp TODO Wallet lazy TODO How messages are handled (bootstrap_server.cpp) When a message is received through the bootstrap server, its header is first checked inside nano::bootstrap_server::receive_header_action () . The message is deserialized and added in add_request () to the std::queue<std::unique_ptr<nano::message>> requests collection which holds a queue of messages. run_next () is then called (and will be called after the request is finished if there are more messages to process), this runs the message through a request_response_visitor object which creates a tcp_message_item and adds it to the tcp_message_manager to be processed. The newest set of messages added were for telemetry. If new messages need adding that can be used as a guide: https://github.com/nanocurrency/nano-node/pull/2446 Websocket Websockets were introduced in https://github.com/nanocurrency/nano-node/pull/1840 . Previously a HTTP callback had to be used, but websockets provides a more efficient 2 way communication protocol. Websocket events are available for various topics. For an example of adding a websocket topic look at: https://github.com/nanocurrency/nano-node/pull/2634 . observers.notify (message_a.data, endpoint); is what ultimately invokes the websocket server to send a message which is deserialized inside nano::websocket::message_builder . Worker There is a single worker thread, the class definition is defined inside nano/lib/worker.cpp, which allows tasks to be added to a queue for execution. This was added in https://github.com/nanocurrency/nano-node/pull/1264 and its primary purpose was to schedule write transactions off the io threads. It is generally recommended to push tasks onto the io threads though to avoid bottlenecking this single thread. Alarm The alarm object is used to schedule a callback to be called at a specific time in the future. It is always executed asynchronously on the io thread. For this reason if the callback creates a write transaction it is pushed onto the worker thread. Database There are 2 logical areas where a persistent file is needed: the ledger and wallets. For this 2 NoSQL databases which store binary data are used, namely LMDB & RocksDB. The ledger database is comprised of a few files: nano/secure/blockstore.hpp (interface) nano/secure/blockstore_partial.hpp (partial implementation of the interface, it allows CRTP for derived classes) nano/node/lmdb/* (anything specific to LMDB goes here) nano/node/rocksdb/* (anything specific to RocksDB goes here) The wallets database uses the wallets_store which only has an LMDB backend. Database upgrades nano::mdb_store::do_upgrades () is where LMDB database upgrades are done. For instance void nano::mdb_store::upgrade_v18_to_v19 () combines all block databases into a single one. Raw mdb functions are normally required as blockstore::block_get () and other functions normally can\u2019t be used because they are updated to the latest db spec. There are currently no rocksdb upgrades but this will follow a similar approach when required. A corresponding test should be added, https://github.com/nanocurrency/nano-node/pull/2429/files is a simple example of adding an upgrade. There are sometimes multiple upgrades during a release if a beta build goes out and a subsequent upgrade is desired. Previously a ledger reset was done and the version was re-used but this was deemed too inconvenient. Block processing There are 4 types of legacy blocks: open, receive, send & change. There are the state blocks which encompass traits from the legacy subtypes as well as support epochs. In various places an epoch_link is checked, this indicates that the link field is set to one of the epoch accounts (for v1 state blocks), or possibly self for v2 state blocks upgrade blocks. No new legacy blocks can be created (there are about 10million), but they still need to be handled in any algorithm which deals with blocks because users can still be bootstrap from scratch. When a node is first launched without a ledger block_store_partial::init () is called, this creates the genesis block. Blocks are then bootstrapped. Ledger nano/secure/ledger.cpp is where blocks are added and deleted to the ledger database. The ledger cache is used when it may be expensive to try and determine the count of something in the ledger. It was originally used for the cemented count, because this is determined by adding the confirmation height from all accounts. This does mean that any external write operations from LMDB (such as CLI command --confirmation_height_clear ) will cause this number to get out of sync. This is not possible with RocksDB backend because it does not allow multi-process write transactions. Node initialization The biggest bottleneck for node start-up is caused by setting up the ledger cache. This requires scanning all accounts & conf height databases. A multi-threaded process (added in https://github.com/nanocurrency/nano-node/pull/2876 ) splits the account space into equal partitions (as accounts should be randomly distributed) and does sequential sorted reads in each partition; this is the most efficient way to search through any of the databases. Point/Random reads are very slow in comparison. CMake developer build options -DNANO_TIMED_LOCKS=10 \u2013 https://github.com/nanocurrency/nano-node/pull/2267 In nano/lib/locks.hpp(.cpp) std::mutex , std::condition_variable , std::unique_lock & std::lock_guard are wrapped in custom classes (with the same interface) which adds some extra timing functionality to check if a mutex was help for a time longer than NANO_TIMED_LOCKS in milliseconds. This is useful to see if mutex contention is a cause of any performance loss. To pinpoint a specific mutex https://github.com/nanocurrency/nano-node/pull/2765 added NANO_TIMED_LOCKS_FILTER=confirmation_height_processor . The full list of mutexes is available in nano/lib/locks.cpp mutex_identifier() . CLI There are 2 places that CLI commands can be added for use with nano_node , nano/node/cli.cpp & nano/nano_node/entry.cpp . The nano/node/cli.cpp CLI commands are also shared with nano_wallet so this is the place to put shared logic which can be used by both. CLI commands prefixed with debug_* shouldn\u2019t really be used by end users unless they are diagnosing issues. Sometimes it can be useful to compare the RPC output with CLI, and rpc results such as block_count will return cached results. IPC When using the nano_rpc as a separate process (either child or manually starting it), there needs to be a way of communicating between processes. IPC supports tcp and unix domain sockets, nano_rpc only supports tcp as it can be run on a different computer. IPC 2.0 adds flatbuffer support ( https://github.com/nanocurrency/nano-node/pull/2487 ) which can be used for the new RPC 2.0 (TBA). Work/Sig verification modifying for tests A common mistake is to request work for the hash of the block to be added, but it should happen on the root (previous one). The work difficulty is different for the live/beta/dev networks and are set using the work_thresholds class. During any local testing, where a lot of blocks are processed, work generation and signature verification can take the majority of the time. To speed this up it can make sense to manually lower the work difficulty even further and change the sig verification to always return true . Signal handling There are 2 sets of signal handlers registered (both are only set when the nano_node is run as a daemon. SIGSEGV & SIGABRT are set at the beginning which will create dump files if there is a segmentation fault during program execution (added in https://github.com/nanocurrency/nano-node/pull/1921/ ). SIGINT & SIGTERM signals catch non-kill intentional closing of the executable, such as pressing ctrl+c (added in https://github.com/nanocurrency/nano-node/pull/2018 ). This shuts down the node allows any running write transactions to finish. Only async signal safe functions should be used in signal handlers, this limits it to very specific functions. Memory allocators A lot of our heap usage is from deserializing block/votes off the wire and ledger database. To solve this we use a memory pool allocator which reuses memory in a freelist: https://github.com/nanocurrency/nano-node/pull/2047 In nano/lib/memory.hpp a nano::make_shared function is defined which checks if the global variable use_memory_pool is set (initialized during node startup reading the config node.use_memory_pools , which defaults to true). The memory is never reclaimed, this is a performance optimization. nano/crypto_lib/ This is a small library which has no dependency to anything in the nano core, which is needed as it is included by the ed25519 library as well. More info here: https://github.com/nanocurrency/nano-node/pull/1870 test/common/ Any functionality which is shared between test projects and may also use gtest library. There is also nano/node/testing.cpp which has no gtest dependency because it is also used in CLI commands too. debug_assert & release_assert debug_assert is essentially the same as the traditional C++ assert but also outputs a stacktrace. Added in https://github.com/nanocurrency/nano-node/pull/2568 . This should be used to check programmer logic. release_assert this is an assert which is triggered in both release/debug build, it also outputs a stacktrace. This was added https://github.com/nanocurrency/nano-node/pull/1114 . This should be used if some invariant doesn\u2019t hold and there is no suitable way to recover from this. Such as reading something from the ledger which is meant to exist but doesn\u2019t, can indicate ledger corruption. Put inside nano/lib or nano/secure? These libraries . nano/lib was originally intended to be used by other programs wanting some of the nano functionality, but those specific extern C functions were removed and it has now become the place to put all commonly used code. As such anything which doesn\u2019t depend on the node should go here, and the secure library is now mostly for ledger specific things. git submodules We have a variety of submodules https://docs.nano.org/node-implementation/contributing/?h=+submodule#about-the-code-base third party dependencies are to be kept as minimal as possible in order to keep build times lean, but if there is a suitable one it can be added a submodule. All threads should have a name set An easy example to follow is https://github.com/nanocurrency/nano-node/pull/2987/files This is so that debuggers/viewers which show threads can pick up the name to make it easier to navigate. It\u2019s been known not to work in the Visual Studio Concurrency visualizer. (de)serializing Where possible we try and store primitives in big-endian. As most systems are little-endian this means using boost::endian::native_to_big on primitives when serializing and boost::endian::big_to_native when deserializing. Boost We use the Boost library where possible, such as coroutine, filesystem, endian converter, lexical_cast, multi_index_container etc.. if there is a static/dynamic Boost library which is not used, there are generally no issues in adding it. Just make sure the build scripts and documentation are updated. Signature checker This is used by both blocks/votes and creates (total threads / 2) to perform signature verification of set batches; this is the biggest compute resource. Being able to lower this would be very beneficial, such as out of process sig verification and/or via GPU. Keeping build times low nano/node/node.hpp is the largest build bottleneck, it can increase build times of files by up to 10 seconds on some systems! Some boost files tend to be large too, they offer forward declaration headers such as <boost/property_tree/ptree_fwd.hpp> & <boost/stacktrace/stacktrace_fwd.hpp> worth checking if they exist for any you are using in header files. peers Peers are written to disk periodically. This was added in https://github.com/nanocurrency/nano-node/pull/1608 If the node has not been run in a long time (1 week), the peers list is cleared and the preconfigured peers list is used, this was added in https://github.com/nanocurrency/nano-node/pull/2506 write_database_queue This was introduced to reduce LMDB write lock contention between the block processor and the confirmation height processor. As during bootstrapping or high TPS the block processor can hold onto the lock up to 5s (by default), before the lock is held by the blockprocessor it signals that it is about to get the LMDB lock, the confirmation height processor can make use of this information and continue processing where it would otherwise be stalled. Ongoing pruning also makes use of this. debug_assert (!mutex.try_lock ()); When functions require that a mutex is required before being called we often check that the mutex is locked. Although this is technically undefined behaviour to be called by a thread which already owns the mutex we have been using this idiom for years and found no issues with the major compilers. Voting/Consensus \u00b6 To confirm a block a sufficient number of votes which are taken from confirm_ack messages are tallied up. If the tally is above the delta inside nano::election::have_quorum () it returns true and the block is considered confirmed. confirm_ack messages can either contain the whole block or a hash (vote by hash). confirm_req message header as well as confirm_ack indicate what the type of the contents is in the header, either not_a_block which means dealing with block hashes or the block type. nano/node/common.cpp contains these messages (among others) and (de)serializing functions. vote_processor Votes are signed by the representative and the vote processor schedules checking these votes through the signature_checker inside nano::vote_processor::verify_votes () . request_aggregator voting.hpp/cpp vote_processor TODO Confirmation height processor When a block is confirmed void nano::node::process_confirmed () the block is added to the confirmation height processor. This begins the process of cementing it and all of its dependents, once this occurs these blocks can never be rolled back. There are 2 confirmation height algorithms bounded and unbounded. Originally only the unbounded one existed, this would store the block hash for the original block confirmed, all its previous blocks, and recurse the bottom most receive block to the source and repeat the process. If this hit something like the binance chain or (any long chain) it could use a lot of memory (unbounded amount). So this brought about the bounded confirmation height processor algorithm which starts at the very bottom of the account chains but does the same recursion when a receive block is hit. This limits the amount of block hashes needing to be stored in memory to be able to cement the bottom most blocks. Checkpoints are used if there are a lot of accounts which need to be traversed to reach which exceeds the maximum amount of memory . It does mean in certain cases the same iteration will need to be done more than once but this should be a rare case only during initial cementing. Once the uncemented count (block count \u2013 cemented count) is less than 16K the unbounded processor is used. As mentioned above this instead starts from the top (original confirmed block) and works downwards and saves all the blocks hit (not just hash) which means they don\u2019t need to be re-read during writing later. This does use a lot more memory though which is why this is limited to a certain number of blocks, once the unbounded cutoff is exceeded the bounded processor resumes. Both algorithms operate with a read transaction first which reduces write lock held time as it can do a lot of iterating. This does mean that there can be some inconsistency by the time the writing is done, but this shouldn\u2019t be an issue because once a block is confirmed by the network it will stay confirmed by debug_assert checks are added to catch any programming mistakes. While it is more effort to maintain 2 algorithms the unbounded one largely existed before so it made sense to re-use it, given the performance improvements in almost cemented ledgers. node_initialized_latch Some classes use node_initialized_latch.wait (); The latch was added in https://github.com/nanocurrency/nano-node/pull/2042 this is to prevent some of the issues in the node constructor initializer list where the node object is passed and a child constructor is wants to use a node member which is not yet initialized. This makes it resume operation once the latch is incremented at the beginning of the node constructor. Frontiers confirmation nano/node/frontiers_confirmation.cpp contains code which starts at the beginning of the accounts database ( nano::blockstore_partial::accounts_begin ) and iterates in ascending order and prioritises accounts based on the number of uncemented blocks (stores up to 100k) and requests confirmation for a limited number of these accounts. When the cemented count is above the hardcoded bootstrap weights this is limited to the number of optimistic elections which is 50 in this case so it is expected to be quite slow in this case. Accounts in wallets are also checked. Telemetry nano/node/telemetry.cpp contains the logic for telemetry processing. This sets up an ongoing telemetry request round (every 60 seconds on the live network) where a telemetry_req message is sent to every peer. There is an alarm timeout of about 10 seconds in which we require the response (telemetry_ack) to be received otherwise it is rejected. Any calls to get_metrics_* return a cached result. To add a new definition to the telemetry_ack message this can be used as a guide which added the active_multiplier : https://github.com/nanocurrency/nano-node/pull/2728 telemetry_ack messages are signed and are backwards compatible with older nodes (from v22 onwards). Those nodes will verify the whole message including any extra unknown data which is appended at the end is just ignored. To prevent ddosing by telemetry_req messages, nodes ignore messages received within that 60second (on live) boundary. This is done in void nano::bootstrap_server::receive_header_action () Stats (counters) The stats object is used to keep a count of events that have happened, this is a useful idiom for checking values in tests and is aggregated in the stats->counts RPC. There are main stat types and then details for that type. A simple example of adding new details and incrementing the stats can be seen here: https://github.com/nanocurrency/nano-node/pull/2515 Adding a type for a stat is a similar procedure just using the nano::stat::type enumerator. Stats (objects) Most classes which have a member variable of container of multiple items (map, vector, list etc..) should have a function with a prototype of: std::unique_ptr<container_info_component> collect_container_info (my_class & my_class, std::string const & name); And then call this in an owning object which should itself be called recursively until it reaches the node object collect_container_info . They are typically not made as part of the class itself because it\u2019s a very specialised function which is only called as part of the stats->object RPC, like so: {\"action\":\"stats\",\"type\":\"objects\"} Initial output when running the node When the node is run it prints out some information about the database used, compiler etc. An example of appending to the output is here: https://github.com/nanocurrency/nano-node/pull/2807 Pruning Pruning occurs periodically inside nano::node::ongoing_ledger_pruning () . Pruning currently requires a full ledger to be bootstrapped and when an account frontier is confirmed it can then be pruned. The hashes of the pruned blocks are put into the pruned database so that we know to ignore any of these old blocks should the node bootstrap them again. Pending blocks cannot be pruned currently. Removing old upgrade version support Sometimes it is necessary/desired to remove being able to upgrade from specific versions. We dropped support for upgrades from v18 and earlier nodes in v1 using https://github.com/nanocurrency/nano-node/pull/2770 Config files TOML config files are used, previously we used json files but TOML config files have the benefit of providing comments inside. There are few config files: There are no versions or upgrades done here, instead any defaults not explicitly overridden in the toml file get updated implicitly. config-node.toml This is actually called daemonconfig.cpp in the code base, but it wraps a node_config object. config-rpc.toml config-wallet.toml These contain settings which can be modified by the user to override the defaults. The most common ones are enabling rpc/websocket & rocksdb. The nano/node/node_rpc_config.cpp are the rpc settings for the node. CMakeLists.txt CMake is used as the build system, and git submodules for any third party dependencies (except boost which must be installed separately by the developer). In CMakeLists.txt header files (.hpp) are above source files (.cpp), no particular reason but consistency is important. nano/boost Use nano/boost/asio nano/boost/beast for includes, this wraps up various includes and prevents warnings being shown (particularly on Windows builds). Running tests \u00b6 The dev network is forced for locally run tests, this lowers work and other settings to make it simpler to test. Build with cmake -DNANO_TESTS_ON .. See docs.nano.org for more information. There may be intermittent failures, if so add them here https://github.com/nanocurrency/nano-node/issues/1121 and fix if possible. Testing implementation details Sometimes it is necessary to be able to change something about a class only for a test. Rather than make this the class interface public just for tests, the specific tests can be added as friends to the class, this is done like so for a test named like so TEST (node, example); class my_class { private: int private_member; // the Test (node, example); test can access this member friend class node_example_Test; }; The test itself needs to be wrapped with the nano { } namespace for this to work correctly, if the class itself is in the nano namespace which is normally the case. nanodb-specification & protocol repositories There are 2 repositories which use kaitai specifications which should be updated (normally near the end of the release) if there are any changes to the https://github.com/nanocurrency/nanodb-specification or https://github.com/nanocurrency/protocol message nano-docs All RPC/CLI changes should have a documentation update specifying the version that they work. There is a documentation label in the nano-node repository which is useful as a reminder that they should be added, documentation updates are often overlooked. Before a release the following should be done: Run tests with TSAN/ASAN/Valgrind. All errors should be fixed before launch unless these are determined to be test related or false positives. We currently have some errors with using coroutines. There are blacklist files for the sanitizers which remove some errors caused by lmdb & rocksdb. Tips: Do not use the node object or include node.hpp in new core source files unless necessary, instead include the dependencies that it requires. We are still in the process of removing this idiom from other files because it adds circular dependencies, potentially ordering bugs and increases the build time. Take care not to have nested tx_begin_write () , it is quite easy to forget about this in tests, it will just cause a deadlock. To solve it, limit the scope: Pass std::shared_ptr parameters by reference where possible, https://github.com/nanocurrency/nano-node/pull/3029 Be cautious with random DB reads, they are much slower than sequential reads. This PR sped up the delegators by a factor of 100 RPC by removing the block_get call needed in the loop. https://github.com/nanocurrency/nano-node/pull/2283 { // Limit scope auto transaction = store->tx_begin_write (); block_put (store.tx_begin_write (), block); } \u2026 auto transaction = store->tx_begin_write (); or if it\u2019s a single write can create a temporary just for that use: block_put (store.tx_begin_write (), block); Be cautious with callback lifetimes with asynchronous callbacks, such as the worker, alarm and asio. The following issue was because of them: int x = 4; worker.push_back ([&x]() { std::cout << x; // x might not be valid by the time this is called, should have been a copy. }); Currently using C++17 with Boost 1.70, at the time of writing C++20 is still not fully implemented by any of the major standards compliant compilers. It may be considered for inclusion no earlier than 2022 at which point Linux LTS versions should support it through the default repositories. There are known exceptions triggered when consume_future is called do not be alarmed when seeing this Areas of future improvement: A lot of tests still use legacy blocks, any new ones should use state blocks. Minimise heap allocation. This can lead to fragmentation which affects long running processes. slow_test run as part of CI Out of process/gpu signature checking FAQs Where are blocks added to the ledger? nano::ledger::process () Where are rpc calls handled? nano/node/json_handler.cpp Where is the genesis block created? nano::blockstore_partial::init () How to stop the node effectively? rpc -> stop () How to use RocksDB in tests? Set the environment variable: TEST_USE_ROCKSDB=1 http://www.acodersjourney.com/2016/02/c-11-auto/ \u21a9 https://help.github.com/articles/resolving-merge-conflicts-after-a-git-rebase/ \u21a9 https://help.github.com/articles/resolving-a-merge-conflict-using-the-command-line/ \u21a9 https://github.com/todotxt/todo.txt-android/wiki/Squash-All-Commits-Related-to-a-Single-Issue-into-a-Single-Commit \u21a9 https://dmitryfrank.com/articles/indent_with_tabs_align_with_spaces \u21a9","title":"Contributing"},{"location":"node-implementation/contributing/#contributing-code-to-the-nano-node","text":"","title":"Contributing code to the Nano node"},{"location":"node-implementation/contributing/#about-the-code-base","text":"Nano is written in C++17 and supports Linux, macOS and Windows. Libraries We use Boost to help us write efficient cross platform code, including the async IO library for networking (asio). Make sure you have the correct Boost version installed. Submodules Name Details cryptopp Provides the implementation for random number generator, SipHash, AES and other cryptographic schemes. phc\u2011winner\u2011argon2 When encrypting with AES, the password first goes through key derivation, and argon2 is our hash of choice for doing that. lmdb The database library used for the ledger and wallet, with local patches for Windows. This is a very fast and portable key/value store with ordered keys. It is extremely resilient to crashes in the program, OS, and power-downs without corruption. rocksdb This database library can be used for the ledger. Provides better file IO and reduced ledger size. miniupnp This library is used to do port mapping if the gateway supports it. cpptoml This library is used for rpc, wallet and node configuration files flatbuffers A (de)serialization library for sending binary messages over IPC instead of plain-text JSON gtest A unit testing library, only used in development environments Qt Wallet To build the GUI, set the NANO_GUI flag in cmake. The desktop wallet uses Qt5, but without the MOC compiler. Hence, you cannot use the signals and slots mechanism. The majority of the Qt wallet code resides in the qt subproject, while the QApplication startup code resides in nano_wallet . Using CMake CMake is used to generate build files and project files for various IDE's. Please familiarize yourself with basic cmake usage, such as how to change cache variables via the command line, ccmake or CMake GUI. This is much more convenient that editing the CMakeLists.txt file directly. Find out more about building in Integration Guides Build Options .","title":"About the code base"},{"location":"node-implementation/contributing/#testing","text":"Add tests If you add new functionality, adding unit tests to avoid regressions in the future is required. The easiest way to get started writing your first test is to base it off one of the existing tests. You'll find these in the core_test & rpc_test directories. There is also slow_test & load_test directories but these are not commonly modified. Make sure the NANO_TEST cache variable in cmake is set. Run tests before creating a pull request Please run the tests before submitting a PR. Go to the build directory and run the core_test binary.","title":"Testing"},{"location":"node-implementation/contributing/#github-collaboration","text":"Communication is the key to working together efficiently. A good way to get in touch with the developers is to join the #development channel on Discord . If you have an idea of an improvement or new feature, consider discussing it first with the team, either on Discord, or by adding an issue. Maybe someone is already working on it, or have suggestions on how to improve on the idea. Security Vulnerability Disclosure Do NOT discuss potential security vulnerabilities on the issue tracker, public forums or open discussion channels If you discover a bug you believe to pose a security risk to the Nano network, please contact bugs@nano.org with a proof of concept with full details of the bug including: Repository of the bug High-level summary Detailed description Steps to reproduce Supporting material/references The potential security impact of the bug","title":"GitHub collaboration"},{"location":"node-implementation/contributing/#code-process","text":"","title":"Code Process"},{"location":"node-implementation/contributing/#fork-and-do-all-your-work-on-a-branch","text":"Nano prefers the standard GitHub workflow. You create a fork of the Nano repository, make branches for features/issues, and commit and push these.","title":"Fork and do all your work on a branch"},{"location":"node-implementation/contributing/#create-pull-requests","text":"Before: Branch out of the develop branch. The master branch is only updated on new releases. Review your code locally. Have you followed the guidelines in this document? Run tests. Did you consider adding a test case for your feature? Run ASAN and TSAN to detect memory or threading bugs Commit and push your fork Create pull request on the upstream repository: Make sure you add a description that clearly describes the purpose of the PR. If the PR solves one or more issues, please reference these in the description. After: Check that CI completes successfully. If not, fix the problem and push an update. Respond to comments and reviews in a timely fashion.","title":"Create pull requests"},{"location":"node-implementation/contributing/#resolve-conflicts","text":"If time passes between your pull request (PR) submission and the team accepting it, merge conflicts may occur due to activity on develop, such as merging other PR's before yours. In order for your PR to be accepted, you must resolve these conflicts. The preferred process is to rebase your changes, resolve any conflicts, and push your changes again. 2 3 Check out your branch git fetch upstream git rebase upstream/develop Resolve conflicts in your favorite editor git add {filename} git rebase --continue Commit and push your branch Consider squashing or amending commits In the review process, you're likely to get feedback. You'll commit and push more changes, get more feedback, etc. This can lead to a messy git history, and can make stuff like bisecting harder. Once your PR is OK'ed, please squash the commits into a one. 4 Note that you can also update the last commit with git commit --amend . Say your last commit had a typo. Instead of committing and having to squash it later, simply commit with amend and push the branch.","title":"Resolve conflicts"},{"location":"node-implementation/contributing/#code-standard","text":"","title":"Code standard"},{"location":"node-implementation/contributing/#formatting","text":"clang-format is used to enforce most of the formatting rules, such as: Tabs for indentation. Open braces go on new lines. Space before open parenthesis. Space after comma. Please run ci/clang-format-all.sh on *nix systems before pushing your code to ensure that the formatting is good. If you want to do formatting from the IDE, chances are there's a plugin available. Visual studio for instance provides a way to automatically format on saving. The definition file .clang-format is located in the project root directory. Make sure you set up your editor to use tabs. Use tabs for indentation, and spaces for alignment 5 . That way, you can use any tab size you want in your favorite editor, but the code will still look good for people with different settings.","title":"Formatting"},{"location":"node-implementation/contributing/#coding-guidelines","text":"Use auto type inference for local variables if it's clear from the context what the type will be. Use your best judgement, sometimes adding explicit types can increase readability 1 Handle exceptions, including IO exceptions for file and network operations. Be liberal with debug_assert . Use asserts to check invariants, not potential runtime errors, which should be handled gracefully. debug_assert has an advantage over normal assert as it will always print out the stacktrace of the current thread when it hits. Debug asserts are for detecting bugs, not error handling. There is also release_assert which is similar to debug_assert but also hits in a release build. When there is unexpected behaviour and no suitable way to recover it can be used to halt program execution. Be liberal with logger.always_log or logger.try_log statements, except in performance critical paths. Add comments to explain complex and subtle situations, but avoid comments that reiterates what the code already says. Use RAII and C++11 smart pointers to manage memory and other resources.","title":"Coding guidelines"},{"location":"node-implementation/contributing/#performance-and-scalabiliy-considerations","text":"When making changes, think about performance and scalability. Pick good data structures and think about algorithmic complexity. For small data sets, std::vector should be your to-go container, as a linear scan through contiguous memory is often faster than any alternative due to memory being read in cache lines. Nested loops yield quadratic behavior - is there an alternative? A typical example is removing an inner lookup loop with an unordered set/map to improve lookup performance to O(1). Make sure your change doesn't conflict with the scalability characteristics described in the white paper.","title":"Performance and scalabiliy considerations"},{"location":"node-implementation/contributing/#security","text":"Your code will be reviewed with security in mind, but please do your part before creating a pull request: Familiarize yourself with best practices for writing secure C++ code. In particular: Consult https://wiki.sei.cmu.edu/confluence/display/cplusplus Avoid using ANSI C functions. Many of these are prone to buffer overruns. Avoid using C strings and direct buffer manipulation. Use static and dynamic analysis tools, such as valgrind, XCode instrumentation, linters and sanitizers. These tools are also great for debugging crashes and performance problems.","title":"Security"},{"location":"node-implementation/contributing/#general-tips-for-contributors","text":"Read the white paper Peruse the code and don't be shy about asking questions if there are parts you don't understand. Make sure you understand the GitHub workflow. Participate in the community by reading and replying to GitHub issues, Reddit posts and tweets. This gives you a great insight into the pain points that exists with the software.","title":"General tips for contributors"},{"location":"node-implementation/contributing/#wip-developer-starter-pack","text":"Items include: Windows/MacOS/Linux C++17 compiler Boost Git CMake This guide is designed to give an overall structure of the core Nano Protocol codebase to help new developers get a better understanding of the different areas and how they interoperate. Due to the rapid changing nature of the protocol it\u2019s possible some of the features are moved to different places or have changed entirely. Working on the protocol requires a very multi-disciplined and wide area of knowledge, none of it is particularly mandatory to get started but a good C++ understanding will help prevent being too overwhelmed initially: Modern C++ knowledge (up to C++17) including multithreading primitives (mutex, condition variables, atomics) & templates, Boost (asio & beast), RocksDB, LMDB, FlatBuffers, JSON-RPC, IPC, networking communication (ip/tcp, message passing, broadcasting algorithms), QT, signal handling, PKI cryptography, git & cross-platform development. The main Nano projects are located inside the /nano subdirectory.","title":"[WIP] Developer starter pack"},{"location":"node-implementation/contributing/#executable-binaries-all-have-nano_-prefix","text":"All executable projects have a main function inside entry.cpp nano_node \u2013 The standard way to start a node. There are 2 source files in here, entry.cpp and daemon.cpp . nano_daemon::daemon::run() is always called so is a good place to put a breakpoint if there are any issues during node operation (especially errors when launching initially). nano_rpc \u2013 This executable does not need to be run explicitly unless out of process RPC is selected. https://docs.nano.org/integration-guides/advanced/?h=+nano_rpc#running-nano-as-a-service Because this project is quite small it is all done inside the entry.cpp file and is probably an easier starting point template should anything else need to be moved out of process in the future. nano_wallet \u2013 This essentially does the same as nano_node but doesn\u2019t support all CLI commands and has a graphical user interface for the wallet.","title":"Executable binaries (all have nano_ prefix)"},{"location":"node-implementation/contributing/#votingconsensus","text":"To confirm a block a sufficient number of votes which are taken from confirm_ack messages are tallied up. If the tally is above the delta inside nano::election::have_quorum () it returns true and the block is considered confirmed. confirm_ack messages can either contain the whole block or a hash (vote by hash). confirm_req message header as well as confirm_ack indicate what the type of the contents is in the header, either not_a_block which means dealing with block hashes or the block type. nano/node/common.cpp contains these messages (among others) and (de)serializing functions.","title":"Voting/Consensus"},{"location":"node-implementation/contributing/#running-tests","text":"The dev network is forced for locally run tests, this lowers work and other settings to make it simpler to test. Build with cmake -DNANO_TESTS_ON .. See docs.nano.org for more information. There may be intermittent failures, if so add them here https://github.com/nanocurrency/nano-node/issues/1121 and fix if possible.","title":"Running tests"},{"location":"node-implementation/database/","text":"Node Implementation - Database \u00b6 Part of work in progress Living Whitepaper This page is part of the Living Whitepaper revisions currently underway to replace the original static whitepaper. These efforts include the Protocol Design and Node Implementation sections of the docs, which will cover and expand on details and topics covered in the original whitepaper . See the bottom of the page for related whitepaper sections and other related details. Some of the sections and headers on this page may be in draft form or just suggestions/framework for later consideration. If you are interested in helping with revisions please connect with us on the #documentation channel on our Discord server . Ledger \u00b6 Blocks \u00b6 Pending blocks \u00b6 Accounts \u00b6 Caching \u00b6 Block cementing \u00b6 Database backends \u00b6 LMDB \u00b6 RocksDB \u00b6 Existing whitepaper sections related to this page: Implementation Other content related to this page: Ledger Management guide","title":"Database"},{"location":"node-implementation/database/#node-implementation-database","text":"Part of work in progress Living Whitepaper This page is part of the Living Whitepaper revisions currently underway to replace the original static whitepaper. These efforts include the Protocol Design and Node Implementation sections of the docs, which will cover and expand on details and topics covered in the original whitepaper . See the bottom of the page for related whitepaper sections and other related details. Some of the sections and headers on this page may be in draft form or just suggestions/framework for later consideration. If you are interested in helping with revisions please connect with us on the #documentation channel on our Discord server .","title":"Node Implementation - Database"},{"location":"node-implementation/database/#ledger","text":"","title":"Ledger"},{"location":"node-implementation/database/#blocks","text":"","title":"Blocks"},{"location":"node-implementation/database/#pending-blocks","text":"","title":"Pending blocks"},{"location":"node-implementation/database/#accounts","text":"","title":"Accounts"},{"location":"node-implementation/database/#caching","text":"","title":"Caching"},{"location":"node-implementation/database/#block-cementing","text":"","title":"Block cementing"},{"location":"node-implementation/database/#database-backends","text":"","title":"Database backends"},{"location":"node-implementation/database/#lmdb","text":"","title":"LMDB"},{"location":"node-implementation/database/#rocksdb","text":"Existing whitepaper sections related to this page: Implementation Other content related to this page: Ledger Management guide","title":"RocksDB"},{"location":"node-implementation/introduction/","text":"Node Implementation - Introduction \u00b6 Part of work in progress Living Whitepaper This page is part of the Living Whitepaper revisions currently underway to replace the original static whitepaper. These efforts include the Protocol Design and Node Implementation sections of the docs, which will cover and expand on details and topics covered in the original whitepaper . See the bottom of the page for related whitepaper sections and other related details. Some of the sections and headers on this page may be in draft form or just suggestions/framework for later consideration. If you are interested in helping with revisions please connect with us on the #documentation channel on our Discord server . Methods and mechanisms built into the current node software that aren't required for compliance with protocol rules, but help provide better efficiency and performance for nodes running on the network. These details could be ignored or implemented in different ways by other versions of node software. Context and scope \u00b6 Efficiency and security \u00b6 Determinism \u00b6 Choice of language and framework \u00b6 Github links \u00b6 Contributing \u00b6 Section Description Components Breakdown of separate functional areas of the node Database Storage and cementing mechanisms, backend database options Voting Vote handling and voting weight management Work Kernel designs, prioritization processes and rework mechanisms Contributing How to contribute to the Nano protocol directly Existing whitepaper sections related to this page: Implementation","title":"Introduction"},{"location":"node-implementation/introduction/#node-implementation-introduction","text":"Part of work in progress Living Whitepaper This page is part of the Living Whitepaper revisions currently underway to replace the original static whitepaper. These efforts include the Protocol Design and Node Implementation sections of the docs, which will cover and expand on details and topics covered in the original whitepaper . See the bottom of the page for related whitepaper sections and other related details. Some of the sections and headers on this page may be in draft form or just suggestions/framework for later consideration. If you are interested in helping with revisions please connect with us on the #documentation channel on our Discord server . Methods and mechanisms built into the current node software that aren't required for compliance with protocol rules, but help provide better efficiency and performance for nodes running on the network. These details could be ignored or implemented in different ways by other versions of node software.","title":"Node Implementation - Introduction"},{"location":"node-implementation/introduction/#context-and-scope","text":"","title":"Context and scope"},{"location":"node-implementation/introduction/#efficiency-and-security","text":"","title":"Efficiency and security"},{"location":"node-implementation/introduction/#determinism","text":"","title":"Determinism"},{"location":"node-implementation/introduction/#choice-of-language-and-framework","text":"","title":"Choice of language and framework"},{"location":"node-implementation/introduction/#github-links","text":"","title":"Github links"},{"location":"node-implementation/introduction/#contributing","text":"Section Description Components Breakdown of separate functional areas of the node Database Storage and cementing mechanisms, backend database options Voting Vote handling and voting weight management Work Kernel designs, prioritization processes and rework mechanisms Contributing How to contribute to the Nano protocol directly Existing whitepaper sections related to this page: Implementation","title":"Contributing"},{"location":"node-implementation/voting/","text":"Node Implementation - Voting \u00b6 Part of work in progress Living Whitepaper This page is part of the Living Whitepaper revisions currently underway to replace the original static whitepaper. These efforts include the Protocol Design and Node Implementation sections of the docs, which will cover and expand on details and topics covered in the original whitepaper . See the bottom of the page for related whitepaper sections and other related details. Some of the sections and headers on this page may be in draft form or just suggestions/framework for later consideration. If you are interested in helping with revisions please connect with us on the #documentation channel on our Discord server . Vote rebroadcasting \u00b6 When a block is processed, Principal Representatives evaluate whether they can generate a vote for the block (dependent blocks already confirmed, etc.). If they can, they generate the vote and publish to all other PRs they are aware of in addition to 2*sqrt(peers) of non-PR nodes. To reduce the load on PRs nodes, they do not republish incoming votes - only Non-PR nodes republish other votes to 1/2*sqrt(peers) to ensure enough coverage across the rest of the network. Due to the direct 1:1 relationship between PR nodes, their latency is mostly geographic/network based. For Non-PRs, there is some gossiping via the random distribution, so the number of hops required is what makes up a majority of the latency and the geographic and network latency is less of a factor. Rep crawler (PRs only) \u00b6 Online weight calculator \u00b6 Active transactions loop \u00b6 Existing whitepaper sections related to this page: Implementation Other content related to this page: Voting as a Representative guide","title":"Voting"},{"location":"node-implementation/voting/#node-implementation-voting","text":"Part of work in progress Living Whitepaper This page is part of the Living Whitepaper revisions currently underway to replace the original static whitepaper. These efforts include the Protocol Design and Node Implementation sections of the docs, which will cover and expand on details and topics covered in the original whitepaper . See the bottom of the page for related whitepaper sections and other related details. Some of the sections and headers on this page may be in draft form or just suggestions/framework for later consideration. If you are interested in helping with revisions please connect with us on the #documentation channel on our Discord server .","title":"Node Implementation - Voting"},{"location":"node-implementation/voting/#vote-rebroadcasting","text":"When a block is processed, Principal Representatives evaluate whether they can generate a vote for the block (dependent blocks already confirmed, etc.). If they can, they generate the vote and publish to all other PRs they are aware of in addition to 2*sqrt(peers) of non-PR nodes. To reduce the load on PRs nodes, they do not republish incoming votes - only Non-PR nodes republish other votes to 1/2*sqrt(peers) to ensure enough coverage across the rest of the network. Due to the direct 1:1 relationship between PR nodes, their latency is mostly geographic/network based. For Non-PRs, there is some gossiping via the random distribution, so the number of hops required is what makes up a majority of the latency and the geographic and network latency is less of a factor.","title":"Vote rebroadcasting"},{"location":"node-implementation/voting/#rep-crawler-prs-only","text":"","title":"Rep crawler (PRs only)"},{"location":"node-implementation/voting/#online-weight-calculator","text":"","title":"Online weight calculator"},{"location":"node-implementation/voting/#active-transactions-loop","text":"Existing whitepaper sections related to this page: Implementation Other content related to this page: Voting as a Representative guide","title":"Active transactions loop"},{"location":"node-implementation/work/","text":"Node Implementation - Work \u00b6 Part of work in progress Living Whitepaper This page is part of the Living Whitepaper revisions currently underway to replace the original static whitepaper. These efforts include the Protocol Design and Node Implementation sections of the docs, which will cover and expand on details and topics covered in the original whitepaper . See the bottom of the page for related whitepaper sections and other related details. Some of the sections and headers on this page may be in draft form or just suggestions/framework for later consideration. If you are interested in helping with revisions please connect with us on the #documentation channel on our Discord server . OpenCL implementation \u00b6 Prioritization \u00b6 Work re-generation \u00b6 Existing whitepaper sections related to this page: Implementation Other content related to this page: Work Generation guide","title":"Work"},{"location":"node-implementation/work/#node-implementation-work","text":"Part of work in progress Living Whitepaper This page is part of the Living Whitepaper revisions currently underway to replace the original static whitepaper. These efforts include the Protocol Design and Node Implementation sections of the docs, which will cover and expand on details and topics covered in the original whitepaper . See the bottom of the page for related whitepaper sections and other related details. Some of the sections and headers on this page may be in draft form or just suggestions/framework for later consideration. If you are interested in helping with revisions please connect with us on the #documentation channel on our Discord server .","title":"Node Implementation - Work"},{"location":"node-implementation/work/#opencl-implementation","text":"","title":"OpenCL implementation"},{"location":"node-implementation/work/#prioritization","text":"","title":"Prioritization"},{"location":"node-implementation/work/#work-re-generation","text":"Existing whitepaper sections related to this page: Implementation Other content related to this page: Work Generation guide","title":"Work re-generation"},{"location":"protocol-design/attack-vectors/","text":"Protocol Design - Attack Vectors \u00b6 Part of work in progress Living Whitepaper This page is part of the Living Whitepaper revisions currently underway to replace the original static whitepaper. These efforts include the Protocol Design and Node Implementation sections of the docs, which will cover and expand on details and topics covered in the original whitepaper . See the bottom of the page for related whitepaper sections and other related details. Some of the sections and headers on this page may be in draft form or just suggestions/framework for later consideration. If you are interested in helping with revisions please connect with us on the #documentation channel on our Discord server . Block gap synchronization \u00b6 Risk Low risk Impacts Network amplify, denial of service Description Each block has a link to its previous block. If a new block arrives where we can't find the previous block, this leaves the node deciding whether it's out of sync or if someone is sending junk data. If a node is out of sync, synchronizing involves a TCP connection to a node that offers bootstrapping which is much more traffic than sending a single UDP packet containing a block; this is a network amplification attack. Defense For blocks with no previous link, nodes will wait until a certain threshold of votes have been observed before initiating a connection to a bootstrap node to synchronize. If a block doesn't receive enough votes it can be assumed to be junk data. Transaction flooding \u00b6 Risk Moderate Impacts High I/O Description Transaction flooding is simply sending as many valid transactions as possible in order to saturate the network. Usually an attacker will send transactions to other accounts they control so it can be continued indefinitely. Defense Each block has a small amount of work associated with it, around 5 seconds to generate and 1 microsecond to validate. This work difference causes an attacker to dedicate a large amount to sustain an attack while wasting a small amount of resources by everyone else. Nodes that are not full historical nodes are able to prune old transactions from their chain, this clamps the storage usage from this type of attack for almost all users. Sybil attack to change ledger entries \u00b6 Risk None Impacts Completely destructive Description A Sybil attack is a person creating a lot of nodes on the network, possibly thousands on a single machine, in order to get a disproportionate vote on networks where each node gets an equal vote. Defense The Nano voting system is weighted based on account balance. Adding extra nodes in to the network will not gain an attacker extra votes. Penny-spend attack \u00b6 Risk Moderate Impacts Ledger bloat Description A penny-spend attack is where an attacker spends infinitesimal quantities to a large number of accounts in order to waste the storage resources of nodes. Defense Blocks publishing is rate-limited by work so this limits accounts to a certain extent. Nodes that are not full historical nodes can prune accounts below a statistical metric where the account is probably not a valid account. Finally, Nano is tuned to use minimal permanent storage space so space required to store one additional account is proportional to the size of one block + indexing ~ 96b + 32b ~ 128b. This equates to 1GB being able to store 8 million penny-spend account. If nodes want to be aggressive, they can calculate a distribution based on access frequency and delegate infrequently used accounts to slower storage. >50% attack \u00b6 Risk Low Impacts Completely destructive Description The metric of consensus for Nano is a balance weighted voting system. If an attacker is able to gain over 50% of the voting strength, they can cause the network to oscillate their decisions rendering the system useless. An attacker must have at least some value tied up in the network as a balance which they're willing to forfeit as an expense to performing this type of attack since this attack ruins the integrity of the system. An attacker is able to lower the amount of balance they must forfeit by preventing good nodes from voting through a network DDOS. Defense There are multiple levels of defense against this type of attack: Primary defense : voting weight being tied to investment in the system; attempting to flip the ledger would be destructive to the system as a whole which would destroy their investment. Secondary defense : cost of this attack is proportional to the market cap of all of Nano. In proof of work systems, technology can be invented that gives disproportionate control compared to monetary investment and if the attack is successful, this technology could be repurposed after the attack is complete. With Nano the cost of attacking the system scales with the system and if an attack were to be successful the cost of the attack can't be recovered. Tertiary defense : In order to maintain the maximum quorum of voters, the next line of defense is representative voting. Account holders who are unable to reliably participate in voting for connectivity reasons can name a representative who can vote with the weight of their balance. Forks in Nano are never accidental so nodes can make policy decisions on how to interact with forked blocks. The only time non-attacker accounts are vulnerable to block forks is if they receive a balance from an attacking account. Accounts wanting to be secure from block forks can wait a little or a lot longer before receiving from an account who generated forks or opt to never receive at all. Receivers could also generate separate accounts for receiving from dubious accounts in order to protect the rest of their balance. A final line of defense is block cementing. As blocks are confirmed in V19.0+, the node marks the height of the last block confirmed for every account and will refuse the replacement of an already confirmed block. Attempts to fork after previous confirmation of a block will immediately fail. The most sophisticated version of a >50% attack is detailed in the diagram below. \"Offline\" is the percentage of representatives who have been named but are not online to vote. \"Stake\" is the amount of investment the attacker is voting with and will be lost if they successfully attack the system. \"Active\" are representatives that are online and voting according to the protocol. An attacker can offset the amount of stake they must forfeit by knocking other voters offline via a network denial of service attack. If this attack can be sustained, the representatives being attacked will become unsynchronized and this is demonstrated by \"Unsynced\". Finally, an attacker can gain a short burst in relative voting strength by switching their denial of service attack to a new set of representatives while the old set is resynchronizing their ledger, this is demonstrated by \"Attacked\". If an attacker is able to cause Stake > Active by a combination of these circumstances, they would be able to successfully flip votes on the ledger at the expense of their stake. We can estimate how much this type of attack could cost by examining the market cap of other systems. If we estimate 33% of representatives are offline or attacked via denial of service, an attacker would need to purchase 33% of the market cap in order to attack the system via voting. Voting attack cost: Euro - M1 in 2014 ~6 trillion, attack amount 2 trillion USD - M0 in 2014 ~4 trillion, attack amount 1.2 trillion UK pound sterling - M0 in 2007 ~1.5 trillion, attack amount 500 billion Bitcoin - Market cap 2014 ~3 billion, attack amount 1 billion Bootstrap poisoning \u00b6 Risk Low Impacts New-user denial of service Description The longer an attacker is able to hold an old private key with a balance, the higher the probability of balances that existed at that time no longer having representatives that are participating in voting because their balances or representatives have transferred to new people. This means if a node is bootstrapped to an old representation of the network where the attacker has a quorum of voting stake compare to representatives at that point in time, they would be able to oscillate voting decisions to that node. If this new user wanted to interact with anyone besides the attacking node all of their transactions would be denied since they have different head blocks. The net result is nodes can waste the time of new nodes in the network by feeding them bad information. Defense Nodes can be paired with an initial database of accounts and known-good block heads; this is a replacement for downloading the database all the way back to the genesis block. The closer the download is to be current, the higher the probability of accurately defending against this attack. In the end this attack is probably no worse than feeding junk data to nodes while bootstrapping since they wouldn't be able to transact with anyone who has a contemporary database. Other attacks \u00b6 Network Attacks Part 2 - Additional deep-dive into potential attack vectors & mitigations Existing whitepaper sections related to this page: Attack Vectors","title":"Attack Vectors"},{"location":"protocol-design/attack-vectors/#protocol-design-attack-vectors","text":"Part of work in progress Living Whitepaper This page is part of the Living Whitepaper revisions currently underway to replace the original static whitepaper. These efforts include the Protocol Design and Node Implementation sections of the docs, which will cover and expand on details and topics covered in the original whitepaper . See the bottom of the page for related whitepaper sections and other related details. Some of the sections and headers on this page may be in draft form or just suggestions/framework for later consideration. If you are interested in helping with revisions please connect with us on the #documentation channel on our Discord server .","title":"Protocol Design - Attack Vectors"},{"location":"protocol-design/attack-vectors/#block-gap-synchronization","text":"Risk Low risk Impacts Network amplify, denial of service Description Each block has a link to its previous block. If a new block arrives where we can't find the previous block, this leaves the node deciding whether it's out of sync or if someone is sending junk data. If a node is out of sync, synchronizing involves a TCP connection to a node that offers bootstrapping which is much more traffic than sending a single UDP packet containing a block; this is a network amplification attack. Defense For blocks with no previous link, nodes will wait until a certain threshold of votes have been observed before initiating a connection to a bootstrap node to synchronize. If a block doesn't receive enough votes it can be assumed to be junk data.","title":"Block gap synchronization"},{"location":"protocol-design/attack-vectors/#transaction-flooding","text":"Risk Moderate Impacts High I/O Description Transaction flooding is simply sending as many valid transactions as possible in order to saturate the network. Usually an attacker will send transactions to other accounts they control so it can be continued indefinitely. Defense Each block has a small amount of work associated with it, around 5 seconds to generate and 1 microsecond to validate. This work difference causes an attacker to dedicate a large amount to sustain an attack while wasting a small amount of resources by everyone else. Nodes that are not full historical nodes are able to prune old transactions from their chain, this clamps the storage usage from this type of attack for almost all users.","title":"Transaction flooding"},{"location":"protocol-design/attack-vectors/#sybil-attack-to-change-ledger-entries","text":"Risk None Impacts Completely destructive Description A Sybil attack is a person creating a lot of nodes on the network, possibly thousands on a single machine, in order to get a disproportionate vote on networks where each node gets an equal vote. Defense The Nano voting system is weighted based on account balance. Adding extra nodes in to the network will not gain an attacker extra votes.","title":"Sybil attack to change ledger entries"},{"location":"protocol-design/attack-vectors/#penny-spend-attack","text":"Risk Moderate Impacts Ledger bloat Description A penny-spend attack is where an attacker spends infinitesimal quantities to a large number of accounts in order to waste the storage resources of nodes. Defense Blocks publishing is rate-limited by work so this limits accounts to a certain extent. Nodes that are not full historical nodes can prune accounts below a statistical metric where the account is probably not a valid account. Finally, Nano is tuned to use minimal permanent storage space so space required to store one additional account is proportional to the size of one block + indexing ~ 96b + 32b ~ 128b. This equates to 1GB being able to store 8 million penny-spend account. If nodes want to be aggressive, they can calculate a distribution based on access frequency and delegate infrequently used accounts to slower storage.","title":"Penny-spend attack"},{"location":"protocol-design/attack-vectors/#50-attack","text":"Risk Low Impacts Completely destructive Description The metric of consensus for Nano is a balance weighted voting system. If an attacker is able to gain over 50% of the voting strength, they can cause the network to oscillate their decisions rendering the system useless. An attacker must have at least some value tied up in the network as a balance which they're willing to forfeit as an expense to performing this type of attack since this attack ruins the integrity of the system. An attacker is able to lower the amount of balance they must forfeit by preventing good nodes from voting through a network DDOS. Defense There are multiple levels of defense against this type of attack: Primary defense : voting weight being tied to investment in the system; attempting to flip the ledger would be destructive to the system as a whole which would destroy their investment. Secondary defense : cost of this attack is proportional to the market cap of all of Nano. In proof of work systems, technology can be invented that gives disproportionate control compared to monetary investment and if the attack is successful, this technology could be repurposed after the attack is complete. With Nano the cost of attacking the system scales with the system and if an attack were to be successful the cost of the attack can't be recovered. Tertiary defense : In order to maintain the maximum quorum of voters, the next line of defense is representative voting. Account holders who are unable to reliably participate in voting for connectivity reasons can name a representative who can vote with the weight of their balance. Forks in Nano are never accidental so nodes can make policy decisions on how to interact with forked blocks. The only time non-attacker accounts are vulnerable to block forks is if they receive a balance from an attacking account. Accounts wanting to be secure from block forks can wait a little or a lot longer before receiving from an account who generated forks or opt to never receive at all. Receivers could also generate separate accounts for receiving from dubious accounts in order to protect the rest of their balance. A final line of defense is block cementing. As blocks are confirmed in V19.0+, the node marks the height of the last block confirmed for every account and will refuse the replacement of an already confirmed block. Attempts to fork after previous confirmation of a block will immediately fail. The most sophisticated version of a >50% attack is detailed in the diagram below. \"Offline\" is the percentage of representatives who have been named but are not online to vote. \"Stake\" is the amount of investment the attacker is voting with and will be lost if they successfully attack the system. \"Active\" are representatives that are online and voting according to the protocol. An attacker can offset the amount of stake they must forfeit by knocking other voters offline via a network denial of service attack. If this attack can be sustained, the representatives being attacked will become unsynchronized and this is demonstrated by \"Unsynced\". Finally, an attacker can gain a short burst in relative voting strength by switching their denial of service attack to a new set of representatives while the old set is resynchronizing their ledger, this is demonstrated by \"Attacked\". If an attacker is able to cause Stake > Active by a combination of these circumstances, they would be able to successfully flip votes on the ledger at the expense of their stake. We can estimate how much this type of attack could cost by examining the market cap of other systems. If we estimate 33% of representatives are offline or attacked via denial of service, an attacker would need to purchase 33% of the market cap in order to attack the system via voting. Voting attack cost: Euro - M1 in 2014 ~6 trillion, attack amount 2 trillion USD - M0 in 2014 ~4 trillion, attack amount 1.2 trillion UK pound sterling - M0 in 2007 ~1.5 trillion, attack amount 500 billion Bitcoin - Market cap 2014 ~3 billion, attack amount 1 billion","title":"&gt;50% attack"},{"location":"protocol-design/attack-vectors/#bootstrap-poisoning","text":"Risk Low Impacts New-user denial of service Description The longer an attacker is able to hold an old private key with a balance, the higher the probability of balances that existed at that time no longer having representatives that are participating in voting because their balances or representatives have transferred to new people. This means if a node is bootstrapped to an old representation of the network where the attacker has a quorum of voting stake compare to representatives at that point in time, they would be able to oscillate voting decisions to that node. If this new user wanted to interact with anyone besides the attacking node all of their transactions would be denied since they have different head blocks. The net result is nodes can waste the time of new nodes in the network by feeding them bad information. Defense Nodes can be paired with an initial database of accounts and known-good block heads; this is a replacement for downloading the database all the way back to the genesis block. The closer the download is to be current, the higher the probability of accurately defending against this attack. In the end this attack is probably no worse than feeding junk data to nodes while bootstrapping since they wouldn't be able to transact with anyone who has a contemporary database.","title":"Bootstrap poisoning"},{"location":"protocol-design/attack-vectors/#other-attacks","text":"Network Attacks Part 2 - Additional deep-dive into potential attack vectors & mitigations Existing whitepaper sections related to this page: Attack Vectors","title":"Other attacks"},{"location":"protocol-design/blocks/","text":"Protocol Design - Blocks \u00b6 Part of work in progress Living Whitepaper This page is part of the Living Whitepaper revisions currently underway to replace the original static whitepaper. These efforts include the Protocol Design and Node Implementation sections of the docs, which will cover and expand on details and topics covered in the original whitepaper . See the bottom of the page for related whitepaper sections and other related details. Some of the sections and headers on this page may be in draft form or just suggestions/framework for later consideration. If you are interested in helping with revisions please connect with us on the #documentation channel on our Discord server . Key terms in this section block is the digital encoding of the transaction details. transaction is the action of creating and publishing a block to the network. Depending on the type of transaction, the block will have different requirements. transfer is the completion of both a send transaction and the corresponding receive transaction, representing the movement of funds which can be sent again by the recipient. State Blocks \u00b6 All new transactions on the Nano Protocol are communicated via blocks. The account's entire state, including the balance after each transaction, is recorded in every block. Transaction amounts are interpreted as the difference in balance between consecutive blocks. Key RPC Format Serialized Description type string - \"state\" account string 32 bytes This account's nano_ address previous 64 hex-char string 32 bytes Previous head block on account; 0 if open block representative string 32 bytes Representative nano_ address balance decimal string 16 bytes Resulting balance (in raw ) link - 32 bytes Multipurpose field - see link table below signature 128 hex-char string 64 bytes ED25519+Blake2b 512-bit signature work 16 hex-char string 8 bytes Proof of Work Nonce Depending on the action each transaction intends to perform, the \"link\" field will have a different value for block_create RPC command: Action RPC Format Description Change string Must be \"0\" Send string Destination \"nano_\" address Receive 64 hex-char string Pairing block's hash (block sending funds) An example of a Nano block: \"block\": { \"type\": \"state\", \"account\": \"nano_3qgmh14nwztqw4wmcdzy4xpqeejey68chx6nciczwn9abji7ihhum9qtpmdr\", \"previous\": \"F47B23107E5F34B2CE06F562B5C435DF72A533251CB414C51B2B62A8F63A00E4\", \"representative\": \"nano_1hza3f7wiiqa7ig3jczyxj5yo86yegcmqk3criaz838j91sxcckpfhbhhra1\", \"balance\": \"1000000000000000000000\", \"link\": \"19D3D919475DEED4696B5D13018151D1AF88B2BD3BCFF048B45031C1F36D1858\", \"link_as_account\": \"nano_18gmu6engqhgtjnppqam181o5nfhj4sdtgyhy36dan3jr9spt84rzwmktafc\", \"signature\": \"3BFBA64A775550E6D49DF1EB8EEC2136DCD74F090E2ED658FBD9E80F17CB1C9F9F7BDE2B93D95558EC2F277FFF15FD11E6E2162A1714731B743D1E941FA4560A\", \"work\": \"cab7404f0b5449d0\" } Note that there is an open proposal to update the state block with version, block height, and subtype fields. Account balance \u00b6 If an account balance decreases, the transaction that caused the decrease is considered a send. Similarly, if an account balance increases, the transaction that caused the increase is considered a receive. Block vs. transaction \u00b6 In traditional blockchain-based cryptocurrencies like Bitcoin, a block is a group of transactions. In Nano, a block is a single transaction, so the term \u201cblock\u201d and \u201ctransaction\u201d are often used interchangeably. \"Transaction\" specifically refers to the action, while block refers to the digital encoding of the transaction. Transactions are signed by the private-key belonging to the account on which the transaction is performed. Creating transactions \u00b6 Open (Receive) \u00b6 To create an account, an open transaction must be issued first. This is always the first transaction (block height 1) of every account-chain and can be created upon the first receipt of funds. To open an account, you must have sent some funds to it with a send transaction from another account. The funds will be pending on the receiving account. The account field stores the public-key (address) derived from the private-key that is used for signing. The link field contains the hash of the transaction that sent the funds. On account creation, a representative must be chosen to vote on your behalf; this can be changed later. The account can declare itself as its own representative. Send \u00b6 A send transaction is one that decreases the sender's account balance by the amount they intend to send. To send from an address, the address must already have been opened with an open (receive) block and therefore will have a balance. The previous field contains the hash of the previous block in the account-chain. The link field contains the account for funds to be sent to. A send block is immutable once confirmed by the network. This means the funds are deducted from the balance of the sender's account and wait as pending until the receiving party signs a block to accept these funds. Pending funds should not be considered awaiting confirmation, as they are as good as spent from the senders account and the sender cannot revoke the transaction. Receive \u00b6 A receive block is very similar to the send block mentioned above, except the account balance is increasing and the link field contains the send block's hash. To complete a transaction, the recipient of sent funds must create a receive block on their own account-chain. The source field references the hash of the associated send transaction. Once this block is created and broadcasted, the account's balance is updated and the funds have officially moved into their account. Change rep \u00b6 Nano account holders have the ability to choose a representative to vote on their behalf. This can be done any time (i.e. in an open, send, or receive transaction) by changing the representative field. In conventional PoS systems, the account owner\u2019s node must be continuosly running to participate in voting. This is impractical for many users, so to remove this requirement Nano was designed to give a representative the power to vote on an account\u2019s behalf. A change transaction is what changes the representative of an account by subtracting the vote weight from the old representative and adding the weight to the new representative. No funds are moved in this transaction, and the representative does not have spending power of the account\u2019s funds. Epoch blocks \u00b6 Since all accounts on the Nano network are asynchronous, an asynchronous form of chain upgrades is needed. Unlike Bitcoin and other traditional blockchains, Nano is not able to say \u201cupgrade at block X\u201d, so Epoch blocks were one of the approaches developed to solve this problem. Epoch blocks are a special block type that can only be generated using a pre-determined private key currently owned by the Nano Foundation . These blocks will be accepted by nodes and be attached as the frontier blocks on each account-chain on the network. This feature was built to allow very limited controls using these blocks: they cannot change account balances or representatives, only upgrade the account versions to allow new block structures. Furthermore, if the majority of the network does not upgrade to a new node version that enables a particular epoch block, then the epoch block will have minimal or no effect. As an account-chain upgrade, Epoch blocks move accounts on the network from Epoch X to Epoch X+1. Any future transactions from an upgraded account will have a minimum version of X+1, which cannot be received by previous node versions. Epoch blocks are unable to change any balances or representatives on accounts. If an epoch block did attempt to change the balance of an account, the node would reject it because the signature would be incorrect, as only the account-chain holder can sign blocks which change balances or representatives. Existing whitepaper sections related to this page: Nano Components System Overview Existing content: Athena and Epoch v2 Blocks Explained Blocks specifications Creating transactions Nano 101: Epoch Blocks Nano How 2: Blocks and Lattices Network Upgrades details on epoch blocks","title":"Blocks"},{"location":"protocol-design/blocks/#protocol-design-blocks","text":"Part of work in progress Living Whitepaper This page is part of the Living Whitepaper revisions currently underway to replace the original static whitepaper. These efforts include the Protocol Design and Node Implementation sections of the docs, which will cover and expand on details and topics covered in the original whitepaper . See the bottom of the page for related whitepaper sections and other related details. Some of the sections and headers on this page may be in draft form or just suggestions/framework for later consideration. If you are interested in helping with revisions please connect with us on the #documentation channel on our Discord server . Key terms in this section block is the digital encoding of the transaction details. transaction is the action of creating and publishing a block to the network. Depending on the type of transaction, the block will have different requirements. transfer is the completion of both a send transaction and the corresponding receive transaction, representing the movement of funds which can be sent again by the recipient.","title":"Protocol Design - Blocks"},{"location":"protocol-design/blocks/#state-blocks","text":"All new transactions on the Nano Protocol are communicated via blocks. The account's entire state, including the balance after each transaction, is recorded in every block. Transaction amounts are interpreted as the difference in balance between consecutive blocks. Key RPC Format Serialized Description type string - \"state\" account string 32 bytes This account's nano_ address previous 64 hex-char string 32 bytes Previous head block on account; 0 if open block representative string 32 bytes Representative nano_ address balance decimal string 16 bytes Resulting balance (in raw ) link - 32 bytes Multipurpose field - see link table below signature 128 hex-char string 64 bytes ED25519+Blake2b 512-bit signature work 16 hex-char string 8 bytes Proof of Work Nonce Depending on the action each transaction intends to perform, the \"link\" field will have a different value for block_create RPC command: Action RPC Format Description Change string Must be \"0\" Send string Destination \"nano_\" address Receive 64 hex-char string Pairing block's hash (block sending funds) An example of a Nano block: \"block\": { \"type\": \"state\", \"account\": \"nano_3qgmh14nwztqw4wmcdzy4xpqeejey68chx6nciczwn9abji7ihhum9qtpmdr\", \"previous\": \"F47B23107E5F34B2CE06F562B5C435DF72A533251CB414C51B2B62A8F63A00E4\", \"representative\": \"nano_1hza3f7wiiqa7ig3jczyxj5yo86yegcmqk3criaz838j91sxcckpfhbhhra1\", \"balance\": \"1000000000000000000000\", \"link\": \"19D3D919475DEED4696B5D13018151D1AF88B2BD3BCFF048B45031C1F36D1858\", \"link_as_account\": \"nano_18gmu6engqhgtjnppqam181o5nfhj4sdtgyhy36dan3jr9spt84rzwmktafc\", \"signature\": \"3BFBA64A775550E6D49DF1EB8EEC2136DCD74F090E2ED658FBD9E80F17CB1C9F9F7BDE2B93D95558EC2F277FFF15FD11E6E2162A1714731B743D1E941FA4560A\", \"work\": \"cab7404f0b5449d0\" } Note that there is an open proposal to update the state block with version, block height, and subtype fields.","title":"State Blocks"},{"location":"protocol-design/blocks/#account-balance","text":"If an account balance decreases, the transaction that caused the decrease is considered a send. Similarly, if an account balance increases, the transaction that caused the increase is considered a receive.","title":"Account balance"},{"location":"protocol-design/blocks/#block-vs-transaction","text":"In traditional blockchain-based cryptocurrencies like Bitcoin, a block is a group of transactions. In Nano, a block is a single transaction, so the term \u201cblock\u201d and \u201ctransaction\u201d are often used interchangeably. \"Transaction\" specifically refers to the action, while block refers to the digital encoding of the transaction. Transactions are signed by the private-key belonging to the account on which the transaction is performed.","title":"Block vs. transaction"},{"location":"protocol-design/blocks/#creating-transactions","text":"","title":"Creating transactions"},{"location":"protocol-design/blocks/#open-receive","text":"To create an account, an open transaction must be issued first. This is always the first transaction (block height 1) of every account-chain and can be created upon the first receipt of funds. To open an account, you must have sent some funds to it with a send transaction from another account. The funds will be pending on the receiving account. The account field stores the public-key (address) derived from the private-key that is used for signing. The link field contains the hash of the transaction that sent the funds. On account creation, a representative must be chosen to vote on your behalf; this can be changed later. The account can declare itself as its own representative.","title":"Open (Receive)"},{"location":"protocol-design/blocks/#send","text":"A send transaction is one that decreases the sender's account balance by the amount they intend to send. To send from an address, the address must already have been opened with an open (receive) block and therefore will have a balance. The previous field contains the hash of the previous block in the account-chain. The link field contains the account for funds to be sent to. A send block is immutable once confirmed by the network. This means the funds are deducted from the balance of the sender's account and wait as pending until the receiving party signs a block to accept these funds. Pending funds should not be considered awaiting confirmation, as they are as good as spent from the senders account and the sender cannot revoke the transaction.","title":"Send"},{"location":"protocol-design/blocks/#receive","text":"A receive block is very similar to the send block mentioned above, except the account balance is increasing and the link field contains the send block's hash. To complete a transaction, the recipient of sent funds must create a receive block on their own account-chain. The source field references the hash of the associated send transaction. Once this block is created and broadcasted, the account's balance is updated and the funds have officially moved into their account.","title":"Receive"},{"location":"protocol-design/blocks/#change-rep","text":"Nano account holders have the ability to choose a representative to vote on their behalf. This can be done any time (i.e. in an open, send, or receive transaction) by changing the representative field. In conventional PoS systems, the account owner\u2019s node must be continuosly running to participate in voting. This is impractical for many users, so to remove this requirement Nano was designed to give a representative the power to vote on an account\u2019s behalf. A change transaction is what changes the representative of an account by subtracting the vote weight from the old representative and adding the weight to the new representative. No funds are moved in this transaction, and the representative does not have spending power of the account\u2019s funds.","title":"Change rep"},{"location":"protocol-design/blocks/#epoch-blocks","text":"Since all accounts on the Nano network are asynchronous, an asynchronous form of chain upgrades is needed. Unlike Bitcoin and other traditional blockchains, Nano is not able to say \u201cupgrade at block X\u201d, so Epoch blocks were one of the approaches developed to solve this problem. Epoch blocks are a special block type that can only be generated using a pre-determined private key currently owned by the Nano Foundation . These blocks will be accepted by nodes and be attached as the frontier blocks on each account-chain on the network. This feature was built to allow very limited controls using these blocks: they cannot change account balances or representatives, only upgrade the account versions to allow new block structures. Furthermore, if the majority of the network does not upgrade to a new node version that enables a particular epoch block, then the epoch block will have minimal or no effect. As an account-chain upgrade, Epoch blocks move accounts on the network from Epoch X to Epoch X+1. Any future transactions from an upgraded account will have a minimum version of X+1, which cannot be received by previous node versions. Epoch blocks are unable to change any balances or representatives on accounts. If an epoch block did attempt to change the balance of an account, the node would reject it because the signature would be incorrect, as only the account-chain holder can sign blocks which change balances or representatives. Existing whitepaper sections related to this page: Nano Components System Overview Existing content: Athena and Epoch v2 Blocks Explained Blocks specifications Creating transactions Nano 101: Epoch Blocks Nano How 2: Blocks and Lattices Network Upgrades details on epoch blocks","title":"Epoch blocks"},{"location":"protocol-design/distribution-and-units/","text":"Protocol Design - Distribution and Units \u00b6 Page may be migrating This page may be migrated into another page or section - TBD. Part of work in progress Living Whitepaper This page is part of the Living Whitepaper revisions currently underway to replace the original static whitepaper. These efforts include the Protocol Design and Node Implementation sections of the docs, which will cover and expand on details and topics covered in the original whitepaper . See the bottom of the page for related whitepaper sections and other related details. Some of the sections and headers on this page may be in draft form or just suggestions/framework for later consideration. If you are interested in helping with revisions please connect with us on the #documentation channel on our Discord server . Divisibility \u00b6 There are three important aspects of divisibility of the supply which are satisfied by the final distributed amount: The supply needs to be able to be divided up amongst a large number of users with users possibly wanting several accounts. Each account needs to be able to represent an adequate dynamic range of value. The supply should be able to deal with deflation over time as accounts are abandoned. Distribution \u00b6 The distribution of Nano (formerly RaiBlocks) was performed through solving manual captchas starting in late 2015 and ending in October 2017. Distribution stopped after ~39% of the Genesis amount was distributed and the rest of the supply was burnt. 1 Distribution Accounts Genesis : nano_3t6k35gi95xu6tergt6p69ck76ogmitsa8mnijtpxm9fkcm736xtoncuohr3 Landing : nano_13ezf4od79h1tgj9aiu4djzcmmguendtjfuhwfukhuucboua8cpoihmh8byo Faucet : nano_35jjmmmh81kydepzeuf9oec8hzkay7msr6yxagzxpcht7thwa5bus5tomgz9 Burn : nano_1111111111111111111111111111111111111111111111111111hifc8npp During distribution the Genesis seed was kept in cold storage and funds were moved to the Landing account once per week to minimize the number of live, undistributed blocks. These were subsequently moved into the Faucet account for distribution until the faucet was closed and remaining funds sent to the Burn account. Total Supply With 2^{128} - 1 2^{128} - 1 raw (i.e. FFFF FFFF FFFF FFFF FFFF FFFF FFFF FFFF HEX raw) in the original Genesis account, upon closing of the faucet and burning of the remaining funds, the total supply which is 100% in circulation ended at ~133,248,297 Nano (or more precisely 133248297920938463463374607431768211455 raw). Since then, additional funds have been sent to the known burn address slightly lowering the amount in circulation as a result. This amount can be found using the available_supply RPC. Unit Dividers \u00b6 A 128 bit integer is used to represent account balances. A set of SI prefixes 2 was used to make the numbers more accessible and avoid confusion. The reference wallet uses Mnano (or NANO/Nano) as a divider. Name SI Prefix Integer Power Gnano 1000000000000000000000000000000000 10^{33} 10^{33} NANO/Nano Mnano 1000000000000000000000000000000 10^{30} 10^{30} knano 1000000000000000000000000000 10^{27} 10^{27} nano 1000000000000000000000000 10^{24} 10^{24} mnano 1000000000000000000000 10^{21} 10^{21} \u03bcnano/unano 1000000000000000000 10^{18} 10^{18} raw 1 10^{0} 10^{0} 1 raw is the smallest possible division and NANO/Nano (Mnano) is the current standard division used in most wallets, on exchanges, etc. https://medium.com/nanocurrency/the-nano-faucet-c99e18ae1202 \u21a9 The SI prefixes are metric prefixes that were standardized for use in the International System of Units (SI) by the International Bureau of Weights and Measures (BIPM). https://www.bipm.org/en/measurement-units/prefixes.html \u21a9","title":"Distribution and Units"},{"location":"protocol-design/distribution-and-units/#protocol-design-distribution-and-units","text":"Page may be migrating This page may be migrated into another page or section - TBD. Part of work in progress Living Whitepaper This page is part of the Living Whitepaper revisions currently underway to replace the original static whitepaper. These efforts include the Protocol Design and Node Implementation sections of the docs, which will cover and expand on details and topics covered in the original whitepaper . See the bottom of the page for related whitepaper sections and other related details. Some of the sections and headers on this page may be in draft form or just suggestions/framework for later consideration. If you are interested in helping with revisions please connect with us on the #documentation channel on our Discord server .","title":"Protocol Design - Distribution and Units"},{"location":"protocol-design/distribution-and-units/#divisibility","text":"There are three important aspects of divisibility of the supply which are satisfied by the final distributed amount: The supply needs to be able to be divided up amongst a large number of users with users possibly wanting several accounts. Each account needs to be able to represent an adequate dynamic range of value. The supply should be able to deal with deflation over time as accounts are abandoned.","title":"Divisibility"},{"location":"protocol-design/distribution-and-units/#distribution","text":"The distribution of Nano (formerly RaiBlocks) was performed through solving manual captchas starting in late 2015 and ending in October 2017. Distribution stopped after ~39% of the Genesis amount was distributed and the rest of the supply was burnt. 1 Distribution Accounts Genesis : nano_3t6k35gi95xu6tergt6p69ck76ogmitsa8mnijtpxm9fkcm736xtoncuohr3 Landing : nano_13ezf4od79h1tgj9aiu4djzcmmguendtjfuhwfukhuucboua8cpoihmh8byo Faucet : nano_35jjmmmh81kydepzeuf9oec8hzkay7msr6yxagzxpcht7thwa5bus5tomgz9 Burn : nano_1111111111111111111111111111111111111111111111111111hifc8npp During distribution the Genesis seed was kept in cold storage and funds were moved to the Landing account once per week to minimize the number of live, undistributed blocks. These were subsequently moved into the Faucet account for distribution until the faucet was closed and remaining funds sent to the Burn account. Total Supply With 2^{128} - 1 2^{128} - 1 raw (i.e. FFFF FFFF FFFF FFFF FFFF FFFF FFFF FFFF HEX raw) in the original Genesis account, upon closing of the faucet and burning of the remaining funds, the total supply which is 100% in circulation ended at ~133,248,297 Nano (or more precisely 133248297920938463463374607431768211455 raw). Since then, additional funds have been sent to the known burn address slightly lowering the amount in circulation as a result. This amount can be found using the available_supply RPC.","title":"Distribution"},{"location":"protocol-design/distribution-and-units/#unit-dividers","text":"A 128 bit integer is used to represent account balances. A set of SI prefixes 2 was used to make the numbers more accessible and avoid confusion. The reference wallet uses Mnano (or NANO/Nano) as a divider. Name SI Prefix Integer Power Gnano 1000000000000000000000000000000000 10^{33} 10^{33} NANO/Nano Mnano 1000000000000000000000000000000 10^{30} 10^{30} knano 1000000000000000000000000000 10^{27} 10^{27} nano 1000000000000000000000000 10^{24} 10^{24} mnano 1000000000000000000000 10^{21} 10^{21} \u03bcnano/unano 1000000000000000000 10^{18} 10^{18} raw 1 10^{0} 10^{0} 1 raw is the smallest possible division and NANO/Nano (Mnano) is the current standard division used in most wallets, on exchanges, etc. https://medium.com/nanocurrency/the-nano-faucet-c99e18ae1202 \u21a9 The SI prefixes are metric prefixes that were standardized for use in the International System of Units (SI) by the International Bureau of Weights and Measures (BIPM). https://www.bipm.org/en/measurement-units/prefixes.html \u21a9","title":"Unit Dividers"},{"location":"protocol-design/introduction/","text":"Protocol Design - Introduction \u00b6 Part of work in progress Living Whitepaper This page is part of the Living Whitepaper revisions currently underway to replace the original static whitepaper. These efforts include the Protocol Design and Node Implementation sections of the docs, which will cover and expand on details and topics covered in the original whitepaper . See the bottom of the page for related whitepaper sections and other related details. Some of the sections and headers on this page may be in draft form or just suggestions/framework for later consideration. If you are interested in helping with revisions please connect with us on the #documentation channel on our Discord server . Contributing to the protocol If you are interested in helping develop the Nano protocol check out our details on contributing code to the Nano node as a starting point to understanding the current implementation contributions, as these are often tightly coupled with protocol-related changes. Living Whitepaper Information \u00b6 The following sections of the Living Whitepaper outline the design of the Nano protocol. The focus here is providing details of the blueprints for the different messages shared between nodes which allow data to be stored and communicated consistently across the network. The following Protocol Design sections are largely required to participate on the network, while the Node Implementation sections primarily cover functionality that improves performance and security through a specific node design. Abstract \u00b6 Since Bitcoin's release in 2009, there has been a growing shift away from traditional, government-backed currencies and financial systems towards modern payments systems based on cryptography, which offer the ability to store and transfer funds in a trustless and secure manner 1 . In order to function effectively, a currency must be easily transferable, non-reversible, and have limited or no fees. Unfortunately, increased transaction times, high fees, limited network scalability, and high energy consumption have raised questions about the practicality of Bitcoin as an everyday currency. Here we introduce Nano, a cryptocurrency with a novel block-lattice architecture where each account has its own blockchain, enabling near instant confirmation, feeless transactions, and scalability that is not artificially limited by protocol-side variables like block sizes or block times. Introduction \u00b6 Nano is a low-latency, feeless, scalable, and environmentally friendly cryptocurrency that improves on many of Bitcoin's core properties via unique design decisions. For example, each Nano user has their own blockchain, allowing them to update their chain asynchronously vs other transactions on the network, resulting in fast transactions with minimal overhead. Transactions keep track of account balances rather than transaction amounts, allowing aggressive database pruning without compromising security. Consensus is maintained by Open Representative Voting (ORV) , which facilitates irreversible finality (full-settlement). User-selected representative nodes vote on each transaction, and every node independently cements each transaction after seeing enough representative votes to achieve quorum . To date, the Nano network has processed more than 53 million transactions with an unpruned ledger size of only 25.33GB. Average transaction confirmation time during typical network conditions is 0.2 seconds 2 . The production network has seen traffic as high as 161 CPS (80.5-161 TPS), while the beta network has achieved >1800 CPS (900-1800 TPS) 3 . Nano\u2019s feeless, split-second transactions make it an ideal cryptocurrency for consumer transactions, while also maintaining decentralization, censorship-resistance, and self-sovereignty. Background \u00b6 In 2008, an anonymous individual under the pseudonym Satoshi Nakamoto published a whitepaper outlining the world\u2019s first decentralized cryptocurrency, Bitcoin 1 . A key innovation brought about by Bitcoin was the blockchain, a public, immutable and decentralized data-structure which is used as a ledger for the currency\u2019s transactions. Unfortunately, as Bitcoin matured, several issues in the protocol made Bitcoin prohibitive for many applications: Poor scalability: Each block in the blockchain can store a limited amount of data, which means the system can only process so many transactions per second, making spots in a block a commodity. Median transaction fees flucutate between a few cents and as high as $34 (currently ~$2.98 as of August 26, 2020) 4 . High latency: Average confirmation times fluctuate between 10 and 300 minutes 5 . In addition, most Bitcoin services require more than one confirmation before considering a transaction fully-settled 6 , which adds additional latency for end users. Power inefficient: The Bitcoin network consumes an estimated 67.26TWh per year (comparable to the power consumption of the Czech Republic), using an average of 570kWh per transaction 7 . Bitcoin, and other cryptocurrencies, function by achieving consensus on their global ledgers in order to verify legitimate transactions while resisting malicious actors. Bitcoin achieves consensus via an economic measure called Proof of Work (PoW). In a PoW system participants compete to compute a number, called a nonce, such that the hash of the entire block is in a target range. This valid range is inversely proportional to the cumulative computation power of the entire Bitcoin network in order to maintain a consistent average time taken to find a valid nonce. The finder of a valid nonce is then allowed to add the block to the blockchain; therefore, those who exhaust more computational resources to compute a nonce play a greater role in the state of the blockchain. PoW provides resistance against a Sybil attack, where an entity behaves as multiple entities to gain additional power in a decentralized system, and also greatly reduces race conditions that inherently exist while accessing a global data-structure. An alternative consensus protocol, Proof of Stake (PoS), was first introduced by Peercoin in 2012 8 . In a PoS system, participants vote with a weight equivalent to the amount of wealth they possess in a given cryptocurrency. With this arrangement, those who have a greater financial investment are given more power and are inherently incentivized to maintain the honesty of the system or risk losing their investment. PoS does away with the wasteful computation power competition, only requiring light-weight software running on low power hardware. While Nano uses a weighted-voting system that can be compared to PoS, it differs significantly from traditional PoS. See the Open Representative Voting (ORV) page for more details. The original Nano (RaiBlocks) paper and first beta implementation were published in December, 2014, making it one of the first Directed Acyclic Graph (DAG) based cryptocurrencies 9 . Soon after, other DAG cryptocurrencies began to develop, most notably DagCoin/Byteball and IOTA 10 , 11 . These DAG-based cryptocurrencies broke the blockchain mold, improving system performance and security. Byteball achieves consensus by relying on a \u201cmain-chain\u201d comprised of honest, reputable and user-trusted \u201cwitnesses\u201d, while IOTA achieves consensus via the cumulative PoW of stacked transactions. Nano achieves consensus via a balance-weighted vote on conflicting transactions. This consensus system provides quicker, more deterministic transactions while still maintaining a strong, decentralized system. Nano continues this development and has positioned itself as one of the highest performing cryptocurrencies. Existing whitepaper sections related to this page: Introduction Background Other existing content related to this page: Nano Overview Representatives and Voting Incentives to run a node S. Nakamoto, \u201cBitcoin: A peer-to-peer electronic cash system,\u201d 2008. [Online]. Available: http://bitcoin.org/bitcoin.pdf \u21a9 \u21a9 \"Block Confirmation Times\", 2020. [Online]. Available: https://repnode.org/network/confirmation \u21a9 \"Nano Stress Tests - Measuring BPS, CPS, & TPS in the real world\", 2020. [Online]. Available: https://forum.nano.org/t/nano-stress-tests-measuring-bps-cps-tps-in-the-real-world/436 \u21a9 \u201cBitcoin median transaction fee historical chart.\u201d [Online]. Available: https://bitinfocharts.com/comparison/bitcoin-median-transaction-fee.html \u21a9 \u201cBitcoin average confirmation time.\u201d [Online]. Available: https://www.blockchain.com/charts/avg-confirmation-time \u21a9 \"Irreversible Transactions - How many confirmation are required\", 2020. [Online]. Available: https://en.bitcoin.it/wiki/Irreversible_Transactions#How_many_confirmations_are_required \u21a9 \"Bitcoin Energy Consumption Index\", 2020. [Online]. Available: https://digiconomist.net/bitcoin-energy-consumption/ \u21a9 S. King and S. Nadal, \u201cPpcoin: Peer-to-peer crypto-currency withproof-of-stake,\u201d 2012. [Online]. Available: https://decred.org/research/king2012.pdf \u21a9 C. LeMahieu, \u201cRaiblocks distributed ledger network,\u201d 2014. https://content.nano.org/whitepaper/Nano_Whitepaper_en.pdf \u21a9 Y. Ribero and D. Raissar, \u201cDagcoin whitepaper,\u201d 2015. Available: https://dagcoin.org/wp-content/uploads/2019/07/Dagcoin_White_Paper.pdf \u21a9 S. Popov, \u201cThe tangle,\u201d 2016. Available: https://assets.ctfassets.net/r1dr6vzfxhev/2t4uxvsIqk0EUau6g2sw0g/45eae33637ca92f85dd9f4a3a218e1ec/iota1_4_3.pdf \u21a9","title":"Introduction"},{"location":"protocol-design/introduction/#protocol-design-introduction","text":"Part of work in progress Living Whitepaper This page is part of the Living Whitepaper revisions currently underway to replace the original static whitepaper. These efforts include the Protocol Design and Node Implementation sections of the docs, which will cover and expand on details and topics covered in the original whitepaper . See the bottom of the page for related whitepaper sections and other related details. Some of the sections and headers on this page may be in draft form or just suggestions/framework for later consideration. If you are interested in helping with revisions please connect with us on the #documentation channel on our Discord server . Contributing to the protocol If you are interested in helping develop the Nano protocol check out our details on contributing code to the Nano node as a starting point to understanding the current implementation contributions, as these are often tightly coupled with protocol-related changes.","title":"Protocol Design - Introduction"},{"location":"protocol-design/introduction/#living-whitepaper-information","text":"The following sections of the Living Whitepaper outline the design of the Nano protocol. The focus here is providing details of the blueprints for the different messages shared between nodes which allow data to be stored and communicated consistently across the network. The following Protocol Design sections are largely required to participate on the network, while the Node Implementation sections primarily cover functionality that improves performance and security through a specific node design.","title":"Living Whitepaper Information"},{"location":"protocol-design/introduction/#abstract","text":"Since Bitcoin's release in 2009, there has been a growing shift away from traditional, government-backed currencies and financial systems towards modern payments systems based on cryptography, which offer the ability to store and transfer funds in a trustless and secure manner 1 . In order to function effectively, a currency must be easily transferable, non-reversible, and have limited or no fees. Unfortunately, increased transaction times, high fees, limited network scalability, and high energy consumption have raised questions about the practicality of Bitcoin as an everyday currency. Here we introduce Nano, a cryptocurrency with a novel block-lattice architecture where each account has its own blockchain, enabling near instant confirmation, feeless transactions, and scalability that is not artificially limited by protocol-side variables like block sizes or block times.","title":"Abstract"},{"location":"protocol-design/introduction/#introduction","text":"Nano is a low-latency, feeless, scalable, and environmentally friendly cryptocurrency that improves on many of Bitcoin's core properties via unique design decisions. For example, each Nano user has their own blockchain, allowing them to update their chain asynchronously vs other transactions on the network, resulting in fast transactions with minimal overhead. Transactions keep track of account balances rather than transaction amounts, allowing aggressive database pruning without compromising security. Consensus is maintained by Open Representative Voting (ORV) , which facilitates irreversible finality (full-settlement). User-selected representative nodes vote on each transaction, and every node independently cements each transaction after seeing enough representative votes to achieve quorum . To date, the Nano network has processed more than 53 million transactions with an unpruned ledger size of only 25.33GB. Average transaction confirmation time during typical network conditions is 0.2 seconds 2 . The production network has seen traffic as high as 161 CPS (80.5-161 TPS), while the beta network has achieved >1800 CPS (900-1800 TPS) 3 . Nano\u2019s feeless, split-second transactions make it an ideal cryptocurrency for consumer transactions, while also maintaining decentralization, censorship-resistance, and self-sovereignty.","title":"Introduction"},{"location":"protocol-design/introduction/#background","text":"In 2008, an anonymous individual under the pseudonym Satoshi Nakamoto published a whitepaper outlining the world\u2019s first decentralized cryptocurrency, Bitcoin 1 . A key innovation brought about by Bitcoin was the blockchain, a public, immutable and decentralized data-structure which is used as a ledger for the currency\u2019s transactions. Unfortunately, as Bitcoin matured, several issues in the protocol made Bitcoin prohibitive for many applications: Poor scalability: Each block in the blockchain can store a limited amount of data, which means the system can only process so many transactions per second, making spots in a block a commodity. Median transaction fees flucutate between a few cents and as high as $34 (currently ~$2.98 as of August 26, 2020) 4 . High latency: Average confirmation times fluctuate between 10 and 300 minutes 5 . In addition, most Bitcoin services require more than one confirmation before considering a transaction fully-settled 6 , which adds additional latency for end users. Power inefficient: The Bitcoin network consumes an estimated 67.26TWh per year (comparable to the power consumption of the Czech Republic), using an average of 570kWh per transaction 7 . Bitcoin, and other cryptocurrencies, function by achieving consensus on their global ledgers in order to verify legitimate transactions while resisting malicious actors. Bitcoin achieves consensus via an economic measure called Proof of Work (PoW). In a PoW system participants compete to compute a number, called a nonce, such that the hash of the entire block is in a target range. This valid range is inversely proportional to the cumulative computation power of the entire Bitcoin network in order to maintain a consistent average time taken to find a valid nonce. The finder of a valid nonce is then allowed to add the block to the blockchain; therefore, those who exhaust more computational resources to compute a nonce play a greater role in the state of the blockchain. PoW provides resistance against a Sybil attack, where an entity behaves as multiple entities to gain additional power in a decentralized system, and also greatly reduces race conditions that inherently exist while accessing a global data-structure. An alternative consensus protocol, Proof of Stake (PoS), was first introduced by Peercoin in 2012 8 . In a PoS system, participants vote with a weight equivalent to the amount of wealth they possess in a given cryptocurrency. With this arrangement, those who have a greater financial investment are given more power and are inherently incentivized to maintain the honesty of the system or risk losing their investment. PoS does away with the wasteful computation power competition, only requiring light-weight software running on low power hardware. While Nano uses a weighted-voting system that can be compared to PoS, it differs significantly from traditional PoS. See the Open Representative Voting (ORV) page for more details. The original Nano (RaiBlocks) paper and first beta implementation were published in December, 2014, making it one of the first Directed Acyclic Graph (DAG) based cryptocurrencies 9 . Soon after, other DAG cryptocurrencies began to develop, most notably DagCoin/Byteball and IOTA 10 , 11 . These DAG-based cryptocurrencies broke the blockchain mold, improving system performance and security. Byteball achieves consensus by relying on a \u201cmain-chain\u201d comprised of honest, reputable and user-trusted \u201cwitnesses\u201d, while IOTA achieves consensus via the cumulative PoW of stacked transactions. Nano achieves consensus via a balance-weighted vote on conflicting transactions. This consensus system provides quicker, more deterministic transactions while still maintaining a strong, decentralized system. Nano continues this development and has positioned itself as one of the highest performing cryptocurrencies. Existing whitepaper sections related to this page: Introduction Background Other existing content related to this page: Nano Overview Representatives and Voting Incentives to run a node S. Nakamoto, \u201cBitcoin: A peer-to-peer electronic cash system,\u201d 2008. [Online]. Available: http://bitcoin.org/bitcoin.pdf \u21a9 \u21a9 \"Block Confirmation Times\", 2020. [Online]. Available: https://repnode.org/network/confirmation \u21a9 \"Nano Stress Tests - Measuring BPS, CPS, & TPS in the real world\", 2020. [Online]. Available: https://forum.nano.org/t/nano-stress-tests-measuring-bps-cps-tps-in-the-real-world/436 \u21a9 \u201cBitcoin median transaction fee historical chart.\u201d [Online]. Available: https://bitinfocharts.com/comparison/bitcoin-median-transaction-fee.html \u21a9 \u201cBitcoin average confirmation time.\u201d [Online]. Available: https://www.blockchain.com/charts/avg-confirmation-time \u21a9 \"Irreversible Transactions - How many confirmation are required\", 2020. [Online]. Available: https://en.bitcoin.it/wiki/Irreversible_Transactions#How_many_confirmations_are_required \u21a9 \"Bitcoin Energy Consumption Index\", 2020. [Online]. Available: https://digiconomist.net/bitcoin-energy-consumption/ \u21a9 S. King and S. Nadal, \u201cPpcoin: Peer-to-peer crypto-currency withproof-of-stake,\u201d 2012. [Online]. Available: https://decred.org/research/king2012.pdf \u21a9 C. LeMahieu, \u201cRaiblocks distributed ledger network,\u201d 2014. https://content.nano.org/whitepaper/Nano_Whitepaper_en.pdf \u21a9 Y. Ribero and D. Raissar, \u201cDagcoin whitepaper,\u201d 2015. Available: https://dagcoin.org/wp-content/uploads/2019/07/Dagcoin_White_Paper.pdf \u21a9 S. Popov, \u201cThe tangle,\u201d 2016. Available: https://assets.ctfassets.net/r1dr6vzfxhev/2t4uxvsIqk0EUau6g2sw0g/45eae33637ca92f85dd9f4a3a218e1ec/iota1_4_3.pdf \u21a9","title":"Background"},{"location":"protocol-design/ledger/","text":"Protocol Design - Ledger \u00b6 Part of work in progress Living Whitepaper This page is part of the Living Whitepaper revisions currently underway to replace the original static whitepaper. These efforts include the Protocol Design and Node Implementation sections of the docs, which will cover and expand on details and topics covered in the original whitepaper . See the bottom of the page for related whitepaper sections and other related details. Some of the sections and headers on this page may be in draft form or just suggestions/framework for later consideration. If you are interested in helping with revisions please connect with us on the #documentation channel on our Discord server . Ledger design \u00b6 The Nano ledger is the global set of accounts where each account has its own chain of transactions ( Figure 1 ). This is a key design component that falls under the category of replacing a run-time agreement with a design-time agreement - everyone agrees via signature checking that only an account owner can modify the balance and representative on their own chain. This converts a seemingly shared data structure (a global blockchain) into a set of non-shared ones (individual account-chains). Each Nano node determines for itself whether or not to add a valid transaction to its local ledger. This means that there is no waiting for leader-selection as there is in single-blockchain cryptocurrencies like Bitcoin, where a single miner or staker extends the global blockchain with a new block (group of transactions) after solving a Proof-of-Work or being chosen through random selection. The block lattice ledger design removes this bottleneck, drastically decreasing transaction latency, improving decentralization, and simplifying transaction validation. Nano has no concept of block sizes or block times that arbitrarily limit the number of transactions that can be processed - the network will confirm as many transactions as current network conditions allow. Figure 1. Each account has its own blockchain containing the account\u2019s balance history. Block 1 must be a receive transaction with it's previous field as constant 0 . Accounts \u00b6 An account is the public-key portion of a digital signature key-pair. The public-key, also referred to as the address, is shared with other network participants while the private-key is kept secret. A digitally signed packet of data ensures that the contents were approved by the private-key holder. One user may control many accounts, but only one public address may exist per account. Although a special private key can be used to publish epoch transactions to all accounts, the only changes allowed for this special type of transaction are related to upgrading the account version. This means that account owners are the only ones who can modify the balance and representative on their own account chains and thus contention only happens on a per-account basis or in relation to epoch distributions 1 . For example, if account A attempts a double spend that must be resolved by the network, account B can still make transactions as normal. Transactions are processed independently and asynchronously. Blocks \u00b6 In traditional blockchain-based cryptocurrencies like Bitcoin, a block is a group of transactions. In Nano, a block contains the details of a single transaction. There are four different transaction types in Nano (send, receive, change representative and epoch) and in order to transfer funds, two transactions are required - a send transaction and a receive transaction. This difference in transaction structures means the terminology used can have different meanings, so it is worth defining these more explicitly: block is the digital encoding of the transaction details ( Figure 2 ). transaction is the action of creating and publishing a block to the network. Depending on the type of transaction, the block will have different requirements. transfer is the completion of both a send transaction and the corresponding receive transaction, representing the movement of funds which can be sent again by the recipient. \"block\": { \"type\": \"state\", \"account\": \"nano_3qgmh14nwztqw4wmcdzy4xpqeejey68chx6nciczwn9abji7ihhum9qtpmdr\", \"previous\": \"F47B23107E5F34B2CE06F562B5C435DF72A533251CB414C51B2B62A8F63A00E4\", \"representative\": \"nano_1hza3f7wiiqa7ig3jczyxj5yo86yegcmqk3criaz838j91sxcckpfhbhhra1\", \"balance\": \"1000000000000000000000\", \"link\": \"19D3D919475DEED4696B5D13018151D1AF88B2BD3BCFF048B45031C1F36D1858\", \"link_as_account\": \"nano_18gmu6engqhgtjnppqam181o5nfhj4sdtgyhy36dan3jr9spt84rzwmktafc\", \"signature\": \"3BFBA64A775550E6D49DF1EB8EEC2136DCD74F090E2ED658FBD9E80F17CB1C9F9F7BDE2B93D95558EC2F277FFF15FD11E6E2162A1714731B743D1E941FA4560A\", \"work\": \"cab7404f0b5449d0\" } Figure 2 - An example Nano block with all required fields Note that there is an open proposal to update the state block with version, block height, and subtype fields. Why require two transactions to transfer \u00b6 Although send transactions confirmed by the network are irreversible, in order for the recipient to send those funds again they first must complete a receive transaction on their account. This receiving requirement to complete a transfer of funds provides a few benefits: Sending of funds can be performed while the receiver is offline Account owners are the only ones who are allowed to modify the balance and representative on their accounts Allows account owners to ignore transactions, which prevents continuous sending of tiny amounts in an attempt to can prevent use of the account Block lattice \u00b6 The lattice structure of the ledger arises from blocks connecting across account-chains. All block types use the previous field to vertically extend the account-chain. In addition, send and receive blocks also use the link field to connect across account-chains. Figure 3 below illustrates the lattice structure at a high level with additional details about blocks available on the blocks page. As illustrated above, the ledger was initiated with a genesis account containing the genesis balance. The genesis balance was a fixed quantity and can never be increased. The genesis balance was divided across various accounts via send transactions registered on the genesis account-chain. The sum of the balances of all accounts in the ledger will never exceed the initial genesis balance, which gives the system an upper bound on quantity and no ability to increase it. Ledger pruning \u00b6 Since Nano every transaction includes a block with the complete current state of an account, the ledger can be significantly pruned. While there are a few exceptions (e.g. pending transactions), Nano's ledger design could be pruned down to one block per account (plus pending), regardless of how many transactions the account has sent or received. Note that pruning is not implemented yet, and exact implementation details are still being tested and discussed. See the official forum or GitHub discussions for more detail. Existing whitepaper sections related to this page: Nano Components Other existing content related to this page: Block Lattice design Accounts, Keys, Seeds, etc. Looking up to Confirmation Height Ledger Management guide Epoch blocks details, Network Upgrades documentation: https://docs.nano.org/releases/network-upgrades/#epoch-blocks \u21a9","title":"Ledger"},{"location":"protocol-design/ledger/#protocol-design-ledger","text":"Part of work in progress Living Whitepaper This page is part of the Living Whitepaper revisions currently underway to replace the original static whitepaper. These efforts include the Protocol Design and Node Implementation sections of the docs, which will cover and expand on details and topics covered in the original whitepaper . See the bottom of the page for related whitepaper sections and other related details. Some of the sections and headers on this page may be in draft form or just suggestions/framework for later consideration. If you are interested in helping with revisions please connect with us on the #documentation channel on our Discord server .","title":"Protocol Design - Ledger"},{"location":"protocol-design/ledger/#ledger-design","text":"The Nano ledger is the global set of accounts where each account has its own chain of transactions ( Figure 1 ). This is a key design component that falls under the category of replacing a run-time agreement with a design-time agreement - everyone agrees via signature checking that only an account owner can modify the balance and representative on their own chain. This converts a seemingly shared data structure (a global blockchain) into a set of non-shared ones (individual account-chains). Each Nano node determines for itself whether or not to add a valid transaction to its local ledger. This means that there is no waiting for leader-selection as there is in single-blockchain cryptocurrencies like Bitcoin, where a single miner or staker extends the global blockchain with a new block (group of transactions) after solving a Proof-of-Work or being chosen through random selection. The block lattice ledger design removes this bottleneck, drastically decreasing transaction latency, improving decentralization, and simplifying transaction validation. Nano has no concept of block sizes or block times that arbitrarily limit the number of transactions that can be processed - the network will confirm as many transactions as current network conditions allow. Figure 1. Each account has its own blockchain containing the account\u2019s balance history. Block 1 must be a receive transaction with it's previous field as constant 0 .","title":"Ledger design"},{"location":"protocol-design/ledger/#accounts","text":"An account is the public-key portion of a digital signature key-pair. The public-key, also referred to as the address, is shared with other network participants while the private-key is kept secret. A digitally signed packet of data ensures that the contents were approved by the private-key holder. One user may control many accounts, but only one public address may exist per account. Although a special private key can be used to publish epoch transactions to all accounts, the only changes allowed for this special type of transaction are related to upgrading the account version. This means that account owners are the only ones who can modify the balance and representative on their own account chains and thus contention only happens on a per-account basis or in relation to epoch distributions 1 . For example, if account A attempts a double spend that must be resolved by the network, account B can still make transactions as normal. Transactions are processed independently and asynchronously.","title":"Accounts"},{"location":"protocol-design/ledger/#blocks","text":"In traditional blockchain-based cryptocurrencies like Bitcoin, a block is a group of transactions. In Nano, a block contains the details of a single transaction. There are four different transaction types in Nano (send, receive, change representative and epoch) and in order to transfer funds, two transactions are required - a send transaction and a receive transaction. This difference in transaction structures means the terminology used can have different meanings, so it is worth defining these more explicitly: block is the digital encoding of the transaction details ( Figure 2 ). transaction is the action of creating and publishing a block to the network. Depending on the type of transaction, the block will have different requirements. transfer is the completion of both a send transaction and the corresponding receive transaction, representing the movement of funds which can be sent again by the recipient. \"block\": { \"type\": \"state\", \"account\": \"nano_3qgmh14nwztqw4wmcdzy4xpqeejey68chx6nciczwn9abji7ihhum9qtpmdr\", \"previous\": \"F47B23107E5F34B2CE06F562B5C435DF72A533251CB414C51B2B62A8F63A00E4\", \"representative\": \"nano_1hza3f7wiiqa7ig3jczyxj5yo86yegcmqk3criaz838j91sxcckpfhbhhra1\", \"balance\": \"1000000000000000000000\", \"link\": \"19D3D919475DEED4696B5D13018151D1AF88B2BD3BCFF048B45031C1F36D1858\", \"link_as_account\": \"nano_18gmu6engqhgtjnppqam181o5nfhj4sdtgyhy36dan3jr9spt84rzwmktafc\", \"signature\": \"3BFBA64A775550E6D49DF1EB8EEC2136DCD74F090E2ED658FBD9E80F17CB1C9F9F7BDE2B93D95558EC2F277FFF15FD11E6E2162A1714731B743D1E941FA4560A\", \"work\": \"cab7404f0b5449d0\" } Figure 2 - An example Nano block with all required fields Note that there is an open proposal to update the state block with version, block height, and subtype fields.","title":"Blocks"},{"location":"protocol-design/ledger/#why-require-two-transactions-to-transfer","text":"Although send transactions confirmed by the network are irreversible, in order for the recipient to send those funds again they first must complete a receive transaction on their account. This receiving requirement to complete a transfer of funds provides a few benefits: Sending of funds can be performed while the receiver is offline Account owners are the only ones who are allowed to modify the balance and representative on their accounts Allows account owners to ignore transactions, which prevents continuous sending of tiny amounts in an attempt to can prevent use of the account","title":"Why require two transactions to transfer"},{"location":"protocol-design/ledger/#block-lattice","text":"The lattice structure of the ledger arises from blocks connecting across account-chains. All block types use the previous field to vertically extend the account-chain. In addition, send and receive blocks also use the link field to connect across account-chains. Figure 3 below illustrates the lattice structure at a high level with additional details about blocks available on the blocks page. As illustrated above, the ledger was initiated with a genesis account containing the genesis balance. The genesis balance was a fixed quantity and can never be increased. The genesis balance was divided across various accounts via send transactions registered on the genesis account-chain. The sum of the balances of all accounts in the ledger will never exceed the initial genesis balance, which gives the system an upper bound on quantity and no ability to increase it.","title":"Block lattice"},{"location":"protocol-design/ledger/#ledger-pruning","text":"Since Nano every transaction includes a block with the complete current state of an account, the ledger can be significantly pruned. While there are a few exceptions (e.g. pending transactions), Nano's ledger design could be pruned down to one block per account (plus pending), regardless of how many transactions the account has sent or received. Note that pruning is not implemented yet, and exact implementation details are still being tested and discussed. See the official forum or GitHub discussions for more detail. Existing whitepaper sections related to this page: Nano Components Other existing content related to this page: Block Lattice design Accounts, Keys, Seeds, etc. Looking up to Confirmation Height Ledger Management guide Epoch blocks details, Network Upgrades documentation: https://docs.nano.org/releases/network-upgrades/#epoch-blocks \u21a9","title":"Ledger pruning"},{"location":"protocol-design/networking/","text":"Protocol Design - Networking \u00b6 Part of work in progress Living Whitepaper This page is part of the Living Whitepaper revisions currently underway to replace the original static whitepaper. These efforts include the Protocol Design and Node Implementation sections of the docs, which will cover and expand on details and topics covered in the original whitepaper . See the bottom of the page for related whitepaper sections and other related details. Some of the sections and headers on this page may be in draft form or just suggestions/framework for later consideration. If you are interested in helping with revisions please connect with us on the #documentation channel on our Discord server . UDP and TCP messages \u00b6 Nano is designed to use the minimum amount of computing resources possible by communicating via stateless messages that fit within a single UDP packet. UDP is used for traffic on the live network while connections via TCP are leveraged for bulk data transfer on the bootstrap network . Network Details \u00b6 Port Type Default Details 7075 TCP Enabled Node bootstrapping server Share port configuration in config-node.toml , option node.peering_port Binds to all adapters; unicast Contents: Raw nano protocol stream Transmits the ledger to new nodes in bulk If blocked other nodes will not be able retrieve the ledger from this node 7076 TCP Disabled RPC server Port configurable in config-rpc.toml , option rpc.port Enable in config-node.toml , option rpc.enable or by starting nano_rpc manually Binds to localhost by default for security reasons, configurable in config-rpc.toml , option rpc.address ; unicast Contents: Unencrypted HTTP requests containing JSON object bodies Allows the node to be queried or controlled through HTTP requests If blocked the node will not be able to be queried or controlled by HTTP WARNING: Exposing this port externally while setting enable_control option to true in configs could expose your wallet, allow the node to be stopped remotely and open your node up to other dangerous activity. See the Node Security page for more details. 7078 TCP Disabled Websocket server Port configurable in config-node.toml , option node.websocket.port Enable in config-node.toml , option node.websocket.enable Binds to localhost by default due to data throughput potentially being very high; producer-subscriber broadcast Contents: Standard websocket frames containing JSON-encoded objects See WebSocket Support for details on configuration 7075 UDP Disabled Deprecated (V21+) Previously this was the node activity port (deprecated in V21) Port configurable in config-node.toml , option node.peering_port Binds to all adapters; unicast Contents: Raw nano protocol datagrams All standard ledger activity goes through this port If blocked the node will not function UDP disabled by default, deprecated As of V21 peering and communicating via UDP has been disabled by default and is deprecated. The ability to use UDP will be removed from the node in a future release yet to be determined. IPV4/IPV6 addressing \u00b6 The system is built to only operate on IPv6 and uses IPv4-mapped IPv6 addresses to connect to IPv4 hosts. Node telemetry \u00b6 In v21 node telemetry was added to node. This allows peers to communicate telemetry metrics to each other. For specific details on the message format see telemetry_ack in the protocol specification . The nodes are designed to reply to telemetry_req messages. They avoid replying if messages are received from the same peer in quick succession; the minimum time until another reply is 60 seconds on the main network, 15 seconds on beta. This is done to reduce bandwidth. Telemetry messsages bypass the node's bandwidth limiter so that services monitoring the network can still do so during when the network is heavily used. Sending telemetry_req frequently within this exclusion zone could see your ip blacklisted by other peers. The node safely handles this for you by doing ongoing requests periodically and only sent when valid to do so. Signing \u00b6 Telemetry_ack messages are signed using ED25519 as follows: ED25519(key = node id public key, message = \"node id || block count || cemented count|| unchecked count || account count || bandwidth capacity || peer count || protocol version || uptime || genesis block hash || major version || minor version || patch version || pre-release version || maker || timestamp since UTC epoch || active difficulty\") The node id used in the initial handshake is used for signing. The genesis block hash should be in big endian. The data is signed so that it cannot be forged by a Man In The Middle (MITM) attack. Peer disconnections Sending incorrectly signed telemetry data to peers will result in being blacklisted as it is seen as malicious, make sure the signing is correct! Verify signatures against known signing done by node by testing local telemetry . Nodes with a different genesis block hash will also be disconnected. Peering process \u00b6 Live traffic \u00b6 Bootstrap traffic \u00b6 Existing whitepaper sections related to this page: Networking","title":"Networking"},{"location":"protocol-design/networking/#protocol-design-networking","text":"Part of work in progress Living Whitepaper This page is part of the Living Whitepaper revisions currently underway to replace the original static whitepaper. These efforts include the Protocol Design and Node Implementation sections of the docs, which will cover and expand on details and topics covered in the original whitepaper . See the bottom of the page for related whitepaper sections and other related details. Some of the sections and headers on this page may be in draft form or just suggestions/framework for later consideration. If you are interested in helping with revisions please connect with us on the #documentation channel on our Discord server .","title":"Protocol Design - Networking"},{"location":"protocol-design/networking/#udp-and-tcp-messages","text":"Nano is designed to use the minimum amount of computing resources possible by communicating via stateless messages that fit within a single UDP packet. UDP is used for traffic on the live network while connections via TCP are leveraged for bulk data transfer on the bootstrap network .","title":"UDP and TCP messages"},{"location":"protocol-design/networking/#network-details","text":"Port Type Default Details 7075 TCP Enabled Node bootstrapping server Share port configuration in config-node.toml , option node.peering_port Binds to all adapters; unicast Contents: Raw nano protocol stream Transmits the ledger to new nodes in bulk If blocked other nodes will not be able retrieve the ledger from this node 7076 TCP Disabled RPC server Port configurable in config-rpc.toml , option rpc.port Enable in config-node.toml , option rpc.enable or by starting nano_rpc manually Binds to localhost by default for security reasons, configurable in config-rpc.toml , option rpc.address ; unicast Contents: Unencrypted HTTP requests containing JSON object bodies Allows the node to be queried or controlled through HTTP requests If blocked the node will not be able to be queried or controlled by HTTP WARNING: Exposing this port externally while setting enable_control option to true in configs could expose your wallet, allow the node to be stopped remotely and open your node up to other dangerous activity. See the Node Security page for more details. 7078 TCP Disabled Websocket server Port configurable in config-node.toml , option node.websocket.port Enable in config-node.toml , option node.websocket.enable Binds to localhost by default due to data throughput potentially being very high; producer-subscriber broadcast Contents: Standard websocket frames containing JSON-encoded objects See WebSocket Support for details on configuration 7075 UDP Disabled Deprecated (V21+) Previously this was the node activity port (deprecated in V21) Port configurable in config-node.toml , option node.peering_port Binds to all adapters; unicast Contents: Raw nano protocol datagrams All standard ledger activity goes through this port If blocked the node will not function UDP disabled by default, deprecated As of V21 peering and communicating via UDP has been disabled by default and is deprecated. The ability to use UDP will be removed from the node in a future release yet to be determined.","title":"Network Details"},{"location":"protocol-design/networking/#ipv4ipv6-addressing","text":"The system is built to only operate on IPv6 and uses IPv4-mapped IPv6 addresses to connect to IPv4 hosts.","title":"IPV4/IPV6 addressing"},{"location":"protocol-design/networking/#node-telemetry","text":"In v21 node telemetry was added to node. This allows peers to communicate telemetry metrics to each other. For specific details on the message format see telemetry_ack in the protocol specification . The nodes are designed to reply to telemetry_req messages. They avoid replying if messages are received from the same peer in quick succession; the minimum time until another reply is 60 seconds on the main network, 15 seconds on beta. This is done to reduce bandwidth. Telemetry messsages bypass the node's bandwidth limiter so that services monitoring the network can still do so during when the network is heavily used. Sending telemetry_req frequently within this exclusion zone could see your ip blacklisted by other peers. The node safely handles this for you by doing ongoing requests periodically and only sent when valid to do so.","title":"Node telemetry"},{"location":"protocol-design/networking/#signing","text":"Telemetry_ack messages are signed using ED25519 as follows: ED25519(key = node id public key, message = \"node id || block count || cemented count|| unchecked count || account count || bandwidth capacity || peer count || protocol version || uptime || genesis block hash || major version || minor version || patch version || pre-release version || maker || timestamp since UTC epoch || active difficulty\") The node id used in the initial handshake is used for signing. The genesis block hash should be in big endian. The data is signed so that it cannot be forged by a Man In The Middle (MITM) attack. Peer disconnections Sending incorrectly signed telemetry data to peers will result in being blacklisted as it is seen as malicious, make sure the signing is correct! Verify signatures against known signing done by node by testing local telemetry . Nodes with a different genesis block hash will also be disconnected.","title":"Signing"},{"location":"protocol-design/networking/#peering-process","text":"","title":"Peering process"},{"location":"protocol-design/networking/#live-traffic","text":"","title":"Live traffic"},{"location":"protocol-design/networking/#bootstrap-traffic","text":"Existing whitepaper sections related to this page: Networking","title":"Bootstrap traffic"},{"location":"protocol-design/orv-consensus/","text":"Protocol Design - ORV Consensus \u00b6 Part of work in progress Living Whitepaper This page is part of the Living Whitepaper revisions currently underway to replace the original static whitepaper. These efforts include the Protocol Design and Node Implementation sections of the docs, which will cover and expand on details and topics covered in the original whitepaper . See the bottom of the page for related whitepaper sections and other related details. Some of the sections and headers on this page may be in draft form or just suggestions/framework for later consideration. If you are interested in helping with revisions please connect with us on the #documentation channel on our Discord server . Existing whitepaper sections: System Overview , Implementation Existing content: Representatives and voting Representatives PoW for Receive block Overview \u00b6 In order to protect against double spending and Sybil attacks , Nano uses a unique consensus mechanism called Open Representative Voting (ORV). In ORV, user-selected representative nodes vote on each transaction, and every node (representative or not) independently cements each transaction after seeing enough representative votes to achieve quorum . Since Nano transactions are processed individually and asynchronously, deterministic finality (irreversible, full-settlement) is achieved in a short period of time, typically less than 1 second 1 . Due to Nano's block-lattice ledger design , only account owners have the ability to sign blocks into their account-chains, so all forks must be the result of poor programming or malicious intent (double-spend) by the account owner, which means that nodes can easily make policy decisions on how to handle forks without affecting legitimate transactions. Because Nano accounts can freely delegate their voting weight to representatives at any time, the users have more control over who has power with consensus and how decentralized the network is. Also note that delegation of voting weight does not mean staking of any funds - the account delegating can still spend all their available funds at any time without restrictions. This is a key advantage to the design of Open Representative Voting (ORV) . With no direct monetary incentive for nodes, this removes emergent centralization forces for longer-term trending toward decentralization of the network. 2 Open Representative Voting (ORV) vs Proof of Stake (PoS) \u00b6 While Nano uses a weighted-voting system ( ORV ) that can be compared to PoS, it differs from traditional PoS because: There is not one monolithic blockchain that requires leader selection (i.e. a staker or a miner) to extend Representatives do not create or produce shared blocks (groups of transactions) Each Nano account has its own blockchain that only the owner can modify (representatives can only modify their own blockchain) In Nano, a block is a single transaction (not a group of transactions). Transactions are evaluated individually and asynchronously Users can remotely re-delegate their voting weight to anyone at any time Anyone can be a representative No funds are staked or locked up Representatives do not earn transaction fees Representatives cannot reverse transactions that nodes have locally confirmed (due to block cementing ). Confirmation Speed \u00b6 Nano's <1 second average transaction confirmation time often leads to questions about how finality can be achieved so quickly vs alternatives like Bitcoin. There are a few factors that contribute to this difference: The block-lattice ledger design replaces a run-time agreement with a design-time agreement A Nano block is a single transaction that can be processed individually and asynchronously vs other transactions Lightweight Open Representative voting (ORV) and contention minimization Only account owners have the ability to sign blocks into their account-chains, so all forks must be the result of poor programming or malicious intent (double-spend) by the account owner, which means that nodes can easily make policy decisions on how to handle forks without affecting legitimate transactions. A Bitcoin block is a group of transactions (~1 Megabyte per block) that has to be propagated and processed together, while a Nano block is a single transaction (~200 bytes) that is almost 5000 times smaller than a Bitcoin block. To make a Nano transaction, a node publishes a block to all the Nano Principal Representatives (PRs) 3 at the speed of internet latency (20-100ms typically, depending on location), and those PRs then generate their vote (another small network packet) and publish it to each other and a subset of non-PR peers (who then publish to a subset of their peers). This pattern of communication is known as gossip-about-gossip. Once a node sees enough PR vote responses to cross its local vote weight threshold for confirmation (>50% of online vote weight by default), it considers the transaction to be confirmed and then cements it as irreversible. Since the vast majority of transactions are not forks (no extra voting for fork resolution required), average Nano confirmation times are comparable to typical request-response internet latency. Principal Representatives vs Non-Principal Representatives \u00b6 There are two types of representatives in Nano: Principal Representatives (PR) and non-principal ones. To become a Principal Representative (PR), a Nano account must have at least 0.1% of online voting weight delegated to it, but the only operational difference between the two representative types is that PR votes are rebroadcasted by other nodes who receive the votes, helping the network reach consensus more quickly. This implementation decision was made in part because of the exponential bandwidth cost of allowing every Nano node (potentially thousands) to send a vote to every other Nano node. Outside of PRs, the vast majority of nodes would not be able to meaningfully contribute to consensus due to their low vote weight delegation. The delegated vote weight for most nodes might only be a millionth of a percent vs total online vote weight, while >50% online vote weight is required for a transaction to achieve confirmation. A 0.1% minimum was thus chosen as a compromise. Incentives for participating in consensus \u00b6 Incentives to run a node Block validation \u00b6 Voting \u00b6 Vote contents \u00b6 Vote-by-hash \u00b6 Fork handling \u00b6 Fork resolution \u00b6 Simple \u00b6 Complex \u00b6 Why PoW for receive blocks \u00b6 Quorum \u00b6 Existing whitepaper sections related to this page: System Overview Implementation Existing content related to this page: Representatives and voting Representatives PoW for Receive block \"Block Confirmation Times\", 2020. [Online]. Available: https://repnode.org/network/confirmation \u21a9 C. LeMahieu, \"Emergent centralization due to economies of scale\", 2020. [Online]. Available: https://medium.com/@clemahieu/emergent-centralization-due-to-economies-of-scale-83cc85a7cbef \u21a9 Srayman, \"Community Blog: Proposal for Nano Node Network Optimizations\", 2020. [Online]. Available: https://medium.com/nanocurrency/proposal-for-nano-node-network-optimizations-21003e79cdba \u21a9","title":"ORV Consensus"},{"location":"protocol-design/orv-consensus/#protocol-design-orv-consensus","text":"Part of work in progress Living Whitepaper This page is part of the Living Whitepaper revisions currently underway to replace the original static whitepaper. These efforts include the Protocol Design and Node Implementation sections of the docs, which will cover and expand on details and topics covered in the original whitepaper . See the bottom of the page for related whitepaper sections and other related details. Some of the sections and headers on this page may be in draft form or just suggestions/framework for later consideration. If you are interested in helping with revisions please connect with us on the #documentation channel on our Discord server . Existing whitepaper sections: System Overview , Implementation Existing content: Representatives and voting Representatives PoW for Receive block","title":"Protocol Design - ORV Consensus"},{"location":"protocol-design/orv-consensus/#overview","text":"In order to protect against double spending and Sybil attacks , Nano uses a unique consensus mechanism called Open Representative Voting (ORV). In ORV, user-selected representative nodes vote on each transaction, and every node (representative or not) independently cements each transaction after seeing enough representative votes to achieve quorum . Since Nano transactions are processed individually and asynchronously, deterministic finality (irreversible, full-settlement) is achieved in a short period of time, typically less than 1 second 1 . Due to Nano's block-lattice ledger design , only account owners have the ability to sign blocks into their account-chains, so all forks must be the result of poor programming or malicious intent (double-spend) by the account owner, which means that nodes can easily make policy decisions on how to handle forks without affecting legitimate transactions. Because Nano accounts can freely delegate their voting weight to representatives at any time, the users have more control over who has power with consensus and how decentralized the network is. Also note that delegation of voting weight does not mean staking of any funds - the account delegating can still spend all their available funds at any time without restrictions. This is a key advantage to the design of Open Representative Voting (ORV) . With no direct monetary incentive for nodes, this removes emergent centralization forces for longer-term trending toward decentralization of the network. 2","title":"Overview"},{"location":"protocol-design/orv-consensus/#open-representative-voting-orv-vs-proof-of-stake-pos","text":"While Nano uses a weighted-voting system ( ORV ) that can be compared to PoS, it differs from traditional PoS because: There is not one monolithic blockchain that requires leader selection (i.e. a staker or a miner) to extend Representatives do not create or produce shared blocks (groups of transactions) Each Nano account has its own blockchain that only the owner can modify (representatives can only modify their own blockchain) In Nano, a block is a single transaction (not a group of transactions). Transactions are evaluated individually and asynchronously Users can remotely re-delegate their voting weight to anyone at any time Anyone can be a representative No funds are staked or locked up Representatives do not earn transaction fees Representatives cannot reverse transactions that nodes have locally confirmed (due to block cementing ).","title":"Open Representative Voting (ORV) vs Proof of Stake (PoS)"},{"location":"protocol-design/orv-consensus/#confirmation-speed","text":"Nano's <1 second average transaction confirmation time often leads to questions about how finality can be achieved so quickly vs alternatives like Bitcoin. There are a few factors that contribute to this difference: The block-lattice ledger design replaces a run-time agreement with a design-time agreement A Nano block is a single transaction that can be processed individually and asynchronously vs other transactions Lightweight Open Representative voting (ORV) and contention minimization Only account owners have the ability to sign blocks into their account-chains, so all forks must be the result of poor programming or malicious intent (double-spend) by the account owner, which means that nodes can easily make policy decisions on how to handle forks without affecting legitimate transactions. A Bitcoin block is a group of transactions (~1 Megabyte per block) that has to be propagated and processed together, while a Nano block is a single transaction (~200 bytes) that is almost 5000 times smaller than a Bitcoin block. To make a Nano transaction, a node publishes a block to all the Nano Principal Representatives (PRs) 3 at the speed of internet latency (20-100ms typically, depending on location), and those PRs then generate their vote (another small network packet) and publish it to each other and a subset of non-PR peers (who then publish to a subset of their peers). This pattern of communication is known as gossip-about-gossip. Once a node sees enough PR vote responses to cross its local vote weight threshold for confirmation (>50% of online vote weight by default), it considers the transaction to be confirmed and then cements it as irreversible. Since the vast majority of transactions are not forks (no extra voting for fork resolution required), average Nano confirmation times are comparable to typical request-response internet latency.","title":"Confirmation Speed"},{"location":"protocol-design/orv-consensus/#principal-representatives-vs-non-principal-representatives","text":"There are two types of representatives in Nano: Principal Representatives (PR) and non-principal ones. To become a Principal Representative (PR), a Nano account must have at least 0.1% of online voting weight delegated to it, but the only operational difference between the two representative types is that PR votes are rebroadcasted by other nodes who receive the votes, helping the network reach consensus more quickly. This implementation decision was made in part because of the exponential bandwidth cost of allowing every Nano node (potentially thousands) to send a vote to every other Nano node. Outside of PRs, the vast majority of nodes would not be able to meaningfully contribute to consensus due to their low vote weight delegation. The delegated vote weight for most nodes might only be a millionth of a percent vs total online vote weight, while >50% online vote weight is required for a transaction to achieve confirmation. A 0.1% minimum was thus chosen as a compromise.","title":"Principal Representatives vs Non-Principal Representatives"},{"location":"protocol-design/orv-consensus/#incentives-for-participating-in-consensus","text":"Incentives to run a node","title":"Incentives for participating in consensus"},{"location":"protocol-design/orv-consensus/#block-validation","text":"","title":"Block validation"},{"location":"protocol-design/orv-consensus/#voting","text":"","title":"Voting"},{"location":"protocol-design/orv-consensus/#vote-contents","text":"","title":"Vote contents"},{"location":"protocol-design/orv-consensus/#vote-by-hash","text":"","title":"Vote-by-hash"},{"location":"protocol-design/orv-consensus/#fork-handling","text":"","title":"Fork handling"},{"location":"protocol-design/orv-consensus/#fork-resolution","text":"","title":"Fork resolution"},{"location":"protocol-design/orv-consensus/#simple","text":"","title":"Simple"},{"location":"protocol-design/orv-consensus/#complex","text":"","title":"Complex"},{"location":"protocol-design/orv-consensus/#why-pow-for-receive-blocks","text":"","title":"Why PoW for receive blocks"},{"location":"protocol-design/orv-consensus/#quorum","text":"Existing whitepaper sections related to this page: System Overview Implementation Existing content related to this page: Representatives and voting Representatives PoW for Receive block \"Block Confirmation Times\", 2020. [Online]. Available: https://repnode.org/network/confirmation \u21a9 C. LeMahieu, \"Emergent centralization due to economies of scale\", 2020. [Online]. Available: https://medium.com/@clemahieu/emergent-centralization-due-to-economies-of-scale-83cc85a7cbef \u21a9 Srayman, \"Community Blog: Proposal for Nano Node Network Optimizations\", 2020. [Online]. Available: https://medium.com/nanocurrency/proposal-for-nano-node-network-optimizations-21003e79cdba \u21a9","title":"Quorum"},{"location":"protocol-design/resource-usage/","text":"Protocol Design - Resource Usage \u00b6 Part of work in progress Living Whitepaper This page is part of the Living Whitepaper revisions currently underway to replace the original static whitepaper. These efforts include the Protocol Design and Node Implementation sections of the docs, which will cover and expand on details and topics covered in the original whitepaper . See the bottom of the page for related whitepaper sections and other related details. Some of the sections and headers on this page may be in draft form or just suggestions/framework for later consideration. If you are interested in helping with revisions please connect with us on the #documentation channel on our Discord server . Network \u00b6 Principal Representatives (Voting) \u00b6 Representatives (Voting) \u00b6 Observer (Non-voting) \u00b6 Disk I/O \u00b6 Disk Capacity \u00b6 Historical \u00b6 Pruned \u00b6 CPU/GPU \u00b6 Work Generation \u00b6 Principal Representative \u00b6 Representative \u00b6 Observer \u00b6 Existing whitepaper sectionsrelated to this page: Resource Usage Existing content related to this page: Representatives and voting Representatives","title":"Resource Usage"},{"location":"protocol-design/resource-usage/#protocol-design-resource-usage","text":"Part of work in progress Living Whitepaper This page is part of the Living Whitepaper revisions currently underway to replace the original static whitepaper. These efforts include the Protocol Design and Node Implementation sections of the docs, which will cover and expand on details and topics covered in the original whitepaper . See the bottom of the page for related whitepaper sections and other related details. Some of the sections and headers on this page may be in draft form or just suggestions/framework for later consideration. If you are interested in helping with revisions please connect with us on the #documentation channel on our Discord server .","title":"Protocol Design - Resource Usage"},{"location":"protocol-design/resource-usage/#network","text":"","title":"Network"},{"location":"protocol-design/resource-usage/#principal-representatives-voting","text":"","title":"Principal Representatives (Voting)"},{"location":"protocol-design/resource-usage/#representatives-voting","text":"","title":"Representatives (Voting)"},{"location":"protocol-design/resource-usage/#observer-non-voting","text":"","title":"Observer (Non-voting)"},{"location":"protocol-design/resource-usage/#disk-io","text":"","title":"Disk I/O"},{"location":"protocol-design/resource-usage/#disk-capacity","text":"","title":"Disk Capacity"},{"location":"protocol-design/resource-usage/#historical","text":"","title":"Historical"},{"location":"protocol-design/resource-usage/#pruned","text":"","title":"Pruned"},{"location":"protocol-design/resource-usage/#cpugpu","text":"","title":"CPU/GPU"},{"location":"protocol-design/resource-usage/#work-generation","text":"","title":"Work Generation"},{"location":"protocol-design/resource-usage/#principal-representative","text":"","title":"Principal Representative"},{"location":"protocol-design/resource-usage/#representative","text":"","title":"Representative"},{"location":"protocol-design/resource-usage/#observer","text":"Existing whitepaper sectionsrelated to this page: Resource Usage Existing content related to this page: Representatives and voting Representatives","title":"Observer"},{"location":"protocol-design/signing-hashing-and-key-derivation/","text":"Protocol Design - Signing, Hashing and Key Derivation \u00b6 Part of work in progress Living Whitepaper This page is part of the Living Whitepaper revisions currently underway to replace the original static whitepaper. These efforts include the Protocol Design and Node Implementation sections of the docs, which will cover and expand on details and topics covered in the original whitepaper . See the bottom of the page for related whitepaper sections and other related details. Some of the sections and headers on this page may be in draft form or just suggestions/framework for later consideration. If you are interested in helping with revisions please connect with us on the #documentation channel on our Discord server . Signing algorithm: ED25519 \u00b6 ED25519 is an elliptic curve algorithm developed in an academic setting with a focus on security from side channel attack, performance, and fixing a lot of the little annoyances in most elliptic curve systems 1 . However, it should be noted that instead of using SHA-512 in the key derivation function, Nano uses Blake2b-512. Incorrect, SHA-512 has been used 0000000000000000000000000000000000000000000000000000000000000000 -> 3B6A27BCCEB6A42D62A3A8D02A6F0D73653215771DE243A63AC048A18B59DA29 Correct, Blake2b-512 digested the seed 0000000000000000000000000000000000000000000000000000000000000000 -> 19D3D919475DEED4696B5D13018151D1AF88B2BD3BCFF048B45031C1F36D1858 Hashing algorithm: Blake2 \u00b6 Compared to existing cryptocurrencies, the hash algorithm chosen is much less important since it's not being used in a Proof-of-Work context. In Nano hashing is used purely as a digest algorithm against block contents. Blake2b-256 is a highly optimized cryptographic hash function whose predecessor was a SHA3 finalist. 2 Key derivation function: Argon2 \u00b6 The key derivation function of Argon2d version 1.0 is used for securing the account keys in the reference wallet. 3 http://ed25519.cr.yp.to/ \u21a9 https://blake2.net/ \u21a9 https://en.wikipedia.org/wiki/Argon2 \u21a9","title":"Signing, Hashing and Key Derivation"},{"location":"protocol-design/signing-hashing-and-key-derivation/#protocol-design-signing-hashing-and-key-derivation","text":"Part of work in progress Living Whitepaper This page is part of the Living Whitepaper revisions currently underway to replace the original static whitepaper. These efforts include the Protocol Design and Node Implementation sections of the docs, which will cover and expand on details and topics covered in the original whitepaper . See the bottom of the page for related whitepaper sections and other related details. Some of the sections and headers on this page may be in draft form or just suggestions/framework for later consideration. If you are interested in helping with revisions please connect with us on the #documentation channel on our Discord server .","title":"Protocol Design - Signing, Hashing and Key Derivation"},{"location":"protocol-design/signing-hashing-and-key-derivation/#signing-algorithm-ed25519","text":"ED25519 is an elliptic curve algorithm developed in an academic setting with a focus on security from side channel attack, performance, and fixing a lot of the little annoyances in most elliptic curve systems 1 . However, it should be noted that instead of using SHA-512 in the key derivation function, Nano uses Blake2b-512. Incorrect, SHA-512 has been used 0000000000000000000000000000000000000000000000000000000000000000 -> 3B6A27BCCEB6A42D62A3A8D02A6F0D73653215771DE243A63AC048A18B59DA29 Correct, Blake2b-512 digested the seed 0000000000000000000000000000000000000000000000000000000000000000 -> 19D3D919475DEED4696B5D13018151D1AF88B2BD3BCFF048B45031C1F36D1858","title":"Signing algorithm: ED25519"},{"location":"protocol-design/signing-hashing-and-key-derivation/#hashing-algorithm-blake2","text":"Compared to existing cryptocurrencies, the hash algorithm chosen is much less important since it's not being used in a Proof-of-Work context. In Nano hashing is used purely as a digest algorithm against block contents. Blake2b-256 is a highly optimized cryptographic hash function whose predecessor was a SHA3 finalist. 2","title":"Hashing algorithm: Blake2"},{"location":"protocol-design/signing-hashing-and-key-derivation/#key-derivation-function-argon2","text":"The key derivation function of Argon2d version 1.0 is used for securing the account keys in the reference wallet. 3 http://ed25519.cr.yp.to/ \u21a9 https://blake2.net/ \u21a9 https://en.wikipedia.org/wiki/Argon2 \u21a9","title":"Key derivation function: Argon2"},{"location":"protocol-design/work/","text":"Protocol Design - Work \u00b6 Part of work in progress Living Whitepaper This page is part of the Living Whitepaper revisions currently underway to replace the original static whitepaper. These efforts include the Protocol Design and Node Implementation sections of the docs, which will cover and expand on details and topics covered in the original whitepaper . See the bottom of the page for related whitepaper sections and other related details. Some of the sections and headers on this page may be in draft form or just suggestions/framework for later consideration. If you are interested in helping with revisions please connect with us on the #documentation channel on our Discord server . Spam resistance \u00b6 A spam transaction is loosely defined as a block broadcasted with the intention of saturating the network, reducing its availability for other network participants, or increasing the size of the ledger. In order to make spam attempts more costly, each valid block in Nano requires a proof-of-work solution to be attached to it - similar to the original proposition of Hashcash 1 . Participants can compute the required work in the order of seconds. The cost of spamming the network then increases linearly with the number of spam transactions, thus reducing the impact of spam transactions from theoretically infinite to a manageable amount. With this design, there is an added step of verifying a block's work. As one could spam invalid blocks (in this context, blocks with invalid work), one key requirement is that the cost of verifying work is negligible. Work algorithm details \u00b6 Every block includes a work field that must be correctly populated. Valid work is obtained by randomly guessing a nonce such that: H(\\text{nonce} || \\text{x}) \\ge \\text{threshold} H(\\text{nonce} || \\text{x}) \\ge \\text{threshold} where H H is an algorithm, usually in the form of a hash function, || || is the concatenation operator, threshold threshold is a parameter of the network that relates to the resources spent to obtain a valid work, and x x is either: The account's public key, in the case of the first block on the account, or The previous block's hash The following image illustrates the process by which valid work is obtained for Block 2 . The work field is not used when signing a block. This design has two consequences: A block can be securely signed locally, while the work is requested from a remote server, with larger resources. This is especially important for devices with low resources. Since all inputs are known before generating a block, a user can precompute the work for the next block, eliminating any time between creating and broadcasting a block. After a block is broadcasted, the next block's work can be computed immediately, using the last block's hash as input. Choosing an algorithm \u00b6 While the specific algorithm used is an implementation decision, there is a minimal set of requirements that must be met for compatibility with the Nano protocol. Asymmetry. Verifying work should take the least amount of resources (including time) as possible. Small proof size. Work should take a minimal amount of a block's size compared to the resources required to generate it, in order to reduce overhead and maximize throughput. Amortization-free. The cost of obtaining work for multiple blocks should scale linearly with the number of blocks. This ensures fairness for all participants. Progress-free. Any attempt at obtaining work should follow a stochastic process, with no dependence on previous attempts. Additional requirements of parameter flexibility, constrained parallelism, and being optimization-free, are desired but not required 2 . Existing whitepaper sections related to this page: System Overview Existing content related to this page: Basics - PoW Dynamic PoW & Prioritization Nano How 4: Proof of Work Work Generation guide A. Back, \u201cHashcash - a denial of service counter-measure,\u201d 2002. [Online]. Available: http://www.hashcash.org/papers/hashcash.pdf \u21a9 For more details on these requirements, refer to A. Biryukov, \"Equihash: Asymmetric Proof-of-Work Based on the Generalized Birthday Problem\" 2017. [Online]. Available: https://doi.org/10.5195/ledger.2017.48 \u21a9","title":"Work"},{"location":"protocol-design/work/#protocol-design-work","text":"Part of work in progress Living Whitepaper This page is part of the Living Whitepaper revisions currently underway to replace the original static whitepaper. These efforts include the Protocol Design and Node Implementation sections of the docs, which will cover and expand on details and topics covered in the original whitepaper . See the bottom of the page for related whitepaper sections and other related details. Some of the sections and headers on this page may be in draft form or just suggestions/framework for later consideration. If you are interested in helping with revisions please connect with us on the #documentation channel on our Discord server .","title":"Protocol Design - Work"},{"location":"protocol-design/work/#spam-resistance","text":"A spam transaction is loosely defined as a block broadcasted with the intention of saturating the network, reducing its availability for other network participants, or increasing the size of the ledger. In order to make spam attempts more costly, each valid block in Nano requires a proof-of-work solution to be attached to it - similar to the original proposition of Hashcash 1 . Participants can compute the required work in the order of seconds. The cost of spamming the network then increases linearly with the number of spam transactions, thus reducing the impact of spam transactions from theoretically infinite to a manageable amount. With this design, there is an added step of verifying a block's work. As one could spam invalid blocks (in this context, blocks with invalid work), one key requirement is that the cost of verifying work is negligible.","title":"Spam resistance"},{"location":"protocol-design/work/#work-algorithm-details","text":"Every block includes a work field that must be correctly populated. Valid work is obtained by randomly guessing a nonce such that: H(\\text{nonce} || \\text{x}) \\ge \\text{threshold} H(\\text{nonce} || \\text{x}) \\ge \\text{threshold} where H H is an algorithm, usually in the form of a hash function, || || is the concatenation operator, threshold threshold is a parameter of the network that relates to the resources spent to obtain a valid work, and x x is either: The account's public key, in the case of the first block on the account, or The previous block's hash The following image illustrates the process by which valid work is obtained for Block 2 . The work field is not used when signing a block. This design has two consequences: A block can be securely signed locally, while the work is requested from a remote server, with larger resources. This is especially important for devices with low resources. Since all inputs are known before generating a block, a user can precompute the work for the next block, eliminating any time between creating and broadcasting a block. After a block is broadcasted, the next block's work can be computed immediately, using the last block's hash as input.","title":"Work algorithm details"},{"location":"protocol-design/work/#choosing-an-algorithm","text":"While the specific algorithm used is an implementation decision, there is a minimal set of requirements that must be met for compatibility with the Nano protocol. Asymmetry. Verifying work should take the least amount of resources (including time) as possible. Small proof size. Work should take a minimal amount of a block's size compared to the resources required to generate it, in order to reduce overhead and maximize throughput. Amortization-free. The cost of obtaining work for multiple blocks should scale linearly with the number of blocks. This ensures fairness for all participants. Progress-free. Any attempt at obtaining work should follow a stochastic process, with no dependence on previous attempts. Additional requirements of parameter flexibility, constrained parallelism, and being optimization-free, are desired but not required 2 . Existing whitepaper sections related to this page: System Overview Existing content related to this page: Basics - PoW Dynamic PoW & Prioritization Nano How 4: Proof of Work Work Generation guide A. Back, \u201cHashcash - a denial of service counter-measure,\u201d 2002. [Online]. Available: http://www.hashcash.org/papers/hashcash.pdf \u21a9 For more details on these requirements, refer to A. Biryukov, \"Equihash: Asymmetric Proof-of-Work Based on the Generalized Birthday Problem\" 2017. [Online]. Available: https://doi.org/10.5195/ledger.2017.48 \u21a9","title":"Choosing an algorithm"},{"location":"releases/current-release-notes/","text":"V21.2 \u00b6 V21.2 Release Available The latest release is V21.2 which adds optimizations for the OpenCL work kernel and resolves issues interrupting node operation during certain network conditions. Upgrading to V21.2 is recommended for all node operators. There are no special integration considerations or impacts with this release if upgrading from V21.0 or higher. If upgrading from V20.0 or lower, please review the V21.0 Release Notes for upgrade notices and other considerations. Node Protocol Database Release Date Release Notes GitHub Links 21.2 18 18 2020-09-03 V21.2 Release - Milestone - Changelog Known Issue V19+: macOS 'Too many open files' Issue: The following error can be seen when attempting to run a full node on macOS using the built-in Qt wallet or other GUI-based wallets: \"Exception while running wallet: open: Too many open files\". This is due to macOS having a very low default file descriptor limit and V19.0 uses more of them after the move to TCP. Solution: For now a workaround is needed to increase the limit. The method depends on the specific macOS version, but some people had success with the recipe in https://superuser.com/a/1171028 . Builds and Commands \u00b6 OS Download link/command Verification Universal Linux https://repo.nano.org/live/binaries/nano-node-V21.2-Linux.tar.bz2 SHA256 Checksum Debian http://repo.nano.org/live/binaries/nano-node-V21.2-Linux.deb SHA256 Checksum macOS https://repo.nano.org/live/binaries/nano-node-V21.2-Darwin.dmg SHA256 Checksum Windows (exe) https://repo.nano.org/live/binaries/nano-node-V21.2-win64.exe SHA256 Checksum Windows (zip) https://repo.nano.org/live/binaries/nano-node-V21.2-win64.zip SHA256 Checksum Docker docker pull nanocurrency/nano:V21.2 or docker pull nanocurrency/nano:latest See Pulling the Docker Image for more details. RHEL/CentOS rpm sudo rpm -iUvh https://repo.nano.org/live/binaries/nanocurrency-21.2-21.el7.x86_64.rpm This installs nano_node and nano_rpc to /usr/bin . SHA256 Checksum Useful guide updates \u00b6 We've been making many useful updates to the documentation here, especially around various guides for managing different aspects of the Nano node. Here are a few worth digging into: NEW Ledger Management NEW Voting as a Representative NEW Work Generation Node Security Block Confirmation Tracking Nano Forum available The Nano Forum is available at https://forum.nano.org/ as a resource to ask questions and get support when participating on the network. The Node and Representative Management category is a great place to ask node upgrade related questions. Join our Technical Update Mailing List Follow this link to sign up for email updates on the latest protocol/node releases and other technical details. This will include network upgrades such as the upcoming epoch distribution: http://eepurl.com/gZucL1","title":"Current Release Notes"},{"location":"releases/current-release-notes/#v212","text":"V21.2 Release Available The latest release is V21.2 which adds optimizations for the OpenCL work kernel and resolves issues interrupting node operation during certain network conditions. Upgrading to V21.2 is recommended for all node operators. There are no special integration considerations or impacts with this release if upgrading from V21.0 or higher. If upgrading from V20.0 or lower, please review the V21.0 Release Notes for upgrade notices and other considerations. Node Protocol Database Release Date Release Notes GitHub Links 21.2 18 18 2020-09-03 V21.2 Release - Milestone - Changelog Known Issue V19+: macOS 'Too many open files' Issue: The following error can be seen when attempting to run a full node on macOS using the built-in Qt wallet or other GUI-based wallets: \"Exception while running wallet: open: Too many open files\". This is due to macOS having a very low default file descriptor limit and V19.0 uses more of them after the move to TCP. Solution: For now a workaround is needed to increase the limit. The method depends on the specific macOS version, but some people had success with the recipe in https://superuser.com/a/1171028 .","title":"V21.2"},{"location":"releases/current-release-notes/#builds-and-commands","text":"OS Download link/command Verification Universal Linux https://repo.nano.org/live/binaries/nano-node-V21.2-Linux.tar.bz2 SHA256 Checksum Debian http://repo.nano.org/live/binaries/nano-node-V21.2-Linux.deb SHA256 Checksum macOS https://repo.nano.org/live/binaries/nano-node-V21.2-Darwin.dmg SHA256 Checksum Windows (exe) https://repo.nano.org/live/binaries/nano-node-V21.2-win64.exe SHA256 Checksum Windows (zip) https://repo.nano.org/live/binaries/nano-node-V21.2-win64.zip SHA256 Checksum Docker docker pull nanocurrency/nano:V21.2 or docker pull nanocurrency/nano:latest See Pulling the Docker Image for more details. RHEL/CentOS rpm sudo rpm -iUvh https://repo.nano.org/live/binaries/nanocurrency-21.2-21.el7.x86_64.rpm This installs nano_node and nano_rpc to /usr/bin . SHA256 Checksum","title":"Builds and Commands"},{"location":"releases/current-release-notes/#useful-guide-updates","text":"We've been making many useful updates to the documentation here, especially around various guides for managing different aspects of the Nano node. Here are a few worth digging into: NEW Ledger Management NEW Voting as a Representative NEW Work Generation Node Security Block Confirmation Tracking Nano Forum available The Nano Forum is available at https://forum.nano.org/ as a resource to ask questions and get support when participating on the network. The Node and Representative Management category is a great place to ask node upgrade related questions.","title":"Useful guide updates"},{"location":"releases/network-upgrades/","text":"Network Upgrades \u00b6 For details on why and how network upgrades happen, along with explanations of the various types, please see the Upgrades overview and Upgrade methods sections further down. Join our Technical Update Mailing List Follow this link to sign up for email updates on the latest protocol/node releases and other technical details. This will include network upgrades such as the upcoming epoch distribution: http://eepurl.com/gZucL1 Upcoming upgrades \u00b6 No upcoming upgrades at this time Future upgrades \u00b6 New PoW algorithm \u00b6 Purpose To help ensure Quality of Service on the network by providing the ability to generate and validate PoW using a new algorithm. This algorithm will be more memory-hard causing the resources required for generating transactions to shift accordingly. Transition details Date Type Description 2019-11-21 Node release Nano node V20.0 released to include a new PoW server and epoch block support. These are only foundational updates and will not be configured for activation in this release. 2020-08-29 Epoch blocks Following the postponing of the Nano PoW algorithm in favor or research towards other options, the original epoch v2 blocks intended for the PoW algorithm update were modified for increasing work difficulty using the existing algorithm in V21.0 and subsequently distributed in August 2020 . Any future PoW algorithm updates will require a different epoch block version. TBD Node release Nano node VXX.X released to include new PoW algorithm in PoW server and final changes allowing transition via epoch blocks. TBD Epoch blocks start Distribution of epoch blocks to each account which upgrades them to use the new PoW algorithm. Once an account is upgraded nodes will only validate work made using the new PoW algorithm for that account. TBD Epoch blocks end Distribution of epoch blocks ends after all accounts are upgraded. Transition Explanation In the above transition plan a phased node upgrade was used to provide support for some foundational elements of the new PoW algorithm while further details of the design are worked out. The epoch block distribution in this transition represents a clean switch from one PoW algorithm to the other - no block in the ledger is allowed to have work generated by either PoW, instead older block versions must use the existing PoW and new block versions must use the newer PoW. This clean switch comes with benefits including reduction in code complexity related to handling two types of PoW generation and validation for the same block versions, and the setting of a clear point in the ledger for each account where work values changed - potentially useful for future snapshoting. To mitigate the impacts of this approach the Nano Foundation will be communicating regularly about progress and monitoring closely the activity on the network to ensure proper conditions exist to finalize the transition. Past upgrades \u00b6 Increased work difficulty \u00b6 Purpose To help ensure Quality of Service on the network by increasing the difficulty required for send and change blocks to be considered valid by the network (8x compared to current). To help offset the difficulty increase and add incentive to receive blocks so ledger pruning can be done more broadly in the future, the difficulty for receive blocks will simultaneously be reduced (\u215b compared to current). Transition details This upgrade is sometimes referenced as the epoch v2 upgrade and the relate events to complete are as follows: Date Type Description 2020-06-16 Node release Nano node V21.0 released which includes changes necessary for supporting new difficulty validation and generation 2020-08-18 v2 epoch blocks distribution start Distribution of v2 epoch blocks to all accounts to mark in the ledger the point at which the new work difficulty levels will be required. The start of this distribution process will occur once key services and over 90% of voting weight on the network has upraded. 2020-08-29 v2 epoch blocks distribution end Distribution of epoch blocks ends after all accounts are upgraded. Nodes de-peered with epoch blocks Due to the nature of the work difficulty changes, any nodes not updated to V21.0+ at the time of epoch block distribution will be de-peered from the network. Transition Explanation When changing the work difficulty requirements it is necessary to mark a point in each account where the difficulty requirements change so bootstrapping and other behaviors can accurately validate historical blocks. For this reason the epoch blocks are being distributed to act as the marker in the ledger. Once epoch block distribution is started the ability to validate the new work difficulty levels is required. Since node versions before V21.0 do not have the ability to do this, they will be immediately de-peered from the network and cannot participate with the current network until upgraded. To mitigate the impacts of this approach the Nano Foundation will be communicating regularly about progress and monitoring closely the activity on the network. Once acceptable conditions exist to finalize the transition, the distribution will begin. The current plan is to start once over 90% of voting weight has been upgraded, along with all the key services on the network. Recommended preparations In order to best prepare for the transition to new thresholds, the following items should be considered: Work generation guide The new Work Generation guide was written to help users and integrations leverage their work generation at all times. Work validation The work_validate RPC has multiple changes to the response, one which will break most existing integrations when upgrading to V21, two others that will become useful after upgrade: If difficulty parameter is not explicitly passed in the request, the existing valid field will not be returned ( breaking ) valid_all is a new return field, true if the work is valid at the current default difficulty (will go up after epoch upgrade) valid_receive is a new return field, true if the work is valid at the lower epoch_2 receive difficulty (only useful after the epoch upgrade is finished) If possible, it is best to avoid using this RPC until the epoch upgrade is completed External work generation nano-work-server has been updated to use the higher threshold ( fffffff800000000 ) by default when not given an explicit difficulty . The work_validate response has the same breaking changes as above. Prefer directly using the server as a work peer as outlined in the guide . The node always requests the appropriate difficulty threshold when using RPC block_create , or work_generate with the optional block . In cases where requesting directly from a node is not possible, avoid using the lower threshold for receive blocks ( fffffe0000000000 ) until the epoch upgrade is fully complete. Work generation performance Testing out work generation capabilities on a machine is recommended. Details for how to accomplish this can be found in the Benchmark section of the Work Generation guide . Active difficulty changes The active difficulty RPC command and WebSocket topic allow programatically retrieving the current difficulty from the network_minimum field in the response. When this field changes from ffffffc000000000 (pre-epoch v2 difficulty) to fffffff800000000 (8x higher epoch v2 difficulty), it indicates the epoch upgrade has begun. Post-distribution changes Accounts that have already been upgraded can optionally use fffffe0000000000 as the lower threshold for receive blocks going forward. The current epoch version of an opened account can be obtained using the account_info RPC, field account_version . Once that field has the value \"2\" , the lower threshold may be used. Other integration considerations Although it is already recommended as best practice, any integrations not already calling for the frontier block when constructing a transaction should do so. If hashes are being internally tracked and frontier is not requested, the integration could unintentionally cause a fork on the account with distribution of epoch blocks. See Step 1: Get Account Info for the account_info RPC recommendation when creating transactions. State blocks \u00b6 Purpose The upgrade to state blocks involved multiple node releases and three different actions on the network including distribution of two canary blocks and the first epoch blocks. Transition Details Date Type Description 2018-03-23 Node release Nano node V11.0 released with support for state blocks built-in but not yet activated. 2018-04-11 Canary block Parse canary block distributed which enabled parsing of state blocks by nodes so manual generation of that block type would be accepted on the network going forward. This action was performed after a majority of the network upgraded to the required V11.0 to allow confirmations to occur on this new block type. 2018-05-20 Canary block Generation canary block distributed which forced the generation of state blocks by nodes going forward. At this point both state and legacy type (open, send, receive, change) blocks remain valid on the network. 2018-08-20 Node release Nano node V15.0 released with support for epoch blocks built-in and away distribution. 2018-10-25 Epoch v1 block distribution start Distribution of epoch v1 blocks begins. 2019-05-24 Epoch v1 block distribution end Distribution of epoch v1 blocks is finished. All accounts, opened and unopened, are now capped and can no longer attempt inserting legacy style blocks. Vote-by-Hash \u00b6 Purpose The upgrade to include the vote-by-hash feature was based on a hardcoded timestamp in the node. After this time nodes began voting using this new feature. Transition Details Date Type Description 2018-08-22 Node release Nano node V15.2 release with support for vote-by-hash but not yet activated. 2018-09-01 00:00:00 UTC Hardcoded date Nodes upgraded to V15.2 began voting using the vote-by-hash method. Nodes not yet upgraded would fail to properly interpret votes so were no longer compatible with the network. Upgrades overview \u00b6 Nano is a protocol, an agreed upon standard that allows computers to communicate with each other and agree on data. Because of these communication standards, having mechanisms that force all nodes to upgrade certain behaviors at the same time is critical to the consensus and consistency in the network. In most blockchain networks these upgrades can be scheduled to take effect once a particular block height is hit because all nodes operate off a single, synchronous chain. Due to the Nano network being asynchronous this method doesn\u2019t work, so instead we need methods for upgrading accounts asynchronously. There are a couple different options for handling these upgrades and the process is currently managed primarily by the Nano Foundation. The upgrades are tested on the beta network to ensure all components are behaving as expecting before being considered for updating on the main network. If the behavior being changed involves consensus, any manual upgrade actions are triggered once a large majority of nodes and major services have upgraded. Of course many features, including protocol changes, can be activated immediately with a new node release, so these network upgrade scenarios are only reserved for certain cases. Options for providing better agreement on capabilities between nodes has been discussed in this GitHub issue . There is also a discussion around how to potentially automate network upgrade processes in this forum topic: https://forum.nano.org/t/automated-network-upgrades/113 . Upgrade methods \u00b6 There are various methods used to upgrade and a brief overview of each, along with benefits and drawbacks, are included below. Upgrades for behaviors contained and activated with a single node release are not included as they are the foundation on top of which these other methods are made capable. Phased node upgrades \u00b6 A feature is introduced in a node release but not activated for use across the network until a subsequent node release. See State block upgrade details for an example. Trigger Uses blocks Benefits Drawbacks Multiple node upgrades No No manual intervention or automated process needed Uses already established upgrade process node operators are used to Longer time period to get feature activated Cannot be used to perform upgrades needed simultaneously across the network Hardcoded date \u00b6 A date is hardcoded into the node release to activate a feature or behavior at a specific time in the future. See Vote-by-Hash upgrade details for an example. Trigger Uses blocks Benefits Drawbacks Node upgrade + specific date No Simple to implement No manual activity required Inability to adjust timing without rushing new release out Canary block(s) \u00b6 The hash of a block is hardcoded in the node such that once that hash is seen by the node, it will activate a feature or behavior. Multiple block hashes can be used to perform different phases of a transition. See State blocks upgrade details for an example. Trigger Uses blocks Benefits Drawbacks Node upgrade + distribution of one block per transition phase Yes Can be used for multi-phase upgrades, including in combination with other options Timing flexible Requires manual intervention Adds additional code complexity Can cause unchecked table to fill during transition Epoch blocks \u00b6 A special block type that can only be generated using a pre-determined private key. These will be accepted by nodes and be attached as the frontier blocks on each account-chain on the network. This feature was built to allow very limited controls using these blocks: they cannot change account balances or representatives, only upgrade the account versions to allow new block structures. See State block upgrade details for an example. Trigger Uses blocks Benefits Drawbacks Node upgrade + distribution of epoch blocks Yes Provides clean upgrade markers directly within the ledger on every account-chain Timing flexible Ability to asynchronously upgrade block versions even for inactive/unopened account chains Requires manual intervention Introduces ability for non-account owner to write to account chain in a highly restricted way Adds additional code complexity Requires large volume of blocks The following are the epoch versions and the related accounts which are used to distribute them to the network. For certain protocol implementations these epoch signers need to be included to efficiently determine whether incoming blocks are epoch blocks. Version Epoch signer account Notes 1 xrb_3t6k35gi95xu6tergt6p69ck76ogmitsa8mnijtpxm9fkcm736xtoncuohr3 Genesis account 2 nano_3qb6o6i1tkzr6jwr5s7eehfxwg9x6eemitdinbpi7u8bjjwsgqfj4wzser3x Undistributed as of June 2020, see Increased work difficulty details above","title":"Network Upgrades"},{"location":"releases/network-upgrades/#network-upgrades","text":"For details on why and how network upgrades happen, along with explanations of the various types, please see the Upgrades overview and Upgrade methods sections further down.","title":"Network Upgrades"},{"location":"releases/network-upgrades/#upcoming-upgrades","text":"No upcoming upgrades at this time","title":"Upcoming upgrades"},{"location":"releases/network-upgrades/#future-upgrades","text":"","title":"Future upgrades"},{"location":"releases/network-upgrades/#new-pow-algorithm","text":"Purpose To help ensure Quality of Service on the network by providing the ability to generate and validate PoW using a new algorithm. This algorithm will be more memory-hard causing the resources required for generating transactions to shift accordingly. Transition details Date Type Description 2019-11-21 Node release Nano node V20.0 released to include a new PoW server and epoch block support. These are only foundational updates and will not be configured for activation in this release. 2020-08-29 Epoch blocks Following the postponing of the Nano PoW algorithm in favor or research towards other options, the original epoch v2 blocks intended for the PoW algorithm update were modified for increasing work difficulty using the existing algorithm in V21.0 and subsequently distributed in August 2020 . Any future PoW algorithm updates will require a different epoch block version. TBD Node release Nano node VXX.X released to include new PoW algorithm in PoW server and final changes allowing transition via epoch blocks. TBD Epoch blocks start Distribution of epoch blocks to each account which upgrades them to use the new PoW algorithm. Once an account is upgraded nodes will only validate work made using the new PoW algorithm for that account. TBD Epoch blocks end Distribution of epoch blocks ends after all accounts are upgraded. Transition Explanation In the above transition plan a phased node upgrade was used to provide support for some foundational elements of the new PoW algorithm while further details of the design are worked out. The epoch block distribution in this transition represents a clean switch from one PoW algorithm to the other - no block in the ledger is allowed to have work generated by either PoW, instead older block versions must use the existing PoW and new block versions must use the newer PoW. This clean switch comes with benefits including reduction in code complexity related to handling two types of PoW generation and validation for the same block versions, and the setting of a clear point in the ledger for each account where work values changed - potentially useful for future snapshoting. To mitigate the impacts of this approach the Nano Foundation will be communicating regularly about progress and monitoring closely the activity on the network to ensure proper conditions exist to finalize the transition.","title":"New PoW algorithm"},{"location":"releases/network-upgrades/#past-upgrades","text":"","title":"Past upgrades"},{"location":"releases/network-upgrades/#increased-work-difficulty","text":"Purpose To help ensure Quality of Service on the network by increasing the difficulty required for send and change blocks to be considered valid by the network (8x compared to current). To help offset the difficulty increase and add incentive to receive blocks so ledger pruning can be done more broadly in the future, the difficulty for receive blocks will simultaneously be reduced (\u215b compared to current). Transition details This upgrade is sometimes referenced as the epoch v2 upgrade and the relate events to complete are as follows: Date Type Description 2020-06-16 Node release Nano node V21.0 released which includes changes necessary for supporting new difficulty validation and generation 2020-08-18 v2 epoch blocks distribution start Distribution of v2 epoch blocks to all accounts to mark in the ledger the point at which the new work difficulty levels will be required. The start of this distribution process will occur once key services and over 90% of voting weight on the network has upraded. 2020-08-29 v2 epoch blocks distribution end Distribution of epoch blocks ends after all accounts are upgraded. Nodes de-peered with epoch blocks Due to the nature of the work difficulty changes, any nodes not updated to V21.0+ at the time of epoch block distribution will be de-peered from the network. Transition Explanation When changing the work difficulty requirements it is necessary to mark a point in each account where the difficulty requirements change so bootstrapping and other behaviors can accurately validate historical blocks. For this reason the epoch blocks are being distributed to act as the marker in the ledger. Once epoch block distribution is started the ability to validate the new work difficulty levels is required. Since node versions before V21.0 do not have the ability to do this, they will be immediately de-peered from the network and cannot participate with the current network until upgraded. To mitigate the impacts of this approach the Nano Foundation will be communicating regularly about progress and monitoring closely the activity on the network. Once acceptable conditions exist to finalize the transition, the distribution will begin. The current plan is to start once over 90% of voting weight has been upgraded, along with all the key services on the network. Recommended preparations In order to best prepare for the transition to new thresholds, the following items should be considered: Work generation guide The new Work Generation guide was written to help users and integrations leverage their work generation at all times. Work validation The work_validate RPC has multiple changes to the response, one which will break most existing integrations when upgrading to V21, two others that will become useful after upgrade: If difficulty parameter is not explicitly passed in the request, the existing valid field will not be returned ( breaking ) valid_all is a new return field, true if the work is valid at the current default difficulty (will go up after epoch upgrade) valid_receive is a new return field, true if the work is valid at the lower epoch_2 receive difficulty (only useful after the epoch upgrade is finished) If possible, it is best to avoid using this RPC until the epoch upgrade is completed External work generation nano-work-server has been updated to use the higher threshold ( fffffff800000000 ) by default when not given an explicit difficulty . The work_validate response has the same breaking changes as above. Prefer directly using the server as a work peer as outlined in the guide . The node always requests the appropriate difficulty threshold when using RPC block_create , or work_generate with the optional block . In cases where requesting directly from a node is not possible, avoid using the lower threshold for receive blocks ( fffffe0000000000 ) until the epoch upgrade is fully complete. Work generation performance Testing out work generation capabilities on a machine is recommended. Details for how to accomplish this can be found in the Benchmark section of the Work Generation guide . Active difficulty changes The active difficulty RPC command and WebSocket topic allow programatically retrieving the current difficulty from the network_minimum field in the response. When this field changes from ffffffc000000000 (pre-epoch v2 difficulty) to fffffff800000000 (8x higher epoch v2 difficulty), it indicates the epoch upgrade has begun. Post-distribution changes Accounts that have already been upgraded can optionally use fffffe0000000000 as the lower threshold for receive blocks going forward. The current epoch version of an opened account can be obtained using the account_info RPC, field account_version . Once that field has the value \"2\" , the lower threshold may be used. Other integration considerations Although it is already recommended as best practice, any integrations not already calling for the frontier block when constructing a transaction should do so. If hashes are being internally tracked and frontier is not requested, the integration could unintentionally cause a fork on the account with distribution of epoch blocks. See Step 1: Get Account Info for the account_info RPC recommendation when creating transactions.","title":"Increased work difficulty"},{"location":"releases/network-upgrades/#state-blocks","text":"Purpose The upgrade to state blocks involved multiple node releases and three different actions on the network including distribution of two canary blocks and the first epoch blocks. Transition Details Date Type Description 2018-03-23 Node release Nano node V11.0 released with support for state blocks built-in but not yet activated. 2018-04-11 Canary block Parse canary block distributed which enabled parsing of state blocks by nodes so manual generation of that block type would be accepted on the network going forward. This action was performed after a majority of the network upgraded to the required V11.0 to allow confirmations to occur on this new block type. 2018-05-20 Canary block Generation canary block distributed which forced the generation of state blocks by nodes going forward. At this point both state and legacy type (open, send, receive, change) blocks remain valid on the network. 2018-08-20 Node release Nano node V15.0 released with support for epoch blocks built-in and away distribution. 2018-10-25 Epoch v1 block distribution start Distribution of epoch v1 blocks begins. 2019-05-24 Epoch v1 block distribution end Distribution of epoch v1 blocks is finished. All accounts, opened and unopened, are now capped and can no longer attempt inserting legacy style blocks.","title":"State blocks"},{"location":"releases/network-upgrades/#vote-by-hash","text":"Purpose The upgrade to include the vote-by-hash feature was based on a hardcoded timestamp in the node. After this time nodes began voting using this new feature. Transition Details Date Type Description 2018-08-22 Node release Nano node V15.2 release with support for vote-by-hash but not yet activated. 2018-09-01 00:00:00 UTC Hardcoded date Nodes upgraded to V15.2 began voting using the vote-by-hash method. Nodes not yet upgraded would fail to properly interpret votes so were no longer compatible with the network.","title":"Vote-by-Hash"},{"location":"releases/network-upgrades/#upgrades-overview","text":"Nano is a protocol, an agreed upon standard that allows computers to communicate with each other and agree on data. Because of these communication standards, having mechanisms that force all nodes to upgrade certain behaviors at the same time is critical to the consensus and consistency in the network. In most blockchain networks these upgrades can be scheduled to take effect once a particular block height is hit because all nodes operate off a single, synchronous chain. Due to the Nano network being asynchronous this method doesn\u2019t work, so instead we need methods for upgrading accounts asynchronously. There are a couple different options for handling these upgrades and the process is currently managed primarily by the Nano Foundation. The upgrades are tested on the beta network to ensure all components are behaving as expecting before being considered for updating on the main network. If the behavior being changed involves consensus, any manual upgrade actions are triggered once a large majority of nodes and major services have upgraded. Of course many features, including protocol changes, can be activated immediately with a new node release, so these network upgrade scenarios are only reserved for certain cases. Options for providing better agreement on capabilities between nodes has been discussed in this GitHub issue . There is also a discussion around how to potentially automate network upgrade processes in this forum topic: https://forum.nano.org/t/automated-network-upgrades/113 .","title":"Upgrades overview"},{"location":"releases/network-upgrades/#upgrade-methods","text":"There are various methods used to upgrade and a brief overview of each, along with benefits and drawbacks, are included below. Upgrades for behaviors contained and activated with a single node release are not included as they are the foundation on top of which these other methods are made capable.","title":"Upgrade methods"},{"location":"releases/network-upgrades/#phased-node-upgrades","text":"A feature is introduced in a node release but not activated for use across the network until a subsequent node release. See State block upgrade details for an example. Trigger Uses blocks Benefits Drawbacks Multiple node upgrades No No manual intervention or automated process needed Uses already established upgrade process node operators are used to Longer time period to get feature activated Cannot be used to perform upgrades needed simultaneously across the network","title":"Phased node upgrades"},{"location":"releases/network-upgrades/#hardcoded-date","text":"A date is hardcoded into the node release to activate a feature or behavior at a specific time in the future. See Vote-by-Hash upgrade details for an example. Trigger Uses blocks Benefits Drawbacks Node upgrade + specific date No Simple to implement No manual activity required Inability to adjust timing without rushing new release out","title":"Hardcoded date"},{"location":"releases/network-upgrades/#canary-blocks","text":"The hash of a block is hardcoded in the node such that once that hash is seen by the node, it will activate a feature or behavior. Multiple block hashes can be used to perform different phases of a transition. See State blocks upgrade details for an example. Trigger Uses blocks Benefits Drawbacks Node upgrade + distribution of one block per transition phase Yes Can be used for multi-phase upgrades, including in combination with other options Timing flexible Requires manual intervention Adds additional code complexity Can cause unchecked table to fill during transition","title":"Canary block(s)"},{"location":"releases/network-upgrades/#epoch-blocks","text":"A special block type that can only be generated using a pre-determined private key. These will be accepted by nodes and be attached as the frontier blocks on each account-chain on the network. This feature was built to allow very limited controls using these blocks: they cannot change account balances or representatives, only upgrade the account versions to allow new block structures. See State block upgrade details for an example. Trigger Uses blocks Benefits Drawbacks Node upgrade + distribution of epoch blocks Yes Provides clean upgrade markers directly within the ledger on every account-chain Timing flexible Ability to asynchronously upgrade block versions even for inactive/unopened account chains Requires manual intervention Introduces ability for non-account owner to write to account chain in a highly restricted way Adds additional code complexity Requires large volume of blocks The following are the epoch versions and the related accounts which are used to distribute them to the network. For certain protocol implementations these epoch signers need to be included to efficiently determine whether incoming blocks are epoch blocks. Version Epoch signer account Notes 1 xrb_3t6k35gi95xu6tergt6p69ck76ogmitsa8mnijtpxm9fkcm736xtoncuohr3 Genesis account 2 nano_3qb6o6i1tkzr6jwr5s7eehfxwg9x6eemitdinbpi7u8bjjwsgqfj4wzser3x Undistributed as of June 2020, see Increased work difficulty details above","title":"Epoch blocks"},{"location":"releases/node-releases/","text":"Node Releases \u00b6 Updates to the Nano protocol are done through major node releases, occurring approximately every 1 to 4 months, and necessary patch releases in between. As changes are made to the protocol over time, newer node versions will stop peering with older versions. Details on which versions are actively peering, supported and being developed are included below. Nano Roadmap moved to GitHub Head over to the new Nano Roadmap GitHub Project for a more dynamic and updated view of the upcoming features under research and implementation for the Nano node and protocol. Current Release \u00b6 The following release is the latest and only release actively supported by the Nano Foundation. This release and the Active Releases below represent the only node versions that will participate on the main network. More details can be found on the Current Release Notes page . Node Protocol Database Release Date Release Notes GitHub Links 21.2 18 18 2020-09-03 V21.2 Release - Milestone - Changelog Known Issue V19+: macOS 'Too many open files' Issue: The following error can be seen when attempting to run a full node on macOS using the built-in Qt wallet or other GUI-based wallets: \"Exception while running wallet: open: Too many open files\". This is due to macOS having a very low default file descriptor limit and V19.0 uses more of them after the move to TCP. Solution: For now a workaround is needed to increase the limit. The method depends on the specific macOS version, but some people had success with the recipe in https://superuser.com/a/1171028 . Builds and Commands OS Download link/command Verification Universal Linux https://repo.nano.org/live/binaries/nano-node-V21.2-Linux.tar.bz2 SHA256 Checksum Debian http://repo.nano.org/live/binaries/nano-node-V21.2-Linux.deb SHA256 Checksum macOS https://repo.nano.org/live/binaries/nano-node-V21.2-Darwin.dmg SHA256 Checksum Windows (exe) https://repo.nano.org/live/binaries/nano-node-V21.2-win64.exe SHA256 Checksum Windows (zip) https://repo.nano.org/live/binaries/nano-node-V21.2-win64.zip SHA256 Checksum Docker docker pull nanocurrency/nano:V21.2 or docker pull nanocurrency/nano:latest See Pulling the Docker Image for more details. RHEL/CentOS rpm sudo rpm -iUvh https://repo.nano.org/live/binaries/nanocurrency-21.2-21.el7.x86_64.rpm This installs nano_node and nano_rpc to /usr/bin . SHA256 Checksum Next Planned Release \u00b6 The following release is currently under development. Details about potential features to be included can be found on the Upcoming Features page . Node Protocol Database Release Date Release Notes GitHub Links 22.0 TBD TBD TBD TBD Release - Milestone - Changelog Setup for testing on beta or test network If you are looking to test the latest version of the node ahead of release, check out the Beta Network and Test Network pages for more details about how to get setup on the appropriate network. Typically general integration and node upgrades are tested on the public test network, while new feature and load testing are conducted on the beta network. Active Releases \u00b6 The following releases can still actively participate on the network by peering with other nodes of the same versions. Any nodes running versions earlier than these will no longer peer with the latest and fall out of sync with the network. Node Protocol Database Release Date Release Notes GitHub Links 21.2 18 18 2020-09-03 V21.2 Release - Milestone - Changelog Known Issue V19+: macOS 'Too many open files' Issue: The following error can be seen when attempting to run a full node on macOS using the built-in Qt wallet or other GUI-based wallets: \"Exception while running wallet: open: Too many open files\". This is due to macOS having a very low default file descriptor limit and V19.0 uses more of them after the move to TCP. Solution: For now a workaround is needed to increase the limit. The method depends on the specific macOS version, but some people had success with the recipe in https://superuser.com/a/1171028 . Node Protocol Database Release Date Release Notes GitHub Links 21.1 18 18 2020-07-14 V21.1 Release - Milestone - Changelog Known Issue V19+: macOS 'Too many open files' Issue: The following error can be seen when attempting to run a full node on macOS using the built-in Qt wallet or other GUI-based wallets: \"Exception while running wallet: open: Too many open files\". This is due to macOS having a very low default file descriptor limit and V19.0 uses more of them after the move to TCP. Solution: For now a workaround is needed to increase the limit. The method depends on the specific macOS version, but some people had success with the recipe in https://superuser.com/a/1171028 . Known Issue Windows V21: Crash when using config node.logging.stable_log_filename Setting node.logging.stable_log_filename configuration option to true results in a node crash on Windows in V21.0 and V21.1, after a node restart. This must be set to false . Node Protocol Database Release Date Release Notes GitHub Links 21.0 18 18 2020-06-16 V21.0 Release - Milestone - Changelog Known Issue V19+: macOS 'Too many open files' Issue: The following error can be seen when attempting to run a full node on macOS using the built-in Qt wallet or other GUI-based wallets: \"Exception while running wallet: open: Too many open files\". This is due to macOS having a very low default file descriptor limit and V19.0 uses more of them after the move to TCP. Solution: For now a workaround is needed to increase the limit. The method depends on the specific macOS version, but some people had success with the recipe in https://superuser.com/a/1171028 . Known Issue Linux V21: 'unable to find libboost' If you are on Linux and unable to get V21.0 to start, unable to find libboost... https://github.com/nanocurrency/nano-node/releases/download/V21.0/nano-node-V21.0.1-Linux.tar.bz2 has been added to the release artifacts with the correct lib rpath. Please use this if you do not wish to move the lib folder into the bin folder after extraction. Known Issue Windows V21: Crash when using config node.logging.stable_log_filename Setting node.logging.stable_log_filename configuration option to true results in a node crash on Windows in V21.0 and V21.1, after a node restart. This must be set to false . Inactive Releases \u00b6 The following versions are no longer peered with by nodes running the active versions above and will not work properly communicate if run on the network. The details below are for historical purposes only. Inactive Releases Node Protocol Database Release Date Release Notes GitHub Links 20.0 17 15 2019-11-12 V20.0 Release - Milestone - Changelog 19.0 17 14 2019-07-11 V19.0 Release - Milestone - Changelog 18.0 16 13 2019-02-21 Release - Milestone - Changelog 17.1 15 2018-12-21 Release - Milestone - Changelog 17.0 15 2018-12-18 Release - Milestone - Changelog 16.3 14 2018-11-20 Release - Milestone - Changelog 16.2 14 2018-10-11 Release - Milestone - Changelog 16.1 14 2018-09-29 Release - Milestone - Changelog 16.0 14 2018-09-11 Release - Milestone - Changelog 15.2 13 2018-08-22 Release - Milestone - Changelog 15.1 13 2018-08-20 Release - Milestone - Changelog 15.0 13 2018-08-20 Release - Milestone - Changelog 14.2 11 2018-06-21 Release - Changelog 14.1 10 2018-06-11 Release - Changelog 14.0 10 2018-06-11 Release - Changelog 13.0 9 2018-05-10 Release - Changelog 12.1 8 2018-04-21 Release - Changelog 12.0 8 2018-04-18 Release - Changelog 11.2 7 2018-04-04 Release - Changelog 11.1 7 2018-03-29 Release - Changelog 11.0 7 2018-03-23 Release - Changelog 10.0 6 2018-02-15 Release - Changelog Details for versions older than 10.0 can be found in tagged releases in Github . Release Notes \u00b6 For the latest release notes, see the Current Release Notes page . To reference release notes for older versions ( V19.0 , V20.0 ), see the Previous Release Notes page .","title":"Node Releases"},{"location":"releases/node-releases/#node-releases","text":"Updates to the Nano protocol are done through major node releases, occurring approximately every 1 to 4 months, and necessary patch releases in between. As changes are made to the protocol over time, newer node versions will stop peering with older versions. Details on which versions are actively peering, supported and being developed are included below. Nano Roadmap moved to GitHub Head over to the new Nano Roadmap GitHub Project for a more dynamic and updated view of the upcoming features under research and implementation for the Nano node and protocol.","title":"Node Releases"},{"location":"releases/node-releases/#current-release","text":"The following release is the latest and only release actively supported by the Nano Foundation. This release and the Active Releases below represent the only node versions that will participate on the main network. More details can be found on the Current Release Notes page . Node Protocol Database Release Date Release Notes GitHub Links 21.2 18 18 2020-09-03 V21.2 Release - Milestone - Changelog Known Issue V19+: macOS 'Too many open files' Issue: The following error can be seen when attempting to run a full node on macOS using the built-in Qt wallet or other GUI-based wallets: \"Exception while running wallet: open: Too many open files\". This is due to macOS having a very low default file descriptor limit and V19.0 uses more of them after the move to TCP. Solution: For now a workaround is needed to increase the limit. The method depends on the specific macOS version, but some people had success with the recipe in https://superuser.com/a/1171028 . Builds and Commands OS Download link/command Verification Universal Linux https://repo.nano.org/live/binaries/nano-node-V21.2-Linux.tar.bz2 SHA256 Checksum Debian http://repo.nano.org/live/binaries/nano-node-V21.2-Linux.deb SHA256 Checksum macOS https://repo.nano.org/live/binaries/nano-node-V21.2-Darwin.dmg SHA256 Checksum Windows (exe) https://repo.nano.org/live/binaries/nano-node-V21.2-win64.exe SHA256 Checksum Windows (zip) https://repo.nano.org/live/binaries/nano-node-V21.2-win64.zip SHA256 Checksum Docker docker pull nanocurrency/nano:V21.2 or docker pull nanocurrency/nano:latest See Pulling the Docker Image for more details. RHEL/CentOS rpm sudo rpm -iUvh https://repo.nano.org/live/binaries/nanocurrency-21.2-21.el7.x86_64.rpm This installs nano_node and nano_rpc to /usr/bin . SHA256 Checksum","title":"Current Release"},{"location":"releases/node-releases/#next-planned-release","text":"The following release is currently under development. Details about potential features to be included can be found on the Upcoming Features page . Node Protocol Database Release Date Release Notes GitHub Links 22.0 TBD TBD TBD TBD Release - Milestone - Changelog Setup for testing on beta or test network If you are looking to test the latest version of the node ahead of release, check out the Beta Network and Test Network pages for more details about how to get setup on the appropriate network. Typically general integration and node upgrades are tested on the public test network, while new feature and load testing are conducted on the beta network.","title":"Next Planned Release"},{"location":"releases/node-releases/#active-releases","text":"The following releases can still actively participate on the network by peering with other nodes of the same versions. Any nodes running versions earlier than these will no longer peer with the latest and fall out of sync with the network. Node Protocol Database Release Date Release Notes GitHub Links 21.2 18 18 2020-09-03 V21.2 Release - Milestone - Changelog Known Issue V19+: macOS 'Too many open files' Issue: The following error can be seen when attempting to run a full node on macOS using the built-in Qt wallet or other GUI-based wallets: \"Exception while running wallet: open: Too many open files\". This is due to macOS having a very low default file descriptor limit and V19.0 uses more of them after the move to TCP. Solution: For now a workaround is needed to increase the limit. The method depends on the specific macOS version, but some people had success with the recipe in https://superuser.com/a/1171028 . Node Protocol Database Release Date Release Notes GitHub Links 21.1 18 18 2020-07-14 V21.1 Release - Milestone - Changelog Known Issue V19+: macOS 'Too many open files' Issue: The following error can be seen when attempting to run a full node on macOS using the built-in Qt wallet or other GUI-based wallets: \"Exception while running wallet: open: Too many open files\". This is due to macOS having a very low default file descriptor limit and V19.0 uses more of them after the move to TCP. Solution: For now a workaround is needed to increase the limit. The method depends on the specific macOS version, but some people had success with the recipe in https://superuser.com/a/1171028 . Known Issue Windows V21: Crash when using config node.logging.stable_log_filename Setting node.logging.stable_log_filename configuration option to true results in a node crash on Windows in V21.0 and V21.1, after a node restart. This must be set to false . Node Protocol Database Release Date Release Notes GitHub Links 21.0 18 18 2020-06-16 V21.0 Release - Milestone - Changelog Known Issue V19+: macOS 'Too many open files' Issue: The following error can be seen when attempting to run a full node on macOS using the built-in Qt wallet or other GUI-based wallets: \"Exception while running wallet: open: Too many open files\". This is due to macOS having a very low default file descriptor limit and V19.0 uses more of them after the move to TCP. Solution: For now a workaround is needed to increase the limit. The method depends on the specific macOS version, but some people had success with the recipe in https://superuser.com/a/1171028 . Known Issue Linux V21: 'unable to find libboost' If you are on Linux and unable to get V21.0 to start, unable to find libboost... https://github.com/nanocurrency/nano-node/releases/download/V21.0/nano-node-V21.0.1-Linux.tar.bz2 has been added to the release artifacts with the correct lib rpath. Please use this if you do not wish to move the lib folder into the bin folder after extraction. Known Issue Windows V21: Crash when using config node.logging.stable_log_filename Setting node.logging.stable_log_filename configuration option to true results in a node crash on Windows in V21.0 and V21.1, after a node restart. This must be set to false .","title":"Active Releases"},{"location":"releases/node-releases/#inactive-releases","text":"The following versions are no longer peered with by nodes running the active versions above and will not work properly communicate if run on the network. The details below are for historical purposes only. Inactive Releases Node Protocol Database Release Date Release Notes GitHub Links 20.0 17 15 2019-11-12 V20.0 Release - Milestone - Changelog 19.0 17 14 2019-07-11 V19.0 Release - Milestone - Changelog 18.0 16 13 2019-02-21 Release - Milestone - Changelog 17.1 15 2018-12-21 Release - Milestone - Changelog 17.0 15 2018-12-18 Release - Milestone - Changelog 16.3 14 2018-11-20 Release - Milestone - Changelog 16.2 14 2018-10-11 Release - Milestone - Changelog 16.1 14 2018-09-29 Release - Milestone - Changelog 16.0 14 2018-09-11 Release - Milestone - Changelog 15.2 13 2018-08-22 Release - Milestone - Changelog 15.1 13 2018-08-20 Release - Milestone - Changelog 15.0 13 2018-08-20 Release - Milestone - Changelog 14.2 11 2018-06-21 Release - Changelog 14.1 10 2018-06-11 Release - Changelog 14.0 10 2018-06-11 Release - Changelog 13.0 9 2018-05-10 Release - Changelog 12.1 8 2018-04-21 Release - Changelog 12.0 8 2018-04-18 Release - Changelog 11.2 7 2018-04-04 Release - Changelog 11.1 7 2018-03-29 Release - Changelog 11.0 7 2018-03-23 Release - Changelog 10.0 6 2018-02-15 Release - Changelog Details for versions older than 10.0 can be found in tagged releases in Github .","title":"Inactive Releases"},{"location":"releases/node-releases/#release-notes","text":"For the latest release notes, see the Current Release Notes page . To reference release notes for older versions ( V19.0 , V20.0 ), see the Previous Release Notes page .","title":"Release Notes"},{"location":"releases/release-v19-0/","text":"V19.0 \u00b6 Node Protocol Database Release Date Release Notes GitHub Links 19.0 17 14 2019-07-11 V19.0 Release - Milestone - Changelog Known Issue V19+: macOS 'Too many open files' Issue: The following error can be seen when attempting to run a full node on macOS using the built-in Qt wallet or other GUI-based wallets: \"Exception while running wallet: open: Too many open files\". This is due to macOS having a very low default file descriptor limit and V19.0 uses more of them after the move to TCP. Solution: For now a workaround is needed to increase the limit. The method depends on the specific macOS version, but some people had success with the recipe in https://superuser.com/a/1171028 . Upgrade Notices \u00b6 Version Limits \u00b6 Upgrades from versions V17.1 and to V19 will involve a sequential database upgrade and impact participation of the node on the network. RPC calls will be unavailable for a long period of time amongst other impacts. Upgrading from V17.1 and earlier to V19.0 not recommended It is highly recommended that nodes are upgraded to V18.0 first or a V18.0 ledger is acquired and used when upgrading to V19.0. Confirmation tracking considerations \u00b6 The addition of confirmation height to the database requires the node to validate that blocks are confirmed before the cementing can occur. This process can take up to 24 hours or longer to complete and will cause an increase in some resource usage, particularly CPU and network bandwidth increases, but won\u2019t impact participation on the network. For integrations watching confirmations, the existing HTTP callback , block_confirm RPC and confirmation_history RPC methods will continue to function as before. Tracking confirmed block hashes required It is required that tracking of confirmed block hashes outside the node is done to avoid potential duplicate notifications from causing issues. This was a requirement in previous versions and remains the same with V19. For those looking to utilize the new WebSocket confirmation subscription or new confirmed field in block_info RPC responses, special considerations should be taken if implementing before confirmation height updates are complete: If the websocket confirmation subscription is hooked up to receive all confirmations (default) then notifications for confirmations will come through during the cementing process on a new or upgrading ledger as the confirmation process will occur (it also fires for dependent confirmations) Calls to block_info for blocks in the ledger before the confirmation height upgrade process began may indicate confirmed as false despite their having been confirmed on the network before. This is expected behavior. To validate that confirmation height upgrade is complete, note the count value from the block_count RPC when the upgrade is started and once the cemented amount returned by this call (include the include_cemented option) is higher than that previous count, cementing is in sync. Emitting nano_ prefixed addresses \u00b6 In this and future versions, all addresses emitted from the node will use the nano_ prefix. It will continue to support input for xrb_ prefixed addresses, but all services must verify they are properly set up to handle the node outputting nano_ prefixed addresses. Live network over TCP \u00b6 Live network traffic over TCP is now available and operates on the same port (7075 for main network, 54000 for beta network) as the bootstrapping network that was already available over TCP. Because of this, existing network setups that are open inbound and outbound on port 7075 for TCP should function as expected with V19.0. For those running production services, it is still recommended to verify network ports setup and consider setting up a new node on internal networks to ensure it can connect and participate on the main network before production nodes are upgraded. To check for proper connection via TCP, call the peers RPC with peer_details option and look for peers with type = tcp . This command can be used to search for these instances: curl -sd '{\"action\": \"peers\", \"peer_details\":\"true\"}' [::1]:7076 | grep \"\\\"type\\\": \\\"tcp\\\"\" | wc -l Major Updates \u00b6 Confirmation Height \u00b6 This provides cementing of blocks by marking on an account the highest block height that has been confirmed for the account. A more detailed look at this feature can be found in the relatd Medium article: https://medium.com/nanocurrency/looking-up-to-confirmation-height-69f0cd2a85bc TCP Network \u00b6 Blocks being published and voted on live are now supported via TCP, with UDP remaining as a fallback. See the TCP callouts in Upgrade Notices above for information about verifying your network setup is ready for the upgrade. Dynamic Proof-of-Work and Prioritization \u00b6 With the ability to track work difficulty seen on the network and have the node wallet produce more difficult work for local blocks, this feature allows users to get their transactions prioritized for processing. More details about this feature can be found in the Medium article: https://medium.com/nanocurrency/dynamic-proof-of-work-prioritization-4618b78c5be9 RPC Process Options \u00b6 By default the RPC server will run in the node process, but can be configured to run as a child process or completely out of process (currently limited to running on the same computer), depending on your needs. See Running Nano as a service for more details. RPC/CLI Updates \u00b6 No Breaking Changes There were no breaking changes made in V19 for any RPC or CLI commands. It is recommended any integrations run tests against V19 before upgrading production nodes, and also explore the various changes below to improve their setups. NEW unopened RPC provides the total pending balance for unopened accounts NEW active_difficulty RPC allows tracking of the difficulty levels seen on the network which can be used to target higher levels of PoW to prioritize transactions Using --diagnostics CLI option now validates config and generates default one if it doesn\u2019t exist wallet_create and wallet_change_seed RPCs accept seed and return restored accounts for easier seed management The pending RPC can now optionally be using sorting by amount Difficulty and multiplier options available in work_generate and work_validate RPCs for easier management of dynamic work levels on blocks State blocks returned by block_info / blocks_info contain subtype for easier identification of block types Json literals supported for block input ( process , sign , and block_hash ) and output ( block_create , block_info , blocks_info , confirmation_info , unchecked_get and unchecked_keys ) on RPC calls A new optional argument include_not_found in blocks_info allows requests which contain invalid block hashes to get results that include an array of blocks_not_found instead of just an error The account_history RPC now: Accepts account_filter to allow filtering of results to a specific account or set of accounts Allows reverse option to return details starting from the head block on the account Block height on account chain now included in response The accounts_pending RPC allows for sorting by amounts For ledger and unopened RPCs a new optional threshold value can be used to limit results by balance A new include_cemented option in block_count RPC adds return of the cemented blocks in the ledger - cemented blocks are ones that have been confirmed and are at or below the confirmation height set on the account Node Configuration Updates \u00b6 Config.json New active_elections_size will limit the number of active elections allowed before dropping occurs. Default is 50,000 but higher settings are recommended for nodes provisioned with 8GB RAM or more New bandwidth_limit will limit the outbound voting traffic to 5MB/s by default New confirmation_history_size provides an adjustable limit on the batching of confirmations return in the confirmation_history RPC. Default 2048 which will support up to ~56 confirmations/sec before confirmations may be missed. The new websocket setup with confirmation subscription is recommended over use of the confirmation_history RPC. Advanced Configuration New vote_generator_delay allows for tuning performance of bundling votes by hash before sending. Rpc_config.json This new file was split out from the config.json file as the RPC server can now be run in its own process. Entries previously existing in config.json were migrated over and new values added. One setting to note: the max_request_size parameter is defaulted to 32MB - if your service is submitting data amounts larger than this you will need to adjust accordingly. Automated config backups Backups of config files will be made prior to upgrades. During upgrades from V18 to V19 you will see a backup created even for the new rpc_config.json - this is expected behavior given the upgrade process. Developer/Debug Options \u00b6 New launch flag for tuning block processor: --block_processor_batch_size , --block_processor_full_size and --block_processor_verification_size New launch flags for disabling TCP real-time network and UDP for debugging connectivity Expanded stats RPC contains additional values related to confirmation height Deprecations \u00b6 The following RPC calls are being deprecated and will be removed in a future release: history payment_begin payment_end payment_init payment_wait Other Notices \u00b6 New nanorep QR code standard A new nanorep QR code standard for easier management of representative changes was added for wallets and other services to consider supporting. New recommended block explorer The Nano Foundation supports a new recommended block explorer - NanoCrawler . We encourage services and exchanges linking out to block explorers to consider using NanoCrawler going forward as it provides solid design and performance for referencing blocks, accounts and more.","title":"V19.0"},{"location":"releases/release-v19-0/#v190","text":"Node Protocol Database Release Date Release Notes GitHub Links 19.0 17 14 2019-07-11 V19.0 Release - Milestone - Changelog Known Issue V19+: macOS 'Too many open files' Issue: The following error can be seen when attempting to run a full node on macOS using the built-in Qt wallet or other GUI-based wallets: \"Exception while running wallet: open: Too many open files\". This is due to macOS having a very low default file descriptor limit and V19.0 uses more of them after the move to TCP. Solution: For now a workaround is needed to increase the limit. The method depends on the specific macOS version, but some people had success with the recipe in https://superuser.com/a/1171028 .","title":"V19.0"},{"location":"releases/release-v19-0/#upgrade-notices","text":"","title":"Upgrade Notices"},{"location":"releases/release-v19-0/#version-limits","text":"Upgrades from versions V17.1 and to V19 will involve a sequential database upgrade and impact participation of the node on the network. RPC calls will be unavailable for a long period of time amongst other impacts. Upgrading from V17.1 and earlier to V19.0 not recommended It is highly recommended that nodes are upgraded to V18.0 first or a V18.0 ledger is acquired and used when upgrading to V19.0.","title":"Version Limits"},{"location":"releases/release-v19-0/#confirmation-tracking-considerations","text":"The addition of confirmation height to the database requires the node to validate that blocks are confirmed before the cementing can occur. This process can take up to 24 hours or longer to complete and will cause an increase in some resource usage, particularly CPU and network bandwidth increases, but won\u2019t impact participation on the network. For integrations watching confirmations, the existing HTTP callback , block_confirm RPC and confirmation_history RPC methods will continue to function as before. Tracking confirmed block hashes required It is required that tracking of confirmed block hashes outside the node is done to avoid potential duplicate notifications from causing issues. This was a requirement in previous versions and remains the same with V19. For those looking to utilize the new WebSocket confirmation subscription or new confirmed field in block_info RPC responses, special considerations should be taken if implementing before confirmation height updates are complete: If the websocket confirmation subscription is hooked up to receive all confirmations (default) then notifications for confirmations will come through during the cementing process on a new or upgrading ledger as the confirmation process will occur (it also fires for dependent confirmations) Calls to block_info for blocks in the ledger before the confirmation height upgrade process began may indicate confirmed as false despite their having been confirmed on the network before. This is expected behavior. To validate that confirmation height upgrade is complete, note the count value from the block_count RPC when the upgrade is started and once the cemented amount returned by this call (include the include_cemented option) is higher than that previous count, cementing is in sync.","title":"Confirmation tracking considerations"},{"location":"releases/release-v19-0/#emitting-nano_-prefixed-addresses","text":"In this and future versions, all addresses emitted from the node will use the nano_ prefix. It will continue to support input for xrb_ prefixed addresses, but all services must verify they are properly set up to handle the node outputting nano_ prefixed addresses.","title":"Emitting nano_ prefixed addresses"},{"location":"releases/release-v19-0/#live-network-over-tcp","text":"Live network traffic over TCP is now available and operates on the same port (7075 for main network, 54000 for beta network) as the bootstrapping network that was already available over TCP. Because of this, existing network setups that are open inbound and outbound on port 7075 for TCP should function as expected with V19.0. For those running production services, it is still recommended to verify network ports setup and consider setting up a new node on internal networks to ensure it can connect and participate on the main network before production nodes are upgraded. To check for proper connection via TCP, call the peers RPC with peer_details option and look for peers with type = tcp . This command can be used to search for these instances: curl -sd '{\"action\": \"peers\", \"peer_details\":\"true\"}' [::1]:7076 | grep \"\\\"type\\\": \\\"tcp\\\"\" | wc -l","title":"Live network over TCP"},{"location":"releases/release-v19-0/#major-updates","text":"","title":"Major Updates"},{"location":"releases/release-v19-0/#confirmation-height","text":"This provides cementing of blocks by marking on an account the highest block height that has been confirmed for the account. A more detailed look at this feature can be found in the relatd Medium article: https://medium.com/nanocurrency/looking-up-to-confirmation-height-69f0cd2a85bc","title":"Confirmation Height"},{"location":"releases/release-v19-0/#tcp-network","text":"Blocks being published and voted on live are now supported via TCP, with UDP remaining as a fallback. See the TCP callouts in Upgrade Notices above for information about verifying your network setup is ready for the upgrade.","title":"TCP Network"},{"location":"releases/release-v19-0/#dynamic-proof-of-work-and-prioritization","text":"With the ability to track work difficulty seen on the network and have the node wallet produce more difficult work for local blocks, this feature allows users to get their transactions prioritized for processing. More details about this feature can be found in the Medium article: https://medium.com/nanocurrency/dynamic-proof-of-work-prioritization-4618b78c5be9","title":"Dynamic Proof-of-Work and Prioritization"},{"location":"releases/release-v19-0/#rpc-process-options","text":"By default the RPC server will run in the node process, but can be configured to run as a child process or completely out of process (currently limited to running on the same computer), depending on your needs. See Running Nano as a service for more details.","title":"RPC Process Options"},{"location":"releases/release-v19-0/#rpccli-updates","text":"No Breaking Changes There were no breaking changes made in V19 for any RPC or CLI commands. It is recommended any integrations run tests against V19 before upgrading production nodes, and also explore the various changes below to improve their setups. NEW unopened RPC provides the total pending balance for unopened accounts NEW active_difficulty RPC allows tracking of the difficulty levels seen on the network which can be used to target higher levels of PoW to prioritize transactions Using --diagnostics CLI option now validates config and generates default one if it doesn\u2019t exist wallet_create and wallet_change_seed RPCs accept seed and return restored accounts for easier seed management The pending RPC can now optionally be using sorting by amount Difficulty and multiplier options available in work_generate and work_validate RPCs for easier management of dynamic work levels on blocks State blocks returned by block_info / blocks_info contain subtype for easier identification of block types Json literals supported for block input ( process , sign , and block_hash ) and output ( block_create , block_info , blocks_info , confirmation_info , unchecked_get and unchecked_keys ) on RPC calls A new optional argument include_not_found in blocks_info allows requests which contain invalid block hashes to get results that include an array of blocks_not_found instead of just an error The account_history RPC now: Accepts account_filter to allow filtering of results to a specific account or set of accounts Allows reverse option to return details starting from the head block on the account Block height on account chain now included in response The accounts_pending RPC allows for sorting by amounts For ledger and unopened RPCs a new optional threshold value can be used to limit results by balance A new include_cemented option in block_count RPC adds return of the cemented blocks in the ledger - cemented blocks are ones that have been confirmed and are at or below the confirmation height set on the account","title":"RPC/CLI Updates"},{"location":"releases/release-v19-0/#node-configuration-updates","text":"Config.json New active_elections_size will limit the number of active elections allowed before dropping occurs. Default is 50,000 but higher settings are recommended for nodes provisioned with 8GB RAM or more New bandwidth_limit will limit the outbound voting traffic to 5MB/s by default New confirmation_history_size provides an adjustable limit on the batching of confirmations return in the confirmation_history RPC. Default 2048 which will support up to ~56 confirmations/sec before confirmations may be missed. The new websocket setup with confirmation subscription is recommended over use of the confirmation_history RPC. Advanced Configuration New vote_generator_delay allows for tuning performance of bundling votes by hash before sending. Rpc_config.json This new file was split out from the config.json file as the RPC server can now be run in its own process. Entries previously existing in config.json were migrated over and new values added. One setting to note: the max_request_size parameter is defaulted to 32MB - if your service is submitting data amounts larger than this you will need to adjust accordingly. Automated config backups Backups of config files will be made prior to upgrades. During upgrades from V18 to V19 you will see a backup created even for the new rpc_config.json - this is expected behavior given the upgrade process.","title":"Node Configuration Updates"},{"location":"releases/release-v19-0/#developerdebug-options","text":"New launch flag for tuning block processor: --block_processor_batch_size , --block_processor_full_size and --block_processor_verification_size New launch flags for disabling TCP real-time network and UDP for debugging connectivity Expanded stats RPC contains additional values related to confirmation height","title":"Developer/Debug Options"},{"location":"releases/release-v19-0/#deprecations","text":"The following RPC calls are being deprecated and will be removed in a future release: history payment_begin payment_end payment_init payment_wait","title":"Deprecations"},{"location":"releases/release-v19-0/#other-notices","text":"New nanorep QR code standard A new nanorep QR code standard for easier management of representative changes was added for wallets and other services to consider supporting. New recommended block explorer The Nano Foundation supports a new recommended block explorer - NanoCrawler . We encourage services and exchanges linking out to block explorers to consider using NanoCrawler going forward as it provides solid design and performance for referencing blocks, accounts and more.","title":"Other Notices"},{"location":"releases/release-v20-0/","text":"V20.0 \u00b6 Node Protocol Database Release Date Release Notes GitHub Links 20.0 17 15 2019-11-12 V20.0 Release - Milestone - Changelog Known Issue V19+: macOS 'Too many open files' Issue: The following error can be seen when attempting to run a full node on macOS using the built-in Qt wallet or other GUI-based wallets: \"Exception while running wallet: open: Too many open files\". This is due to macOS having a very low default file descriptor limit and V19.0 uses more of them after the move to TCP. Solution: For now a workaround is needed to increase the limit. The method depends on the specific macOS version, but some people had success with the recipe in https://superuser.com/a/1171028 . Known Issue V20: Peers stake reporting inaccurate (Windows only) Issue: For Windows builds only, when calling confirmation_quorum RPC the peers_stake_total amount returned may be inaccurate, returning a range from the correct full peer stake amount down to 0. Solution: A solution to the issue has been found and as this is a reporting issue only, the fix will be included in the next released version. For those manually building the node, patching the fix pull request onto the V20.0 tag can resolve the issue now. Or alternatively, building on the V20.0 tag with RelWithDebInfo option, see Build Instructions for Windows . Upgrade Notices \u00b6 Only node V18.0 and higher supported With V20.0 only nodes V18.0 and higher will be peered with on the network (see Active Releases above). This means any nodes running versions earlier than 18.0 will begin to lose peers and fall out of sync over time once upgrades to V20.0 begin. If you are running a node version earlier than V18.0, please update as soon as possible to avoid disruption. Database upgrades \u00b6 Upgrade requires downtime, read carefully Please review the following details carefully as the automatic database upgrade process will cause downtime for the node. This version brings some new optimizations to the ledger which require database upgrades to be performed. Due to the nature of upgrades, the following impacts will occur: Upgrade times depend on specs of the node host but are expected to be between 5 and 15 minutes for most cases. Upgrade activities are synchronous which means the node will not be participating on the network and RPC requests won\u2019t be available during the upgrade process - services requiring uptime should plan to swap out their ledger for one upgraded by a separate node or download from a trusted source. Ledger size will grow by up to 50% during this process - please ensure you have free disk space of 3x the current ledger before starting the upgrade (currently ~16GB on the main network). A database vacuum will be automatically performed after the upgrade to reclaim disk space, which can be verified complete in the logs. Doing proper ledger backups is recommended before starting this process. Ensure you have enough disk space to allow for any ledger backups plus the additional disk space required for the database upgrade mentioned above. A new config option in V20, node.backup_before_upgrade , will allow for automated ledger backups between future versions. New .toml config files \u00b6 A new setup in V20.0 uses internal default config values, so config files are only needed for non-default settings. During upgrade new .toml format files will be created for the config.json and rpc_config.json files if they contain non-default values. Before migration config_backup_toml_migration.json and rpc_config_backup_toml_migration.json files will be created for backup. The following commands can be used to generated commented out, complete config files for review: Only set non-default values in .toml files It is not recommended to uncomment all values in the .toml file output from commands below. Instead, only uncomment or insert non-default values to ensure any default value changes in future release are only overridden when needed. Name Description Generated with config-node.toml Node configuration nano_node --generate_config node config-rpc.toml RPC configuration nano_node --generate_config rpc config-nano-pow-server.toml Proof of work server configuration nano_pow_server --generate_config config-qtwallet.toml Qt developer wallet configuration This file is maintained by the Qt wallet More details on the new configuration setup can be found in the node Configuration documentation . Networking changes \u00b6 Improvements to default network setup in this version requires less setup from node operators, specifically around port forwarding. Although new setups will immediately benefit, any existing systems that have already setup port forwarding may be impacted by these changes. For those systems, we recommend validating your network setup allows proper peering with a test V20.0 node prior to upgrading. If you run into issues, review the Troubleshooting UPnP documentation for assistance. Additional help can be sought in the Node and Representative Management forum category . Proof-of-Work management \u00b6 A couple changes to PoW management that services should be aware of: With OpenCL enabled, nodes will still use the local CPU for work generation by default. Setting node.work_threads to 0 will turn this off if required. Regenerating PoW for delayed transactions during high network load will now happen by default through the process RPC . If you wish to turn this off, setting watch_work to false is required. Other updates to review Improvements to the External Management and Block Confirmation and Tracking documentation should help clarify the recommended approaches to building integrations. Major Updates \u00b6 Migration to .toml config files \u00b6 Better legibility, support for comments, and no more having the node write to your config files are some of the benefits of this upgrade. Any non-default values captured in your existing .json files will be migrated and you can export a full list of configuration options for use with simple commands. See additional callouts in Upgrade Notices above and in the node Configuration documentation . Proof-of-Work regeneration outside development wallet \u00b6 Any requests to the process RPC will have the new watch_work option turned on by default, allowing the node to regenerate Proof-of-Work for blocks even if they are outside of the node\u2019s development wallet. This makes Dynamic PoW and prioritization function more consistently across the network. If you have an external integration utilizing this RPC call, you will automatically start taking advantage of rework during confirmation delays on the network. RocksDB experimental support \u00b6 With better disk IO usage, RocksDB is being introduced in this version with experimental support. It is not recommended for use in production, but those interested in testing out a more performant database for the ledger should checkout how to install RocksDB and try it out on development and test systems. We also have a related discussion in our forum for those interested. Active elections and other optimizations \u00b6 Thanks to our excellent community testers putting effort into collecting and analyzing block, voting and confirmation data from the beta network, we\u2019ve found various optimizations with the active elections process, confirmation request attempts and bootstrapping behaviors. Various changes have been implemented to help reduce resource usage on nodes in various areas and increase the available throughput on the network. This feature also enhances the effectiveness of prioritization and rework of PoW. No action is needed to take advantage of these great updates. Infrastructure for PoW transition \u00b6 Back in September we announced a new PoW algorithm design we had been working on which aimed to be memory hard. After open sourcing an implementation of the algorithm, an efficient low-memory solution was found and we subsequently removed the algorithm implementation from V20 . As part of the original implementation work we were able to setup infrastructure for moving PoW out of the node process in the future, and also added support for version 2 of epoch blocks, which will allow the network upgrade later when a new PoW algorithm is ready. These updates will be included in Lydia but not be utilized until a future version. To follow along with node releases going forward, check out the Upcoming Features page. RPC Updates \u00b6 BEHAVIOR CHANGE process now takes an optional flag watch_work (default true ). Unless set to false , processed blocks can be subject to PoW rework BEHAVIOR CHANGE bootstrap , bootstrap_any and boostrap_lazy will now throw errors when certain launch flags are used to disabled bootstrap methods - see each RPC page for details BEHAVIOR CHANGE RPCs requiring work generation will now throw errors when work generation is disabled (no work peers , no OpenCL and no work threads configured) block_count no longer requires config option enable_control to get the cemented block count unchecked now takes an optional flag json_block to return blocks in JSON-format version now includes more fields - network label, identifier (hash of the genesis open block) and build information peers and node_id now return node IDs with a node_ prefix work_generate and work_validate can now take a multiplier (against base difficulty) to set a different difficulty threshold CLI Updates \u00b6 NEW generate_config [node|rpc] prints sample configuration files to stdout use_defaults additional argument to generate uncommented entries (not recommended) NEW config passes configuration arguments, alternative to setting in the config file Node Configuration Updates \u00b6 Support in Nano Forum For node operators looking to upgrade to V20.0 or tune their configurations, the Node and Representative Management category of the forum is a great resource to use. Generate .toml config to see options As noted in the Upgrade Notices above, this version will migrate your existing .json files over to .toml files. Only non-default values for these fields will be added to the new .toml file. If you wish to adjust other options, use the config generation commands to see all available options. The following options are notable node configuration updates. Additional configuration changes have been included in this release and can be found when generating the config files. backup_before_upgrade (default false ) enables automatic backup of the ledger and wallet databases when updating to a new node version work_watcher_period (default 5 seconds) controls how frequently the node should check the confirmation status of block in the work watcher, and re-generate higher difficulty work if unconfirmed max_work_generate_multiplier (default 64.0 ) previously max_work_generate_difficulty , now a multiplier for easier management, specifies the absolute maximum difficulty multiplier to be used for work generation Developer/Debug Options \u00b6 New RPC epoch_upgrade allowing easier epoch distribution ( Note - this epoch requires a special private key to be used, see the Network Upgrades page for information) RPC bootstrap has a new optional \"bypass_frontier_confirmation\" RPC bootstrap_status now displays more data about the current bootstrap attempt New CLI debug_stacktrace displays an example stacktrace, simulating an unexpected program crash New CLI debug_account_versions displays the total number of accounts separated by version and opened/unopened CLI debug_validate_blocks updated to cover more cases CLI debug_profile_verify renamed to debug_profile_validate and now provides simplified work validation profiling New CMake build options: NANO_ROCKSDB enables use of the RocksDB database backend, experimental NANO_WARN_TO_ERR turns compiler warnings into errors on Linux/Mac NANO_TIMED_LOCKS provides information on mutexes held for a long time NANO_STACKTRACE_BACKTRACE uses libbacktrace to provide stacktraces CI_BUILD if set, uses the TRAVIS_TAG environment variable to modify the locally reported node version, to help with support tickets Deprecations \u00b6 The following functionality is now deprecated and will be removed in a future release: Addresses containing a dash (ex. nano- or xrb- ) are being deprecated and will not longer be compatible with the node in a future release. Addresses using underscores will only be supported.","title":"V20.0"},{"location":"releases/release-v20-0/#v200","text":"Node Protocol Database Release Date Release Notes GitHub Links 20.0 17 15 2019-11-12 V20.0 Release - Milestone - Changelog Known Issue V19+: macOS 'Too many open files' Issue: The following error can be seen when attempting to run a full node on macOS using the built-in Qt wallet or other GUI-based wallets: \"Exception while running wallet: open: Too many open files\". This is due to macOS having a very low default file descriptor limit and V19.0 uses more of them after the move to TCP. Solution: For now a workaround is needed to increase the limit. The method depends on the specific macOS version, but some people had success with the recipe in https://superuser.com/a/1171028 . Known Issue V20: Peers stake reporting inaccurate (Windows only) Issue: For Windows builds only, when calling confirmation_quorum RPC the peers_stake_total amount returned may be inaccurate, returning a range from the correct full peer stake amount down to 0. Solution: A solution to the issue has been found and as this is a reporting issue only, the fix will be included in the next released version. For those manually building the node, patching the fix pull request onto the V20.0 tag can resolve the issue now. Or alternatively, building on the V20.0 tag with RelWithDebInfo option, see Build Instructions for Windows .","title":"V20.0"},{"location":"releases/release-v20-0/#upgrade-notices","text":"Only node V18.0 and higher supported With V20.0 only nodes V18.0 and higher will be peered with on the network (see Active Releases above). This means any nodes running versions earlier than 18.0 will begin to lose peers and fall out of sync over time once upgrades to V20.0 begin. If you are running a node version earlier than V18.0, please update as soon as possible to avoid disruption.","title":"Upgrade Notices"},{"location":"releases/release-v20-0/#database-upgrades","text":"Upgrade requires downtime, read carefully Please review the following details carefully as the automatic database upgrade process will cause downtime for the node. This version brings some new optimizations to the ledger which require database upgrades to be performed. Due to the nature of upgrades, the following impacts will occur: Upgrade times depend on specs of the node host but are expected to be between 5 and 15 minutes for most cases. Upgrade activities are synchronous which means the node will not be participating on the network and RPC requests won\u2019t be available during the upgrade process - services requiring uptime should plan to swap out their ledger for one upgraded by a separate node or download from a trusted source. Ledger size will grow by up to 50% during this process - please ensure you have free disk space of 3x the current ledger before starting the upgrade (currently ~16GB on the main network). A database vacuum will be automatically performed after the upgrade to reclaim disk space, which can be verified complete in the logs. Doing proper ledger backups is recommended before starting this process. Ensure you have enough disk space to allow for any ledger backups plus the additional disk space required for the database upgrade mentioned above. A new config option in V20, node.backup_before_upgrade , will allow for automated ledger backups between future versions.","title":"Database upgrades"},{"location":"releases/release-v20-0/#new-toml-config-files","text":"A new setup in V20.0 uses internal default config values, so config files are only needed for non-default settings. During upgrade new .toml format files will be created for the config.json and rpc_config.json files if they contain non-default values. Before migration config_backup_toml_migration.json and rpc_config_backup_toml_migration.json files will be created for backup. The following commands can be used to generated commented out, complete config files for review: Only set non-default values in .toml files It is not recommended to uncomment all values in the .toml file output from commands below. Instead, only uncomment or insert non-default values to ensure any default value changes in future release are only overridden when needed. Name Description Generated with config-node.toml Node configuration nano_node --generate_config node config-rpc.toml RPC configuration nano_node --generate_config rpc config-nano-pow-server.toml Proof of work server configuration nano_pow_server --generate_config config-qtwallet.toml Qt developer wallet configuration This file is maintained by the Qt wallet More details on the new configuration setup can be found in the node Configuration documentation .","title":"New .toml config files"},{"location":"releases/release-v20-0/#networking-changes","text":"Improvements to default network setup in this version requires less setup from node operators, specifically around port forwarding. Although new setups will immediately benefit, any existing systems that have already setup port forwarding may be impacted by these changes. For those systems, we recommend validating your network setup allows proper peering with a test V20.0 node prior to upgrading. If you run into issues, review the Troubleshooting UPnP documentation for assistance. Additional help can be sought in the Node and Representative Management forum category .","title":"Networking changes"},{"location":"releases/release-v20-0/#proof-of-work-management","text":"A couple changes to PoW management that services should be aware of: With OpenCL enabled, nodes will still use the local CPU for work generation by default. Setting node.work_threads to 0 will turn this off if required. Regenerating PoW for delayed transactions during high network load will now happen by default through the process RPC . If you wish to turn this off, setting watch_work to false is required. Other updates to review Improvements to the External Management and Block Confirmation and Tracking documentation should help clarify the recommended approaches to building integrations.","title":"Proof-of-Work management"},{"location":"releases/release-v20-0/#major-updates","text":"","title":"Major Updates"},{"location":"releases/release-v20-0/#migration-to-toml-config-files","text":"Better legibility, support for comments, and no more having the node write to your config files are some of the benefits of this upgrade. Any non-default values captured in your existing .json files will be migrated and you can export a full list of configuration options for use with simple commands. See additional callouts in Upgrade Notices above and in the node Configuration documentation .","title":"Migration to .toml config files"},{"location":"releases/release-v20-0/#proof-of-work-regeneration-outside-development-wallet","text":"Any requests to the process RPC will have the new watch_work option turned on by default, allowing the node to regenerate Proof-of-Work for blocks even if they are outside of the node\u2019s development wallet. This makes Dynamic PoW and prioritization function more consistently across the network. If you have an external integration utilizing this RPC call, you will automatically start taking advantage of rework during confirmation delays on the network.","title":"Proof-of-Work regeneration outside development wallet"},{"location":"releases/release-v20-0/#rocksdb-experimental-support","text":"With better disk IO usage, RocksDB is being introduced in this version with experimental support. It is not recommended for use in production, but those interested in testing out a more performant database for the ledger should checkout how to install RocksDB and try it out on development and test systems. We also have a related discussion in our forum for those interested.","title":"RocksDB experimental support"},{"location":"releases/release-v20-0/#active-elections-and-other-optimizations","text":"Thanks to our excellent community testers putting effort into collecting and analyzing block, voting and confirmation data from the beta network, we\u2019ve found various optimizations with the active elections process, confirmation request attempts and bootstrapping behaviors. Various changes have been implemented to help reduce resource usage on nodes in various areas and increase the available throughput on the network. This feature also enhances the effectiveness of prioritization and rework of PoW. No action is needed to take advantage of these great updates.","title":"Active elections and other optimizations"},{"location":"releases/release-v20-0/#infrastructure-for-pow-transition","text":"Back in September we announced a new PoW algorithm design we had been working on which aimed to be memory hard. After open sourcing an implementation of the algorithm, an efficient low-memory solution was found and we subsequently removed the algorithm implementation from V20 . As part of the original implementation work we were able to setup infrastructure for moving PoW out of the node process in the future, and also added support for version 2 of epoch blocks, which will allow the network upgrade later when a new PoW algorithm is ready. These updates will be included in Lydia but not be utilized until a future version. To follow along with node releases going forward, check out the Upcoming Features page.","title":"Infrastructure for PoW transition"},{"location":"releases/release-v20-0/#rpc-updates","text":"BEHAVIOR CHANGE process now takes an optional flag watch_work (default true ). Unless set to false , processed blocks can be subject to PoW rework BEHAVIOR CHANGE bootstrap , bootstrap_any and boostrap_lazy will now throw errors when certain launch flags are used to disabled bootstrap methods - see each RPC page for details BEHAVIOR CHANGE RPCs requiring work generation will now throw errors when work generation is disabled (no work peers , no OpenCL and no work threads configured) block_count no longer requires config option enable_control to get the cemented block count unchecked now takes an optional flag json_block to return blocks in JSON-format version now includes more fields - network label, identifier (hash of the genesis open block) and build information peers and node_id now return node IDs with a node_ prefix work_generate and work_validate can now take a multiplier (against base difficulty) to set a different difficulty threshold","title":"RPC Updates"},{"location":"releases/release-v20-0/#cli-updates","text":"NEW generate_config [node|rpc] prints sample configuration files to stdout use_defaults additional argument to generate uncommented entries (not recommended) NEW config passes configuration arguments, alternative to setting in the config file","title":"CLI Updates"},{"location":"releases/release-v20-0/#node-configuration-updates","text":"Support in Nano Forum For node operators looking to upgrade to V20.0 or tune their configurations, the Node and Representative Management category of the forum is a great resource to use. Generate .toml config to see options As noted in the Upgrade Notices above, this version will migrate your existing .json files over to .toml files. Only non-default values for these fields will be added to the new .toml file. If you wish to adjust other options, use the config generation commands to see all available options. The following options are notable node configuration updates. Additional configuration changes have been included in this release and can be found when generating the config files. backup_before_upgrade (default false ) enables automatic backup of the ledger and wallet databases when updating to a new node version work_watcher_period (default 5 seconds) controls how frequently the node should check the confirmation status of block in the work watcher, and re-generate higher difficulty work if unconfirmed max_work_generate_multiplier (default 64.0 ) previously max_work_generate_difficulty , now a multiplier for easier management, specifies the absolute maximum difficulty multiplier to be used for work generation","title":"Node Configuration Updates"},{"location":"releases/release-v20-0/#developerdebug-options","text":"New RPC epoch_upgrade allowing easier epoch distribution ( Note - this epoch requires a special private key to be used, see the Network Upgrades page for information) RPC bootstrap has a new optional \"bypass_frontier_confirmation\" RPC bootstrap_status now displays more data about the current bootstrap attempt New CLI debug_stacktrace displays an example stacktrace, simulating an unexpected program crash New CLI debug_account_versions displays the total number of accounts separated by version and opened/unopened CLI debug_validate_blocks updated to cover more cases CLI debug_profile_verify renamed to debug_profile_validate and now provides simplified work validation profiling New CMake build options: NANO_ROCKSDB enables use of the RocksDB database backend, experimental NANO_WARN_TO_ERR turns compiler warnings into errors on Linux/Mac NANO_TIMED_LOCKS provides information on mutexes held for a long time NANO_STACKTRACE_BACKTRACE uses libbacktrace to provide stacktraces CI_BUILD if set, uses the TRAVIS_TAG environment variable to modify the locally reported node version, to help with support tickets","title":"Developer/Debug Options"},{"location":"releases/release-v20-0/#deprecations","text":"The following functionality is now deprecated and will be removed in a future release: Addresses containing a dash (ex. nano- or xrb- ) are being deprecated and will not longer be compatible with the node in a future release. Addresses using underscores will only be supported.","title":"Deprecations"},{"location":"releases/release-v21-0/","text":"V21.0 \u00b6 Node Protocol Database Release Date Release Notes GitHub Links 21.0 18 18 2020-06-16 V21.0 Release - Milestone - Changelog Known Issue V19+: macOS 'Too many open files' Issue: The following error can be seen when attempting to run a full node on macOS using the built-in Qt wallet or other GUI-based wallets: \"Exception while running wallet: open: Too many open files\". This is due to macOS having a very low default file descriptor limit and V19.0 uses more of them after the move to TCP. Solution: For now a workaround is needed to increase the limit. The method depends on the specific macOS version, but some people had success with the recipe in https://superuser.com/a/1171028 . Known Issue Linux V21: 'unable to find libboost' If you are on Linux and unable to get V21.0 to start, unable to find libboost... https://github.com/nanocurrency/nano-node/releases/download/V21.0/nano-node-V21.0.1-Linux.tar.bz2 has been added to the release artifacts with the correct lib rpath. Please use this if you do not wish to move the lib folder into the bin folder after extraction. Known Issue Windows V21: Crash when using config node.logging.stable_log_filename Setting node.logging.stable_log_filename configuration option to true results in a node crash on Windows in V21.0 and V21.1, after a node restart. This must be set to false . Upgrade Notices \u00b6 Upgrade notices for nodes upgrading below V21.0 These upgrade notices and other details are only for nodes upgrading from V20.0 and lower. For operators upgrading to the latest from V21.0 or higher there are no special considerations. The following key upgrade details should be reviewed by all node operators to determine how they will impact plans for upgrading: Database upgrades \u00b6 An in-place database upgrade will occur with this release to accomodate epoch-related flags. Machines will need at least 30GB free disk space to accommodate the upgrade. During the upgrade process, which may take multiple hours to complete depending on the machine specs, the node will not participate on the network or respond to RPC calls. As a result, the recommended approach is to upgrade the ledger in a separate environment before replacing on production . For detailed steps on this approach and other options, see the Updating the node section of the Ledger Management page. Minor RPC breaking changes \u00b6 Although breaking changes were kept to a minimum in this release, there are two RPC calls with such changes: work_validate and bootstrap_status . For integrations using them, carefully review the additional details on these changes included in the RPC Updates section below. Upcoming v2 epoch upgrade \u00b6 As outlined in the February Development Update: V21 PoW Difficulty Increases , an epoch block distribution must be done to complete the upgrade to the new work difficulty thresholds. All integrations generating work are encouraged to review the details on the Network Upgrades page under the Upcoming upgrades section ahead of the epoch V2 distribution. Only nodes V21.0+ will be active after epoch distribution Nodes upgrading to V21.0+ will remain peered with nodes V19.0 and V20.0 on the network until the epoch v2 block distribution begins. After the first epoch v2 block is distributed, all nodes not running V21.0+ will no longer be able to participate on the network. This distribution will occur once 90% of voting weight and key services on the network have upgraded. Communications around the progress towards this goal will be sent following the release. More details about this network upgrade can be found on the Network Upgrades page under the Upcoming upgrades section All network participants are encouraged to upgrade to V21.1 as soon as possible to avoid disruption. UDP disabled by default \u00b6 With all active peers capable of communicating via TCP, the UDP connections will be disabled by default in this version. To avoid disruptions, all nodes should allow traffic on 7075 TCP (see Network Ports details) and once upgraded, the peers RPC call should return at least dozens of peers and the confirmation_quorum RPC call should have a peers_stake_total value in the high tens of millions of Nano. Although not recommended, if necessary the temporary use of UDP can be done with the new --enable_udp flag. Major Updates \u00b6 Work difficulty increase \u00b6 As mentioned in the Upgrade Notices section above, work difficulty changes were implemented in V21, but will not be activated until epoch v2 blocks are distributed at a future date. Please review the Upcoming upgrades section of the Network Upgrades page for details. Updates on the progress toward the epoch upgrade will be posted in our many social channels as well as sent through our technical updates mailing list which can be joined here: Join Mailing List . Node Telemetry \u00b6 To allow better communication between nodes about various performance and other details, telemetry was added between peers. Various version details, account and block counts, active difficulty and more can be discovered from individual peers or summarized across them. Details of what is shared and options for receiving them can be found in the node telemetry WebSocket section and node_telemetry RPC. For protocol level details, see Node Telemetry section under Protocol Design > Networking. Telemetry can be forged Although the telemetry messages are signed by nodes, the data provided by other peers can be forged by malicious nodes so they cannot be guaranteed as accurate. All details in these messages should be used as rough indicators of peer and broad network situations, but not exclusively relied on for any key integration or network activities. Continued conversation around telemetry is happening through the related forum discussion . IPC 2.0 \u00b6 As a key update towards the upcoming RPC 2.0 redesign, this background upgrade will provide more performant communication to the node, allow easier integration across various languages by supporting Flatbuffers and provide the foundation for more granular authorization of specific calls . Better election alignment and performance \u00b6 Behind the scenes many improvements were made to better streamline alignment of elections across the network and allow for better performance. Resource usage by nodes, particularly network bandwidth, will be reduced even further than previous levels. No action is needed to take advantage of this increase other than upgrading your node to V21 as soon as you can! Node Configuration and Management Updates \u00b6 Support in Nano Forum For node operators looking to upgrade their node or tune their configurations, the Node and Representative Management category of the forum is a great resource to use. The following options are notable node configuration updates. Additional configuration changes have been included in this release and can be found when generating the config files. The ability to enable a static log file name is available via the node.logging.stable_log_filename option. If update to true , a static log file of log/node.log will be written to and rotated to timestamped files once full. This option requires the node being built with Boost 1.70+ (default for Docker images and published binaries). Nodes will now clear their peers lists and online weight if they are started after more than 1 week of being offline. This aims to improve re-peering in these situations, as well as provide more accurate online weight values as the node begins participating on the network again ( related PR ). When watch_work is set to false in the process RPC, it is no longer required to have enable_control = true in the config-rpc.toml file. Log when voting, warn multiple accounts When the node is started there are new messages pushed to the logs which indicate when voting is enabled and how many representatives are configured to vote. A warning will be included in both the logs and stdout if multiple representatives are configured to be voting. RPC Updates \u00b6 BREAKING CHANGE work_validate has multiple changes to the response, one which will break most existing integrations: If difficulty parameter is not explicitly passed in the request, the existing valid field will not be returned ( breaking ) valid_all is a new return field, true if the work is valid at the current default difficulty (will go up after epoch upgrade) valid_receive is a new return field, true if the work is valid at the lower epoch_2 receive difficulty (only useful after the epoch upgrade is finished) To best understand how these and other epoch related changes will impact your integration, it is highly recommended that the Upcoming upgrades > Increased work difficulty section of the Network Upgrades is carefully reviewed active_difficulty RPC and WebSocket will automatically begin returning the higher difficulty threshold for send/change blocks in the network_minimum field once the epoch upgrade begins, otherwise the response formats will remain the same BREAKING CHANGE bootstrap_status responses now have connections field as an array of connection-related fields and adds an attempts field with an area of individual bootstrap attempt details, each including information such as a unique id, type of bootstrap (legacy, lazy) and various other granular information. block_create response now contains the difficulty value of the work included in the block for easy reference by integrations. When generating work for the created block, the node ledger data is used to estimate the required difficulty threshold. work_generate request now accepts optional block (and corresponding boolean json_block ), which is used to estimate the required difficulty threshold by using ledger data. Two common use-cases are generating work for blocks created elsewhere, and re-generating work for a previously published block. account_info responses now contain confirmation_height_frontier which is the hash of the last confirmed block. Including subtype in process RPC calls highly recommended In order to avoid potential incorrect sends including the optional subtype parameter on all process RPC calls is highly recommended . In the next version of the RPC this parameter will be required. CLI Updates \u00b6 NEW --debug_generate_crash_report greatly simplifies troubleshooting when a node crashes in Linux . NEW --rebuild_database provides a better compaction method for LMDB. NOTE: This requires approximately data.ldb file size * 2 in free space on disk. NEW --compare_rep_weights gives the ability to compare the current ledger voting weight distribution against the hard coded weights provided in the node on release. Useful when attempting to use a downloaded ledger. More details on use can be found on the Ledger Management page . NEW --inactive_votes_cache_size allows adjusting of the cache that holds votes where the block does not have an action election, default is 16384 votes. WebSockets \u00b6 Updates to WebSocket subscriptions are now allowed on the confirmation topic. With options of accounts_add and accounts_del an existing subscription can now be more easily managed to avoid resubscribing with a large list of accounts or managing multiple subscriptions. NEW bootstrap topic provides notifications about the starting and exiting of bootstrap attempts. NEW new_unconfirmed_block topic provides notifications about blocks which were just processed and are being seen by the node for the first time. This is useful for integrations that want to watch for blocks they didn't create themselves, but for which they want to update with new work (external work watcher). WebSocket server is now enabled by default in V21+ Docker images to make it more consistent with RPC server setup and documented port mappings Developer/Debug Options \u00b6 confirmation_active RPC response includes new unconfirmed and confirmed fields to help with more granular election tracking and monitoring When the node is started there are new messages pushed to the logs which indicate when voting is enabled and how many representatives are configured to vote. A warning will be included in both the logs and stdout if multiple representatives are configured to be voting. New --debug_generate_crash_report CLI command consumes the dump files to create a helpful crash report. See What to do if the node crashes (Linux) for more details on using this command. New logging.log_rpc configuration can be optionally set to false to prevent explicit logging of RPC requests made to the node Deprecations \u00b6 The following functionality is now deprecated and will be removed in a future release: UDP is disabled by default in this version and will be removed in a future release. Launch flag --disable_udp is deprecated and temporary use of UDP can be done with the new --enable_udp flag.","title":"V21.0"},{"location":"releases/release-v21-0/#v210","text":"Node Protocol Database Release Date Release Notes GitHub Links 21.0 18 18 2020-06-16 V21.0 Release - Milestone - Changelog Known Issue V19+: macOS 'Too many open files' Issue: The following error can be seen when attempting to run a full node on macOS using the built-in Qt wallet or other GUI-based wallets: \"Exception while running wallet: open: Too many open files\". This is due to macOS having a very low default file descriptor limit and V19.0 uses more of them after the move to TCP. Solution: For now a workaround is needed to increase the limit. The method depends on the specific macOS version, but some people had success with the recipe in https://superuser.com/a/1171028 . Known Issue Linux V21: 'unable to find libboost' If you are on Linux and unable to get V21.0 to start, unable to find libboost... https://github.com/nanocurrency/nano-node/releases/download/V21.0/nano-node-V21.0.1-Linux.tar.bz2 has been added to the release artifacts with the correct lib rpath. Please use this if you do not wish to move the lib folder into the bin folder after extraction. Known Issue Windows V21: Crash when using config node.logging.stable_log_filename Setting node.logging.stable_log_filename configuration option to true results in a node crash on Windows in V21.0 and V21.1, after a node restart. This must be set to false .","title":"V21.0"},{"location":"releases/release-v21-0/#upgrade-notices","text":"Upgrade notices for nodes upgrading below V21.0 These upgrade notices and other details are only for nodes upgrading from V20.0 and lower. For operators upgrading to the latest from V21.0 or higher there are no special considerations. The following key upgrade details should be reviewed by all node operators to determine how they will impact plans for upgrading:","title":"Upgrade Notices"},{"location":"releases/release-v21-0/#database-upgrades","text":"An in-place database upgrade will occur with this release to accomodate epoch-related flags. Machines will need at least 30GB free disk space to accommodate the upgrade. During the upgrade process, which may take multiple hours to complete depending on the machine specs, the node will not participate on the network or respond to RPC calls. As a result, the recommended approach is to upgrade the ledger in a separate environment before replacing on production . For detailed steps on this approach and other options, see the Updating the node section of the Ledger Management page.","title":"Database upgrades"},{"location":"releases/release-v21-0/#minor-rpc-breaking-changes","text":"Although breaking changes were kept to a minimum in this release, there are two RPC calls with such changes: work_validate and bootstrap_status . For integrations using them, carefully review the additional details on these changes included in the RPC Updates section below.","title":"Minor RPC breaking changes"},{"location":"releases/release-v21-0/#upcoming-v2-epoch-upgrade","text":"As outlined in the February Development Update: V21 PoW Difficulty Increases , an epoch block distribution must be done to complete the upgrade to the new work difficulty thresholds. All integrations generating work are encouraged to review the details on the Network Upgrades page under the Upcoming upgrades section ahead of the epoch V2 distribution. Only nodes V21.0+ will be active after epoch distribution Nodes upgrading to V21.0+ will remain peered with nodes V19.0 and V20.0 on the network until the epoch v2 block distribution begins. After the first epoch v2 block is distributed, all nodes not running V21.0+ will no longer be able to participate on the network. This distribution will occur once 90% of voting weight and key services on the network have upgraded. Communications around the progress towards this goal will be sent following the release. More details about this network upgrade can be found on the Network Upgrades page under the Upcoming upgrades section All network participants are encouraged to upgrade to V21.1 as soon as possible to avoid disruption.","title":"Upcoming v2 epoch upgrade"},{"location":"releases/release-v21-0/#udp-disabled-by-default","text":"With all active peers capable of communicating via TCP, the UDP connections will be disabled by default in this version. To avoid disruptions, all nodes should allow traffic on 7075 TCP (see Network Ports details) and once upgraded, the peers RPC call should return at least dozens of peers and the confirmation_quorum RPC call should have a peers_stake_total value in the high tens of millions of Nano. Although not recommended, if necessary the temporary use of UDP can be done with the new --enable_udp flag.","title":"UDP disabled by default"},{"location":"releases/release-v21-0/#major-updates","text":"","title":"Major Updates"},{"location":"releases/release-v21-0/#work-difficulty-increase","text":"As mentioned in the Upgrade Notices section above, work difficulty changes were implemented in V21, but will not be activated until epoch v2 blocks are distributed at a future date. Please review the Upcoming upgrades section of the Network Upgrades page for details. Updates on the progress toward the epoch upgrade will be posted in our many social channels as well as sent through our technical updates mailing list which can be joined here: Join Mailing List .","title":"Work difficulty increase"},{"location":"releases/release-v21-0/#node-telemetry","text":"To allow better communication between nodes about various performance and other details, telemetry was added between peers. Various version details, account and block counts, active difficulty and more can be discovered from individual peers or summarized across them. Details of what is shared and options for receiving them can be found in the node telemetry WebSocket section and node_telemetry RPC. For protocol level details, see Node Telemetry section under Protocol Design > Networking. Telemetry can be forged Although the telemetry messages are signed by nodes, the data provided by other peers can be forged by malicious nodes so they cannot be guaranteed as accurate. All details in these messages should be used as rough indicators of peer and broad network situations, but not exclusively relied on for any key integration or network activities. Continued conversation around telemetry is happening through the related forum discussion .","title":"Node Telemetry"},{"location":"releases/release-v21-0/#ipc-20","text":"As a key update towards the upcoming RPC 2.0 redesign, this background upgrade will provide more performant communication to the node, allow easier integration across various languages by supporting Flatbuffers and provide the foundation for more granular authorization of specific calls .","title":"IPC 2.0"},{"location":"releases/release-v21-0/#better-election-alignment-and-performance","text":"Behind the scenes many improvements were made to better streamline alignment of elections across the network and allow for better performance. Resource usage by nodes, particularly network bandwidth, will be reduced even further than previous levels. No action is needed to take advantage of this increase other than upgrading your node to V21 as soon as you can!","title":"Better election alignment and performance"},{"location":"releases/release-v21-0/#node-configuration-and-management-updates","text":"Support in Nano Forum For node operators looking to upgrade their node or tune their configurations, the Node and Representative Management category of the forum is a great resource to use. The following options are notable node configuration updates. Additional configuration changes have been included in this release and can be found when generating the config files. The ability to enable a static log file name is available via the node.logging.stable_log_filename option. If update to true , a static log file of log/node.log will be written to and rotated to timestamped files once full. This option requires the node being built with Boost 1.70+ (default for Docker images and published binaries). Nodes will now clear their peers lists and online weight if they are started after more than 1 week of being offline. This aims to improve re-peering in these situations, as well as provide more accurate online weight values as the node begins participating on the network again ( related PR ). When watch_work is set to false in the process RPC, it is no longer required to have enable_control = true in the config-rpc.toml file. Log when voting, warn multiple accounts When the node is started there are new messages pushed to the logs which indicate when voting is enabled and how many representatives are configured to vote. A warning will be included in both the logs and stdout if multiple representatives are configured to be voting.","title":"Node Configuration and Management Updates"},{"location":"releases/release-v21-0/#rpc-updates","text":"BREAKING CHANGE work_validate has multiple changes to the response, one which will break most existing integrations: If difficulty parameter is not explicitly passed in the request, the existing valid field will not be returned ( breaking ) valid_all is a new return field, true if the work is valid at the current default difficulty (will go up after epoch upgrade) valid_receive is a new return field, true if the work is valid at the lower epoch_2 receive difficulty (only useful after the epoch upgrade is finished) To best understand how these and other epoch related changes will impact your integration, it is highly recommended that the Upcoming upgrades > Increased work difficulty section of the Network Upgrades is carefully reviewed active_difficulty RPC and WebSocket will automatically begin returning the higher difficulty threshold for send/change blocks in the network_minimum field once the epoch upgrade begins, otherwise the response formats will remain the same BREAKING CHANGE bootstrap_status responses now have connections field as an array of connection-related fields and adds an attempts field with an area of individual bootstrap attempt details, each including information such as a unique id, type of bootstrap (legacy, lazy) and various other granular information. block_create response now contains the difficulty value of the work included in the block for easy reference by integrations. When generating work for the created block, the node ledger data is used to estimate the required difficulty threshold. work_generate request now accepts optional block (and corresponding boolean json_block ), which is used to estimate the required difficulty threshold by using ledger data. Two common use-cases are generating work for blocks created elsewhere, and re-generating work for a previously published block. account_info responses now contain confirmation_height_frontier which is the hash of the last confirmed block. Including subtype in process RPC calls highly recommended In order to avoid potential incorrect sends including the optional subtype parameter on all process RPC calls is highly recommended . In the next version of the RPC this parameter will be required.","title":"RPC Updates"},{"location":"releases/release-v21-0/#cli-updates","text":"NEW --debug_generate_crash_report greatly simplifies troubleshooting when a node crashes in Linux . NEW --rebuild_database provides a better compaction method for LMDB. NOTE: This requires approximately data.ldb file size * 2 in free space on disk. NEW --compare_rep_weights gives the ability to compare the current ledger voting weight distribution against the hard coded weights provided in the node on release. Useful when attempting to use a downloaded ledger. More details on use can be found on the Ledger Management page . NEW --inactive_votes_cache_size allows adjusting of the cache that holds votes where the block does not have an action election, default is 16384 votes.","title":"CLI Updates"},{"location":"releases/release-v21-0/#websockets","text":"Updates to WebSocket subscriptions are now allowed on the confirmation topic. With options of accounts_add and accounts_del an existing subscription can now be more easily managed to avoid resubscribing with a large list of accounts or managing multiple subscriptions. NEW bootstrap topic provides notifications about the starting and exiting of bootstrap attempts. NEW new_unconfirmed_block topic provides notifications about blocks which were just processed and are being seen by the node for the first time. This is useful for integrations that want to watch for blocks they didn't create themselves, but for which they want to update with new work (external work watcher). WebSocket server is now enabled by default in V21+ Docker images to make it more consistent with RPC server setup and documented port mappings","title":"WebSockets"},{"location":"releases/release-v21-0/#developerdebug-options","text":"confirmation_active RPC response includes new unconfirmed and confirmed fields to help with more granular election tracking and monitoring When the node is started there are new messages pushed to the logs which indicate when voting is enabled and how many representatives are configured to vote. A warning will be included in both the logs and stdout if multiple representatives are configured to be voting. New --debug_generate_crash_report CLI command consumes the dump files to create a helpful crash report. See What to do if the node crashes (Linux) for more details on using this command. New logging.log_rpc configuration can be optionally set to false to prevent explicit logging of RPC requests made to the node","title":"Developer/Debug Options"},{"location":"releases/release-v21-0/#deprecations","text":"The following functionality is now deprecated and will be removed in a future release: UDP is disabled by default in this version and will be removed in a future release. Launch flag --disable_udp is deprecated and temporary use of UDP can be done with the new --enable_udp flag.","title":"Deprecations"},{"location":"releases/release-v21-1/","text":"V21.1 \u00b6 Node Protocol Database Release Date Release Notes GitHub Links 21.1 18 18 2020-07-14 V21.1 Release - Milestone - Changelog Known Issue V19+: macOS 'Too many open files' Issue: The following error can be seen when attempting to run a full node on macOS using the built-in Qt wallet or other GUI-based wallets: \"Exception while running wallet: open: Too many open files\". This is due to macOS having a very low default file descriptor limit and V19.0 uses more of them after the move to TCP. Solution: For now a workaround is needed to increase the limit. The method depends on the specific macOS version, but some people had success with the recipe in https://superuser.com/a/1171028 . Known Issue Windows V21: Crash when using config node.logging.stable_log_filename Setting node.logging.stable_log_filename configuration option to true results in a node crash on Windows in V21.0 and V21.1, after a node restart. This must be set to false . No special upgrade considerations V21.1 is a service release which doesn't require any special upgrade considerations when upgrading from V21.0.","title":"V21.1"},{"location":"releases/release-v21-1/#v211","text":"Node Protocol Database Release Date Release Notes GitHub Links 21.1 18 18 2020-07-14 V21.1 Release - Milestone - Changelog Known Issue V19+: macOS 'Too many open files' Issue: The following error can be seen when attempting to run a full node on macOS using the built-in Qt wallet or other GUI-based wallets: \"Exception while running wallet: open: Too many open files\". This is due to macOS having a very low default file descriptor limit and V19.0 uses more of them after the move to TCP. Solution: For now a workaround is needed to increase the limit. The method depends on the specific macOS version, but some people had success with the recipe in https://superuser.com/a/1171028 . Known Issue Windows V21: Crash when using config node.logging.stable_log_filename Setting node.logging.stable_log_filename configuration option to true results in a node crash on Windows in V21.0 and V21.1, after a node restart. This must be set to false . No special upgrade considerations V21.1 is a service release which doesn't require any special upgrade considerations when upgrading from V21.0.","title":"V21.1"},{"location":"releases/roadmap/","text":"Roadmap \u00b6 Nano Roadmap moved to GitHub Head over to the new Nano Roadmap GitHub Project for a more dynamic and updated view of the upcoming features under research and implementation on the Nano node and protocol.","title":"Roadmap"},{"location":"releases/roadmap/#roadmap","text":"Nano Roadmap moved to GitHub Head over to the new Nano Roadmap GitHub Project for a more dynamic and updated view of the upcoming features under research and implementation on the Nano node and protocol.","title":"Roadmap"},{"location":"running-a-node/advanced-monitoring/","text":"Advanced Monitoring \u00b6 For keeping a closer watch on node performance a Prometheus-based exporter monitoring solution is avialable. It provides an easy way to automatically gather and export a multitude of stats and metrics from the node RPC, as well as from the machine running the exporter. For added security, the exporter doesn't require opening any additional inbound ports as the metrics are pushed out to a Prometheus push gateway, which can be hosted externally. Prometheus is an open-source systems monitoring and alerting toolkit. For a brief overview of everything it offers, see What is Prometheus? Basic monitoring option For a simpler monitoring setup that is maintained by the Nano community and provides a public website to view details on, see the monitoring details on the Voting as a Representative page . Recommended architecture \u00b6 The diagram below illustrates a recommended architecture of components: This configuration was recommended as it splits the concerns across two servers: one hosting the node and exporter, with another hosting the push gateway, Prometheus server and graphing/visualization tools. However, there are a variety of configuration options to allow separation of each component onto different servers, depending on the needs. Installation \u00b6 The following provides the basic details for installing and connecting the components outlined above. Step 1: Setup and configure Nano node \u00b6 These configuration options are set in the config-node.toml file . Get a Nano node setup with Docker or binaries Update config node.rpc.enable = true If you want to gather nano_stats_objects* metrics , update config rpc.enable_control = true Restart the node for settings to take effect Step 2: Install Prometheus push gateway \u00b6 For the best security, it is recommended to run this on a separate server. By default this will need to accept incoming connections from the exporter on TCP port 9091 . Requires python 3.7+ Download and run the prometheus-pushgateway Accept incoming TCP port 9091 connections from the node/exporter server Step 3: Install and run the Nano node exporter \u00b6 Typical configurations will have the exporter running on the same server as the node. If so, --rpchost is local as noted below. Install via pip pip install nano-prom-exporter Example run command nano-prom -h --rpchost ::1 \\ --rpcport 7076 \\ --datapath ~/Nano/Nano \\ --pushgateway your-exporter-and-node.server.org:9091 \\ --hostname MyNanoMetrics See the README for more details on usage. Step 4: View your metrics \u00b6 To validate data is available from the exporter, the /targets endpoint on port 9090 at the URL of the push gateway will show job health: http://your-new.monitor.org:9090/targets . The endpoint pushing the data should have State = UP if everything is working well. There is also a /graph endpoint to do some manual querying of available data: http://your-new.monitor.org:9090/graph Step 5: Install Grafana \u00b6 Once you've verified metrics are properly being captured, you can setup visualization amd analysis solutions. One popular option is Grafana, which can be installed from here: https://grafana.com/grafana/download . If Grafana is being installed on a different server from the Promethus push gateway TCP port 9090 will need to be opened as well. Once running, a sample file can be used from our repository to kickstart your dashboard setup: https://github.com/nanocurrency/nano_prom_exporter/blob/master/sample-grafana-dashboard.json . Other options can be explored in the Visualization section of the Prometheus site. Connecting to other push gateways \u00b6 The exporter supports sending metrics to multiple push gateways using a config.ini file and the --config_path option in the command to accept the location. Within this file the authentication can be managed between different endpoints and support for selecting specific metrics per push gateway will added soon. See the README for more details on usage. Although no public push gateways for node monitoring are available at this time, there may be opportunities in the future to share your node metrics with the community or other monitoring setups to provide a better view of network performance. Check back here and keep an eye out for these public gateways to become available. And if you know of any public push gateways available to send this useful node data to, please let us know .","title":"Advanced Monitoring"},{"location":"running-a-node/advanced-monitoring/#advanced-monitoring","text":"For keeping a closer watch on node performance a Prometheus-based exporter monitoring solution is avialable. It provides an easy way to automatically gather and export a multitude of stats and metrics from the node RPC, as well as from the machine running the exporter. For added security, the exporter doesn't require opening any additional inbound ports as the metrics are pushed out to a Prometheus push gateway, which can be hosted externally. Prometheus is an open-source systems monitoring and alerting toolkit. For a brief overview of everything it offers, see What is Prometheus? Basic monitoring option For a simpler monitoring setup that is maintained by the Nano community and provides a public website to view details on, see the monitoring details on the Voting as a Representative page .","title":"Advanced Monitoring"},{"location":"running-a-node/advanced-monitoring/#recommended-architecture","text":"The diagram below illustrates a recommended architecture of components: This configuration was recommended as it splits the concerns across two servers: one hosting the node and exporter, with another hosting the push gateway, Prometheus server and graphing/visualization tools. However, there are a variety of configuration options to allow separation of each component onto different servers, depending on the needs.","title":"Recommended architecture"},{"location":"running-a-node/advanced-monitoring/#installation","text":"The following provides the basic details for installing and connecting the components outlined above.","title":"Installation"},{"location":"running-a-node/advanced-monitoring/#step-1-setup-and-configure-nano-node","text":"These configuration options are set in the config-node.toml file . Get a Nano node setup with Docker or binaries Update config node.rpc.enable = true If you want to gather nano_stats_objects* metrics , update config rpc.enable_control = true Restart the node for settings to take effect","title":"Step 1: Setup and configure Nano node"},{"location":"running-a-node/advanced-monitoring/#step-2-install-prometheus-push-gateway","text":"For the best security, it is recommended to run this on a separate server. By default this will need to accept incoming connections from the exporter on TCP port 9091 . Requires python 3.7+ Download and run the prometheus-pushgateway Accept incoming TCP port 9091 connections from the node/exporter server","title":"Step 2: Install Prometheus push gateway"},{"location":"running-a-node/advanced-monitoring/#step-3-install-and-run-the-nano-node-exporter","text":"Typical configurations will have the exporter running on the same server as the node. If so, --rpchost is local as noted below. Install via pip pip install nano-prom-exporter Example run command nano-prom -h --rpchost ::1 \\ --rpcport 7076 \\ --datapath ~/Nano/Nano \\ --pushgateway your-exporter-and-node.server.org:9091 \\ --hostname MyNanoMetrics See the README for more details on usage.","title":"Step 3: Install and run the Nano node exporter"},{"location":"running-a-node/advanced-monitoring/#step-4-view-your-metrics","text":"To validate data is available from the exporter, the /targets endpoint on port 9090 at the URL of the push gateway will show job health: http://your-new.monitor.org:9090/targets . The endpoint pushing the data should have State = UP if everything is working well. There is also a /graph endpoint to do some manual querying of available data: http://your-new.monitor.org:9090/graph","title":"Step 4: View your metrics"},{"location":"running-a-node/advanced-monitoring/#step-5-install-grafana","text":"Once you've verified metrics are properly being captured, you can setup visualization amd analysis solutions. One popular option is Grafana, which can be installed from here: https://grafana.com/grafana/download . If Grafana is being installed on a different server from the Promethus push gateway TCP port 9090 will need to be opened as well. Once running, a sample file can be used from our repository to kickstart your dashboard setup: https://github.com/nanocurrency/nano_prom_exporter/blob/master/sample-grafana-dashboard.json . Other options can be explored in the Visualization section of the Prometheus site.","title":"Step 5: Install Grafana"},{"location":"running-a-node/advanced-monitoring/#connecting-to-other-push-gateways","text":"The exporter supports sending metrics to multiple push gateways using a config.ini file and the --config_path option in the command to accept the location. Within this file the authentication can be managed between different endpoints and support for selecting specific metrics per push gateway will added soon. See the README for more details on usage. Although no public push gateways for node monitoring are available at this time, there may be opportunities in the future to share your node metrics with the community or other monitoring setups to provide a better view of network performance. Check back here and keep an eye out for these public gateways to become available. And if you know of any public push gateways available to send this useful node data to, please let us know .","title":"Connecting to other push gateways"},{"location":"running-a-node/beta-network/","text":"Joining the beta network \u00b6 Testing is currently ongoing on the beta network for Version 22 Read through this page if you would like to participate. The beta network exists for the purpose of conducting certain network-wide activites including load testing and [new node releases and features testing]((#node-release-testing). These activities can cause the network to become unstable or inaccessible at times due to heavy traffic, occasional resetting of the genesis/ledger or the introduction of bugs due to new features. As a result, an alternative test network is also available which will be more stable and is a better fit for learning node setup and management, and testing out upgrades and other activities for Nano before moving to production. With those things in consideration, if you are interested in helping with testing on the beta network we are excited to help you out - so keep reading! Node release testing \u00b6 The Nano Foundation maintains a few beta nodes on the network and various community members also setup nodes to help provide an environment more similar to the main network. During each development cycle Development Builds (DB) are prepared and shared in the Discord Beta Testing section of channels where early testing is coordinated. Once features are stabilized and included, release builds are published as Release Candidates (RC). Starting with RC1 and incrementing with each published build if needed (RC2, RC3, etc.). Final release of a version typically follows quickly once the RC is observed to be stable. Warning Development Builds (DBs) are only recommended for use on the beta network, and Release Candidate builds (RCs) are only recommended for use on the test and beta networks Running a beta node \u00b6 Setting up a node on the beta network is similar to the main network. To start you should install docker and be familiar with the general setup and Docker management processes. Network ports \u00b6 Beta Network Ports Overview 54000 TCP: For live network activity and bootstrap network activity 55000 TCP: For communication with RPC server. Anyone with access to this port can control your node's RPC. 57000 TCP: For communication with websocket server . Depending on configuration, data throughput can be very high. Directory locations \u00b6 OS Location Windows C: \\U sers \\< user> \\A ppData \\L ocal \\N anoBeta \\ macOS /Users/<user>/Library/NanoBeta/ Linux /home/<user>/NanoBeta/ Pulling the Docker image \u00b6 Pulls the latest release of the Nano Node: docker pull nanocurrency/nano-beta Pulls a specific version of the Nano node: docker pull nanocurrency/nano-beta:<tag> Pulls the latest release which includes any release candidate versions: docker pull nanocurrency/nano-beta:latest-including-rc A list of beta tags can be found at the official Nano Currency Docker Hub Starting the Docker container \u00b6 docker run --restart = unless-stopped -d \\ -p 54000 :54000 \\ -p [ ::1 ] :55000:55000 \\ -p [ ::1 ] :57000:57000 \\ -v ${ NANO_HOST_DIR_BETA } :/root \\ --name ${ NANO_NAME } \\ nanocurrency/nano-beta:latest-including-rc Tip For an explanation of the options included in the Docker run command, see Starting the Container details for the main network. See Docker management for other related commands Separate host directories Be sure to use a different host directory for main network and beta network Docker node setups. Attempting to use the same directory will result in issues. Additional beta resources \u00b6 URL Description https://beta.nanocrawler.cc/ Beta Explorer https://beta.nanoticker.info/ Beta node details and stats https://b.repnode.org/ Beta node details and stats Differences from the main network \u00b6 Parameter Main Network Beta Network Comment Epoch 1 difficulty threshold ffffffc000000000 fffff00000000000 64 times lower on the beta network Epoch 2 send/change threshold fffffff800000000 fffff00000000000 Same as epoch 1 on the beta network Epoch 2 receive threshold fffffe0000000000 ffffe00000000000 2 times lower than epoch 1 Testing Builds \u00b6 Most of the resources needed to participate on the beta network can be found within the #beta-xxxxxxx channels on our Discord server . As much of the discussion, planning and engagement happens here, all participants are highly encouraged to join there. Binaries \u00b6 In addition to the Docker details above, the latest binary builds of the node for the beta network are shared in the #beta-announcements channel on our Discord server . These assets are also available on the GitHub repository Releases page under RC# and DB# tags, which can also be used to manually build if necessary. Beta fund distribution \u00b6 The funds used for testing transactions on the beta network are generated from a new genesis block and distributed in bulk to various testers running nodes on the network. For small amounts suitable for most basic integration, you can get beta Nano from the #beta-faucet channel on Discord. If you plan to consistently run a node on beta and want to participate in consensus as a Representative, please connect with Zach - ATX#0646 or argakiig#1783 in the #beta-net channel on our Discord server . Beta ledger file \u00b6 To help get beta nodes in sync more quickly it is recommended that an updated ledger file is downloaded and placed into the data directory. Often referred to as a \"fast sync\", more details around this approach can be found in the Ledger Management guide . Since the beta network contains no value, validating the blocks, voting weights and confirmation heights isn't necessary. The following command will download and unzip a recent ledger snapshot. Any existing ledger files should be backed up elswhere as this will override them. From within the data directory run: curl -O https://s3.us-east-2.amazonaws.com/beta-snapshot.nano.org/data.tar.gz; tar -xzvf data.tar.gz; rm -fr data.tar.gz Build contents and test cases \u00b6 With each DB a GitHub Project board will be created in the Nano GitHub Organization containing all the Pull Requests newly added in the DB, changes from previous DBs that still need network testing, and issues with the various test cases that are targeted to be run with that build. For those looking to assist with these tests, we encourage connecting with the other beta network participants in the #beta-net channel on our Discord server .","title":"Beta Network"},{"location":"running-a-node/beta-network/#joining-the-beta-network","text":"Testing is currently ongoing on the beta network for Version 22 Read through this page if you would like to participate. The beta network exists for the purpose of conducting certain network-wide activites including load testing and [new node releases and features testing]((#node-release-testing). These activities can cause the network to become unstable or inaccessible at times due to heavy traffic, occasional resetting of the genesis/ledger or the introduction of bugs due to new features. As a result, an alternative test network is also available which will be more stable and is a better fit for learning node setup and management, and testing out upgrades and other activities for Nano before moving to production. With those things in consideration, if you are interested in helping with testing on the beta network we are excited to help you out - so keep reading!","title":"Joining the beta network"},{"location":"running-a-node/beta-network/#node-release-testing","text":"The Nano Foundation maintains a few beta nodes on the network and various community members also setup nodes to help provide an environment more similar to the main network. During each development cycle Development Builds (DB) are prepared and shared in the Discord Beta Testing section of channels where early testing is coordinated. Once features are stabilized and included, release builds are published as Release Candidates (RC). Starting with RC1 and incrementing with each published build if needed (RC2, RC3, etc.). Final release of a version typically follows quickly once the RC is observed to be stable. Warning Development Builds (DBs) are only recommended for use on the beta network, and Release Candidate builds (RCs) are only recommended for use on the test and beta networks","title":"Node release testing"},{"location":"running-a-node/beta-network/#running-a-beta-node","text":"Setting up a node on the beta network is similar to the main network. To start you should install docker and be familiar with the general setup and Docker management processes.","title":"Running a beta node"},{"location":"running-a-node/beta-network/#network-ports","text":"Beta Network Ports Overview 54000 TCP: For live network activity and bootstrap network activity 55000 TCP: For communication with RPC server. Anyone with access to this port can control your node's RPC. 57000 TCP: For communication with websocket server . Depending on configuration, data throughput can be very high.","title":"Network ports"},{"location":"running-a-node/beta-network/#directory-locations","text":"OS Location Windows C: \\U sers \\< user> \\A ppData \\L ocal \\N anoBeta \\ macOS /Users/<user>/Library/NanoBeta/ Linux /home/<user>/NanoBeta/","title":"Directory locations"},{"location":"running-a-node/beta-network/#pulling-the-docker-image","text":"Pulls the latest release of the Nano Node: docker pull nanocurrency/nano-beta Pulls a specific version of the Nano node: docker pull nanocurrency/nano-beta:<tag> Pulls the latest release which includes any release candidate versions: docker pull nanocurrency/nano-beta:latest-including-rc A list of beta tags can be found at the official Nano Currency Docker Hub","title":"Pulling the Docker image"},{"location":"running-a-node/beta-network/#starting-the-docker-container","text":"docker run --restart = unless-stopped -d \\ -p 54000 :54000 \\ -p [ ::1 ] :55000:55000 \\ -p [ ::1 ] :57000:57000 \\ -v ${ NANO_HOST_DIR_BETA } :/root \\ --name ${ NANO_NAME } \\ nanocurrency/nano-beta:latest-including-rc Tip For an explanation of the options included in the Docker run command, see Starting the Container details for the main network. See Docker management for other related commands Separate host directories Be sure to use a different host directory for main network and beta network Docker node setups. Attempting to use the same directory will result in issues.","title":"Starting the Docker container"},{"location":"running-a-node/beta-network/#additional-beta-resources","text":"URL Description https://beta.nanocrawler.cc/ Beta Explorer https://beta.nanoticker.info/ Beta node details and stats https://b.repnode.org/ Beta node details and stats","title":"Additional beta resources"},{"location":"running-a-node/beta-network/#differences-from-the-main-network","text":"Parameter Main Network Beta Network Comment Epoch 1 difficulty threshold ffffffc000000000 fffff00000000000 64 times lower on the beta network Epoch 2 send/change threshold fffffff800000000 fffff00000000000 Same as epoch 1 on the beta network Epoch 2 receive threshold fffffe0000000000 ffffe00000000000 2 times lower than epoch 1","title":"Differences from the main network"},{"location":"running-a-node/beta-network/#testing-builds","text":"Most of the resources needed to participate on the beta network can be found within the #beta-xxxxxxx channels on our Discord server . As much of the discussion, planning and engagement happens here, all participants are highly encouraged to join there.","title":"Testing Builds"},{"location":"running-a-node/beta-network/#binaries","text":"In addition to the Docker details above, the latest binary builds of the node for the beta network are shared in the #beta-announcements channel on our Discord server . These assets are also available on the GitHub repository Releases page under RC# and DB# tags, which can also be used to manually build if necessary.","title":"Binaries"},{"location":"running-a-node/beta-network/#beta-fund-distribution","text":"The funds used for testing transactions on the beta network are generated from a new genesis block and distributed in bulk to various testers running nodes on the network. For small amounts suitable for most basic integration, you can get beta Nano from the #beta-faucet channel on Discord. If you plan to consistently run a node on beta and want to participate in consensus as a Representative, please connect with Zach - ATX#0646 or argakiig#1783 in the #beta-net channel on our Discord server .","title":"Beta fund distribution"},{"location":"running-a-node/beta-network/#beta-ledger-file","text":"To help get beta nodes in sync more quickly it is recommended that an updated ledger file is downloaded and placed into the data directory. Often referred to as a \"fast sync\", more details around this approach can be found in the Ledger Management guide . Since the beta network contains no value, validating the blocks, voting weights and confirmation heights isn't necessary. The following command will download and unzip a recent ledger snapshot. Any existing ledger files should be backed up elswhere as this will override them. From within the data directory run: curl -O https://s3.us-east-2.amazonaws.com/beta-snapshot.nano.org/data.tar.gz; tar -xzvf data.tar.gz; rm -fr data.tar.gz","title":"Beta ledger file"},{"location":"running-a-node/beta-network/#build-contents-and-test-cases","text":"With each DB a GitHub Project board will be created in the Nano GitHub Organization containing all the Pull Requests newly added in the DB, changes from previous DBs that still need network testing, and issues with the various test cases that are targeted to be run with that build. For those looking to assist with these tests, we encourage connecting with the other beta network participants in the #beta-net channel on our Discord server .","title":"Build contents and test cases"},{"location":"running-a-node/beyond-the-node/","text":"Beyond the Node \u00b6 Building tools and services \u00b6 Congrats! Now that you understand more about how Nano works and setup your own node to participate on the network, the next step is building tools and services on the node. Our Integration Guides are a great starting point to help you understand how you can leverage your node to create amazing applications that utilize the unique value transfer features of Nano. Need some inspiration? \u00b6 A big part of the Nano community is the Nano Center . Run by a group of Nano enthusiasts, their website helps manage requests for assistance and funding for Nano-related projects. Check out the in progress and past funded projects for some great ideas and opportunities to join in building on top of Nano! For even more details about the many projects that help make our ecosystem robust, head over to Nano.org for examples of wallets, services and more that have integrated Nano. Keep learning \u00b6 If you're ready to keep building with Nano, head over to The Basics of our Integration Guides.","title":"Beyond the Node"},{"location":"running-a-node/beyond-the-node/#beyond-the-node","text":"","title":"Beyond the Node"},{"location":"running-a-node/beyond-the-node/#building-tools-and-services","text":"Congrats! Now that you understand more about how Nano works and setup your own node to participate on the network, the next step is building tools and services on the node. Our Integration Guides are a great starting point to help you understand how you can leverage your node to create amazing applications that utilize the unique value transfer features of Nano.","title":"Building tools and services"},{"location":"running-a-node/beyond-the-node/#need-some-inspiration","text":"A big part of the Nano community is the Nano Center . Run by a group of Nano enthusiasts, their website helps manage requests for assistance and funding for Nano-related projects. Check out the in progress and past funded projects for some great ideas and opportunities to join in building on top of Nano! For even more details about the many projects that help make our ecosystem robust, head over to Nano.org for examples of wallets, services and more that have integrated Nano.","title":"Need some inspiration?"},{"location":"running-a-node/beyond-the-node/#keep-learning","text":"If you're ready to keep building with Nano, head over to The Basics of our Integration Guides.","title":"Keep learning"},{"location":"running-a-node/configuration-https/","text":"HTTPS Support \u00b6 The RPC server supports TLS to allow HTTPS requests, as well as optional client certificates. To enable TLS, the node must first be built with the NANO_SECURE_RPC cmake cache flag set to ON . OpenSSL must be installed. When running cmake initially, you may need to set -DOPENSSL_ROOT_DIR as well, depending on your system. Configuration \u00b6 The following section in config-rpc.toml enables TLS: [secure] enable = true verbose_logging = true server_cert_path = \"tls/server.cert.pem\" server_key_path = \"tls/server.key.pem\" server_key_passphrase = \"test\" server_dh_path = \"tls/dh1024.pem\" client_certs_path = \"tls/clients\" Testing with a self-signed server certificate \u00b6 The server_cert_path setting can be a single server certificate, or a chain file if using an intermediate CA. In this test, we'll generate a self-signed certificate. There are many ways to do this, but here we use openssl's req command to generate a certificate and a password protected keyfile: openssl req -newkey rsa:2048 -keyout server.key.pem -x509 -days 3650 -out server.cert.pem The passphrase must match the server_key_passphrase toml config setting. Pass -nodes if you don't want a password. OpenSSL will now ask you for certification details. For the server cert, only Common Name is important. Make sure you set it to the fully qualified domain name. While testing, you should add this domain name to your hosts file. Country Name (2 letter code) []:US State or Province Name (full name) []: Locality Name (eg, city) []: Organization Name (eg, company) []:MyNanoRPCServer Organizational Unit Name (eg, section) []:MyNanoThing Common Name (eg, fully qualified host name) []:www.example.com Email Address []: We also need to generate a Diffie-Hellman params file: openssl dhparam -out dh1024.pem 1024 Test call \u00b6 Create a POST request to https://www.example.com:7076 with the following body: { \"action\" : \"block_count\" } If using curl , self-signed certificates requires the --insecure flag. Client certificates (optional) \u00b6 If a directory is specified in client_certs_path , only clients with trusted client certificates will be able to connect. By trusted, we mean any client with a client certificate that's also installed in client_certs_path . Revoking access can be done by removing the client certificate file from the node. Generate and install client certificates \u00b6 Repeat the following process for each client/user you want to grant access: openssl req -newkey rsa:2048 -nodes -keyout rpcuser1.key.pem -x509 -days 365 -out rpcuser1.cert.pem The Common Name must be unique and should be something descriptive, like \"rpc.user.1\" For efficiency reasons, the client certificate must be renamed to its subject hash (or use a softlink) openssl x509 -in rpcuser1.cert.pem -noout -subject_hash 0fb8533c ln -s rpcuser1.cert.pem 0fb8533c.0 Distribute the client certificate and key file to the RPC user. Testing client certificates with Postman \u00b6 Use the full version of Postman, not the Chrome extension. In settings, select the Certificates tab. Add the cert.pem and key.pem files. The hostname must be the same as the hostname used in Common Name when generating the server certificate. Add this hostname to your hosts file if it's different from the machine hostname. If you get an error, check the node log file. Make sure the client certificates are installed. Single PEM file \u00b6 Some clients may want a single PEM file: cat rpcuser1.cert.pem rpcuser1.key.pem > rpcuser1.pem","title":"HTTPS Configuration"},{"location":"running-a-node/configuration-https/#https-support","text":"The RPC server supports TLS to allow HTTPS requests, as well as optional client certificates. To enable TLS, the node must first be built with the NANO_SECURE_RPC cmake cache flag set to ON . OpenSSL must be installed. When running cmake initially, you may need to set -DOPENSSL_ROOT_DIR as well, depending on your system.","title":"HTTPS Support"},{"location":"running-a-node/configuration-https/#configuration","text":"The following section in config-rpc.toml enables TLS: [secure] enable = true verbose_logging = true server_cert_path = \"tls/server.cert.pem\" server_key_path = \"tls/server.key.pem\" server_key_passphrase = \"test\" server_dh_path = \"tls/dh1024.pem\" client_certs_path = \"tls/clients\"","title":"Configuration"},{"location":"running-a-node/configuration-https/#testing-with-a-self-signed-server-certificate","text":"The server_cert_path setting can be a single server certificate, or a chain file if using an intermediate CA. In this test, we'll generate a self-signed certificate. There are many ways to do this, but here we use openssl's req command to generate a certificate and a password protected keyfile: openssl req -newkey rsa:2048 -keyout server.key.pem -x509 -days 3650 -out server.cert.pem The passphrase must match the server_key_passphrase toml config setting. Pass -nodes if you don't want a password. OpenSSL will now ask you for certification details. For the server cert, only Common Name is important. Make sure you set it to the fully qualified domain name. While testing, you should add this domain name to your hosts file. Country Name (2 letter code) []:US State or Province Name (full name) []: Locality Name (eg, city) []: Organization Name (eg, company) []:MyNanoRPCServer Organizational Unit Name (eg, section) []:MyNanoThing Common Name (eg, fully qualified host name) []:www.example.com Email Address []: We also need to generate a Diffie-Hellman params file: openssl dhparam -out dh1024.pem 1024","title":"Testing with a self-signed server certificate"},{"location":"running-a-node/configuration-https/#test-call","text":"Create a POST request to https://www.example.com:7076 with the following body: { \"action\" : \"block_count\" } If using curl , self-signed certificates requires the --insecure flag.","title":"Test call"},{"location":"running-a-node/configuration-https/#client-certificates-optional","text":"If a directory is specified in client_certs_path , only clients with trusted client certificates will be able to connect. By trusted, we mean any client with a client certificate that's also installed in client_certs_path . Revoking access can be done by removing the client certificate file from the node.","title":"Client certificates (optional)"},{"location":"running-a-node/configuration-https/#generate-and-install-client-certificates","text":"Repeat the following process for each client/user you want to grant access: openssl req -newkey rsa:2048 -nodes -keyout rpcuser1.key.pem -x509 -days 365 -out rpcuser1.cert.pem The Common Name must be unique and should be something descriptive, like \"rpc.user.1\" For efficiency reasons, the client certificate must be renamed to its subject hash (or use a softlink) openssl x509 -in rpcuser1.cert.pem -noout -subject_hash 0fb8533c ln -s rpcuser1.cert.pem 0fb8533c.0 Distribute the client certificate and key file to the RPC user.","title":"Generate and install client certificates"},{"location":"running-a-node/configuration-https/#testing-client-certificates-with-postman","text":"Use the full version of Postman, not the Chrome extension. In settings, select the Certificates tab. Add the cert.pem and key.pem files. The hostname must be the same as the hostname used in Common Name when generating the server certificate. Add this hostname to your hosts file if it's different from the machine hostname. If you get an error, check the node log file. Make sure the client certificates are installed.","title":"Testing client certificates with Postman"},{"location":"running-a-node/configuration-https/#single-pem-file","text":"Some clients may want a single PEM file: cat rpcuser1.cert.pem rpcuser1.key.pem > rpcuser1.pem","title":"Single PEM file"},{"location":"running-a-node/configuration/","text":"Node Configuration \u00b6 The Nano node software is designed to run with little or no configuration. All configuration options have defaults that can be changed using TOML configuration files, by passing configuration values via the command line, or a combination of the two methods. Automatic migration and backups of JSON files Versions prior to 20 use JSON as the configuration file format, and these will be automatically migrated to TOML files on startup. Note that only non-default values are migrated. In version 19.0 when the node is upgraded between releases, including any beta releases, all config files will be backed up prior to the upgrade in the same directory for easy recovery if needed. As TOML files are never upgraded by the node, no backups are created for these. V19.0 and earlier config.json file Below is a complete example of the config.json file used by V19.0 and earlier: { \"version\" : \"(int)\" , // Walle t versio n \"wallet\" : \"(string)\" , // De fault walle t t o load o n boo t (o nl y f or GUI walle t ) \"account\" : \"(string)\" , // De fault accou nt t o load o n boo t (o nl y f or GUI walle t ) \"node\" : { \"version\" : \"(int)\" , // Node versio n \"peering_port\" : \"7075\" , // De fault n ode por t \"bootstrap_fraction_numerator\" : \"1\" , \"enable_voting\" : \"false\" , // E na ble or disable vo t i n g f or blocks. I f disabled , saves some resources \"receive_minimum\" : \"1000000000000000000000000\" , // Mi n imum impor t receivable , de fault 1 Rai \"logging\" : { \"ledger\" : \"false\" , // Track i n comi n g blocks \"ledger_duplicate\" : \"false\" , \"network\" : \"true\" , // Track ge neral net work i nf o like f orks \"network_timeout\" : \"false\" , // Track TCP socke t disco nne c t io ns due t o t imeou t \"network_message\" : \"false\" , \"network_publish\" : \"false\" , // Track blocks you publish t o \"network_packet\" : \"false\" , // Track packe ts origi n \"network_keepalive\" : \"false\" , // Track keepalive messages \"network_node_id_handshake\" : \"false\" , // Track n ode_id messages \"node_lifetime_tracing\" : \"false\" , \"insufficient_work\" : \"true\" , \"bulk_pull\" : \"false\" , // Boo tstra p rela te d loggi n g \"work_generation_time\" : \"true\" , \"log_to_cerr\" : \"false\" , \"max_size\" : \"16777216\" , // Max size o f logs be f ore old f iles dele t io n . De fault is 16 MB \"rotation_size\" : \"4194304\" , // Size o f Log File be f ore ro tat io n i n by tes , De fault is 4 MB \"version\" : \"(int)\" , // Loggi n g co nf ig versio n \"vote\" : \"false\" , // Track vo t i n g ac t ivi t ies \"flush\" : \"true\" , // Se tt i n g t his t o false gives be tter per f orma n ce , bu t may lose e ntr ies o n crashes. \"upnp_details\" : \"false\" , // De ter mi nes i f up n p discovery de ta ils are logged (de fault o ff t o avoid shari n g device i nf o whe n shippi n g logs) \"timing\" : \"false\" , // Logs dura t io ns o f key fun c t io ns , such as ba t ch veri f ica t io n , e t c. \"log_ipc\" : \"true\" , // Loggi n g o f IPC rela te d messages \"min_time_between_output\" : \"5\" , // Mi n imum t ime be t wee n log calls , i n ms \"single_line_record\" : \"false\" // Log each record i n si n gle li ne (i n cludi n g block co ntent & elec t io n resul ts wi t h vo tes ) }, \"vote_minimum\" : \"1000000000000000000000000000000000\" , // Preve nts vo t i n g i f delega te d weigh t is u n der t his t hreshold \"work_peers\" : \"\" , // Delega te a n ode your hash work , you nee d t o ge t RPC access t o t ha t n ode \"preconfigured_peers\" : [ // Lis t o f de faults peers t o co nne c t o n boo t \"peering.nano.org\" , \"::ffff:138.201.94.249\" ], \"preconfigured_representatives\" : [ // Lis t o f de faults represe ntat ives , which you delega te vo t i n g weigh t , o f your walle t \"nano_3arg3asgtigae3xckabaaewkx3bzsh7nwz7jkmjos79ihyaxwphhm6qgjps4\" , \"nano_1stofnrxuz3cai7ze75o174bpm7scwj9jn3nxsn8ntzg784jf1gzn1jjdkou\" , \"nano_1q3hqecaw15cjt7thbtxu3pbzr1eihtzzpzxguoc37bj1wc5ffoh7w74gi6p\" , \"nano_3dmtrrws3pocycmbqwawk6xs7446qxa36fcncush4s1pejk16ksbmakis78m\" , \"nano_3hd4ezdgsp15iemx7h81in7xz5tpxi43b6b41zn3qmwiuypankocw3awes5k\" , \"nano_1awsn43we17c1oshdru4azeqjz9wii41dy8npubm4rg11so7dx3jtqgoeahy\" , \"nano_1anrzcuwe64rwxzcco8dkhpyxpi8kd7zsjc1oeimpc3ppca4mrjtwnqposrs\" , \"nano_1hza3f7wiiqa7ig3jczyxj5yo86yegcmqk3criaz838j91sxcckpfhbhhra1\" ], \"online_weight_minimum\" : \"60000000000000000000000000000000000000\" , // O nl i ne weigh t mi n imum required t o co nf irm block \"online_weight_quorum\" : \"50\" , // Perce nta ge o f vo tes required t o rollback blocks \"password_fanout\" : \"1024\" , \"io_threads\" : \"4\" , \"work_threads\" : \"4\" , // PoW work t hreads. By de fault all available CPU t hreads , se t lower value f or 24 / 7 services \"callback_address\" : \"::ffff:127.0.0.1\" , // Callback IP address , i n sample IPv 4 localhos t \"callback_port\" : \"17076\" , // Callback por t \"callback_target\" : \"/\" , // Callback tar ge t , i n sample roo t o f callback lis ten i n g server \"bootstrap_connections\" : \"16\" , // Mul t i - co nne c t io n boo tstra p. Should be a power o f 2. \"bootstrap_connections_max\" : \"4\" , // Allowed i n comi n g boo tstra p co nne c t io ns cou nt . Lower value save IOPS & ba n dwid t h. 64 recomme n ded f or high -e n d fast n odes , 0 f or HDD home users , \"lmdb_max_dbs\" : \"128\" , // Maximum ope n DBs (MAX_DBS h tt ps : //lmdb.read t hedocs.io/e n /release/) , i n crease de fault i f more t ha n 100 walle ts required \"block_processor_batch_max_time\" : \"5000\" , // Number o f milliseco n ds t he block processor works a t a t ime \"allow_local_peers\" : \"false\" , // To allow local hos t peeri n g \"signature_checker_threads\" : \"1\" , // Number o f t hreads t o use f or veri f yi n g sig natures \"unchecked_cutoff_time\" : \"14400\" , // Number o f seco n ds u n checked e ntr y survives be f ore bei n g clea ne d \"tcp_io_timeout\" : \"15\" , // Timeou t i n seco n ds f or TCP co nne c t - , read - a n d wri te opera t io ns \"pow_sleep_interval\" : \"0\" , // The amou nt t o sleep a fter each ba t ch o f POW calcula t io ns . Reduces max CPU usage a t t he expe ns ive o f a lo n ger workge nerat io n t ime. \"external_address\" : \"::\" , \"external_port\" : \"0\" , \"tcp_incoming_connections_max\" : \"1024\" , // Allowed i n comi n g TCP co nne c t io ns cou nt \"websocket\" : { \"enable\" : \"false\" , \"address\" : \"::1\" , // De fault IPv 6 address t o lis ten o n . I f usi n g Docker , cha n ge address t o :: ffff : 0.0.0.0 t o lis ten o n all i nterfa ces wi t hi n t he co nta i ner . \"port\" : \"7078\" }, \"ipc\" : { // For more de ta ils abou t t hese op t io ns see t he IPC sec t io n below \"tcp\" : { \"enable\" : \"false\" , \"port\" : \"7077\" , \"io_timeout\" : \"15\" }, \"local\" : { \"version\" : \"1\" , \"enable\" : \"false\" , \"allow_unsafe\" : \"false\" , \"path\" : \"\\/tmp\\/nano\" , \"io_timeout\" : \"15\" } }, \"diagnostics\" : { \"txn_tracking\" : { \"enable\" : \"false\" , // Tracks lmdb transa c t io ns \"min_read_txn_time\" : \"5000\" , // Logs s ta ck tra ce whe n read transa c t io ns are held lo n ger t ha n t his t ime (milliseco n ds) \"min_write_txn_time\" : \"500\" , // Logs s ta ck tra ce whe n wri te transa c t io ns are held lo n ger t ha n t his t ime (milliseco n ds) \"ignore_writes_below_block_processor_max_time\" : \"true\" // Ig n ore a n y block processor wri tes less t ha n block_processor_max_ t ime } }, \"use_memory_pools\" : \"true\" , // Improve per f orma n ce by usi n g memory pools (No te : Memory alloca te d will be reused bu t ne ver reclaimed , i f havi n g memory issues t he n tr y turn i n g t his o ff ) \"confirmation_history_size\" : \"2048\" , // Co ntr ols co nf irma t io n his t ory size , de fault se tt i n g preserves exis t i n g behavior \"bandwidth_limit\" : \"5242880\" , // Ou t bou n d vo t i n g traff ic limi t i n by tes /sec a fter which messages will be dropped \"vote_generator_delay\" : \"100\" , // Delay i n ms be f ore vo tes are se nt ou t t o allow f or be tter bu n dli n g o f hashes i n vo tes \"vote_generator_threshold\" : \"3\" , // De f i nes t he poi nt a t which t he n ode will delay se n di n g vo tes f or a n o t her vo te _ge nerat or_delay. Allows f or more hashes t o be bu n dled u n der load \"active_elections_size\" : \"50000\" , // Limi ts nu mber o f ac t ive elec t io ns i n co nta i ner be f ore droppi n g will be co ns idered (o t her co n di t io ns mus t also be sa t is f ied) , mi n imum value allowed is 250. \"conf_height_processor_batch_min_time\" : \"50\" , // Amou nt o f t ime i n ms t o ba t ch se tt i n g co nf irma t io n heigh ts f or accou nts duri n g high t ps t o reduce wri te I/O bo ttlene cks. \"backup_before_upgrade\" : \"false\" , // Backup ledger & walle t da ta bases be f ore each upgrade \"work_watcher_period\" : \"5\" , // Time be t wee n checks f or co nf irma t io n a n d re - ge nerat i n g higher di ff icul t y work i f u n co nf irmed , f or blocks i n t he work wa t cher \"max_work_generate_multiplier\" : \"256.0\" , // Maximum allowed di ff icul t y mul t iplier f or work ge nerat io n (double). Used f or work_ge nerate RPC reques ts & i nternal walle t work wa t cher \"frontiers_confirmation\" : \"auto\" // Mode f or f orce fr o nt iers co nf irma t io n . \"auto\" mode (de fault ) : I f n o t Pri n cipal Represe ntat ive , s tart fr o nt ier co nf irma t io n process every 15 mi nutes ; i f Pri n cipal Represe ntat ive , s tart fr o nt ier co nf irma t io n process every 3 mi nutes . \"always\" : S tart fr o nt ier co nf irma t io n process every 3 mi nutes . \"disabled\" : Do n o t s tart fr o nt ier co nf irma t io n process }, \"rpc_enable\" : \"true\" , // E na ble (i n - process or child process) or disable RPC. Ou t o f process rpc servers ca n s t ill be used i f lau n ched ma nuall y. \"rpc\" : { \"enable_sign_hash\" : \"true\" , \"version\" : \"1\" , \"child_process\" : { \"enable\" : \"false\" , // Whe t her t he rpc server is ru n as a child process ra t her t ha n i n - process \"rpc_path\" : \"C:\\\\Users\\\\Wesley\\\\Documents\\\\raiblocks\\\\build\\\\Debug\\\\nano_rpc.exe\" , // The nan o_rpc execu ta ble t o ru n i f e na bled (Wi n dows example). } }, \"opencl_enable\" : \"false\" , // E na ble GPU hashi n g \"opencl\" : { \"platform\" : \"0\" , // Pla tf orm ID \"device\" : \"0\" , // Device ID \"threads\" : \"1048576\" } } Configuration file locations \u00b6 The node and its related processes will look for the files listed below, either in their default location or the location specified with --data_path . These files are optional . The table includes a command which can be used to generate a documented TOML file with defaults suitable for the system. Name Description Generated with config-node.toml Node configuration nano_node --generate_config node config-rpc.toml RPC configuration nano_node --generate_config rpc config-nano-pow-server.toml Proof of work server configuration nano_pow_server --generate_config config-qtwallet.toml Qt developer wallet configuration This file is maintained by the Qt wallet The default locations of the config files are listed in the table below. OS Location Windows C: \\U sers \\< user> \\A ppData \\L ocal \\N ano \\ macOS /Users/<user>/Library/Nano/ Linux /home/<user>/Nano/ Options formatting \u00b6 Config options are referred to in the documentation using the format category.option where category can be multiple levels. For example, the node.enable_voting option would correspond to the following entry in the TOML file: [node] # Enable or disable voting. Enabling this option requires additional system resources, namely increased CPU, bandwidth and disk usage. # type:bool enable_voting = true While a multiple category option like node.websocket.enable would correspond to this TOML file entry: [node.websocket] # Enable or disable WebSocket server. # type:bool enable = false Passing config values on the command line \u00b6 Instead of changing the config file, config values can be passed in via the --config option, which can be repeated multiple times. Example that enables the RPC and WebSocket servers: nano_node --config rpc.enable=true --config node.websocket.enable=true The way strings are passed is as follows: v22 + uses quotes ( \" ) such as: nano_node --config node.httpcallback.target=\"api/callback\" Arrays must not have spaces inbetween entries. v21 and earlier must use escaped quotes ( \\\" ) such as: nano_node --config node.httpcallback.target=\\\"api/callback\\\" For backwards compatibility this is also supported in v22 + Mixing config options on the command line and TOML files If a config file exists, config values passed in via the command line will take precedence. Notable configuration options \u00b6 As of V20.0 the sample TOML packaged with the binaries and available for generation via the command line are commented out with descriptions of each option. Where applicable the following integration areas have those options included along with additional context where necessary. Work generation \u00b6 See the Work Generation guide . WebSockets \u00b6 See the WebSockets Integration guide . RPC \u00b6 rpc.enable \u00b6 To enable communication via RPC, set this configuration option in the config-node.toml file. [rpc] # Enable or disable RPC # type:bool enable = true enable_control \u00b6 This configuration option is set in the config-rpc.toml file. Due to their sensitive or dangerous nature, certain RPC calls/options require this setting to be enabled before they can be used. Examples of RPC calls that require this include: stop : allows you to completely stop the node from running work_generate : allows potential consumption of CPU or GPU resources on the node or attached work peers to generate PoW send : can be used to transfer available funds in the wallet to another account Various other wallet and resource-heavy operations # Enable or disable control-level requests. # WARNING: Enabling this gives anyone with RPC access the ability to stop the node and access wallet funds. # type:bool enable_control = false Dangerous RPC calls controlled by enable_control Due to the sensitive or dangerous nature of these calls, caution should be used when considering setting enable_control to true in your config file. It is highly recommended to only enable this when RPC ports are listening exclusively to local or loopback IP addresses or other measure are put in place outside the node to limit RPC access to dangerous calls. For more details see the Node Security page . More advanced options for controlling the process the RPC server runs under can be found in the Running Nano as a service guide . logging.stable_log_filename \u00b6 Known Issue Windows V21: Crash when using config node.logging.stable_log_filename Setting node.logging.stable_log_filename configuration option to true results in a node crash on Windows in V21.0 and V21.1, after a node restart. This must be set to false . This configuration option is set in the config-node.toml file . By default this option is set to false which results in all log files having a timestamp appended to them, even the currently active file. If set to true the currently active log file will have a static name at log/node.log for easier management. [logging] # Append to log/node.log without a timestamp in the filename. # The file is not emptied on startup if it exists, but appended to. # type:bool stable_log_filename = true logging.log_rpc \u00b6 This configuration option is set in the config-rpc.toml file. By default, all RPC calls and the time spent handling each one are logged . This can be optionally turned off by switching option logging.log_rpc to false [logging] # Whether to log RPC calls. # type:bool log_rpc = true IPC \u00b6 See the IPC Integration guide . Voting \u00b6 See the Voting as a Representative guide . Ledger backends \u00b6 See the Ledger Management guide . HTTPS support \u00b6 See the HTTPS Support guide . HTTP callback \u00b6 Tip When possible, using a WebSocket is recommended as it provides more efficiency, more options for types of information to receive and better control over the volume of notifications with filtering. These configuration options are set in the config-node.toml file. [node.httpcallback] # Callback address. # type:string,ip #address = \"\" # Callback port number. # type:uint16 #port = 0 # Callback target path. # type:string,uri #target = \"\" JSON POST requests with every confirmed block are sent to the callback server as defined in the config values above: http://callback_address:callback_port<callback_target> . Callback target should include a leading slash. For details on how to integrate using the HTTP callback, see the HTTP Callback section of the Integration Guides . Network Details \u00b6 Port Type Default Details 7075 TCP Enabled Node bootstrapping server Share port configuration in config-node.toml , option node.peering_port Binds to all adapters; unicast Contents: Raw nano protocol stream Transmits the ledger to new nodes in bulk If blocked other nodes will not be able retrieve the ledger from this node 7076 TCP Disabled RPC server Port configurable in config-rpc.toml , option rpc.port Enable in config-node.toml , option rpc.enable or by starting nano_rpc manually Binds to localhost by default for security reasons, configurable in config-rpc.toml , option rpc.address ; unicast Contents: Unencrypted HTTP requests containing JSON object bodies Allows the node to be queried or controlled through HTTP requests If blocked the node will not be able to be queried or controlled by HTTP WARNING: Exposing this port externally while setting enable_control option to true in configs could expose your wallet, allow the node to be stopped remotely and open your node up to other dangerous activity. See the Node Security page for more details. 7078 TCP Disabled Websocket server Port configurable in config-node.toml , option node.websocket.port Enable in config-node.toml , option node.websocket.enable Binds to localhost by default due to data throughput potentially being very high; producer-subscriber broadcast Contents: Standard websocket frames containing JSON-encoded objects See WebSocket Support for details on configuration 7075 UDP Disabled Deprecated (V21+) Previously this was the node activity port (deprecated in V21) Port configurable in config-node.toml , option node.peering_port Binds to all adapters; unicast Contents: Raw nano protocol datagrams All standard ledger activity goes through this port If blocked the node will not function UDP disabled by default, deprecated As of V21 peering and communicating via UDP has been disabled by default and is deprecated. The ability to use UDP will be removed from the node in a future release yet to be determined.","title":"Configuration"},{"location":"running-a-node/configuration/#node-configuration","text":"The Nano node software is designed to run with little or no configuration. All configuration options have defaults that can be changed using TOML configuration files, by passing configuration values via the command line, or a combination of the two methods. Automatic migration and backups of JSON files Versions prior to 20 use JSON as the configuration file format, and these will be automatically migrated to TOML files on startup. Note that only non-default values are migrated. In version 19.0 when the node is upgraded between releases, including any beta releases, all config files will be backed up prior to the upgrade in the same directory for easy recovery if needed. As TOML files are never upgraded by the node, no backups are created for these. V19.0 and earlier config.json file Below is a complete example of the config.json file used by V19.0 and earlier: { \"version\" : \"(int)\" , // Walle t versio n \"wallet\" : \"(string)\" , // De fault walle t t o load o n boo t (o nl y f or GUI walle t ) \"account\" : \"(string)\" , // De fault accou nt t o load o n boo t (o nl y f or GUI walle t ) \"node\" : { \"version\" : \"(int)\" , // Node versio n \"peering_port\" : \"7075\" , // De fault n ode por t \"bootstrap_fraction_numerator\" : \"1\" , \"enable_voting\" : \"false\" , // E na ble or disable vo t i n g f or blocks. I f disabled , saves some resources \"receive_minimum\" : \"1000000000000000000000000\" , // Mi n imum impor t receivable , de fault 1 Rai \"logging\" : { \"ledger\" : \"false\" , // Track i n comi n g blocks \"ledger_duplicate\" : \"false\" , \"network\" : \"true\" , // Track ge neral net work i nf o like f orks \"network_timeout\" : \"false\" , // Track TCP socke t disco nne c t io ns due t o t imeou t \"network_message\" : \"false\" , \"network_publish\" : \"false\" , // Track blocks you publish t o \"network_packet\" : \"false\" , // Track packe ts origi n \"network_keepalive\" : \"false\" , // Track keepalive messages \"network_node_id_handshake\" : \"false\" , // Track n ode_id messages \"node_lifetime_tracing\" : \"false\" , \"insufficient_work\" : \"true\" , \"bulk_pull\" : \"false\" , // Boo tstra p rela te d loggi n g \"work_generation_time\" : \"true\" , \"log_to_cerr\" : \"false\" , \"max_size\" : \"16777216\" , // Max size o f logs be f ore old f iles dele t io n . De fault is 16 MB \"rotation_size\" : \"4194304\" , // Size o f Log File be f ore ro tat io n i n by tes , De fault is 4 MB \"version\" : \"(int)\" , // Loggi n g co nf ig versio n \"vote\" : \"false\" , // Track vo t i n g ac t ivi t ies \"flush\" : \"true\" , // Se tt i n g t his t o false gives be tter per f orma n ce , bu t may lose e ntr ies o n crashes. \"upnp_details\" : \"false\" , // De ter mi nes i f up n p discovery de ta ils are logged (de fault o ff t o avoid shari n g device i nf o whe n shippi n g logs) \"timing\" : \"false\" , // Logs dura t io ns o f key fun c t io ns , such as ba t ch veri f ica t io n , e t c. \"log_ipc\" : \"true\" , // Loggi n g o f IPC rela te d messages \"min_time_between_output\" : \"5\" , // Mi n imum t ime be t wee n log calls , i n ms \"single_line_record\" : \"false\" // Log each record i n si n gle li ne (i n cludi n g block co ntent & elec t io n resul ts wi t h vo tes ) }, \"vote_minimum\" : \"1000000000000000000000000000000000\" , // Preve nts vo t i n g i f delega te d weigh t is u n der t his t hreshold \"work_peers\" : \"\" , // Delega te a n ode your hash work , you nee d t o ge t RPC access t o t ha t n ode \"preconfigured_peers\" : [ // Lis t o f de faults peers t o co nne c t o n boo t \"peering.nano.org\" , \"::ffff:138.201.94.249\" ], \"preconfigured_representatives\" : [ // Lis t o f de faults represe ntat ives , which you delega te vo t i n g weigh t , o f your walle t \"nano_3arg3asgtigae3xckabaaewkx3bzsh7nwz7jkmjos79ihyaxwphhm6qgjps4\" , \"nano_1stofnrxuz3cai7ze75o174bpm7scwj9jn3nxsn8ntzg784jf1gzn1jjdkou\" , \"nano_1q3hqecaw15cjt7thbtxu3pbzr1eihtzzpzxguoc37bj1wc5ffoh7w74gi6p\" , \"nano_3dmtrrws3pocycmbqwawk6xs7446qxa36fcncush4s1pejk16ksbmakis78m\" , \"nano_3hd4ezdgsp15iemx7h81in7xz5tpxi43b6b41zn3qmwiuypankocw3awes5k\" , \"nano_1awsn43we17c1oshdru4azeqjz9wii41dy8npubm4rg11so7dx3jtqgoeahy\" , \"nano_1anrzcuwe64rwxzcco8dkhpyxpi8kd7zsjc1oeimpc3ppca4mrjtwnqposrs\" , \"nano_1hza3f7wiiqa7ig3jczyxj5yo86yegcmqk3criaz838j91sxcckpfhbhhra1\" ], \"online_weight_minimum\" : \"60000000000000000000000000000000000000\" , // O nl i ne weigh t mi n imum required t o co nf irm block \"online_weight_quorum\" : \"50\" , // Perce nta ge o f vo tes required t o rollback blocks \"password_fanout\" : \"1024\" , \"io_threads\" : \"4\" , \"work_threads\" : \"4\" , // PoW work t hreads. By de fault all available CPU t hreads , se t lower value f or 24 / 7 services \"callback_address\" : \"::ffff:127.0.0.1\" , // Callback IP address , i n sample IPv 4 localhos t \"callback_port\" : \"17076\" , // Callback por t \"callback_target\" : \"/\" , // Callback tar ge t , i n sample roo t o f callback lis ten i n g server \"bootstrap_connections\" : \"16\" , // Mul t i - co nne c t io n boo tstra p. Should be a power o f 2. \"bootstrap_connections_max\" : \"4\" , // Allowed i n comi n g boo tstra p co nne c t io ns cou nt . Lower value save IOPS & ba n dwid t h. 64 recomme n ded f or high -e n d fast n odes , 0 f or HDD home users , \"lmdb_max_dbs\" : \"128\" , // Maximum ope n DBs (MAX_DBS h tt ps : //lmdb.read t hedocs.io/e n /release/) , i n crease de fault i f more t ha n 100 walle ts required \"block_processor_batch_max_time\" : \"5000\" , // Number o f milliseco n ds t he block processor works a t a t ime \"allow_local_peers\" : \"false\" , // To allow local hos t peeri n g \"signature_checker_threads\" : \"1\" , // Number o f t hreads t o use f or veri f yi n g sig natures \"unchecked_cutoff_time\" : \"14400\" , // Number o f seco n ds u n checked e ntr y survives be f ore bei n g clea ne d \"tcp_io_timeout\" : \"15\" , // Timeou t i n seco n ds f or TCP co nne c t - , read - a n d wri te opera t io ns \"pow_sleep_interval\" : \"0\" , // The amou nt t o sleep a fter each ba t ch o f POW calcula t io ns . Reduces max CPU usage a t t he expe ns ive o f a lo n ger workge nerat io n t ime. \"external_address\" : \"::\" , \"external_port\" : \"0\" , \"tcp_incoming_connections_max\" : \"1024\" , // Allowed i n comi n g TCP co nne c t io ns cou nt \"websocket\" : { \"enable\" : \"false\" , \"address\" : \"::1\" , // De fault IPv 6 address t o lis ten o n . I f usi n g Docker , cha n ge address t o :: ffff : 0.0.0.0 t o lis ten o n all i nterfa ces wi t hi n t he co nta i ner . \"port\" : \"7078\" }, \"ipc\" : { // For more de ta ils abou t t hese op t io ns see t he IPC sec t io n below \"tcp\" : { \"enable\" : \"false\" , \"port\" : \"7077\" , \"io_timeout\" : \"15\" }, \"local\" : { \"version\" : \"1\" , \"enable\" : \"false\" , \"allow_unsafe\" : \"false\" , \"path\" : \"\\/tmp\\/nano\" , \"io_timeout\" : \"15\" } }, \"diagnostics\" : { \"txn_tracking\" : { \"enable\" : \"false\" , // Tracks lmdb transa c t io ns \"min_read_txn_time\" : \"5000\" , // Logs s ta ck tra ce whe n read transa c t io ns are held lo n ger t ha n t his t ime (milliseco n ds) \"min_write_txn_time\" : \"500\" , // Logs s ta ck tra ce whe n wri te transa c t io ns are held lo n ger t ha n t his t ime (milliseco n ds) \"ignore_writes_below_block_processor_max_time\" : \"true\" // Ig n ore a n y block processor wri tes less t ha n block_processor_max_ t ime } }, \"use_memory_pools\" : \"true\" , // Improve per f orma n ce by usi n g memory pools (No te : Memory alloca te d will be reused bu t ne ver reclaimed , i f havi n g memory issues t he n tr y turn i n g t his o ff ) \"confirmation_history_size\" : \"2048\" , // Co ntr ols co nf irma t io n his t ory size , de fault se tt i n g preserves exis t i n g behavior \"bandwidth_limit\" : \"5242880\" , // Ou t bou n d vo t i n g traff ic limi t i n by tes /sec a fter which messages will be dropped \"vote_generator_delay\" : \"100\" , // Delay i n ms be f ore vo tes are se nt ou t t o allow f or be tter bu n dli n g o f hashes i n vo tes \"vote_generator_threshold\" : \"3\" , // De f i nes t he poi nt a t which t he n ode will delay se n di n g vo tes f or a n o t her vo te _ge nerat or_delay. Allows f or more hashes t o be bu n dled u n der load \"active_elections_size\" : \"50000\" , // Limi ts nu mber o f ac t ive elec t io ns i n co nta i ner be f ore droppi n g will be co ns idered (o t her co n di t io ns mus t also be sa t is f ied) , mi n imum value allowed is 250. \"conf_height_processor_batch_min_time\" : \"50\" , // Amou nt o f t ime i n ms t o ba t ch se tt i n g co nf irma t io n heigh ts f or accou nts duri n g high t ps t o reduce wri te I/O bo ttlene cks. \"backup_before_upgrade\" : \"false\" , // Backup ledger & walle t da ta bases be f ore each upgrade \"work_watcher_period\" : \"5\" , // Time be t wee n checks f or co nf irma t io n a n d re - ge nerat i n g higher di ff icul t y work i f u n co nf irmed , f or blocks i n t he work wa t cher \"max_work_generate_multiplier\" : \"256.0\" , // Maximum allowed di ff icul t y mul t iplier f or work ge nerat io n (double). Used f or work_ge nerate RPC reques ts & i nternal walle t work wa t cher \"frontiers_confirmation\" : \"auto\" // Mode f or f orce fr o nt iers co nf irma t io n . \"auto\" mode (de fault ) : I f n o t Pri n cipal Represe ntat ive , s tart fr o nt ier co nf irma t io n process every 15 mi nutes ; i f Pri n cipal Represe ntat ive , s tart fr o nt ier co nf irma t io n process every 3 mi nutes . \"always\" : S tart fr o nt ier co nf irma t io n process every 3 mi nutes . \"disabled\" : Do n o t s tart fr o nt ier co nf irma t io n process }, \"rpc_enable\" : \"true\" , // E na ble (i n - process or child process) or disable RPC. Ou t o f process rpc servers ca n s t ill be used i f lau n ched ma nuall y. \"rpc\" : { \"enable_sign_hash\" : \"true\" , \"version\" : \"1\" , \"child_process\" : { \"enable\" : \"false\" , // Whe t her t he rpc server is ru n as a child process ra t her t ha n i n - process \"rpc_path\" : \"C:\\\\Users\\\\Wesley\\\\Documents\\\\raiblocks\\\\build\\\\Debug\\\\nano_rpc.exe\" , // The nan o_rpc execu ta ble t o ru n i f e na bled (Wi n dows example). } }, \"opencl_enable\" : \"false\" , // E na ble GPU hashi n g \"opencl\" : { \"platform\" : \"0\" , // Pla tf orm ID \"device\" : \"0\" , // Device ID \"threads\" : \"1048576\" } }","title":"Node Configuration"},{"location":"running-a-node/configuration/#configuration-file-locations","text":"The node and its related processes will look for the files listed below, either in their default location or the location specified with --data_path . These files are optional . The table includes a command which can be used to generate a documented TOML file with defaults suitable for the system. Name Description Generated with config-node.toml Node configuration nano_node --generate_config node config-rpc.toml RPC configuration nano_node --generate_config rpc config-nano-pow-server.toml Proof of work server configuration nano_pow_server --generate_config config-qtwallet.toml Qt developer wallet configuration This file is maintained by the Qt wallet The default locations of the config files are listed in the table below. OS Location Windows C: \\U sers \\< user> \\A ppData \\L ocal \\N ano \\ macOS /Users/<user>/Library/Nano/ Linux /home/<user>/Nano/","title":"Configuration file locations"},{"location":"running-a-node/configuration/#options-formatting","text":"Config options are referred to in the documentation using the format category.option where category can be multiple levels. For example, the node.enable_voting option would correspond to the following entry in the TOML file: [node] # Enable or disable voting. Enabling this option requires additional system resources, namely increased CPU, bandwidth and disk usage. # type:bool enable_voting = true While a multiple category option like node.websocket.enable would correspond to this TOML file entry: [node.websocket] # Enable or disable WebSocket server. # type:bool enable = false","title":"Options formatting"},{"location":"running-a-node/configuration/#passing-config-values-on-the-command-line","text":"Instead of changing the config file, config values can be passed in via the --config option, which can be repeated multiple times. Example that enables the RPC and WebSocket servers: nano_node --config rpc.enable=true --config node.websocket.enable=true The way strings are passed is as follows: v22 + uses quotes ( \" ) such as: nano_node --config node.httpcallback.target=\"api/callback\" Arrays must not have spaces inbetween entries. v21 and earlier must use escaped quotes ( \\\" ) such as: nano_node --config node.httpcallback.target=\\\"api/callback\\\" For backwards compatibility this is also supported in v22 + Mixing config options on the command line and TOML files If a config file exists, config values passed in via the command line will take precedence.","title":"Passing config values on the command line"},{"location":"running-a-node/configuration/#notable-configuration-options","text":"As of V20.0 the sample TOML packaged with the binaries and available for generation via the command line are commented out with descriptions of each option. Where applicable the following integration areas have those options included along with additional context where necessary.","title":"Notable configuration options"},{"location":"running-a-node/configuration/#work-generation","text":"See the Work Generation guide .","title":"Work generation"},{"location":"running-a-node/configuration/#websockets","text":"See the WebSockets Integration guide .","title":"WebSockets"},{"location":"running-a-node/configuration/#rpc","text":"","title":"RPC"},{"location":"running-a-node/configuration/#rpcenable","text":"To enable communication via RPC, set this configuration option in the config-node.toml file. [rpc] # Enable or disable RPC # type:bool enable = true","title":"rpc.enable"},{"location":"running-a-node/configuration/#enable_control","text":"This configuration option is set in the config-rpc.toml file. Due to their sensitive or dangerous nature, certain RPC calls/options require this setting to be enabled before they can be used. Examples of RPC calls that require this include: stop : allows you to completely stop the node from running work_generate : allows potential consumption of CPU or GPU resources on the node or attached work peers to generate PoW send : can be used to transfer available funds in the wallet to another account Various other wallet and resource-heavy operations # Enable or disable control-level requests. # WARNING: Enabling this gives anyone with RPC access the ability to stop the node and access wallet funds. # type:bool enable_control = false Dangerous RPC calls controlled by enable_control Due to the sensitive or dangerous nature of these calls, caution should be used when considering setting enable_control to true in your config file. It is highly recommended to only enable this when RPC ports are listening exclusively to local or loopback IP addresses or other measure are put in place outside the node to limit RPC access to dangerous calls. For more details see the Node Security page . More advanced options for controlling the process the RPC server runs under can be found in the Running Nano as a service guide .","title":"enable_control"},{"location":"running-a-node/configuration/#loggingstable_log_filename","text":"Known Issue Windows V21: Crash when using config node.logging.stable_log_filename Setting node.logging.stable_log_filename configuration option to true results in a node crash on Windows in V21.0 and V21.1, after a node restart. This must be set to false . This configuration option is set in the config-node.toml file . By default this option is set to false which results in all log files having a timestamp appended to them, even the currently active file. If set to true the currently active log file will have a static name at log/node.log for easier management. [logging] # Append to log/node.log without a timestamp in the filename. # The file is not emptied on startup if it exists, but appended to. # type:bool stable_log_filename = true","title":"logging.stable_log_filename"},{"location":"running-a-node/configuration/#logginglog_rpc","text":"This configuration option is set in the config-rpc.toml file. By default, all RPC calls and the time spent handling each one are logged . This can be optionally turned off by switching option logging.log_rpc to false [logging] # Whether to log RPC calls. # type:bool log_rpc = true","title":"logging.log_rpc"},{"location":"running-a-node/configuration/#ipc","text":"See the IPC Integration guide .","title":"IPC"},{"location":"running-a-node/configuration/#voting","text":"See the Voting as a Representative guide .","title":"Voting"},{"location":"running-a-node/configuration/#ledger-backends","text":"See the Ledger Management guide .","title":"Ledger backends"},{"location":"running-a-node/configuration/#https-support","text":"See the HTTPS Support guide .","title":"HTTPS support"},{"location":"running-a-node/configuration/#http-callback","text":"Tip When possible, using a WebSocket is recommended as it provides more efficiency, more options for types of information to receive and better control over the volume of notifications with filtering. These configuration options are set in the config-node.toml file. [node.httpcallback] # Callback address. # type:string,ip #address = \"\" # Callback port number. # type:uint16 #port = 0 # Callback target path. # type:string,uri #target = \"\" JSON POST requests with every confirmed block are sent to the callback server as defined in the config values above: http://callback_address:callback_port<callback_target> . Callback target should include a leading slash. For details on how to integrate using the HTTP callback, see the HTTP Callback section of the Integration Guides .","title":"HTTP callback"},{"location":"running-a-node/configuration/#network-details","text":"Port Type Default Details 7075 TCP Enabled Node bootstrapping server Share port configuration in config-node.toml , option node.peering_port Binds to all adapters; unicast Contents: Raw nano protocol stream Transmits the ledger to new nodes in bulk If blocked other nodes will not be able retrieve the ledger from this node 7076 TCP Disabled RPC server Port configurable in config-rpc.toml , option rpc.port Enable in config-node.toml , option rpc.enable or by starting nano_rpc manually Binds to localhost by default for security reasons, configurable in config-rpc.toml , option rpc.address ; unicast Contents: Unencrypted HTTP requests containing JSON object bodies Allows the node to be queried or controlled through HTTP requests If blocked the node will not be able to be queried or controlled by HTTP WARNING: Exposing this port externally while setting enable_control option to true in configs could expose your wallet, allow the node to be stopped remotely and open your node up to other dangerous activity. See the Node Security page for more details. 7078 TCP Disabled Websocket server Port configurable in config-node.toml , option node.websocket.port Enable in config-node.toml , option node.websocket.enable Binds to localhost by default due to data throughput potentially being very high; producer-subscriber broadcast Contents: Standard websocket frames containing JSON-encoded objects See WebSocket Support for details on configuration 7075 UDP Disabled Deprecated (V21+) Previously this was the node activity port (deprecated in V21) Port configurable in config-node.toml , option node.peering_port Binds to all adapters; unicast Contents: Raw nano protocol datagrams All standard ledger activity goes through this port If blocked the node will not function UDP disabled by default, deprecated As of V21 peering and communicating via UDP has been disabled by default and is deprecated. The ability to use UDP will be removed from the node in a future release yet to be determined.","title":"Network Details"},{"location":"running-a-node/docker-management/","text":"Docker Management \u00b6 Docker greatly simplifies node management. Below we will go over some of the best practices for managing your Docker Image. Docker Limitations Although Docker is a great choice for many setups, there are some limitations to be aware of: It is not recommended to run a *nix container, such as the officially provided one, on a Windows host - there are known issues with handling ports which prevent proper communication with peers. V19 and lower: Due to the startup script built into the Docker containers, Launch Options for the nano_node service run inside the container cannot be easily used. These options are available as of V20. Nano Directory \u00b6 The Nano directory contains: wallets file ( wallets.ldb ), log files , optional config files, ledger file (data.ldb) and related lock files. Protect wallet and backup files The built-in node wallet is for use in development and testing only. Those using it should take care in protecting access to the wallets.ldb file and backup files, whether encrypted or not, for added security. For Docker setups, the ${NANO_HOST_DIR} indicated in the steps below will be the location of these files on your host machine. Managing the Container \u00b6 Starting \u00b6 The following command will start the node container. Either set the specified environment variables (i.e. NANO_NAME=nano_node ) or substitute in explicit values to the docker run command. ${NANO_NAME} - The name that you would like to assign to the docker container. ${NANO_TAG} - The version of docker image you will be running. For consumers, latest is acceptable, but for enterprise use, a manually set tag to the latest version number is recommended. ${NANO_HOST_DIR} - Location on the host computer where the ledger, configuration files, and logs will be stored. The Docker container will directly store files such as config-node.toml and data.ldb into this directory. docker run --restart = unless-stopped -d \\ -p 7075 :7075/udp \\ -p 7075 :7075 \\ -p [ ::1 ] :7076:7076 \\ -p [ ::1 ] :7078:7078 \\ -v ${ NANO_HOST_DIR } :/root \\ --name ${ NANO_NAME } \\ nanocurrency/nano: ${ NANO_TAG } Option Purpose -d Starts the docker container as a daemon -p 7075:7075/udp Maps the network activity port (deprecated since V21) -p 7075:7075 Maps the bootstrapping TCP port -v ${NANO_HOST_DIR}:/root Maps the host's Nano directory to the guest /root directory --restart=unless-stopped Restarts the container if it crashes nanocurrency/nano:${NANO_TAG} Specifies the container to execute with tag -p [::1]:7076:7076 or -p 127.0.0.1:7076:7076 Indicates that only RPC commands originating from the host will be accepted. WARNING: Without the proper IP configured here, anyone with access to your system's IP address can control your nano_node. -p [::1]:7078:7078 or -p 127.0.0.1:7078:7078 Indicates that only the host can create a connection to the websocket server . Data throughput can be very high depending on configuration, which could slow down the node if available outside the host. If you wish to use different ports, change the host ports in the docker run command; do not change the ports in the config-node.toml file. This will start the docker container using host ports 7075 and 7076 and put the data in a permanent location in your hosts's home directory, outside the docker container. Upon successful startup, Docker will return the container's full ID. A typical ID will look something like the value below. 0118ad5b48489303aa9d195f8a45ddc74a90e8a7209fc67d5483aabf3170d619 Note As of V21 peering and communicating via UDP has been disabled by default and is deprecated. The ability to use UDP will be removed from the node in a future release yet to be determined. For more information, see the network details . On port 7075, only TCP is required since V21. Warning If you are running multiple nano_node Docker containers, DO NOT share the same ${NANO_HOST_DIR} , each nano_node requires its own independent files. Stopping \u00b6 To stop your Nano Node: docker stop ${ NANO_NAME } Restarting \u00b6 If you need to restart your node for any reason: docker restart ${ NANO_NAME } Checking Status \u00b6 A list of currently running containers can be found by issuing the following command. docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 0118ad5b4848 nanocurrency/nano \"/bin/bash /entry.sh\" 41 seconds ago Up 56 seconds 0 .0.0.0:7075->7075/tcp, 0 .0.0.0:7075->7075/udp, 127 .0.0.1:7076->7076/tcp nano_node_1 Updating the Docker Image \u00b6 First, stop the container if it is running. docker stop ${ NANO_NAME } Then we can download the latest version with docker pull (or whichever version we need). Pull latest release of the Nano Node docker pull nanocurrency/nano Or pull the Nano Node tagged with \"V19.0\" from Dockerhub docker pull nanocurrency/nano:V19.0 Lastly, we start up the docker container again using the same command. Updating Node Configuration \u00b6 First, stop the container if it is running. docker stop ${ NANO_NAME } Warning Modifications made to configuration files while the Docker container is running have no effect until the container is restarted. You may now edit the configuration files located in ${NANO_HOST_DIR} using your preferred text editor. Once modifications are complete, start up the docker container again using the same command. Enable Voting When setting up a new node, voting is disabled by default in the configuration file and must be manually enabled in order to participate in consensus. See enable_voting configuration option for more details. Docker Compose \u00b6 A sample docker-compose.yml is provided to model the same behavior as the docker cli examples above version: '3' services: node: image: \"nanocurrency/nano:${NANO_TAG}\" # tag you wish to pull, none for latest restart: \"unless-stopped\" ports: - \"7075:7075/udp\" #udp network traffic (deprecated since V21) - \"7075:7075\" #tcp network traffic - \"[::1]:7076:7076\" #rpc to localhost only - \"[::1]:7078:7078\" #websocket to localhost only volumes: - \"${NANO_HOST_DIR}:/root\" #path to host directory Docker entrypoint support \u00b6 As of v20.0, the docker entry script has migrated to a command with default arguments: Usage: /entry.sh nano_node [[--]daemon] [cli_options] [-l] [-v size] [--]daemon start as daemon either cli [--daemon] form or short form [daemon] cli_options nano_node cli options <see nano_node --help> -l log to console <use docker logs {container}> -v<size> vacuum database if over size GB on startup /entry.sh bash [other] other bash pass through /entry.sh [*] * usage default: /entry.sh nano_node daemon -l Docker USER Support \u00b6 As of v20.0, the docker containers support the --user= and -w= flags. To maintain existing compatibility the Docker containers are being built with USER ROOT and WORK_DIR /root The problem with this is that the container ends up writing files to your mounted path as root. Best practices would dictate that since there is no need for privilege escalation we can create a user and run under that context instead. In the event you wish to use the --user=nanocurrency -w=/home/nanocurrency flags the directory you mount should have permissions changed for uid:guid 1000:1000 using sudo chown -R 1000:1000 <local_path> and your mount flag will become -v <local_path>:/home/nanocurrency This will be changed to default to USER nanocurrency and WORK_DIR /home/nanocurrency in a future release RPC calls to the node \u00b6 You can use the RPC interface on the local host via curl to interact with the node. For example the version of the node: curl -d '{ \"action\" : \"version\" }' [ ::1 ] :7076 Or the blockcount: curl -d '{ \"action\" : \"block_count\" }' [ ::1 ] :7076 In addition, you can make use of command-line JSON utilities such as jq to parse and manipulate the structured data retrieved from curl . For example the account information associated with certain block: curl -s -d '{ \"action\": \"blocks_info\", \"hashes\": [\"87434F8041869A01C8F6F263B87972D7BA443A72E0A97D7A3FD0CCC2358FD6F9\"], \"json_block\": \"true\" }' [ ::1 ] :7076 | jq \".blocks[].block_account\" For other commands, review the RPC Protocol details. Troubleshooting \u00b6 If you get Error starting userland proxy: port is not a proto:IP:port: 'tcp:[:'. or want to expose IPv4 port, use -p 127.0.0.1:7076:7076 . Likewise, if you get curl: (7) Couldn't connect to server when interacting with the node, replace [::1]:7076 with 127.0.0.1:7076 . If you get create ~: volume name is too short, names should be at least two alphanumeric characters. replace the ~ with the full pathname such as /Users/someuser .","title":"Docker Management"},{"location":"running-a-node/docker-management/#docker-management","text":"Docker greatly simplifies node management. Below we will go over some of the best practices for managing your Docker Image. Docker Limitations Although Docker is a great choice for many setups, there are some limitations to be aware of: It is not recommended to run a *nix container, such as the officially provided one, on a Windows host - there are known issues with handling ports which prevent proper communication with peers. V19 and lower: Due to the startup script built into the Docker containers, Launch Options for the nano_node service run inside the container cannot be easily used. These options are available as of V20.","title":"Docker Management"},{"location":"running-a-node/docker-management/#nano-directory","text":"The Nano directory contains: wallets file ( wallets.ldb ), log files , optional config files, ledger file (data.ldb) and related lock files. Protect wallet and backup files The built-in node wallet is for use in development and testing only. Those using it should take care in protecting access to the wallets.ldb file and backup files, whether encrypted or not, for added security. For Docker setups, the ${NANO_HOST_DIR} indicated in the steps below will be the location of these files on your host machine.","title":"Nano Directory"},{"location":"running-a-node/docker-management/#managing-the-container","text":"","title":"Managing the Container"},{"location":"running-a-node/docker-management/#starting","text":"The following command will start the node container. Either set the specified environment variables (i.e. NANO_NAME=nano_node ) or substitute in explicit values to the docker run command. ${NANO_NAME} - The name that you would like to assign to the docker container. ${NANO_TAG} - The version of docker image you will be running. For consumers, latest is acceptable, but for enterprise use, a manually set tag to the latest version number is recommended. ${NANO_HOST_DIR} - Location on the host computer where the ledger, configuration files, and logs will be stored. The Docker container will directly store files such as config-node.toml and data.ldb into this directory. docker run --restart = unless-stopped -d \\ -p 7075 :7075/udp \\ -p 7075 :7075 \\ -p [ ::1 ] :7076:7076 \\ -p [ ::1 ] :7078:7078 \\ -v ${ NANO_HOST_DIR } :/root \\ --name ${ NANO_NAME } \\ nanocurrency/nano: ${ NANO_TAG } Option Purpose -d Starts the docker container as a daemon -p 7075:7075/udp Maps the network activity port (deprecated since V21) -p 7075:7075 Maps the bootstrapping TCP port -v ${NANO_HOST_DIR}:/root Maps the host's Nano directory to the guest /root directory --restart=unless-stopped Restarts the container if it crashes nanocurrency/nano:${NANO_TAG} Specifies the container to execute with tag -p [::1]:7076:7076 or -p 127.0.0.1:7076:7076 Indicates that only RPC commands originating from the host will be accepted. WARNING: Without the proper IP configured here, anyone with access to your system's IP address can control your nano_node. -p [::1]:7078:7078 or -p 127.0.0.1:7078:7078 Indicates that only the host can create a connection to the websocket server . Data throughput can be very high depending on configuration, which could slow down the node if available outside the host. If you wish to use different ports, change the host ports in the docker run command; do not change the ports in the config-node.toml file. This will start the docker container using host ports 7075 and 7076 and put the data in a permanent location in your hosts's home directory, outside the docker container. Upon successful startup, Docker will return the container's full ID. A typical ID will look something like the value below. 0118ad5b48489303aa9d195f8a45ddc74a90e8a7209fc67d5483aabf3170d619 Note As of V21 peering and communicating via UDP has been disabled by default and is deprecated. The ability to use UDP will be removed from the node in a future release yet to be determined. For more information, see the network details . On port 7075, only TCP is required since V21. Warning If you are running multiple nano_node Docker containers, DO NOT share the same ${NANO_HOST_DIR} , each nano_node requires its own independent files.","title":"Starting"},{"location":"running-a-node/docker-management/#stopping","text":"To stop your Nano Node: docker stop ${ NANO_NAME }","title":"Stopping"},{"location":"running-a-node/docker-management/#restarting","text":"If you need to restart your node for any reason: docker restart ${ NANO_NAME }","title":"Restarting"},{"location":"running-a-node/docker-management/#checking-status","text":"A list of currently running containers can be found by issuing the following command. docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 0118ad5b4848 nanocurrency/nano \"/bin/bash /entry.sh\" 41 seconds ago Up 56 seconds 0 .0.0.0:7075->7075/tcp, 0 .0.0.0:7075->7075/udp, 127 .0.0.1:7076->7076/tcp nano_node_1","title":"Checking Status"},{"location":"running-a-node/docker-management/#updating-the-docker-image","text":"First, stop the container if it is running. docker stop ${ NANO_NAME } Then we can download the latest version with docker pull (or whichever version we need). Pull latest release of the Nano Node docker pull nanocurrency/nano Or pull the Nano Node tagged with \"V19.0\" from Dockerhub docker pull nanocurrency/nano:V19.0 Lastly, we start up the docker container again using the same command.","title":"Updating the Docker Image"},{"location":"running-a-node/docker-management/#updating-node-configuration","text":"First, stop the container if it is running. docker stop ${ NANO_NAME } Warning Modifications made to configuration files while the Docker container is running have no effect until the container is restarted. You may now edit the configuration files located in ${NANO_HOST_DIR} using your preferred text editor. Once modifications are complete, start up the docker container again using the same command. Enable Voting When setting up a new node, voting is disabled by default in the configuration file and must be manually enabled in order to participate in consensus. See enable_voting configuration option for more details.","title":"Updating Node Configuration"},{"location":"running-a-node/docker-management/#docker-compose","text":"A sample docker-compose.yml is provided to model the same behavior as the docker cli examples above version: '3' services: node: image: \"nanocurrency/nano:${NANO_TAG}\" # tag you wish to pull, none for latest restart: \"unless-stopped\" ports: - \"7075:7075/udp\" #udp network traffic (deprecated since V21) - \"7075:7075\" #tcp network traffic - \"[::1]:7076:7076\" #rpc to localhost only - \"[::1]:7078:7078\" #websocket to localhost only volumes: - \"${NANO_HOST_DIR}:/root\" #path to host directory","title":"Docker Compose"},{"location":"running-a-node/docker-management/#docker-entrypoint-support","text":"As of v20.0, the docker entry script has migrated to a command with default arguments: Usage: /entry.sh nano_node [[--]daemon] [cli_options] [-l] [-v size] [--]daemon start as daemon either cli [--daemon] form or short form [daemon] cli_options nano_node cli options <see nano_node --help> -l log to console <use docker logs {container}> -v<size> vacuum database if over size GB on startup /entry.sh bash [other] other bash pass through /entry.sh [*] * usage default: /entry.sh nano_node daemon -l","title":"Docker entrypoint support"},{"location":"running-a-node/docker-management/#docker-user-support","text":"As of v20.0, the docker containers support the --user= and -w= flags. To maintain existing compatibility the Docker containers are being built with USER ROOT and WORK_DIR /root The problem with this is that the container ends up writing files to your mounted path as root. Best practices would dictate that since there is no need for privilege escalation we can create a user and run under that context instead. In the event you wish to use the --user=nanocurrency -w=/home/nanocurrency flags the directory you mount should have permissions changed for uid:guid 1000:1000 using sudo chown -R 1000:1000 <local_path> and your mount flag will become -v <local_path>:/home/nanocurrency This will be changed to default to USER nanocurrency and WORK_DIR /home/nanocurrency in a future release","title":"Docker USER Support"},{"location":"running-a-node/docker-management/#rpc-calls-to-the-node","text":"You can use the RPC interface on the local host via curl to interact with the node. For example the version of the node: curl -d '{ \"action\" : \"version\" }' [ ::1 ] :7076 Or the blockcount: curl -d '{ \"action\" : \"block_count\" }' [ ::1 ] :7076 In addition, you can make use of command-line JSON utilities such as jq to parse and manipulate the structured data retrieved from curl . For example the account information associated with certain block: curl -s -d '{ \"action\": \"blocks_info\", \"hashes\": [\"87434F8041869A01C8F6F263B87972D7BA443A72E0A97D7A3FD0CCC2358FD6F9\"], \"json_block\": \"true\" }' [ ::1 ] :7076 | jq \".blocks[].block_account\" For other commands, review the RPC Protocol details.","title":"RPC calls to the node"},{"location":"running-a-node/docker-management/#troubleshooting","text":"If you get Error starting userland proxy: port is not a proto:IP:port: 'tcp:[:'. or want to expose IPv4 port, use -p 127.0.0.1:7076:7076 . Likewise, if you get curl: (7) Couldn't connect to server when interacting with the node, replace [::1]:7076 with 127.0.0.1:7076 . If you get create ~: volume name is too short, names should be at least two alphanumeric characters. replace the ~ with the full pathname such as /Users/someuser .","title":"Troubleshooting"},{"location":"running-a-node/ledger-management/","text":"Ledger Management \u00b6 Default and experimental backends available By default the node uses LMDB as the ledger backend, which the first part of this guide is focused on. The second part of the guide covers RocksDB , which is an experimental option available as of v20.0+ . Ledger file \u00b6 The node automatically manages the full Nano ledger in the data.ldb file which can be found in the data directory at these locations: OS Location Windows C: \\U sers \\< user> \\A ppData \\L ocal \\N ano \\ macOS /Users/<user>/Library/Nano/ Linux /home/<user>/Nano/ This file will grow in size as the ledger does. As of September 2020 there are over 56 million blocks in the ledger which requires at least 29GB of free space. See hardware recommendations for more preferred node specs. RocksDB uses many files The above details are for the default LMDB database setup. If using RocksDB, please note that it uses potentially 100s of SST files to manage the ledger so details should be followed from the RocksDB Ledger Backend section below. Updating the node may require a lengthy ledger upgrade Read the guide further down this page for some tips on how to minimize downtime during an update. Configuration \u00b6 Available in Version 21.0+ only Within the node.lmdb section of the config-node.toml file, the following options can be set to better tune LMDB performance for the available resources. Option name Details map_size Allows the map size to be changed (default value is 128GB). This only affects the ledger database. max_databases Maximum open LMDB databases. Increase default if more than 100 wallets is required. External management is recommended when a large amounts of wallets are required. sync LMDB environment flags. Applies to ledger, not wallet: always : Default (MDB_NOSUBDIR | MDB_NOTLS | MDB_NORDAHEAD). nosync_safe : Do not flush meta data eagerly. This may cause loss of transactions, but maintains integrity (MDB_NOSUBDIR | MDB_NOTLS | MDB_NORDAHEAD | MDB_NOMETASYNC). nosync_unsafe : Let the OS decide when to flush to disk. On filesystems with write ordering, this has the same guarantees as nosync_safe, otherwise corruption may occur on system crash (MDB_NOSUBDIR | MDB_NOTLS | MDB_NORDAHEAD | MDB_NOSYNC). nosync_unsafe_large_memory : Use a writeable memory map. Let the OS decide when to flush to disk, and make the request asynchronous. This may give better performance on systems where the database fits entirely in memory, otherwise it may be slower. Note that this option will expand the file size logically to map_size. It may expand the file physically on some file systems. (MDB_NOSUBDIR | MDB_NOTLS | MDB_NORDAHEAD | MDB_NOSYNC | MDB_WRITEMAP | MDB_MAPASYNC). Bootstrapping \u00b6 When starting a new node the ledger must be downloaded and kept updated in order to participate on the network properly. This is done automatically via bootstrapping - the node downloads and verifies blocks from other nodes across the network. This process can take hours to days to complete depending on network conditions and hardware specifications . Restarting node during bootstrapping not recommended It is highly recommended to avoid restarting the node during bootstrapping as this can cause extra delays in the syncing process. An exception can be made when it is very clear from calls to the block_count RPC that block counts are stuck for multiple hours. Tuning options \u00b6 Depending on machine and networking resources, the bootstrap performance can be improved by updating the following configuration values in the config-node.toml file: node.bootstrap_connections_max : up to max of 128 node.bootstrap_connections : up to max of 16 node.bootstrap_initiator_threads : set to 2 The additional resource usage these options cause should be considered, especially if left during normal operation (after initial bootstrap is complete). Downloaded ledger files \u00b6 Always backup your ledgers file Whenever you are attempting to change the ledger, it is highly recommended you create backups of the existing data.ldb file to ensure you have a rollback point if issues are encountered. To avoid bootstrapping times, a ledger file ( data.ldb ) can be downloaded off-network and added to the data file used by the node. This process is sometimes referred to as a \"fast sync\". The Nano Foundation provides a daily ledger file download in the #ledger channel of our Discord server . This is posted by the robot Nano Snapshots Uploader and contains checksums for validation. Alternatively, one of My Nano Ninja APIs redirects the current ledger file preserved at Yandex : wget -O ledger.7z https://mynano.ninja/api/ledger/download -q --show-progress Verify the checksum of the above downloaded ledger file: printf \"%s ledger.7z\" ` wget -q -O - https://mynano.ninja/api/ledger/checksum/sha256 ` | sha256sum --check Be patient and wait for the message ledger.7z: OK . Before using this method there are a few considerations to ensure it is done safely: Data source \u00b6 Make sure you trust the source providing the data to you. If you are unfamiliar with the individual or organization providing the ledger, consider other options for the data or fallback to the default of bootstrapping from the network. Validating blocks and voting weights \u00b6 Blocks are confirmed using the voting weight of representatives and these weights are determined by the account balances assigned to those representatives. In addition, the node releases contain a hard-coded set of representative weights captured at the time of the node release to help this process during bootstrapping. If looking to use a downloaded ledger there is a risk of it providing inaccurate representative voting weights. Although the potential impacts of this are minimal, below are some recommended steps to take which can help provide additional confidence the ledger can be used. Scan the ledger for integrity using the --debug_validate_blocks CLI command . If issues are found they should be inspected carefully and alternative sources of a ledger may need to be considered as failures with this command have a high chance of indicating potentially malicious behavior. Review the differences in representative voting weights by running the --compare_rep_weights CLI command ( v21.0+ only) with the new ledger in the default data directory (old ledger backed up) or in a different data directory by using the optional --data_path argument. This will compare the new ledger voting weights against the hardcoded values in the node (set at the time of release). See the CLI command for details on the output with special attention paid to entries in the outliers and newcomers sections. By inspecting those addresses in public explorers such as Nanocrawler.cc , this can help to determine if voting weight may have been manipulated in the downloaded ledger. If you need support with this process or need help in evaluating some of the CLI command results, join the Node and Representative Management category on the Nano Forums . Confirmation data \u00b6 Within each account on the ledger a confirmation height is set. This indicates the height of the last block on that chain where quorum was observed on the network. This is set locally by the node and a new ledger file may include this information with it. If the ledger is from a trusted source this confirmation data can be kept, which will save bandwidth and resources on the network by not querying for votes to verify these confirmations. If confirmation data for the ledger is not trusted the --confirmation_height_clear CLI can be used to clear these out. Updating the node \u00b6 Occasionally, updating to the latest node version requires upgrading the existing ledger which can have the following effects: Significant downtime, from a few minutes to several hours, during which the node RPC is not accessible and no voting occurs. The upgrade is especially slower if the ledger is not on an SSD. Temporary increased disk space usage - up to 3x the current ledger size in total (e.g. 60GB for a 20GB ledger) In order to minimize downtime, consider performing the update in a different machine, and replacing the ledger file once complete. Note the following instructions, where Machine A has the node and ledger, and Machine B will be updating it. Create a directory /home/<user>/Nano_Update on Machine B. Stop the node on Machine A. If enough free space (at least data.ldb size) is available on Machine A: Make a local copy of data.ldb in any directory. Start the node again on Machine A, resuming operation. Move the local copy of the ledger from Machine A to /home/<user>/Nano_Update/data.ldb on Machine B. Skip the next step. If there is not enough free space on Machine A: Copy data.ldb from Machine A to /home/<user>/Nano_Update/data.ldb on Machine B. Start the node again on Machine A, resuming operation. Download the latest node version to Machine B. For the purposes of this guide, using a binary is easier. Run the following command on Machine B (varies based on your operating system): ./nano_node --debug_block_count --data_path /home/<user>/Nano_Update --config node.logging.log_to_cerr=true The message \"Upgrade in progress...\" will be displayed if a ledger upgrade is required. Wait until the command finishes and do not stop the upgrade preemptively . Copy /home/<user>/Nano_Update/data.ldb from Machine B to a temporary location on Machine A. do not overwrite data.ldb on Machine A while the node is running . Stop the node on Machine A. Replace /home/<user>/Nano/data.ldb with the transferred file. Upgrade to the latest node version on Machine A as you would do normally. In the event that you are unable to upgrade the ledger on another machine but would still like to minimize downtime, consider obtaining the ledger from another source as a last resource. RocksDB Ledger Backend \u00b6 RocksDB is experimental, do not use in production RocksDB is being included in V20.0 as experimental only. Future versions of the node may allow for production use of RocksDB, however old experimental RocksDB ledgers are not guarenteed to be compatible and may require resyncing from scratch. If you are testing RocksDB and want to discuss results, configurations, etc. please join the forum topic here: https://forum.nano.org/t/rocksdb-ledger-backend-testing/111 The node ledger currently uses LMDB (Lightning memory-mapped database) by default as the data store. As of v20+ the option to use RocksDB becomes available as an experimental option. This document will not go into much detail about theses key-value data stores as there is a lot of information available online. It is anticipated that bootstrapping will be slower using RocksDB during the initial version at least, but live traffic should be faster due to singluar writes being cached in memory and flushed to disk in bulk. Using RocksDB requires a few extra steps as it is an externally required dependency which requires a recent version of RocksDB, so older repositories may not be sufficient, it also requires zlib . If using the docker node, skip to Enable RocksDB . Installation \u00b6 Linux Ubuntu 19.04 and later: sudo apt-get install zlib1g-dev sudo apt-get install librocksdb-dev Otherwise: sudo apt-get install zlib1g-dev export USE_RTTI=1 git clone https://github.com/facebook/rocksdb.git cd rocksdb make static_lib make install MacOS brew install rocksdb Windows Recommended way is to use vcpkg : add set (VCPKG_LIBRARY_LINKAGE static) to the top of %VCPKG_DIR%\\ports\\rocksdb\\portfile.cmake vcpkg install rocksdb:x64-windows For other or more detailed instructions visit the official page: https://github.com/facebook/rocksdb/blob/master/INSTALL.md Build node with RocksDB support \u00b6 Once RocksDB is installed successfully, the node must be built with RocksDB support using the CMake variable -DNANO_ROCKSDB=ON The following CMake options can be used to specify where the RocksDB and zlib libraries are if they cannot be found automatically: ROCKSDB_INCLUDE_DIRS ROCKSDB_LIBRARIES ZLIB_LIBRARY ZLIB_INCLUDE_DIR Enable RocksDB \u00b6 This can be enabled by adding the following to the config-node.toml file: [node.rocksdb] enable = true There are many other options which can be set. Due to RocksDB generally using more memory the defaults have been made pessimistic in order to run on a wider range of lower end devices. Recommended settings if on a system with 8GB or more RAM (see TOML comments in the generated file for more information on what these do): [node.rocksdb] bloom_filter_bits = 10 block_cache = 1024 enable_pipelined_write=true cache_index_and_filter_blocks=true block_size=64 memtable_size=128 num_memtables=3 total_memtable_size=0 Comparision: LMDB RocksDB Tested with the node for many years Experimental status 1 file (data.ldb) 100+ SST files *15GB live ledger size Smaller file size (11GB) Not many options to configure Very configurable Unlikely to be further optimized Many optimizations possible in future Part of the node build process Required external dep (incl recent version 5.13+) - Less file I/O (writes are flushed in bulk) - May use more memory * At the time of writing (Oct 2019) RocksDB Limitations: Automatic backups not currently supported Database transaction tracker is not supported Cannot execute CLI commands which require writing to the database, such as nano_node --peer_clear these must be executed when the node is stopped Snapshotting with RocksDB When backing up using the --snapshot CLI option, it is currently set up to do incremental backups, which reduces the need to copy the whole database. However if the original files are deleted, then the backup directory should also be deleted otherwise there can be inconsistencies.","title":"Ledger Management"},{"location":"running-a-node/ledger-management/#ledger-management","text":"Default and experimental backends available By default the node uses LMDB as the ledger backend, which the first part of this guide is focused on. The second part of the guide covers RocksDB , which is an experimental option available as of v20.0+ .","title":"Ledger Management"},{"location":"running-a-node/ledger-management/#ledger-file","text":"The node automatically manages the full Nano ledger in the data.ldb file which can be found in the data directory at these locations: OS Location Windows C: \\U sers \\< user> \\A ppData \\L ocal \\N ano \\ macOS /Users/<user>/Library/Nano/ Linux /home/<user>/Nano/ This file will grow in size as the ledger does. As of September 2020 there are over 56 million blocks in the ledger which requires at least 29GB of free space. See hardware recommendations for more preferred node specs. RocksDB uses many files The above details are for the default LMDB database setup. If using RocksDB, please note that it uses potentially 100s of SST files to manage the ledger so details should be followed from the RocksDB Ledger Backend section below. Updating the node may require a lengthy ledger upgrade Read the guide further down this page for some tips on how to minimize downtime during an update.","title":"Ledger file"},{"location":"running-a-node/ledger-management/#configuration","text":"Available in Version 21.0+ only Within the node.lmdb section of the config-node.toml file, the following options can be set to better tune LMDB performance for the available resources. Option name Details map_size Allows the map size to be changed (default value is 128GB). This only affects the ledger database. max_databases Maximum open LMDB databases. Increase default if more than 100 wallets is required. External management is recommended when a large amounts of wallets are required. sync LMDB environment flags. Applies to ledger, not wallet: always : Default (MDB_NOSUBDIR | MDB_NOTLS | MDB_NORDAHEAD). nosync_safe : Do not flush meta data eagerly. This may cause loss of transactions, but maintains integrity (MDB_NOSUBDIR | MDB_NOTLS | MDB_NORDAHEAD | MDB_NOMETASYNC). nosync_unsafe : Let the OS decide when to flush to disk. On filesystems with write ordering, this has the same guarantees as nosync_safe, otherwise corruption may occur on system crash (MDB_NOSUBDIR | MDB_NOTLS | MDB_NORDAHEAD | MDB_NOSYNC). nosync_unsafe_large_memory : Use a writeable memory map. Let the OS decide when to flush to disk, and make the request asynchronous. This may give better performance on systems where the database fits entirely in memory, otherwise it may be slower. Note that this option will expand the file size logically to map_size. It may expand the file physically on some file systems. (MDB_NOSUBDIR | MDB_NOTLS | MDB_NORDAHEAD | MDB_NOSYNC | MDB_WRITEMAP | MDB_MAPASYNC).","title":"Configuration"},{"location":"running-a-node/ledger-management/#bootstrapping","text":"When starting a new node the ledger must be downloaded and kept updated in order to participate on the network properly. This is done automatically via bootstrapping - the node downloads and verifies blocks from other nodes across the network. This process can take hours to days to complete depending on network conditions and hardware specifications . Restarting node during bootstrapping not recommended It is highly recommended to avoid restarting the node during bootstrapping as this can cause extra delays in the syncing process. An exception can be made when it is very clear from calls to the block_count RPC that block counts are stuck for multiple hours.","title":"Bootstrapping"},{"location":"running-a-node/ledger-management/#tuning-options","text":"Depending on machine and networking resources, the bootstrap performance can be improved by updating the following configuration values in the config-node.toml file: node.bootstrap_connections_max : up to max of 128 node.bootstrap_connections : up to max of 16 node.bootstrap_initiator_threads : set to 2 The additional resource usage these options cause should be considered, especially if left during normal operation (after initial bootstrap is complete).","title":"Tuning options"},{"location":"running-a-node/ledger-management/#downloaded-ledger-files","text":"Always backup your ledgers file Whenever you are attempting to change the ledger, it is highly recommended you create backups of the existing data.ldb file to ensure you have a rollback point if issues are encountered. To avoid bootstrapping times, a ledger file ( data.ldb ) can be downloaded off-network and added to the data file used by the node. This process is sometimes referred to as a \"fast sync\". The Nano Foundation provides a daily ledger file download in the #ledger channel of our Discord server . This is posted by the robot Nano Snapshots Uploader and contains checksums for validation. Alternatively, one of My Nano Ninja APIs redirects the current ledger file preserved at Yandex : wget -O ledger.7z https://mynano.ninja/api/ledger/download -q --show-progress Verify the checksum of the above downloaded ledger file: printf \"%s ledger.7z\" ` wget -q -O - https://mynano.ninja/api/ledger/checksum/sha256 ` | sha256sum --check Be patient and wait for the message ledger.7z: OK . Before using this method there are a few considerations to ensure it is done safely:","title":"Downloaded ledger files"},{"location":"running-a-node/ledger-management/#data-source","text":"Make sure you trust the source providing the data to you. If you are unfamiliar with the individual or organization providing the ledger, consider other options for the data or fallback to the default of bootstrapping from the network.","title":"Data source"},{"location":"running-a-node/ledger-management/#validating-blocks-and-voting-weights","text":"Blocks are confirmed using the voting weight of representatives and these weights are determined by the account balances assigned to those representatives. In addition, the node releases contain a hard-coded set of representative weights captured at the time of the node release to help this process during bootstrapping. If looking to use a downloaded ledger there is a risk of it providing inaccurate representative voting weights. Although the potential impacts of this are minimal, below are some recommended steps to take which can help provide additional confidence the ledger can be used. Scan the ledger for integrity using the --debug_validate_blocks CLI command . If issues are found they should be inspected carefully and alternative sources of a ledger may need to be considered as failures with this command have a high chance of indicating potentially malicious behavior. Review the differences in representative voting weights by running the --compare_rep_weights CLI command ( v21.0+ only) with the new ledger in the default data directory (old ledger backed up) or in a different data directory by using the optional --data_path argument. This will compare the new ledger voting weights against the hardcoded values in the node (set at the time of release). See the CLI command for details on the output with special attention paid to entries in the outliers and newcomers sections. By inspecting those addresses in public explorers such as Nanocrawler.cc , this can help to determine if voting weight may have been manipulated in the downloaded ledger. If you need support with this process or need help in evaluating some of the CLI command results, join the Node and Representative Management category on the Nano Forums .","title":"Validating blocks and voting weights"},{"location":"running-a-node/ledger-management/#confirmation-data","text":"Within each account on the ledger a confirmation height is set. This indicates the height of the last block on that chain where quorum was observed on the network. This is set locally by the node and a new ledger file may include this information with it. If the ledger is from a trusted source this confirmation data can be kept, which will save bandwidth and resources on the network by not querying for votes to verify these confirmations. If confirmation data for the ledger is not trusted the --confirmation_height_clear CLI can be used to clear these out.","title":"Confirmation data"},{"location":"running-a-node/ledger-management/#updating-the-node","text":"Occasionally, updating to the latest node version requires upgrading the existing ledger which can have the following effects: Significant downtime, from a few minutes to several hours, during which the node RPC is not accessible and no voting occurs. The upgrade is especially slower if the ledger is not on an SSD. Temporary increased disk space usage - up to 3x the current ledger size in total (e.g. 60GB for a 20GB ledger) In order to minimize downtime, consider performing the update in a different machine, and replacing the ledger file once complete. Note the following instructions, where Machine A has the node and ledger, and Machine B will be updating it. Create a directory /home/<user>/Nano_Update on Machine B. Stop the node on Machine A. If enough free space (at least data.ldb size) is available on Machine A: Make a local copy of data.ldb in any directory. Start the node again on Machine A, resuming operation. Move the local copy of the ledger from Machine A to /home/<user>/Nano_Update/data.ldb on Machine B. Skip the next step. If there is not enough free space on Machine A: Copy data.ldb from Machine A to /home/<user>/Nano_Update/data.ldb on Machine B. Start the node again on Machine A, resuming operation. Download the latest node version to Machine B. For the purposes of this guide, using a binary is easier. Run the following command on Machine B (varies based on your operating system): ./nano_node --debug_block_count --data_path /home/<user>/Nano_Update --config node.logging.log_to_cerr=true The message \"Upgrade in progress...\" will be displayed if a ledger upgrade is required. Wait until the command finishes and do not stop the upgrade preemptively . Copy /home/<user>/Nano_Update/data.ldb from Machine B to a temporary location on Machine A. do not overwrite data.ldb on Machine A while the node is running . Stop the node on Machine A. Replace /home/<user>/Nano/data.ldb with the transferred file. Upgrade to the latest node version on Machine A as you would do normally. In the event that you are unable to upgrade the ledger on another machine but would still like to minimize downtime, consider obtaining the ledger from another source as a last resource.","title":"Updating the node"},{"location":"running-a-node/ledger-management/#rocksdb-ledger-backend","text":"RocksDB is experimental, do not use in production RocksDB is being included in V20.0 as experimental only. Future versions of the node may allow for production use of RocksDB, however old experimental RocksDB ledgers are not guarenteed to be compatible and may require resyncing from scratch. If you are testing RocksDB and want to discuss results, configurations, etc. please join the forum topic here: https://forum.nano.org/t/rocksdb-ledger-backend-testing/111 The node ledger currently uses LMDB (Lightning memory-mapped database) by default as the data store. As of v20+ the option to use RocksDB becomes available as an experimental option. This document will not go into much detail about theses key-value data stores as there is a lot of information available online. It is anticipated that bootstrapping will be slower using RocksDB during the initial version at least, but live traffic should be faster due to singluar writes being cached in memory and flushed to disk in bulk. Using RocksDB requires a few extra steps as it is an externally required dependency which requires a recent version of RocksDB, so older repositories may not be sufficient, it also requires zlib . If using the docker node, skip to Enable RocksDB .","title":"RocksDB Ledger Backend"},{"location":"running-a-node/ledger-management/#installation","text":"Linux Ubuntu 19.04 and later: sudo apt-get install zlib1g-dev sudo apt-get install librocksdb-dev Otherwise: sudo apt-get install zlib1g-dev export USE_RTTI=1 git clone https://github.com/facebook/rocksdb.git cd rocksdb make static_lib make install MacOS brew install rocksdb Windows Recommended way is to use vcpkg : add set (VCPKG_LIBRARY_LINKAGE static) to the top of %VCPKG_DIR%\\ports\\rocksdb\\portfile.cmake vcpkg install rocksdb:x64-windows For other or more detailed instructions visit the official page: https://github.com/facebook/rocksdb/blob/master/INSTALL.md","title":"Installation"},{"location":"running-a-node/ledger-management/#build-node-with-rocksdb-support","text":"Once RocksDB is installed successfully, the node must be built with RocksDB support using the CMake variable -DNANO_ROCKSDB=ON The following CMake options can be used to specify where the RocksDB and zlib libraries are if they cannot be found automatically: ROCKSDB_INCLUDE_DIRS ROCKSDB_LIBRARIES ZLIB_LIBRARY ZLIB_INCLUDE_DIR","title":"Build node with RocksDB support"},{"location":"running-a-node/ledger-management/#enable-rocksdb","text":"This can be enabled by adding the following to the config-node.toml file: [node.rocksdb] enable = true There are many other options which can be set. Due to RocksDB generally using more memory the defaults have been made pessimistic in order to run on a wider range of lower end devices. Recommended settings if on a system with 8GB or more RAM (see TOML comments in the generated file for more information on what these do): [node.rocksdb] bloom_filter_bits = 10 block_cache = 1024 enable_pipelined_write=true cache_index_and_filter_blocks=true block_size=64 memtable_size=128 num_memtables=3 total_memtable_size=0 Comparision: LMDB RocksDB Tested with the node for many years Experimental status 1 file (data.ldb) 100+ SST files *15GB live ledger size Smaller file size (11GB) Not many options to configure Very configurable Unlikely to be further optimized Many optimizations possible in future Part of the node build process Required external dep (incl recent version 5.13+) - Less file I/O (writes are flushed in bulk) - May use more memory * At the time of writing (Oct 2019) RocksDB Limitations: Automatic backups not currently supported Database transaction tracker is not supported Cannot execute CLI commands which require writing to the database, such as nano_node --peer_clear these must be executed when the node is stopped Snapshotting with RocksDB When backing up using the --snapshot CLI option, it is currently set up to do incremental backups, which reduces the need to copy the whole database. However if the original files are deleted, then the backup directory should also be deleted otherwise there can be inconsistencies.","title":"Enable RocksDB"},{"location":"running-a-node/node-setup/","text":"Node Setup \u00b6 While you can run a Nano node by downloading a binary or building from source, it is recommended to use a Docker container. When using the official Docker images , your node will be much easier to upgrade and maintain. Docker Limitations Although Docker is a great choice for many setups, there are some limitations to be aware of: It is not recommended to run a *nix container, such as the officially provided one, on a Windows host - there are known issues with handling ports which prevent proper communication with peers. V19 and lower: Due to the startup script built into the Docker containers, Launch Options for the nano_node service run inside the container cannot be easily used. These options are available as of V20. Setup Assumptions The guides found on this site make some basic assumptions that should be understood before continuing: You have a basic understanding of Docker. You are using Nano's official Docker images to manage your node. If you decide to use a different method, you will need to be able to fill in the gaps when following along. Beta Network Setup The details below are focused on running a node on the main network. The beta network is also available for testing and is a great place to learn about node management. Beta nodes also help improve our network, so please consider running one! See the Beta Network page for details on how to setup a node on this test network. Hardware recommendations \u00b6 Principal Representative Nodes \u00b6 The following are minimum recommended specifications for nodes with more than 0.1% of the online voting weight ( Principal Representatives ): 4GB RAM Quad-Core CPU 200 Mbps bandwidth (2TB or more of available monthly bandwidth) SSD-based hard drive with 80GB+ of free space Non-voting and Representative Nodes \u00b6 The following are minimum recommended specifications for non-voting nodes and Represntative nodes with less than 0.1% of the online voting weight (regular Representatives ): 2GB RAM (additional RAM or swap space may be needed if bootstrapping a new node from scratch) Dual-Core CPU 100 Mbps bandwidth (2TB or more of available monthly bandwidth) SSD-based hard drive with 80GB+ of free space Varied resource usage Various factors affect resource usage including how often RPC calls are made, other applications running on the machine, etc. These recommendations should be evaluated along with other considerations. Work Generation guide For nodes being used with services requiring regular or high volume sending and receiving of transactions, special considerations must be made for handling Proof-of-Work generation activities. Find details on configuring a GPU, external work services and more for the perfect setup in the Work Generation guide . Network Ports \u00b6 The nano_node will use two configurable ports throughout its lifecycle. The default values suggested by the network details are below: Network Ports Overview 7075 TCP: For live network activity (since V19.0) and bootstrap network activity 7076 TCP: For communication with RPC server. Do not expose this outside of your production environment. Anyone with access to this port can control your node's RPC. 7078 TCP: For communication with websocket server . Depending on configuration, data throughput can be very high. 7075 UDP: For live network activity (fallback since V19.0, deprecated and disabled V21+) UDP disabled by default, deprecated As of V21 peering and communicating via UDP has been disabled by default and is deprecated. The ability to use UDP will be removed from the node in a future release yet to be determined. By default nano_node will attempt to use UPnP. Troubleshooting information can be found here Installing Docker \u00b6 Docker must be installed on the host machine and instructions can be found here: https://docs.docker.com/install/ . We recommend installing the latest stable version available. Pulling the Docker Image \u00b6 The Docker image can be downloaded via docker pull . We can either grab the latest or a specific version/tag. Not specifying a tag defaults to latest . An example of each is found below. Pulls the latest release of the Nano Node: docker pull nanocurrency/nano Pulls a specific version of the Nano node: docker pull nanocurrency/nano:V20.0 Tip If you are running in an enterprise environment, it is recommended that you explicitly specify the latest stable version to ensure deterministic containers. A list of tags can be found at the official Nano Currency Docker Hub . Warning - Multiple Node Setups Never use the same seed on multiple running nano_node instances at the same time. Multiple nano_nodes using the same seed can result in network race conditions that degrade performance for your personal accounts. In addition, Publishing transactions from two nodes with the same account at the same time may cause an account fork which requires a slower representative voting process. Similarly, if you are running a representative account on multiple nodes, they may publish conflicting votes, causing your representative to be ignored by the network. Performance degradation in enterprise environments may be significant. Starting the Node \u00b6 With Docker there are basic commands for managing containers. To properly bring the node up, learn these commands beginning with starting the container . Advanced Builds For additional options around building the node to run on various platforms, head over to the Integration Guides Build Options . Additional setup \u00b6 The above instructions cover getting a node up and running with the default configuration settings. Additional setup areas to explore include: Learning more about managing the node in a Docker container Updating node configuration options to enable various features Setting up the node to vote as a representative Finding out how to best manage your ledger file Join our Technical Update Mailing List Follow this link to sign up for email updates on the latest protocol/node releases and other technical details. This will include network upgrades such as the upcoming epoch distribution: http://eepurl.com/gZucL1","title":"Node Setup"},{"location":"running-a-node/node-setup/#node-setup","text":"While you can run a Nano node by downloading a binary or building from source, it is recommended to use a Docker container. When using the official Docker images , your node will be much easier to upgrade and maintain. Docker Limitations Although Docker is a great choice for many setups, there are some limitations to be aware of: It is not recommended to run a *nix container, such as the officially provided one, on a Windows host - there are known issues with handling ports which prevent proper communication with peers. V19 and lower: Due to the startup script built into the Docker containers, Launch Options for the nano_node service run inside the container cannot be easily used. These options are available as of V20. Setup Assumptions The guides found on this site make some basic assumptions that should be understood before continuing: You have a basic understanding of Docker. You are using Nano's official Docker images to manage your node. If you decide to use a different method, you will need to be able to fill in the gaps when following along. Beta Network Setup The details below are focused on running a node on the main network. The beta network is also available for testing and is a great place to learn about node management. Beta nodes also help improve our network, so please consider running one! See the Beta Network page for details on how to setup a node on this test network.","title":"Node Setup"},{"location":"running-a-node/node-setup/#hardware-recommendations","text":"","title":"Hardware recommendations"},{"location":"running-a-node/node-setup/#principal-representative-nodes","text":"The following are minimum recommended specifications for nodes with more than 0.1% of the online voting weight ( Principal Representatives ): 4GB RAM Quad-Core CPU 200 Mbps bandwidth (2TB or more of available monthly bandwidth) SSD-based hard drive with 80GB+ of free space","title":"Principal Representative Nodes"},{"location":"running-a-node/node-setup/#non-voting-and-representative-nodes","text":"The following are minimum recommended specifications for non-voting nodes and Represntative nodes with less than 0.1% of the online voting weight (regular Representatives ): 2GB RAM (additional RAM or swap space may be needed if bootstrapping a new node from scratch) Dual-Core CPU 100 Mbps bandwidth (2TB or more of available monthly bandwidth) SSD-based hard drive with 80GB+ of free space Varied resource usage Various factors affect resource usage including how often RPC calls are made, other applications running on the machine, etc. These recommendations should be evaluated along with other considerations. Work Generation guide For nodes being used with services requiring regular or high volume sending and receiving of transactions, special considerations must be made for handling Proof-of-Work generation activities. Find details on configuring a GPU, external work services and more for the perfect setup in the Work Generation guide .","title":"Non-voting and Representative Nodes"},{"location":"running-a-node/node-setup/#network-ports","text":"The nano_node will use two configurable ports throughout its lifecycle. The default values suggested by the network details are below: Network Ports Overview 7075 TCP: For live network activity (since V19.0) and bootstrap network activity 7076 TCP: For communication with RPC server. Do not expose this outside of your production environment. Anyone with access to this port can control your node's RPC. 7078 TCP: For communication with websocket server . Depending on configuration, data throughput can be very high. 7075 UDP: For live network activity (fallback since V19.0, deprecated and disabled V21+) UDP disabled by default, deprecated As of V21 peering and communicating via UDP has been disabled by default and is deprecated. The ability to use UDP will be removed from the node in a future release yet to be determined. By default nano_node will attempt to use UPnP. Troubleshooting information can be found here","title":"Network Ports"},{"location":"running-a-node/node-setup/#installing-docker","text":"Docker must be installed on the host machine and instructions can be found here: https://docs.docker.com/install/ . We recommend installing the latest stable version available.","title":"Installing Docker"},{"location":"running-a-node/node-setup/#pulling-the-docker-image","text":"The Docker image can be downloaded via docker pull . We can either grab the latest or a specific version/tag. Not specifying a tag defaults to latest . An example of each is found below. Pulls the latest release of the Nano Node: docker pull nanocurrency/nano Pulls a specific version of the Nano node: docker pull nanocurrency/nano:V20.0 Tip If you are running in an enterprise environment, it is recommended that you explicitly specify the latest stable version to ensure deterministic containers. A list of tags can be found at the official Nano Currency Docker Hub . Warning - Multiple Node Setups Never use the same seed on multiple running nano_node instances at the same time. Multiple nano_nodes using the same seed can result in network race conditions that degrade performance for your personal accounts. In addition, Publishing transactions from two nodes with the same account at the same time may cause an account fork which requires a slower representative voting process. Similarly, if you are running a representative account on multiple nodes, they may publish conflicting votes, causing your representative to be ignored by the network. Performance degradation in enterprise environments may be significant.","title":"Pulling the Docker Image"},{"location":"running-a-node/node-setup/#starting-the-node","text":"With Docker there are basic commands for managing containers. To properly bring the node up, learn these commands beginning with starting the container . Advanced Builds For additional options around building the node to run on various platforms, head over to the Integration Guides Build Options .","title":"Starting the Node"},{"location":"running-a-node/node-setup/#additional-setup","text":"The above instructions cover getting a node up and running with the default configuration settings. Additional setup areas to explore include: Learning more about managing the node in a Docker container Updating node configuration options to enable various features Setting up the node to vote as a representative Finding out how to best manage your ledger file","title":"Additional setup"},{"location":"running-a-node/overview/","text":"Running a Node Overview \u00b6 Running a node is a key way to help decentralize the network and provide a network access point for systems built on top of Nano. Before setting up a node we recommend reviewing the following details in order to understand more about the motivations for running, required upkeep, types and recommended specifications for nodes. Why run a node? \u00b6 By design, the incentives for running a Nano node are not built into the network itself, but instead are external. This is an important difference compared to nearly all other cryptocurrency networks and allows Nano to operate securely without transaction fees. 1 2 These indirect, external incentives include the following and more: Advertising exposure from their representative showing up on curated representative lists Transaction fee savings for businesses and organizations accepting Nano as payment Helping support and further decentralize a global payment network Having a trusted access point for building additional software on the network Regardless of the motivation for running a node, it will only benefit the network if proper care is taken to ensure it is run on correctly provisioned machines and ongoing maintenance of the node, OS and any supporting systems are routinely done. Node types \u00b6 Dedicated Representative nodes recommended Due to the resources needed to participate in the voting process, it is recommended that any node setup as a Representative should be dedicated to generating consensus . If the resources of the Representative are used for other activities, such as application integrations or , it reduces the potential benefit that node brings to the network. Review Node security guide Regardless of the type of node you are planning to run, make sure to review the Node security guide to ensure best practice with configuration, firewalls and more. Non-voting nodes \u00b6 When first setting up a node it will not be configured to participate in consensus by voting on traffic. This type of node is common and is recommended for all integrations. If your goal in setting up a node is to learn how to integrate and use Nano for payments, this is the best starting point. If you want to dedicate resources to help secure consensus on the network, then a Representative node should be explored. Representative nodes \u00b6 If a node is setup with a Representative account, is configured to vote and has less than 0.1% of online voting weight delegated to them, they are a considered Representative node. These nodes will validate and vote on transactions seen on the network; however, other nodes on the network will not rebroadcast their votes. Principal Representative nodes \u00b6 Representative nodes with at least 0.1% of the online voting weight delegated to them participate more broadly in network consensus because they send votes to their peers which are subsequently rebroadcast. These nodes have the most impact to the security and availability of the network so keeping them secure and following maintenance recommendations should be taken seriously. Becoming a Principal Representative With the ability for any user on the network to redelegate their voting weight, even an account with no weight today can become a Principal Representative over time. Hardware recommendations \u00b6 Nodes consume CPU, RAM, disk IO and bandwidth IO resources, all of which come at a cost. In order to keep the node participating and in-sync, the recommended specifications for machines based on node type below should be followed. Principal Representative Nodes \u00b6 The following are minimum recommended specifications for nodes with more than 0.1% of the online voting weight ( Principal Representatives ): 4GB RAM Quad-Core CPU 200 Mbps bandwidth (2TB or more of available monthly bandwidth) SSD-based hard drive with 80GB+ of free space Non-voting and Representative Nodes \u00b6 The following are minimum recommended specifications for non-voting nodes and Represntative nodes with less than 0.1% of the online voting weight (regular Representatives ): 2GB RAM (additional RAM or swap space may be needed if bootstrapping a new node from scratch) Dual-Core CPU 100 Mbps bandwidth (2TB or more of available monthly bandwidth) SSD-based hard drive with 80GB+ of free space Varied resource usage Various factors affect resource usage including how often RPC calls are made, other applications running on the machine, etc. These recommendations should be evaluated along with other considerations. Work Generation guide For nodes being used with services requiring regular or high volume sending and receiving of transactions, special considerations must be made for handling Proof-of-Work generation activities. Find details on configuring a GPU, external work services and more for the perfect setup in the Work Generation guide . Maintenance \u00b6 Join our Technical Update Mailing List Follow this link to sign up for email updates on the latest protocol/node releases and other technical details. This will include network upgrades such as the upcoming epoch distribution: http://eepurl.com/gZucL1 With any system, ongoing maintenance must be taken into account to avoid issues. The following are a few examples of regular activities that should be committed to, especially when running a Representative or Principal Representative node: Performing OS-level updates and security patches regularly applied Upgrading to the latest node versions as they are available Following best practices for securing passwords or other sensitive data related to the node Without taking care of the security and maintenance of systems hosting the node, any benefit to the network could be lost. Continue learning about how best to keep the node secure in our Node security guide . https://medium.com/nanocurrency/the-incentives-to-run-a-node-ccc3510c2562 \u21a9 https://medium.com/@clemahieu/emergent-centralization-due-to-economies-of-scale-83cc85a7cbef \u21a9","title":"Overview"},{"location":"running-a-node/overview/#running-a-node-overview","text":"Running a node is a key way to help decentralize the network and provide a network access point for systems built on top of Nano. Before setting up a node we recommend reviewing the following details in order to understand more about the motivations for running, required upkeep, types and recommended specifications for nodes.","title":"Running a Node Overview"},{"location":"running-a-node/overview/#why-run-a-node","text":"By design, the incentives for running a Nano node are not built into the network itself, but instead are external. This is an important difference compared to nearly all other cryptocurrency networks and allows Nano to operate securely without transaction fees. 1 2 These indirect, external incentives include the following and more: Advertising exposure from their representative showing up on curated representative lists Transaction fee savings for businesses and organizations accepting Nano as payment Helping support and further decentralize a global payment network Having a trusted access point for building additional software on the network Regardless of the motivation for running a node, it will only benefit the network if proper care is taken to ensure it is run on correctly provisioned machines and ongoing maintenance of the node, OS and any supporting systems are routinely done.","title":"Why run a node?"},{"location":"running-a-node/overview/#node-types","text":"Dedicated Representative nodes recommended Due to the resources needed to participate in the voting process, it is recommended that any node setup as a Representative should be dedicated to generating consensus . If the resources of the Representative are used for other activities, such as application integrations or , it reduces the potential benefit that node brings to the network. Review Node security guide Regardless of the type of node you are planning to run, make sure to review the Node security guide to ensure best practice with configuration, firewalls and more.","title":"Node types"},{"location":"running-a-node/overview/#non-voting-nodes","text":"When first setting up a node it will not be configured to participate in consensus by voting on traffic. This type of node is common and is recommended for all integrations. If your goal in setting up a node is to learn how to integrate and use Nano for payments, this is the best starting point. If you want to dedicate resources to help secure consensus on the network, then a Representative node should be explored.","title":"Non-voting nodes"},{"location":"running-a-node/overview/#representative-nodes","text":"If a node is setup with a Representative account, is configured to vote and has less than 0.1% of online voting weight delegated to them, they are a considered Representative node. These nodes will validate and vote on transactions seen on the network; however, other nodes on the network will not rebroadcast their votes.","title":"Representative nodes"},{"location":"running-a-node/overview/#principal-representative-nodes","text":"Representative nodes with at least 0.1% of the online voting weight delegated to them participate more broadly in network consensus because they send votes to their peers which are subsequently rebroadcast. These nodes have the most impact to the security and availability of the network so keeping them secure and following maintenance recommendations should be taken seriously. Becoming a Principal Representative With the ability for any user on the network to redelegate their voting weight, even an account with no weight today can become a Principal Representative over time.","title":"Principal Representative nodes"},{"location":"running-a-node/overview/#hardware-recommendations","text":"Nodes consume CPU, RAM, disk IO and bandwidth IO resources, all of which come at a cost. In order to keep the node participating and in-sync, the recommended specifications for machines based on node type below should be followed.","title":"Hardware recommendations"},{"location":"running-a-node/overview/#principal-representative-nodes_1","text":"The following are minimum recommended specifications for nodes with more than 0.1% of the online voting weight ( Principal Representatives ): 4GB RAM Quad-Core CPU 200 Mbps bandwidth (2TB or more of available monthly bandwidth) SSD-based hard drive with 80GB+ of free space","title":"Principal Representative Nodes"},{"location":"running-a-node/overview/#non-voting-and-representative-nodes","text":"The following are minimum recommended specifications for non-voting nodes and Represntative nodes with less than 0.1% of the online voting weight (regular Representatives ): 2GB RAM (additional RAM or swap space may be needed if bootstrapping a new node from scratch) Dual-Core CPU 100 Mbps bandwidth (2TB or more of available monthly bandwidth) SSD-based hard drive with 80GB+ of free space Varied resource usage Various factors affect resource usage including how often RPC calls are made, other applications running on the machine, etc. These recommendations should be evaluated along with other considerations. Work Generation guide For nodes being used with services requiring regular or high volume sending and receiving of transactions, special considerations must be made for handling Proof-of-Work generation activities. Find details on configuring a GPU, external work services and more for the perfect setup in the Work Generation guide .","title":"Non-voting and Representative Nodes"},{"location":"running-a-node/overview/#maintenance","text":"","title":"Maintenance"},{"location":"running-a-node/security/","text":"Node Security \u00b6 There are many reasons to run a Nano node on the network. Nodes are the participants that help vote on transaction validity, assist other nodes with bootstrapping blocks in the ledger and providing an access point to all accounts. But those who choose to run them should be making a long-term commitment to run them on proper hardware , keep them updated with the latest release and, most importantly, keep their setup as secure as possible. Join our Technical Update Mailing List Follow this link to sign up for email updates on the latest protocol/node releases and other technical details. This will include network upgrades such as the upcoming epoch distribution: http://eepurl.com/gZucL1 The details below are guidelines on things to watch out for when setting up and securing your Nano node. As the node can be run on many different operating systems, some of these guidelines have been kept more general. There are plenty of resources online for learning how to apply these guidelines to more specific setups and additional details will be included in the docs here as they are appropriate. Node configuration \u00b6 Enabling control \u00b6 Various RPC calls are marked as requiring the enable_control option to be turned on before they can be called. This extra level of permission to use these RPCs was put in place because the calls can be dangerous in a couple ways: They can potentially allow access to wallet funds They can consume extra node resources compared to other calls, such as using more disk space or requiring additional computation to complete By turning enable_control on, anyone with access to your RPC can run these potentially dangerous commands, so it is only recommended with port configurations where RPC access is restricted to local and loopback addresses only. If your RPC is exposed to external or non-loopback addresses, the node will print out warnings to stdout and your logs to help make you aware of potential exposure. Port configuration \u00b6 Opening default port 7075 on UDP and TCP is required for the node to participate on the main network and this should be done unrestricted. The default port for RPC access is 7076 and should only be available to those you wish to have control of the node. Verifying the configuration in config-rpc.toml file for address and enable_control should be done on all nodes, alonside other access verifications outlined below. Opening RPC port externally and enabling control is potentially dangerous As mentioned above, enabling control allows anyone with RPC access to make potentially dangerous calls to your node. If turning on enable_control , you must carefully review any access granted to the RPC port (default 7076 ) to ensure it is as secure as possible. Firewalls \u00b6 There are various firewall options available across operating systems. IPTables, PeerBlock, Windows Firewall and others allow you to better control access to your host machine and thus your node. By having a firewall in place you can completely block unused and unnecessary ports, as well as whitelist other ports for access only from trusted IP addresses. Using this in combination with good server access and port configuration practices helps harden your node setup even further. Server access \u00b6 Due to the node currently processing all transactions, keeping them running and online as much as possible is recommended, so many operators use dedicated servers or shared servers, often in data centers or cloud providers. When running node on a remote machine, access to that machine should be tightened up in various ways. Some common tips are included below which may or may not apply to your specific system: Use private/public key pairs exclusively for authentication over SSH, which involves disabling password-based authentication Disable root login entirely Disable remote logins for accounts with an empty password Change default SSH port Use a firewall to whitelist IP access to SSH connections Set timeouts for idle SSH connections Get setup to block SSH brute force attempts automatically with tools like Fail2ban Limit the maximimum authentication attempts allowed Setup alerts and monitoring for SSH connections Using a variety of these control measures for server access can increase your resistance to unauthorized access to your host machine and help protect your node from interference. Docker considerations \u00b6 When running a node in Docker there is an extra layer of port controls between the node in the Docker container and the host machine. The default node configuration provided with Docker images in Docker hub , along with examples in our documentation for commands such as docker run , result in allowing RPC access only to the machine hosting the container. This is the recommended setup for most nodes. To make sure Docker security is understood by any node operator and the setup used is as secure as possible, we recommend reading up on general best practices for using Docker, consider running Docker with non-root USER and verifying external access to RPC calls are controlled sufficiently by the Docker host machine.","title":"Security"},{"location":"running-a-node/security/#node-security","text":"There are many reasons to run a Nano node on the network. Nodes are the participants that help vote on transaction validity, assist other nodes with bootstrapping blocks in the ledger and providing an access point to all accounts. But those who choose to run them should be making a long-term commitment to run them on proper hardware , keep them updated with the latest release and, most importantly, keep their setup as secure as possible.","title":"Node Security"},{"location":"running-a-node/security/#node-configuration","text":"","title":"Node configuration"},{"location":"running-a-node/security/#enabling-control","text":"Various RPC calls are marked as requiring the enable_control option to be turned on before they can be called. This extra level of permission to use these RPCs was put in place because the calls can be dangerous in a couple ways: They can potentially allow access to wallet funds They can consume extra node resources compared to other calls, such as using more disk space or requiring additional computation to complete By turning enable_control on, anyone with access to your RPC can run these potentially dangerous commands, so it is only recommended with port configurations where RPC access is restricted to local and loopback addresses only. If your RPC is exposed to external or non-loopback addresses, the node will print out warnings to stdout and your logs to help make you aware of potential exposure.","title":"Enabling control"},{"location":"running-a-node/security/#port-configuration","text":"Opening default port 7075 on UDP and TCP is required for the node to participate on the main network and this should be done unrestricted. The default port for RPC access is 7076 and should only be available to those you wish to have control of the node. Verifying the configuration in config-rpc.toml file for address and enable_control should be done on all nodes, alonside other access verifications outlined below. Opening RPC port externally and enabling control is potentially dangerous As mentioned above, enabling control allows anyone with RPC access to make potentially dangerous calls to your node. If turning on enable_control , you must carefully review any access granted to the RPC port (default 7076 ) to ensure it is as secure as possible.","title":"Port configuration"},{"location":"running-a-node/security/#firewalls","text":"There are various firewall options available across operating systems. IPTables, PeerBlock, Windows Firewall and others allow you to better control access to your host machine and thus your node. By having a firewall in place you can completely block unused and unnecessary ports, as well as whitelist other ports for access only from trusted IP addresses. Using this in combination with good server access and port configuration practices helps harden your node setup even further.","title":"Firewalls"},{"location":"running-a-node/security/#server-access","text":"Due to the node currently processing all transactions, keeping them running and online as much as possible is recommended, so many operators use dedicated servers or shared servers, often in data centers or cloud providers. When running node on a remote machine, access to that machine should be tightened up in various ways. Some common tips are included below which may or may not apply to your specific system: Use private/public key pairs exclusively for authentication over SSH, which involves disabling password-based authentication Disable root login entirely Disable remote logins for accounts with an empty password Change default SSH port Use a firewall to whitelist IP access to SSH connections Set timeouts for idle SSH connections Get setup to block SSH brute force attempts automatically with tools like Fail2ban Limit the maximimum authentication attempts allowed Setup alerts and monitoring for SSH connections Using a variety of these control measures for server access can increase your resistance to unauthorized access to your host machine and help protect your node from interference.","title":"Server access"},{"location":"running-a-node/security/#docker-considerations","text":"When running a node in Docker there is an extra layer of port controls between the node in the Docker container and the host machine. The default node configuration provided with Docker images in Docker hub , along with examples in our documentation for commands such as docker run , result in allowing RPC access only to the machine hosting the container. This is the recommended setup for most nodes. To make sure Docker security is understood by any node operator and the setup used is as secure as possible, we recommend reading up on general best practices for using Docker, consider running Docker with non-root USER and verifying external access to RPC calls are controlled sufficiently by the Docker host machine.","title":"Docker considerations"},{"location":"running-a-node/test-network/","text":"Test network \u00b6 The test network exists primarily for the purpose of conducting general integration and node upgrade testing in light volumes. By providing a network with similar parameters to the main network (work difficulty, etc.) this is the best environment for connecting test or staging versions of services and applications to for small scale tests. In order to keep the network as stable as possible, the Nano Foundation will maintain nodes on this network on the latest Release Candidate (RC) or release version, it will not be updated with beta or development features. For load testing and new node releases and features testing, head over to the beta network page where details on how to conduct those types of network-wide testing exist. Running a test node \u00b6 Setting up a node on the test network is similar to the beta network. To start you should install docker and be familiar with the general setup and Docker management processes. Network ports \u00b6 Test Network Ports Overview 17075 TCP: For live network activity and bootstrap network activity 17076 TCP: For communication with RPC server. Anyone with access to this port can control your node's RPC. 17078 TCP: For communication with websocket server . Depending on configuration, data throughput can be very high. Directory locations \u00b6 OS Location Windows C: \\U sers \\< user> \\A ppData \\L ocal \\N anoTest \\ macOS /Users/<user>/Library/NanoTest/ Linux /home/<user>/NanoTest/ Binaries \u00b6 In addition to the Docker details above, the latest binary builds of the node for the test network can be found below. These will only change when Release Candidates (RC) builds are ready, or when final releases are done. However, the first build available today is actually a development build since the changes to enable this network were recently introduced. OS Version Download link/command Linux V22.0DB6 https://repo.nano.org/test/binaries/nano-node-V22.0DB6-Linux.tar.bz2 macOS V22.0DB6 https://repo.nano.org/test/binaries/nano-node-V22.0DB6-Darwin.dmg Windows V22.0DB6 https://repo.nano.org/test/binaries/nano-node-V22.0DB6-win64.exe Docker V22.0DB6 docker pull nanocurrency/nano-test:V22.0DB6 or docker pull nanocurrency/nano-test:latest See Pulling the Docker Image for more details. If manual builds are needed, see the build options page for details. Pulling the Docker image \u00b6 Pulls the latest release of the Nano Node: docker pull nanocurrency/nano-test Pulls a specific version of the Nano node: docker pull nanocurrency/nano-test:<tag> Pulls the latest release which includes any release candidate versions: docker pull nanocurrency/nano-test:latest-including-rc A list of beta tags can be found at the official Nano Currency Docker Hub Starting the Docker container \u00b6 docker run --restart = unless-stopped -d \\ -p 17075 :17075 \\ -p [ ::1 ] :17076:17076 \\ -p [ ::1 ] :17078:17078 \\ -v ${ NANO_HOST_DIR_TEST } :/root \\ --name ${ NANO_NAME } \\ nanocurrency/nano-test:latest-including-rc Tip For an explanation of the options included in the Docker run command, see Starting the Container details for the main network. See Docker management for other related commands Separate host directories Be sure to use a different host directory for main network, beta network and test network Docker node setups. Attempting to use the same directory will result in issues. Getting test funds \u00b6 One you have a node up and running the ledger should bootstrap from the network quickly, and then you just need some test network specific Nano funds. We are currently working on a faucet setup to enable self-service options, but for now please reach out to Zach - ATX#0646 and argakiig#1783 on Discord or email infrastructure@nano.org with the account number you would like funds distributed to for the test network.","title":"Test Network"},{"location":"running-a-node/test-network/#test-network","text":"The test network exists primarily for the purpose of conducting general integration and node upgrade testing in light volumes. By providing a network with similar parameters to the main network (work difficulty, etc.) this is the best environment for connecting test or staging versions of services and applications to for small scale tests. In order to keep the network as stable as possible, the Nano Foundation will maintain nodes on this network on the latest Release Candidate (RC) or release version, it will not be updated with beta or development features. For load testing and new node releases and features testing, head over to the beta network page where details on how to conduct those types of network-wide testing exist.","title":"Test network"},{"location":"running-a-node/test-network/#running-a-test-node","text":"Setting up a node on the test network is similar to the beta network. To start you should install docker and be familiar with the general setup and Docker management processes.","title":"Running a test node"},{"location":"running-a-node/test-network/#network-ports","text":"Test Network Ports Overview 17075 TCP: For live network activity and bootstrap network activity 17076 TCP: For communication with RPC server. Anyone with access to this port can control your node's RPC. 17078 TCP: For communication with websocket server . Depending on configuration, data throughput can be very high.","title":"Network ports"},{"location":"running-a-node/test-network/#directory-locations","text":"OS Location Windows C: \\U sers \\< user> \\A ppData \\L ocal \\N anoTest \\ macOS /Users/<user>/Library/NanoTest/ Linux /home/<user>/NanoTest/","title":"Directory locations"},{"location":"running-a-node/test-network/#binaries","text":"In addition to the Docker details above, the latest binary builds of the node for the test network can be found below. These will only change when Release Candidates (RC) builds are ready, or when final releases are done. However, the first build available today is actually a development build since the changes to enable this network were recently introduced. OS Version Download link/command Linux V22.0DB6 https://repo.nano.org/test/binaries/nano-node-V22.0DB6-Linux.tar.bz2 macOS V22.0DB6 https://repo.nano.org/test/binaries/nano-node-V22.0DB6-Darwin.dmg Windows V22.0DB6 https://repo.nano.org/test/binaries/nano-node-V22.0DB6-win64.exe Docker V22.0DB6 docker pull nanocurrency/nano-test:V22.0DB6 or docker pull nanocurrency/nano-test:latest See Pulling the Docker Image for more details. If manual builds are needed, see the build options page for details.","title":"Binaries"},{"location":"running-a-node/test-network/#pulling-the-docker-image","text":"Pulls the latest release of the Nano Node: docker pull nanocurrency/nano-test Pulls a specific version of the Nano node: docker pull nanocurrency/nano-test:<tag> Pulls the latest release which includes any release candidate versions: docker pull nanocurrency/nano-test:latest-including-rc A list of beta tags can be found at the official Nano Currency Docker Hub","title":"Pulling the Docker image"},{"location":"running-a-node/test-network/#starting-the-docker-container","text":"docker run --restart = unless-stopped -d \\ -p 17075 :17075 \\ -p [ ::1 ] :17076:17076 \\ -p [ ::1 ] :17078:17078 \\ -v ${ NANO_HOST_DIR_TEST } :/root \\ --name ${ NANO_NAME } \\ nanocurrency/nano-test:latest-including-rc Tip For an explanation of the options included in the Docker run command, see Starting the Container details for the main network. See Docker management for other related commands Separate host directories Be sure to use a different host directory for main network, beta network and test network Docker node setups. Attempting to use the same directory will result in issues.","title":"Starting the Docker container"},{"location":"running-a-node/test-network/#getting-test-funds","text":"One you have a node up and running the ledger should bootstrap from the network quickly, and then you just need some test network specific Nano funds. We are currently working on a faucet setup to enable self-service options, but for now please reach out to Zach - ATX#0646 and argakiig#1783 on Discord or email infrastructure@nano.org with the account number you would like funds distributed to for the test network.","title":"Getting test funds"},{"location":"running-a-node/troubleshooting/","text":"Troubleshooting \u00b6 Log Files \u00b6 The default location of standard node log files for various systems: OS Location Windows C: \\U sers \\< user> \\A ppData \\L ocal \\N ano \\l og -or- %LOCALAPPDATA% \\N ano \\l og macOS /Users/<user>/Library/Nano/log Linux /home/<user>/Nano/log To get a static file name for the currently active log file, see the stable_log_filename configuration option What to do if the node crashes (Linux) \u00b6 Do not restart the node If your node crashes, please follow this guide before attempting to run it again. If the node crashes, the most commonly seen message is \"Segmentation fault (core dumped)\". When using docker, this message will only show up in the docker logs. In any case, this is often not enough to go on in terms of figuring out what went wrong. The next steps detail what you should do to provide us with as much information as possible about the problem. When you are done gathering all information, please create a new Github issue , or reach us on Discord in the #support channel, detailing your issue as much as possible. Getting the latest node log The following command will order the log files such that the first one in the output is the most recent. If you restarted the node since the crash, then the relevant log file is not the latest one. Please be careful to give us the relevant log file. # Nano -> NanoBeta if debugging a beta node ls -dlt ~/Nano/log/* | head Please provide the complete log file. Please follow the steps below for the corresponding node version you are using. Should there be an error obtaining the information in a newer version, the older version steps should then be attempted. v21 + nodes \u00b6 Step 1: Make sure addr2line is installed It is likely installed already, consult documentation for your linux distribution if it is not mentioned below: Ubuntu/Debian apt-get install binutils Fedora 22+ dnf install binutils (Optional) Step 2: Save crash dump files The next step will clean up the dump files generated during the crash, if you wish to keep these then save nano_node_backtrace.dump , and all nano_node_crash_load_address_dump_*.txt files. Step 3: Generate crash report Run: ./nano_node --debug_generate_crash_report This will generate a text file nano_node_crash_report.txt please send us the contents of this file. v20 nodes \u00b6 Step 1: Getting dmesg information Depending on the error, it is possible you do not find any useful information in this step, in which case please move on to Step 3. Run the following command and look for nano_node at the end. If you see a relevant message, gather all messages with a similar timestamp - the number within brackets on the left. dmesg Example output: [ 6.336071] IPv6: ADDRCONF(NETDEV_CHANGE): wlp2s0: link becomes ready [ 6.375123] wlp2s0: Limiting TX power to 23 (23 - 0) dBm as advertised by **:**:**:**:**:** [ 6141.711993] show_signal_msg: 23 callbacks suppressed [ 6141.711995] I/O[14487]: segfault at 1 ip 000055c69d3a1634 sp 00007f6e9332df10 error 6 in nano_node[55c69d25f000+70b000] [ 6141.711999] Code: 24 70 48 83 c5 10 48 89 c3 48 39 ef 74 b6 e8 e3 b8 39 00 eb af 90 41 57 41 56 41 55 41 54 49 89 fc 55 53 48 81 ec a8 00 00 00 <c6> 04 25 01 00 00 00 31 64 48 8b 04 25 28 00 00 00 48 89 84 24 98 From this output, only the last 3 lines are relevant. Step 2: Getting syslog information More information might be available in syslog. Run the following command and look for the time the crash ocurred. cat /var/log/syslog Example output: Aug 15 11:56:07 ubuntu-server kernel: [6141.711993] show_signal_msg: 23 callbacks suppressed Aug 15 11:56:07 ubuntu-server kernel: [6141.711995] I/O[25975]: segfault at 1 ip 000055b2960e2d24 sp 00007fcff50f6fc0 error 6 in nano_node[55b295f9b000+6d8000] Aug 15 11:56:07 ubuntu-server kernel: [6141.711999] Code: 24 70 48 83 c5 10 48 89 c3 48 39 ef 74 b6 e8 e3 b8 39 00 eb af 90 41 57 41 56 41 55 41 54 49 89 fc 55 53 48 81 ec a8 00 00 00 <c6> 04 25 01 00 00 00 31 64 48 8b 04 25 28 00 00 00 48 89 84 24 98 Include the relevant lines from the output. In this example, the log is similar to the one from Step 2. Step 3: Getting a backtrace dump This command will produce some basic information about the error. Not using docker : ./nano_node --debug_output_last_backtrace_dump > nano_node_backtrace_output.txt Using docker : mkdir -p /tmp/nano_node_crash && cd $_ docker exec ${ NANO_NAME } nano_node --debug_output_last_backtrace_dump > nano_node_backtrace_output.txt docker exec ${ NANO_NAME } sh -c 'mkdir -p crash_files; mv nano_node_crash*.txt crash_files/' docker cp ${ NANO_NAME } :/crash_files/ . && mv crash_files/* . Step 4: Producing the archive file See the output of this command for the name of the file you should include in your report. FILE = \"nano_node_crash_ $( date + \"%Y-%m-%d_%H-%M-%S.tar.gz\" ) \" && tar czf $FILE --exclude = *.tar.gz nano_node_* && echo \"Created archive $FILE \" Statistics from RPC \u00b6 The \"stats\" RPC command can be used by external processes to query statistics, such as traffic counters. This is useful for diagnostics, monitoring and display in admin consoles. Statistics are optionally logged to separate text files. For implementations details, please see Statistics API Duplicate observer stats Under certain conditions, confirmations seen through the observer type stat can be duplicates. In order to get accurate data, block hashes must be tracked and validated against previously seen hashes. Configuration \u00b6 All configuration nodes and values are optional, with the default values shown in comments below: \"node\" : { ... \"statistics\" : { // Sampli n g co nf igura t io n (op t io nal ) // O nl y ac t iva te i f you nee d sampli n g i nf orma t io n , as t here's some overhead associa te d wi t h t his feature . \"sampling\" : { \"enabled\" : \"true\" , // I f sampli n g is e na bled. De fault false . \"capacity\" : \"5\" , // How ma n y samples t o keep. Mus t be se t i f sampli n g is e na bled. \"interval\" : \"1000\" // Sample i nter val i n milliseco n ds. Mus t be se t i f sampli n g is e na bled. }, // File loggi n g (op t io nal ) \"log\" : { \"interval_counters\" : \"5000\" , // How o ften t o wri te cou nters t o f ile i n milliseco n ds. De fault 0 (o ff ) \"interval_samples\" : \"5000\" , // How o ften t o wri te samples t o f ile , milliseco n ds. De fault 0 (o ff ) \"rotation_count\" : \"5\" , // Ro tate f ile a fter wri t i n g s tat is t ics t his ma n y t imes. De fault 100. \"headers\" : \"true\" , // Wri te header co nta i n i n g log \"filename_counters\" : \"counters.stat\" , \"filename_samples\" : \"samples.stat\" } } } Available type, detail and direction values \u00b6 type: traffic_udp traffic_tcp error message block ledger rollback bootstrap vote election http_callback peering ipc tcp udp confirmation_height confirmation_observer drop aggregator requests filter telemetry details: all // error specific bad_sender insufficient_work http_callback unreachable_host // confirmation_observer specific active_quorum active_conf_height inactive_conf_height // ledger block bootstrap send receive open change state_block epoch_block fork old gap_previous gap_source // message specific keepalive publish republish_vote confirm_req confirm_ack node_id_handshake telemetry_req telemetry_ack // bootstrap callback initiate initiate_lazy initiate_wallet_lazy // bootstrap specific bulk_pull bulk_pull_account bulk_pull_deserialize_receive_block bulk_pull_error_starting_request bulk_pull_failed_account bulk_pull_receive_block_failure bulk_pull_request_failure bulk_push frontier_req frontier_confirmation_failed frontier_confirmation_successful error_socket_close // vote specific vote_valid vote_replay vote_indeterminate vote_invalid vote_overflow // election specific vote_new vote_cached late_block late_block_seconds election_non_priority election_priority election_block_conflict election_difficulty_update election_drop election_restart // udp blocking overflow invalid_magic invalid_network invalid_header invalid_message_type invalid_keepalive_message invalid_publish_message invalid_confirm_req_message invalid_confirm_ack_message invalid_node_id_handshake_message invalid_telemetry_req_message invalid_telemetry_ack_message outdated_version // tcp tcp_accept_success tcp_accept_failure tcp_write_drop tcp_write_no_socket_drop tcp_excluded // ipc invocations // peering handshake // confirmation height blocks_confirmed blocks_confirmed_unbounded blocks_confirmed_bounded invalid_block // [request] aggregator aggregator_accepted aggregator_dropped // requests requests_cached_hashes requests_generated_hashes requests_cached_votes requests_generated_votes requests_cannot_vote requests_unknown // duplicate duplicate_publish // telemetry invalid_signature different_genesis_hash node_id_mismatch request_within_protection_cache_zone no_response_received unsolicited_telemetry_ack failed_send_telemetry_req dir (direction) : in out RPC Command \u00b6 Counters query: \u00b6 { \"action\" : \"stats\" , \"type\" : \"counters\" } Counters response \u00b6 { \"type\" : \"counters\" , \"created\" : \"2018.03.29 01:46:36\" , \"entries\" : [ { \"time\" : \"01:46:36\" , \"type\" : \"traffic\" , \"detail\" : \"all\" , \"dir\" : \"in\" , \"value\" : \"3122792\" }, { \"time\" : \"01:46:36\" , \"type\" : \"traffic\" , \"detail\" : \"all\" , \"dir\" : \"out\" , \"value\" : \"203184\" }, { \"time\" : \"01:46:36\" , \"type\" : \"message\" , \"detail\" : \"all\" , \"dir\" : \"in\" , \"value\" : \"12494\" }, { \"time\" : \"01:46:36\" , \"type\" : \"message\" , \"detail\" : \"all\" , \"dir\" : \"out\" , \"value\" : \"1380\" }, { \"time\" : \"01:46:36\" , \"type\" : \"message\" , \"detail\" : \"keepalive\" , \"dir\" : \"in\" , \"value\" : \"172\" }, ... ] } Samples query: \u00b6 { \"action\" : \"stats\" , \"type\" : \"samples\" } Samples response \u00b6 { \"type\" : \"samples\" , \"created\" : \"2018.03.29 01:47:08\" , \"entries\" : [ { \"time\" : \"01:47:04\" , \"type\" : \"traffic\" , \"detail\" : \"all\" , \"dir\" : \"in\" , \"value\" : \"59480\" }, { \"time\" : \"01:47:05\" , \"type\" : \"traffic\" , \"detail\" : \"all\" , \"dir\" : \"in\" , \"value\" : \"44496\" }, { \"time\" : \"01:47:06\" , \"type\" : \"traffic\" , \"detail\" : \"all\" , \"dir\" : \"in\" , \"value\" : \"44136\" }, { \"time\" : \"01:47:07\" , \"type\" : \"traffic\" , \"detail\" : \"all\" , \"dir\" : \"in\" , \"value\" : \"18784\" }, { \"time\" : \"01:47:08\" , \"type\" : \"traffic\" , \"detail\" : \"all\" , \"dir\" : \"in\" , \"value\" : \"22680\" }, { \"time\" : \"01:47:03\" , \"type\" : \"traffic\" , \"detail\" : \"all\" , \"dir\" : \"out\" , \"value\" : \"4128\" }, { \"time\" : \"01:47:04\" , \"type\" : \"message\" , \"detail\" : \"all\" , \"dir\" : \"out\" , \"value\" : \"17\" }, { \"time\" : \"01:47:05\" , \"type\" : \"message\" , \"detail\" : \"all\" , \"dir\" : \"out\" , \"value\" : \"10\" }, ... ] } Log file example \u00b6 counters.stat As specified in the example config, sampling interval is 1 second, stats are logged every 5 seconds, and the file rotates after 5 log cycles. counters,2018.03.29 01:45:36 01:44:56,bootstrap,all,out,1 01:45:36,bootstrap,initiate,out,2 counters,2018.03.29 01:45:41 01:45:41,traffic,all,in,456344 01:45:41,traffic,all,out,189520 01:45:41,message,all,in,1925 01:45:41,message,all,out,1289 01:45:38,message,keepalive,in,165 01:45:41,message,keepalive,out,1027 01:45:41,message,publish,in,34 01:45:38,message,confirm_req,in,164 01:45:41,message,confirm_req,out,262 01:45:41,message,confirm_ack,in,1562 01:45:36,bootstrap,all,out,2 01:45:41,bootstrap,initiate,out,3 samples.stat As specified in the example config, logging is done every 5 seconds and the sampling capacity is 5 (how many samplings are kept) samples,2018.03.29 01:45:36 01:45:36,bootstrap,initiate,out,2 samples,2018.03.29 01:45:41 01:45:37,traffic,all,in,322608 01:45:38,traffic,all,in,37064 01:45:39,traffic,all,in,38752 01:45:40,traffic,all,in,25632 01:45:38,traffic,all,out,185072 01:45:39,traffic,all,out,3072 01:45:41,traffic,all,out,920 01:45:37,message,all,in,1387 01:45:38,message,all,in,126 01:45:39,message,all,in,179 01:45:40,message,all,in,101 01:45:37,message,all,out,1254 01:45:38,message,all,out,10 01:45:39,message,all,out,16 01:45:41,message,all,out,6 01:45:38,message,keepalive,in,165 01:45:38,message,keepalive,out,1011 01:45:39,message,keepalive,out,12 01:45:41,message,keepalive,out,3 01:45:37,message,publish,in,19 01:45:38,message,publish,in,8 01:45:40,message,publish,in,3 01:45:41,message,publish,in,4 01:45:38,message,confirm_req,in,164 01:45:37,message,confirm_req,out,249 01:45:38,message,confirm_req,out,3 01:45:39,message,confirm_req,out,6 01:45:41,message,confirm_req,out,3 01:45:37,message,confirm_ack,in,1046 01:45:38,message,confirm_ack,in,141 01:45:39,message,confirm_ack,in,150 01:45:40,message,confirm_ack,in,100 01:45:36,bootstrap,all,out,2 01:45:36,bootstrap,initiate,out,2 01:45:41,bootstrap,initiate,out,1 Troubleshooting UPnP \u00b6 Ensure UPnP is enabled \u00b6 UPnP will be enabled unless the external port is set in either the config [node] ... # The external address of this node (NAT). If not set, the node will request this information via UPnP. # type:string,ip external_address = \"::ffff:<some_public_ipv4>\" or via cli flag --config node.external_address = \"::ffff:<some_public_ipv4>\" Enable UPnP logging \u00b6 Appending this to your launch command will enable upnp logging. --config node.logging.upnp_details = true Error UPnP Messages \u00b6 Check the beginning of the logs for UPNP_* messages Port Mapping Conflict Check for static routes [ 2019 -Oct-29 11 :06:56.641389 ] : UPnP failed 718 : ConflictInMappingEntry [ 2019 -Oct-29 11 :06:56.644387 ] : UPnP failed 718 : ConflictInMappingEntry Normal UPnP Messages \u00b6 [ 2019 -Oct-29 11 :06:56.641389 ] : UPNP_GetSpecificPortMappingEntry failed 714 : NoSuchEntryInArray [ 2019 -Oct-29 11 :06:56.644387 ] : UPNP_GetSpecificPortMappingEntry failed 714 : NoSuchEntryInArray This message is expected when starting the node and will go away after the UPnP has mappeded the port","title":"Troubleshooting"},{"location":"running-a-node/troubleshooting/#troubleshooting","text":"","title":"Troubleshooting"},{"location":"running-a-node/troubleshooting/#log-files","text":"The default location of standard node log files for various systems: OS Location Windows C: \\U sers \\< user> \\A ppData \\L ocal \\N ano \\l og -or- %LOCALAPPDATA% \\N ano \\l og macOS /Users/<user>/Library/Nano/log Linux /home/<user>/Nano/log To get a static file name for the currently active log file, see the stable_log_filename configuration option","title":"Log Files"},{"location":"running-a-node/troubleshooting/#what-to-do-if-the-node-crashes-linux","text":"Do not restart the node If your node crashes, please follow this guide before attempting to run it again. If the node crashes, the most commonly seen message is \"Segmentation fault (core dumped)\". When using docker, this message will only show up in the docker logs. In any case, this is often not enough to go on in terms of figuring out what went wrong. The next steps detail what you should do to provide us with as much information as possible about the problem. When you are done gathering all information, please create a new Github issue , or reach us on Discord in the #support channel, detailing your issue as much as possible. Getting the latest node log The following command will order the log files such that the first one in the output is the most recent. If you restarted the node since the crash, then the relevant log file is not the latest one. Please be careful to give us the relevant log file. # Nano -> NanoBeta if debugging a beta node ls -dlt ~/Nano/log/* | head Please provide the complete log file. Please follow the steps below for the corresponding node version you are using. Should there be an error obtaining the information in a newer version, the older version steps should then be attempted.","title":"What to do if the node crashes (Linux)"},{"location":"running-a-node/troubleshooting/#v21-nodes","text":"Step 1: Make sure addr2line is installed It is likely installed already, consult documentation for your linux distribution if it is not mentioned below: Ubuntu/Debian apt-get install binutils Fedora 22+ dnf install binutils (Optional) Step 2: Save crash dump files The next step will clean up the dump files generated during the crash, if you wish to keep these then save nano_node_backtrace.dump , and all nano_node_crash_load_address_dump_*.txt files. Step 3: Generate crash report Run: ./nano_node --debug_generate_crash_report This will generate a text file nano_node_crash_report.txt please send us the contents of this file.","title":"v21+ nodes"},{"location":"running-a-node/troubleshooting/#v20-nodes","text":"Step 1: Getting dmesg information Depending on the error, it is possible you do not find any useful information in this step, in which case please move on to Step 3. Run the following command and look for nano_node at the end. If you see a relevant message, gather all messages with a similar timestamp - the number within brackets on the left. dmesg Example output: [ 6.336071] IPv6: ADDRCONF(NETDEV_CHANGE): wlp2s0: link becomes ready [ 6.375123] wlp2s0: Limiting TX power to 23 (23 - 0) dBm as advertised by **:**:**:**:**:** [ 6141.711993] show_signal_msg: 23 callbacks suppressed [ 6141.711995] I/O[14487]: segfault at 1 ip 000055c69d3a1634 sp 00007f6e9332df10 error 6 in nano_node[55c69d25f000+70b000] [ 6141.711999] Code: 24 70 48 83 c5 10 48 89 c3 48 39 ef 74 b6 e8 e3 b8 39 00 eb af 90 41 57 41 56 41 55 41 54 49 89 fc 55 53 48 81 ec a8 00 00 00 <c6> 04 25 01 00 00 00 31 64 48 8b 04 25 28 00 00 00 48 89 84 24 98 From this output, only the last 3 lines are relevant. Step 2: Getting syslog information More information might be available in syslog. Run the following command and look for the time the crash ocurred. cat /var/log/syslog Example output: Aug 15 11:56:07 ubuntu-server kernel: [6141.711993] show_signal_msg: 23 callbacks suppressed Aug 15 11:56:07 ubuntu-server kernel: [6141.711995] I/O[25975]: segfault at 1 ip 000055b2960e2d24 sp 00007fcff50f6fc0 error 6 in nano_node[55b295f9b000+6d8000] Aug 15 11:56:07 ubuntu-server kernel: [6141.711999] Code: 24 70 48 83 c5 10 48 89 c3 48 39 ef 74 b6 e8 e3 b8 39 00 eb af 90 41 57 41 56 41 55 41 54 49 89 fc 55 53 48 81 ec a8 00 00 00 <c6> 04 25 01 00 00 00 31 64 48 8b 04 25 28 00 00 00 48 89 84 24 98 Include the relevant lines from the output. In this example, the log is similar to the one from Step 2. Step 3: Getting a backtrace dump This command will produce some basic information about the error. Not using docker : ./nano_node --debug_output_last_backtrace_dump > nano_node_backtrace_output.txt Using docker : mkdir -p /tmp/nano_node_crash && cd $_ docker exec ${ NANO_NAME } nano_node --debug_output_last_backtrace_dump > nano_node_backtrace_output.txt docker exec ${ NANO_NAME } sh -c 'mkdir -p crash_files; mv nano_node_crash*.txt crash_files/' docker cp ${ NANO_NAME } :/crash_files/ . && mv crash_files/* . Step 4: Producing the archive file See the output of this command for the name of the file you should include in your report. FILE = \"nano_node_crash_ $( date + \"%Y-%m-%d_%H-%M-%S.tar.gz\" ) \" && tar czf $FILE --exclude = *.tar.gz nano_node_* && echo \"Created archive $FILE \"","title":"v20 nodes"},{"location":"running-a-node/troubleshooting/#statistics-from-rpc","text":"The \"stats\" RPC command can be used by external processes to query statistics, such as traffic counters. This is useful for diagnostics, monitoring and display in admin consoles. Statistics are optionally logged to separate text files. For implementations details, please see Statistics API Duplicate observer stats Under certain conditions, confirmations seen through the observer type stat can be duplicates. In order to get accurate data, block hashes must be tracked and validated against previously seen hashes.","title":"Statistics from RPC"},{"location":"running-a-node/troubleshooting/#configuration","text":"All configuration nodes and values are optional, with the default values shown in comments below: \"node\" : { ... \"statistics\" : { // Sampli n g co nf igura t io n (op t io nal ) // O nl y ac t iva te i f you nee d sampli n g i nf orma t io n , as t here's some overhead associa te d wi t h t his feature . \"sampling\" : { \"enabled\" : \"true\" , // I f sampli n g is e na bled. De fault false . \"capacity\" : \"5\" , // How ma n y samples t o keep. Mus t be se t i f sampli n g is e na bled. \"interval\" : \"1000\" // Sample i nter val i n milliseco n ds. Mus t be se t i f sampli n g is e na bled. }, // File loggi n g (op t io nal ) \"log\" : { \"interval_counters\" : \"5000\" , // How o ften t o wri te cou nters t o f ile i n milliseco n ds. De fault 0 (o ff ) \"interval_samples\" : \"5000\" , // How o ften t o wri te samples t o f ile , milliseco n ds. De fault 0 (o ff ) \"rotation_count\" : \"5\" , // Ro tate f ile a fter wri t i n g s tat is t ics t his ma n y t imes. De fault 100. \"headers\" : \"true\" , // Wri te header co nta i n i n g log \"filename_counters\" : \"counters.stat\" , \"filename_samples\" : \"samples.stat\" } } }","title":"Configuration"},{"location":"running-a-node/troubleshooting/#available-type-detail-and-direction-values","text":"type: traffic_udp traffic_tcp error message block ledger rollback bootstrap vote election http_callback peering ipc tcp udp confirmation_height confirmation_observer drop aggregator requests filter telemetry details: all // error specific bad_sender insufficient_work http_callback unreachable_host // confirmation_observer specific active_quorum active_conf_height inactive_conf_height // ledger block bootstrap send receive open change state_block epoch_block fork old gap_previous gap_source // message specific keepalive publish republish_vote confirm_req confirm_ack node_id_handshake telemetry_req telemetry_ack // bootstrap callback initiate initiate_lazy initiate_wallet_lazy // bootstrap specific bulk_pull bulk_pull_account bulk_pull_deserialize_receive_block bulk_pull_error_starting_request bulk_pull_failed_account bulk_pull_receive_block_failure bulk_pull_request_failure bulk_push frontier_req frontier_confirmation_failed frontier_confirmation_successful error_socket_close // vote specific vote_valid vote_replay vote_indeterminate vote_invalid vote_overflow // election specific vote_new vote_cached late_block late_block_seconds election_non_priority election_priority election_block_conflict election_difficulty_update election_drop election_restart // udp blocking overflow invalid_magic invalid_network invalid_header invalid_message_type invalid_keepalive_message invalid_publish_message invalid_confirm_req_message invalid_confirm_ack_message invalid_node_id_handshake_message invalid_telemetry_req_message invalid_telemetry_ack_message outdated_version // tcp tcp_accept_success tcp_accept_failure tcp_write_drop tcp_write_no_socket_drop tcp_excluded // ipc invocations // peering handshake // confirmation height blocks_confirmed blocks_confirmed_unbounded blocks_confirmed_bounded invalid_block // [request] aggregator aggregator_accepted aggregator_dropped // requests requests_cached_hashes requests_generated_hashes requests_cached_votes requests_generated_votes requests_cannot_vote requests_unknown // duplicate duplicate_publish // telemetry invalid_signature different_genesis_hash node_id_mismatch request_within_protection_cache_zone no_response_received unsolicited_telemetry_ack failed_send_telemetry_req dir (direction) : in out","title":"Available type, detail and direction values"},{"location":"running-a-node/troubleshooting/#rpc-command","text":"","title":"RPC Command"},{"location":"running-a-node/troubleshooting/#counters-query","text":"{ \"action\" : \"stats\" , \"type\" : \"counters\" }","title":"Counters query:"},{"location":"running-a-node/troubleshooting/#counters-response","text":"{ \"type\" : \"counters\" , \"created\" : \"2018.03.29 01:46:36\" , \"entries\" : [ { \"time\" : \"01:46:36\" , \"type\" : \"traffic\" , \"detail\" : \"all\" , \"dir\" : \"in\" , \"value\" : \"3122792\" }, { \"time\" : \"01:46:36\" , \"type\" : \"traffic\" , \"detail\" : \"all\" , \"dir\" : \"out\" , \"value\" : \"203184\" }, { \"time\" : \"01:46:36\" , \"type\" : \"message\" , \"detail\" : \"all\" , \"dir\" : \"in\" , \"value\" : \"12494\" }, { \"time\" : \"01:46:36\" , \"type\" : \"message\" , \"detail\" : \"all\" , \"dir\" : \"out\" , \"value\" : \"1380\" }, { \"time\" : \"01:46:36\" , \"type\" : \"message\" , \"detail\" : \"keepalive\" , \"dir\" : \"in\" , \"value\" : \"172\" }, ... ] }","title":"Counters response"},{"location":"running-a-node/troubleshooting/#samples-query","text":"{ \"action\" : \"stats\" , \"type\" : \"samples\" }","title":"Samples query:"},{"location":"running-a-node/troubleshooting/#samples-response","text":"{ \"type\" : \"samples\" , \"created\" : \"2018.03.29 01:47:08\" , \"entries\" : [ { \"time\" : \"01:47:04\" , \"type\" : \"traffic\" , \"detail\" : \"all\" , \"dir\" : \"in\" , \"value\" : \"59480\" }, { \"time\" : \"01:47:05\" , \"type\" : \"traffic\" , \"detail\" : \"all\" , \"dir\" : \"in\" , \"value\" : \"44496\" }, { \"time\" : \"01:47:06\" , \"type\" : \"traffic\" , \"detail\" : \"all\" , \"dir\" : \"in\" , \"value\" : \"44136\" }, { \"time\" : \"01:47:07\" , \"type\" : \"traffic\" , \"detail\" : \"all\" , \"dir\" : \"in\" , \"value\" : \"18784\" }, { \"time\" : \"01:47:08\" , \"type\" : \"traffic\" , \"detail\" : \"all\" , \"dir\" : \"in\" , \"value\" : \"22680\" }, { \"time\" : \"01:47:03\" , \"type\" : \"traffic\" , \"detail\" : \"all\" , \"dir\" : \"out\" , \"value\" : \"4128\" }, { \"time\" : \"01:47:04\" , \"type\" : \"message\" , \"detail\" : \"all\" , \"dir\" : \"out\" , \"value\" : \"17\" }, { \"time\" : \"01:47:05\" , \"type\" : \"message\" , \"detail\" : \"all\" , \"dir\" : \"out\" , \"value\" : \"10\" }, ... ] }","title":"Samples response"},{"location":"running-a-node/troubleshooting/#log-file-example","text":"counters.stat As specified in the example config, sampling interval is 1 second, stats are logged every 5 seconds, and the file rotates after 5 log cycles. counters,2018.03.29 01:45:36 01:44:56,bootstrap,all,out,1 01:45:36,bootstrap,initiate,out,2 counters,2018.03.29 01:45:41 01:45:41,traffic,all,in,456344 01:45:41,traffic,all,out,189520 01:45:41,message,all,in,1925 01:45:41,message,all,out,1289 01:45:38,message,keepalive,in,165 01:45:41,message,keepalive,out,1027 01:45:41,message,publish,in,34 01:45:38,message,confirm_req,in,164 01:45:41,message,confirm_req,out,262 01:45:41,message,confirm_ack,in,1562 01:45:36,bootstrap,all,out,2 01:45:41,bootstrap,initiate,out,3 samples.stat As specified in the example config, logging is done every 5 seconds and the sampling capacity is 5 (how many samplings are kept) samples,2018.03.29 01:45:36 01:45:36,bootstrap,initiate,out,2 samples,2018.03.29 01:45:41 01:45:37,traffic,all,in,322608 01:45:38,traffic,all,in,37064 01:45:39,traffic,all,in,38752 01:45:40,traffic,all,in,25632 01:45:38,traffic,all,out,185072 01:45:39,traffic,all,out,3072 01:45:41,traffic,all,out,920 01:45:37,message,all,in,1387 01:45:38,message,all,in,126 01:45:39,message,all,in,179 01:45:40,message,all,in,101 01:45:37,message,all,out,1254 01:45:38,message,all,out,10 01:45:39,message,all,out,16 01:45:41,message,all,out,6 01:45:38,message,keepalive,in,165 01:45:38,message,keepalive,out,1011 01:45:39,message,keepalive,out,12 01:45:41,message,keepalive,out,3 01:45:37,message,publish,in,19 01:45:38,message,publish,in,8 01:45:40,message,publish,in,3 01:45:41,message,publish,in,4 01:45:38,message,confirm_req,in,164 01:45:37,message,confirm_req,out,249 01:45:38,message,confirm_req,out,3 01:45:39,message,confirm_req,out,6 01:45:41,message,confirm_req,out,3 01:45:37,message,confirm_ack,in,1046 01:45:38,message,confirm_ack,in,141 01:45:39,message,confirm_ack,in,150 01:45:40,message,confirm_ack,in,100 01:45:36,bootstrap,all,out,2 01:45:36,bootstrap,initiate,out,2 01:45:41,bootstrap,initiate,out,1","title":"Log file example"},{"location":"running-a-node/troubleshooting/#troubleshooting-upnp","text":"","title":"Troubleshooting UPnP"},{"location":"running-a-node/troubleshooting/#ensure-upnp-is-enabled","text":"UPnP will be enabled unless the external port is set in either the config [node] ... # The external address of this node (NAT). If not set, the node will request this information via UPnP. # type:string,ip external_address = \"::ffff:<some_public_ipv4>\" or via cli flag --config node.external_address = \"::ffff:<some_public_ipv4>\"","title":"Ensure UPnP is enabled"},{"location":"running-a-node/troubleshooting/#enable-upnp-logging","text":"Appending this to your launch command will enable upnp logging. --config node.logging.upnp_details = true","title":"Enable UPnP logging"},{"location":"running-a-node/troubleshooting/#error-upnp-messages","text":"Check the beginning of the logs for UPNP_* messages Port Mapping Conflict Check for static routes [ 2019 -Oct-29 11 :06:56.641389 ] : UPnP failed 718 : ConflictInMappingEntry [ 2019 -Oct-29 11 :06:56.644387 ] : UPnP failed 718 : ConflictInMappingEntry","title":"Error UPnP Messages"},{"location":"running-a-node/troubleshooting/#normal-upnp-messages","text":"[ 2019 -Oct-29 11 :06:56.641389 ] : UPNP_GetSpecificPortMappingEntry failed 714 : NoSuchEntryInArray [ 2019 -Oct-29 11 :06:56.644387 ] : UPNP_GetSpecificPortMappingEntry failed 714 : NoSuchEntryInArray This message is expected when starting the node and will go away after the UPnP has mappeded the port","title":"Normal UPnP Messages"},{"location":"running-a-node/voting-as-a-representative/","text":"Voting as a Representative \u00b6 The default node setup guide provides instructions for getting a non-voting node setup, but if you're looking to run a Representative node , and perhaps hoping to become a Principal Representative , the node will need to be configured to vote and be setup with a Representative account. Join our Technical Update Mailing List Follow this link to sign up for email updates on the latest protocol/node releases and other technical details. This will include network upgrades such as the upcoming epoch distribution: http://eepurl.com/gZucL1 Before getting into the setup instructions, there are a few important considerations: Commitment, security and maintenance \u00b6 Running a Nano Representative is a commitment to helping secure the network. This can only be done if the operation of the node is taken seriously. Prepare for the necessary maintenance on the node and host machine Carefully review the security guide and follow general security best practices at all times Ensure you are prepared for the time and cost commitments of maintaining the node over the long term to help maximize the benefits Hardware recommendations \u00b6 Principal Representative Nodes \u00b6 The following are minimum recommended specifications for nodes with more than 0.1% of the online voting weight ( Principal Representatives ): 4GB RAM Quad-Core CPU 200 Mbps bandwidth (2TB or more of available monthly bandwidth) SSD-based hard drive with 80GB+ of free space Non-voting and Representative Nodes \u00b6 The following are minimum recommended specifications for non-voting nodes and Represntative nodes with less than 0.1% of the online voting weight (regular Representatives ): 2GB RAM (additional RAM or swap space may be needed if bootstrapping a new node from scratch) Dual-Core CPU 100 Mbps bandwidth (2TB or more of available monthly bandwidth) SSD-based hard drive with 80GB+ of free space Varied resource usage Various factors affect resource usage including how often RPC calls are made, other applications running on the machine, etc. These recommendations should be evaluated along with other considerations. Work Generation guide For nodes being used with services requiring regular or high volume sending and receiving of transactions, special considerations must be made for handling Proof-of-Work generation activities. Find details on configuring a GPU, external work services and more for the perfect setup in the Work Generation guide . Step 1: Enable voting \u00b6 For the node to start voting, the following configuration options need to be updated: node.enable_voting \u00b6 As of V18.0, newly setup nodes have voting disabled by default. In order to participate in network consensus, this value must be updated in the config-node.toml file. [node] # Enable or disable voting. Enabling this option requires additional system resources, namely increased CPU, bandwidth and disk usage. # type:bool enable_voting = true rpc.enable \u00b6 To enable communication via RPC, set this configuration option in the config-node.toml file. [rpc] # Enable or disable RPC # type:bool enable = true enable_control \u00b6 This configuration option, which is needed to create the account for the Representative, is set in the config-rpc.toml file. Please make sure you are aware of the sensitive RPC calls enabling this option opens up as detailed on the configuration page . # Enable or disable control-level requests. # WARNING: Enabling this gives anyone with RPC access the ability to stop the node and access wallet funds. # type:bool enable_control = true Step 2: Setup Representative account \u00b6 Add a representative account to a wallet: Use wallet_create RPC, optionally with seed if you already know your representative account\u2019s seed One of the following: wallet_add RPC, if you have a private key and didn\u2019t have a seed before account_create RPC if you had a seed or are creating a new representative account Verify the account is in the wallet with account_list Open the account - until you do account_info and others will fail: Send some funds to the account, at least 0.01 Nano Use search_pending to make the wallet open the account automatically Use account_info to verify the state of the account If the account is still not open, use receive as a backup Step 3: Restart the node and check voting \u00b6 Before the node will vote, the representative account configured above must have at least 1000 Nano delegated to it. This is done by changing the representative of other accounts in your wallet with account_representative_set . If you do not control over 1000 Nano, you will need to have others delegate their weight to your representative. Once you have enough weight, after a few minutes you can search for your representative account on the mynano.ninja site to verify it is voting. Warning - Multiple Node Setups Never use the same seed on multiple running nano_node instances at the same time. Multiple nano_nodes using the same seed can result in network race conditions that degrade performance for your personal accounts. In addition, Publishing transactions from two nodes with the same account at the same time may cause an account fork which requires a slower representative voting process. Similarly, if you are running a representative account on multiple nodes, they may publish conflicting votes, causing your representative to be ignored by the network. Performance degradation in enterprise environments may be significant. Step 4 (Optional): Disable RPC control commands for more security \u00b6 enable_control was only needed to create the account which the Representative uses to vote. It is not actually needed for voting. Therefore there is no need to actually keep it active after the node is prepared for voting. In the config-rpc.toml file, you can disable the control commands again by setting enable_control back to false. # Enable or disable control-level requests. # WARNING: Enabling this gives anyone with RPC access the ability to stop the node and access wallet funds. # type:bool enable_control = false Step 5: Monitoring and more \u00b6 Congratulations on getting your representative setup! If you are able to do a good job maintaining the node and keeping it performing well, you may have a chance at becoming a Principal Representative . To reach this higher level of participation in consensus, you must get at least 0.1% of online voting weight delegated to your node. After that any votes you send for transactions will be rebroadcast by other nodes to help with consensus even more. Once you are comfortable with your node setup and want to connect it to the broader Nano ecosystem, there are a few recommended options: Setup monitoring \u00b6 Details for setting up a popular monitoring service for the node can be found at https://github.com/NanoTools/nanoNodeMonitor . Not only can this provide a website for viewing the status and promoting your representative, but it also provides metrics to popular services in the ecosystem who help monitor the broader network status and performance, such as NanoCrawler.cc and MyNano.ninja . Connect with community services \u00b6 At MyNano.ninja you can also verify your representative and share additional details about your social accounts. Many community members use this service to evaluate representatives which can help you get additional weight if your setup is reliable and well maintained. Ongoing maintenance and support \u00b6 As you continue maintaining your representative there are great community resources available for support: Ask questions in the Node and Representative Management category of the Nano Forum Connect on the Nano Discord server for discussion around node maintenance Join our Technical Updates Mailing List to stay updated on releases, network upgrade details and more","title":"Voting as a Representative"},{"location":"running-a-node/voting-as-a-representative/#voting-as-a-representative","text":"The default node setup guide provides instructions for getting a non-voting node setup, but if you're looking to run a Representative node , and perhaps hoping to become a Principal Representative , the node will need to be configured to vote and be setup with a Representative account.","title":"Voting as a Representative"},{"location":"running-a-node/voting-as-a-representative/#commitment-security-and-maintenance","text":"Running a Nano Representative is a commitment to helping secure the network. This can only be done if the operation of the node is taken seriously. Prepare for the necessary maintenance on the node and host machine Carefully review the security guide and follow general security best practices at all times Ensure you are prepared for the time and cost commitments of maintaining the node over the long term to help maximize the benefits","title":"Commitment, security and maintenance"},{"location":"running-a-node/voting-as-a-representative/#hardware-recommendations","text":"","title":"Hardware recommendations"},{"location":"running-a-node/voting-as-a-representative/#principal-representative-nodes","text":"The following are minimum recommended specifications for nodes with more than 0.1% of the online voting weight ( Principal Representatives ): 4GB RAM Quad-Core CPU 200 Mbps bandwidth (2TB or more of available monthly bandwidth) SSD-based hard drive with 80GB+ of free space","title":"Principal Representative Nodes"},{"location":"running-a-node/voting-as-a-representative/#non-voting-and-representative-nodes","text":"The following are minimum recommended specifications for non-voting nodes and Represntative nodes with less than 0.1% of the online voting weight (regular Representatives ): 2GB RAM (additional RAM or swap space may be needed if bootstrapping a new node from scratch) Dual-Core CPU 100 Mbps bandwidth (2TB or more of available monthly bandwidth) SSD-based hard drive with 80GB+ of free space Varied resource usage Various factors affect resource usage including how often RPC calls are made, other applications running on the machine, etc. These recommendations should be evaluated along with other considerations. Work Generation guide For nodes being used with services requiring regular or high volume sending and receiving of transactions, special considerations must be made for handling Proof-of-Work generation activities. Find details on configuring a GPU, external work services and more for the perfect setup in the Work Generation guide .","title":"Non-voting and Representative Nodes"},{"location":"running-a-node/voting-as-a-representative/#step-1-enable-voting","text":"For the node to start voting, the following configuration options need to be updated:","title":"Step 1: Enable voting"},{"location":"running-a-node/voting-as-a-representative/#nodeenable_voting","text":"As of V18.0, newly setup nodes have voting disabled by default. In order to participate in network consensus, this value must be updated in the config-node.toml file. [node] # Enable or disable voting. Enabling this option requires additional system resources, namely increased CPU, bandwidth and disk usage. # type:bool enable_voting = true","title":"node.enable_voting"},{"location":"running-a-node/voting-as-a-representative/#rpcenable","text":"To enable communication via RPC, set this configuration option in the config-node.toml file. [rpc] # Enable or disable RPC # type:bool enable = true","title":"rpc.enable"},{"location":"running-a-node/voting-as-a-representative/#enable_control","text":"This configuration option, which is needed to create the account for the Representative, is set in the config-rpc.toml file. Please make sure you are aware of the sensitive RPC calls enabling this option opens up as detailed on the configuration page . # Enable or disable control-level requests. # WARNING: Enabling this gives anyone with RPC access the ability to stop the node and access wallet funds. # type:bool enable_control = true","title":"enable_control"},{"location":"running-a-node/voting-as-a-representative/#step-2-setup-representative-account","text":"Add a representative account to a wallet: Use wallet_create RPC, optionally with seed if you already know your representative account\u2019s seed One of the following: wallet_add RPC, if you have a private key and didn\u2019t have a seed before account_create RPC if you had a seed or are creating a new representative account Verify the account is in the wallet with account_list Open the account - until you do account_info and others will fail: Send some funds to the account, at least 0.01 Nano Use search_pending to make the wallet open the account automatically Use account_info to verify the state of the account If the account is still not open, use receive as a backup","title":"Step 2: Setup Representative account"},{"location":"running-a-node/voting-as-a-representative/#step-3-restart-the-node-and-check-voting","text":"Before the node will vote, the representative account configured above must have at least 1000 Nano delegated to it. This is done by changing the representative of other accounts in your wallet with account_representative_set . If you do not control over 1000 Nano, you will need to have others delegate their weight to your representative. Once you have enough weight, after a few minutes you can search for your representative account on the mynano.ninja site to verify it is voting. Warning - Multiple Node Setups Never use the same seed on multiple running nano_node instances at the same time. Multiple nano_nodes using the same seed can result in network race conditions that degrade performance for your personal accounts. In addition, Publishing transactions from two nodes with the same account at the same time may cause an account fork which requires a slower representative voting process. Similarly, if you are running a representative account on multiple nodes, they may publish conflicting votes, causing your representative to be ignored by the network. Performance degradation in enterprise environments may be significant.","title":"Step 3: Restart the node and check voting"},{"location":"running-a-node/voting-as-a-representative/#step-4-optional-disable-rpc-control-commands-for-more-security","text":"enable_control was only needed to create the account which the Representative uses to vote. It is not actually needed for voting. Therefore there is no need to actually keep it active after the node is prepared for voting. In the config-rpc.toml file, you can disable the control commands again by setting enable_control back to false. # Enable or disable control-level requests. # WARNING: Enabling this gives anyone with RPC access the ability to stop the node and access wallet funds. # type:bool enable_control = false","title":"Step 4 (Optional): Disable RPC control commands for more security"},{"location":"running-a-node/voting-as-a-representative/#step-5-monitoring-and-more","text":"Congratulations on getting your representative setup! If you are able to do a good job maintaining the node and keeping it performing well, you may have a chance at becoming a Principal Representative . To reach this higher level of participation in consensus, you must get at least 0.1% of online voting weight delegated to your node. After that any votes you send for transactions will be rebroadcast by other nodes to help with consensus even more. Once you are comfortable with your node setup and want to connect it to the broader Nano ecosystem, there are a few recommended options:","title":"Step 5: Monitoring and more"},{"location":"running-a-node/voting-as-a-representative/#setup-monitoring","text":"Details for setting up a popular monitoring service for the node can be found at https://github.com/NanoTools/nanoNodeMonitor . Not only can this provide a website for viewing the status and promoting your representative, but it also provides metrics to popular services in the ecosystem who help monitor the broader network status and performance, such as NanoCrawler.cc and MyNano.ninja .","title":"Setup monitoring"},{"location":"running-a-node/voting-as-a-representative/#connect-with-community-services","text":"At MyNano.ninja you can also verify your representative and share additional details about your social accounts. Many community members use this service to evaluate representatives which can help you get additional weight if your setup is reliable and well maintained.","title":"Connect with community services"},{"location":"running-a-node/voting-as-a-representative/#ongoing-maintenance-and-support","text":"As you continue maintaining your representative there are great community resources available for support: Ask questions in the Node and Representative Management category of the Nano Forum Connect on the Nano Discord server for discussion around node maintenance Join our Technical Updates Mailing List to stay updated on releases, network upgrade details and more","title":"Ongoing maintenance and support"},{"location":"snippets/alternative-work-generation-setup-preferred/","text":"Alternative work generation setup preferred Due to potential performance impacts to nodes participating on the network (voting, staying in sync, etc.), when possible this option should be updated to a value of 0 to turn off local work generation. Please see the Work Generation guide for best practices.","title":"Alternative work generation setup preferred"},{"location":"snippets/beta-directory-locations/","text":"OS Location Windows C: \\U sers \\< user> \\A ppData \\L ocal \\N anoBeta \\ macOS /Users/<user>/Library/NanoBeta/ Linux /home/<user>/NanoBeta/","title":"Beta directory locations"},{"location":"snippets/beta-network-details-simple/","text":"Beta Network Ports Overview 54000 TCP: For live network activity and bootstrap network activity 55000 TCP: For communication with RPC server. Anyone with access to this port can control your node's RPC. 57000 TCP: For communication with websocket server . Depending on configuration, data throughput can be very high.","title":"Beta network details simple"},{"location":"snippets/community-links/","text":"Nano.org | Forum | GitHub | Twitter | Discord | Reddit | Medium Facebook | LinkedIn | YouTube | Instagram","title":"Community links"},{"location":"snippets/config-node-option-node-enable-voting-true/","text":"node.enable_voting \u00b6 As of V18.0, newly setup nodes have voting disabled by default. In order to participate in network consensus, this value must be updated in the config-node.toml file. [node] # Enable or disable voting. Enabling this option requires additional system resources, namely increased CPU, bandwidth and disk usage. # type:bool enable_voting = true","title":"Config node option node enable voting true"},{"location":"snippets/config-node-option-node-enable-voting-true/#nodeenable_voting","text":"As of V18.0, newly setup nodes have voting disabled by default. In order to participate in network consensus, this value must be updated in the config-node.toml file. [node] # Enable or disable voting. Enabling this option requires additional system resources, namely increased CPU, bandwidth and disk usage. # type:bool enable_voting = true","title":"node.enable_voting"},{"location":"snippets/config-node-option-rpc-enable-true/","text":"rpc.enable \u00b6 To enable communication via RPC, set this configuration option in the config-node.toml file. [rpc] # Enable or disable RPC # type:bool enable = true","title":"Config node option rpc enable true"},{"location":"snippets/config-node-option-rpc-enable-true/#rpcenable","text":"To enable communication via RPC, set this configuration option in the config-node.toml file. [rpc] # Enable or disable RPC # type:bool enable = true","title":"rpc.enable"},{"location":"snippets/contributing-code/","text":"Contributing to the code If you are interested in helping develop the C++ based Nano node we will help you out! Check out our details on contributing code to the Nano node to get started.","title":"Contributing code"},{"location":"snippets/current-beta-build-links/","text":"OS Version Download link/command Linux V21.1RC1 https://repo.nano.org/beta/binaries/nano-node-V21.1RC1-Linux.tar.bz2 macOS V21.1RC1 https://repo.nano.org/beta/binaries/nano-node-V21.1RC1-Darwin.dmg Windows V21.1RC1 https://repo.nano.org/beta/binaries/nano-node-V21.1RC1-win64.exe Docker V21.1RC1 docker pull nanocurrency/nano-beta:V21.1RC1 or docker pull nanocurrency/nano-beta:latest See Pulling the Docker Image for more details.","title":"Current beta build links"},{"location":"snippets/current-release-build-links/","text":"OS Download link/command Verification Universal Linux https://repo.nano.org/live/binaries/nano-node-V21.2-Linux.tar.bz2 SHA256 Checksum Debian http://repo.nano.org/live/binaries/nano-node-V21.2-Linux.deb SHA256 Checksum macOS https://repo.nano.org/live/binaries/nano-node-V21.2-Darwin.dmg SHA256 Checksum Windows (exe) https://repo.nano.org/live/binaries/nano-node-V21.2-win64.exe SHA256 Checksum Windows (zip) https://repo.nano.org/live/binaries/nano-node-V21.2-win64.zip SHA256 Checksum Docker docker pull nanocurrency/nano:V21.2 or docker pull nanocurrency/nano:latest See Pulling the Docker Image for more details. RHEL/CentOS rpm sudo rpm -iUvh https://repo.nano.org/live/binaries/nanocurrency-21.2-21.el7.x86_64.rpm This installs nano_node and nano_rpc to /usr/bin . SHA256 Checksum","title":"Current release build links"},{"location":"snippets/current-test-build-links/","text":"OS Version Download link/command Linux V22.0DB6 https://repo.nano.org/test/binaries/nano-node-V22.0DB6-Linux.tar.bz2 macOS V22.0DB6 https://repo.nano.org/test/binaries/nano-node-V22.0DB6-Darwin.dmg Windows V22.0DB6 https://repo.nano.org/test/binaries/nano-node-V22.0DB6-win64.exe Docker V22.0DB6 docker pull nanocurrency/nano-test:V22.0DB6 or docker pull nanocurrency/nano-test:latest See Pulling the Docker Image for more details.","title":"Current test build links"},{"location":"snippets/debug-only-command/","text":"Debug purposes only This call is for internal diagnostics/debug purposes only. Do not rely on this interface being stable and do not use in a production system.","title":"Debug only command"},{"location":"snippets/dedicated-representative-nodes/","text":"Dedicated Representative nodes recommended Due to the resources needed to participate in the voting process, it is recommended that any node setup as a Representative should be dedicated to generating consensus . If the resources of the Representative are used for other activities, such as application integrations or , it reduces the potential benefit that node brings to the network.","title":"Dedicated representative nodes"},{"location":"snippets/directory-contents/","text":"The Nano directory contains: wallets file ( wallets.ldb ), log files , optional config files, ledger file (data.ldb) and related lock files. Protect wallet and backup files The built-in node wallet is for use in development and testing only. Those using it should take care in protecting access to the wallets.ldb file and backup files, whether encrypted or not, for added security.","title":"Directory contents"},{"location":"snippets/directory-locations/","text":"OS Location Windows C: \\U sers \\< user> \\A ppData \\L ocal \\N ano \\ macOS /Users/<user>/Library/Nano/ Linux /home/<user>/Nano/","title":"Directory locations"},{"location":"snippets/docker-limitations/","text":"Docker Limitations Although Docker is a great choice for many setups, there are some limitations to be aware of: It is not recommended to run a *nix container, such as the officially provided one, on a Windows host - there are known issues with handling ports which prevent proper communication with peers. V19 and lower: Due to the startup script built into the Docker containers, Launch Options for the nano_node service run inside the container cannot be easily used. These options are available as of V20.","title":"Docker limitations"},{"location":"snippets/enable-control-warning/","text":"Dangerous RPC calls controlled by enable_control This RPC command/option requires enable_control to be enabled within the RPC config file. Enabling this means that anyone with access to the RPC port could potentially access wallet funds , stop the node from running and take other dangerous actions. Use caution when enabling this option, especially with external RPC access available. For more details see the Node Security page .","title":"Enable control warning"},{"location":"snippets/enable-voting/","text":"Enable Voting When setting up a new node, voting is disabled by default in the configuration file and must be manually enabled in order to participate in consensus. See enable_voting configuration option for more details.","title":"Enable voting"},{"location":"snippets/external-libraries-warning/","text":"External libraries, review before using The linked resources below contain code dealing with private key management and/or execution of transactions. The Nano Foundation does not control this code, does not endorse it and is not responsible for its use. Use of this code requires review and is at your own discretion.","title":"External libraries warning"},{"location":"snippets/hardware-recommendations/","text":"Principal Representative Nodes \u00b6 The following are minimum recommended specifications for nodes with more than 0.1% of the online voting weight ( Principal Representatives ): 4GB RAM Quad-Core CPU 200 Mbps bandwidth (2TB or more of available monthly bandwidth) SSD-based hard drive with 80GB+ of free space Non-voting and Representative Nodes \u00b6 The following are minimum recommended specifications for non-voting nodes and Represntative nodes with less than 0.1% of the online voting weight (regular Representatives ): 2GB RAM (additional RAM or swap space may be needed if bootstrapping a new node from scratch) Dual-Core CPU 100 Mbps bandwidth (2TB or more of available monthly bandwidth) SSD-based hard drive with 80GB+ of free space Varied resource usage Various factors affect resource usage including how often RPC calls are made, other applications running on the machine, etc. These recommendations should be evaluated along with other considerations. Work Generation guide For nodes being used with services requiring regular or high volume sending and receiving of transactions, special considerations must be made for handling Proof-of-Work generation activities. Find details on configuring a GPU, external work services and more for the perfect setup in the Work Generation guide .","title":"Hardware recommendations"},{"location":"snippets/hardware-recommendations/#principal-representative-nodes","text":"The following are minimum recommended specifications for nodes with more than 0.1% of the online voting weight ( Principal Representatives ): 4GB RAM Quad-Core CPU 200 Mbps bandwidth (2TB or more of available monthly bandwidth) SSD-based hard drive with 80GB+ of free space","title":"Principal Representative Nodes"},{"location":"snippets/hardware-recommendations/#non-voting-and-representative-nodes","text":"The following are minimum recommended specifications for non-voting nodes and Represntative nodes with less than 0.1% of the online voting weight (regular Representatives ): 2GB RAM (additional RAM or swap space may be needed if bootstrapping a new node from scratch) Dual-Core CPU 100 Mbps bandwidth (2TB or more of available monthly bandwidth) SSD-based hard drive with 80GB+ of free space Varied resource usage Various factors affect resource usage including how often RPC calls are made, other applications running on the machine, etc. These recommendations should be evaluated along with other considerations. Work Generation guide For nodes being used with services requiring regular or high volume sending and receiving of transactions, special considerations must be made for handling Proof-of-Work generation activities. Find details on configuring a GPU, external work services and more for the perfect setup in the Work Generation guide .","title":"Non-voting and Representative Nodes"},{"location":"snippets/includes-unconfirmed/","text":"Includes unconfirmed blocks This call may return results that include unconfirmed blocks, so it should not be used in any processes or integrations requiring only details from blocks confirmed by the network.","title":"Includes unconfirmed"},{"location":"snippets/join-technical-mailing-list/","text":"Join our Technical Update Mailing List Follow this link to sign up for email updates on the latest protocol/node releases and other technical details. This will include network upgrades such as the upcoming epoch distribution: http://eepurl.com/gZucL1","title":"Join technical mailing list"},{"location":"snippets/known-issue-macos-too-many-open-files/","text":"Known Issue V19+: macOS 'Too many open files' Issue: The following error can be seen when attempting to run a full node on macOS using the built-in Qt wallet or other GUI-based wallets: \"Exception while running wallet: open: Too many open files\". This is due to macOS having a very low default file descriptor limit and V19.0 uses more of them after the move to TCP. Solution: For now a workaround is needed to increase the limit. The method depends on the specific macOS version, but some people had success with the recipe in https://superuser.com/a/1171028 .","title":"Known issue macos too many open files"},{"location":"snippets/known-issue-peers-stake-reporting/","text":"Known Issue V20: Peers stake reporting inaccurate (Windows only) Issue: For Windows builds only, when calling confirmation_quorum RPC the peers_stake_total amount returned may be inaccurate, returning a range from the correct full peer stake amount down to 0. Solution: A solution to the issue has been found and as this is a reporting issue only, the fix will be included in the next released version. For those manually building the node, patching the fix pull request onto the V20.0 tag can resolve the issue now. Or alternatively, building on the V20.0 tag with RelWithDebInfo option, see Build Instructions for Windows .","title":"Known issue peers stake reporting"},{"location":"snippets/known-issue-unable-to-find-libboost/","text":"Known Issue Linux V21: 'unable to find libboost' If you are on Linux and unable to get V21.0 to start, unable to find libboost... https://github.com/nanocurrency/nano-node/releases/download/V21.0/nano-node-V21.0.1-Linux.tar.bz2 has been added to the release artifacts with the correct lib rpath. Please use this if you do not wish to move the lib folder into the bin folder after extraction.","title":"Known issue unable to find libboost"},{"location":"snippets/known-issue-windows-logging-stable/","text":"Known Issue Windows V21: Crash when using config node.logging.stable_log_filename Setting node.logging.stable_log_filename configuration option to true results in a node crash on Windows in V21.0 and V21.1, after a node restart. This must be set to false .","title":"Known issue windows logging stable"},{"location":"snippets/multiple-confirmation-notifications/","text":"Multiple notifications for blocks Depending on the node setup and sync status, multiple confirmation notifications for the same block hash may be sent by a single tracking mechanism. In order to prevent potential issues, integrations must track these block hashes externally to the node and prevent any unwanted actions based on multiple notifications.","title":"Multiple confirmation notifications"},{"location":"snippets/multiple-node-setups-warning/","text":"Warning - Multiple Node Setups Never use the same seed on multiple running nano_node instances at the same time. Multiple nano_nodes using the same seed can result in network race conditions that degrade performance for your personal accounts. In addition, Publishing transactions from two nodes with the same account at the same time may cause an account fork which requires a slower representative voting process. Similarly, if you are running a representative account on multiple nodes, they may publish conflicting votes, causing your representative to be ignored by the network. Performance degradation in enterprise environments may be significant.","title":"Multiple node setups warning"},{"location":"snippets/network-details-simple/","text":"Network Ports Overview 7075 TCP: For live network activity (since V19.0) and bootstrap network activity 7076 TCP: For communication with RPC server. Do not expose this outside of your production environment. Anyone with access to this port can control your node's RPC. 7078 TCP: For communication with websocket server . Depending on configuration, data throughput can be very high. 7075 UDP: For live network activity (fallback since V19.0, deprecated and disabled V21+) UDP disabled by default, deprecated As of V21 peering and communicating via UDP has been disabled by default and is deprecated. The ability to use UDP will be removed from the node in a future release yet to be determined.","title":"Network details simple"},{"location":"snippets/network-details/","text":"Network Details \u00b6 Port Type Default Details 7075 TCP Enabled Node bootstrapping server Share port configuration in config-node.toml , option node.peering_port Binds to all adapters; unicast Contents: Raw nano protocol stream Transmits the ledger to new nodes in bulk If blocked other nodes will not be able retrieve the ledger from this node 7076 TCP Disabled RPC server Port configurable in config-rpc.toml , option rpc.port Enable in config-node.toml , option rpc.enable or by starting nano_rpc manually Binds to localhost by default for security reasons, configurable in config-rpc.toml , option rpc.address ; unicast Contents: Unencrypted HTTP requests containing JSON object bodies Allows the node to be queried or controlled through HTTP requests If blocked the node will not be able to be queried or controlled by HTTP WARNING: Exposing this port externally while setting enable_control option to true in configs could expose your wallet, allow the node to be stopped remotely and open your node up to other dangerous activity. See the Node Security page for more details. 7078 TCP Disabled Websocket server Port configurable in config-node.toml , option node.websocket.port Enable in config-node.toml , option node.websocket.enable Binds to localhost by default due to data throughput potentially being very high; producer-subscriber broadcast Contents: Standard websocket frames containing JSON-encoded objects See WebSocket Support for details on configuration 7075 UDP Disabled Deprecated (V21+) Previously this was the node activity port (deprecated in V21) Port configurable in config-node.toml , option node.peering_port Binds to all adapters; unicast Contents: Raw nano protocol datagrams All standard ledger activity goes through this port If blocked the node will not function UDP disabled by default, deprecated As of V21 peering and communicating via UDP has been disabled by default and is deprecated. The ability to use UDP will be removed from the node in a future release yet to be determined.","title":"Network details"},{"location":"snippets/network-details/#network-details","text":"Port Type Default Details 7075 TCP Enabled Node bootstrapping server Share port configuration in config-node.toml , option node.peering_port Binds to all adapters; unicast Contents: Raw nano protocol stream Transmits the ledger to new nodes in bulk If blocked other nodes will not be able retrieve the ledger from this node 7076 TCP Disabled RPC server Port configurable in config-rpc.toml , option rpc.port Enable in config-node.toml , option rpc.enable or by starting nano_rpc manually Binds to localhost by default for security reasons, configurable in config-rpc.toml , option rpc.address ; unicast Contents: Unencrypted HTTP requests containing JSON object bodies Allows the node to be queried or controlled through HTTP requests If blocked the node will not be able to be queried or controlled by HTTP WARNING: Exposing this port externally while setting enable_control option to true in configs could expose your wallet, allow the node to be stopped remotely and open your node up to other dangerous activity. See the Node Security page for more details. 7078 TCP Disabled Websocket server Port configurable in config-node.toml , option node.websocket.port Enable in config-node.toml , option node.websocket.enable Binds to localhost by default due to data throughput potentially being very high; producer-subscriber broadcast Contents: Standard websocket frames containing JSON-encoded objects See WebSocket Support for details on configuration 7075 UDP Disabled Deprecated (V21+) Previously this was the node activity port (deprecated in V21) Port configurable in config-node.toml , option node.peering_port Binds to all adapters; unicast Contents: Raw nano protocol datagrams All standard ledger activity goes through this port If blocked the node will not function UDP disabled by default, deprecated As of V21 peering and communicating via UDP has been disabled by default and is deprecated. The ability to use UDP will be removed from the node in a future release yet to be determined.","title":"Network Details"},{"location":"snippets/only-official-builds-supported/","text":"Only Official Builds Supported The fastest and most recommended method of installation is through Docker management Only official release builds are recommended and supported for use on the main network Builds created from git should be done using the available release tags ( V21.2 etc.)","title":"Only official builds supported"},{"location":"snippets/process-sub-type-recommended/","text":"Including subtype in process RPC calls highly recommended In order to avoid potential incorrect sends including the optional subtype parameter on all process RPC calls is highly recommended . In the next version of the RPC this parameter will be required.","title":"Process sub type recommended"},{"location":"snippets/release-details-v18-0/","text":"Node Protocol Database Release Date Release Notes GitHub Links 18.0 16 13 2019-02-21 Release - Milestone - Changelog","title":"Release details v18 0"},{"location":"snippets/release-details-v19-0/","text":"Node Protocol Database Release Date Release Notes GitHub Links 19.0 17 14 2019-07-11 V19.0 Release - Milestone - Changelog Known Issue V19+: macOS 'Too many open files' Issue: The following error can be seen when attempting to run a full node on macOS using the built-in Qt wallet or other GUI-based wallets: \"Exception while running wallet: open: Too many open files\". This is due to macOS having a very low default file descriptor limit and V19.0 uses more of them after the move to TCP. Solution: For now a workaround is needed to increase the limit. The method depends on the specific macOS version, but some people had success with the recipe in https://superuser.com/a/1171028 .","title":"Release details v19 0"},{"location":"snippets/release-details-v20-0/","text":"Node Protocol Database Release Date Release Notes GitHub Links 20.0 17 15 2019-11-12 V20.0 Release - Milestone - Changelog Known Issue V19+: macOS 'Too many open files' Issue: The following error can be seen when attempting to run a full node on macOS using the built-in Qt wallet or other GUI-based wallets: \"Exception while running wallet: open: Too many open files\". This is due to macOS having a very low default file descriptor limit and V19.0 uses more of them after the move to TCP. Solution: For now a workaround is needed to increase the limit. The method depends on the specific macOS version, but some people had success with the recipe in https://superuser.com/a/1171028 . Known Issue V20: Peers stake reporting inaccurate (Windows only) Issue: For Windows builds only, when calling confirmation_quorum RPC the peers_stake_total amount returned may be inaccurate, returning a range from the correct full peer stake amount down to 0. Solution: A solution to the issue has been found and as this is a reporting issue only, the fix will be included in the next released version. For those manually building the node, patching the fix pull request onto the V20.0 tag can resolve the issue now. Or alternatively, building on the V20.0 tag with RelWithDebInfo option, see Build Instructions for Windows .","title":"Release details v20 0"},{"location":"snippets/release-details-v21-0/","text":"Node Protocol Database Release Date Release Notes GitHub Links 21.0 18 18 2020-06-16 V21.0 Release - Milestone - Changelog Known Issue V19+: macOS 'Too many open files' Issue: The following error can be seen when attempting to run a full node on macOS using the built-in Qt wallet or other GUI-based wallets: \"Exception while running wallet: open: Too many open files\". This is due to macOS having a very low default file descriptor limit and V19.0 uses more of them after the move to TCP. Solution: For now a workaround is needed to increase the limit. The method depends on the specific macOS version, but some people had success with the recipe in https://superuser.com/a/1171028 . Known Issue Linux V21: 'unable to find libboost' If you are on Linux and unable to get V21.0 to start, unable to find libboost... https://github.com/nanocurrency/nano-node/releases/download/V21.0/nano-node-V21.0.1-Linux.tar.bz2 has been added to the release artifacts with the correct lib rpath. Please use this if you do not wish to move the lib folder into the bin folder after extraction. Known Issue Windows V21: Crash when using config node.logging.stable_log_filename Setting node.logging.stable_log_filename configuration option to true results in a node crash on Windows in V21.0 and V21.1, after a node restart. This must be set to false .","title":"Release details v21 0"},{"location":"snippets/release-details-v21-1/","text":"Node Protocol Database Release Date Release Notes GitHub Links 21.1 18 18 2020-07-14 V21.1 Release - Milestone - Changelog Known Issue V19+: macOS 'Too many open files' Issue: The following error can be seen when attempting to run a full node on macOS using the built-in Qt wallet or other GUI-based wallets: \"Exception while running wallet: open: Too many open files\". This is due to macOS having a very low default file descriptor limit and V19.0 uses more of them after the move to TCP. Solution: For now a workaround is needed to increase the limit. The method depends on the specific macOS version, but some people had success with the recipe in https://superuser.com/a/1171028 . Known Issue Windows V21: Crash when using config node.logging.stable_log_filename Setting node.logging.stable_log_filename configuration option to true results in a node crash on Windows in V21.0 and V21.1, after a node restart. This must be set to false .","title":"Release details v21 1"},{"location":"snippets/release-details-v21-2/","text":"Node Protocol Database Release Date Release Notes GitHub Links 21.2 18 18 2020-09-03 V21.2 Release - Milestone - Changelog Known Issue V19+: macOS 'Too many open files' Issue: The following error can be seen when attempting to run a full node on macOS using the built-in Qt wallet or other GUI-based wallets: \"Exception while running wallet: open: Too many open files\". This is due to macOS having a very low default file descriptor limit and V19.0 uses more of them after the move to TCP. Solution: For now a workaround is needed to increase the limit. The method depends on the specific macOS version, but some people had success with the recipe in https://superuser.com/a/1171028 .","title":"Release details v21 2"},{"location":"snippets/release-details-v22-0/","text":"Node Protocol Database Release Date Release Notes GitHub Links 22.0 TBD TBD TBD TBD Release - Milestone - Changelog","title":"Release details v22 0"},{"location":"snippets/rpc_include_only_confirmed_recommended/","text":"Optional include_only_confirmed recommended By default this will return blocks not in active elections but unconfirmed (e.g., block was received but node was restarted, election was dropped, new ledger with reset confirmation height). To avoid potential issues related to these situations setting the include_only_confirmed = true is recommended for most use cases.","title":"Rpc include only confirmed recommended"},{"location":"snippets/setup-beta-test-testing/","text":"Setup for testing on beta or test network If you are looking to test the latest version of the node ahead of release, check out the Beta Network and Test Network pages for more details about how to get setup on the appropriate network. Typically general integration and node upgrades are tested on the public test network, while new feature and load testing are conducted on the beta network.","title":"Setup beta test testing"},{"location":"snippets/telemetry-can-be-forged/","text":"Telemetry can be forged Although the telemetry messages are signed by nodes, the data provided by other peers can be forged by malicious nodes so they cannot be guaranteed as accurate. All details in these messages should be used as rough indicators of peer and broad network situations, but not exclusively relied on for any key integration or network activities.","title":"Telemetry can be forged"},{"location":"snippets/terms-block-transaction-transfer/","text":"block is the digital encoding of the transaction details. transaction is the action of creating and publishing a block to the network. Depending on the type of transaction, the block will have different requirements. transfer is the completion of both a send transaction and the corresponding receive transaction, representing the movement of funds which can be sent again by the recipient.","title":"Terms block transaction transfer"},{"location":"snippets/test-directory-locations/","text":"OS Location Windows C: \\U sers \\< user> \\A ppData \\L ocal \\N anoTest \\ macOS /Users/<user>/Library/NanoTest/ Linux /home/<user>/NanoTest/","title":"Test directory locations"},{"location":"snippets/test-network-details-simple/","text":"Test Network Ports Overview 17075 TCP: For live network activity and bootstrap network activity 17076 TCP: For communication with RPC server. Anyone with access to this port can control your node's RPC. 17078 TCP: For communication with websocket server . Depending on configuration, data throughput can be very high.","title":"Test network details simple"},{"location":"snippets/toml-config-commands/","text":"Name Description Generated with config-node.toml Node configuration nano_node --generate_config node config-rpc.toml RPC configuration nano_node --generate_config rpc config-nano-pow-server.toml Proof of work server configuration nano_pow_server --generate_config config-qtwallet.toml Qt developer wallet configuration This file is maintained by the Qt wallet","title":"Toml config commands"},{"location":"snippets/udp-deprecated/","text":"UDP disabled by default, deprecated As of V21 peering and communicating via UDP has been disabled by default and is deprecated. The ability to use UDP will be removed from the node in a future release yet to be determined.","title":"Udp deprecated"},{"location":"snippets/unconfirmed-information/","text":"Unconfirmed information This call returns information that may be based on unconfirmed blocks. These details should not be relied on for any process or integration that requires confirmed blocks.","title":"Unconfirmed information"},{"location":"snippets/unsupported-configuration/","text":"Unsupported configuration This documentation is intended only for developers of the Nano Node software, and will not result in a supported configuration. End-users are advised to use releases. The fastest and most recommended method of installation is through Docker . Running node as a service . To manage a node, use RPC commands or the CLI .","title":"Unsupported configuration"},{"location":"snippets/wip-living-whitepaper/","text":"Part of work in progress Living Whitepaper This page is part of the Living Whitepaper revisions currently underway to replace the original static whitepaper. These efforts include the Protocol Design and Node Implementation sections of the docs, which will cover and expand on details and topics covered in the original whitepaper . See the bottom of the page for related whitepaper sections and other related details. Some of the sections and headers on this page may be in draft form or just suggestions/framework for later consideration. If you are interested in helping with revisions please connect with us on the #documentation channel on our Discord server .","title":"Wip living whitepaper"},{"location":"what-is-nano/living-whitepaper/","text":"Nano - Digital money for the modern world \u00b6 Part of work in progress Living Whitepaper This page is part of the Living Whitepaper revisions currently underway to replace the original static whitepaper. These efforts include the Protocol Design and Node Implementation sections of the docs, which will cover and expand on details and topics covered in the original whitepaper . See the bottom of the page for related whitepaper sections and other related details. Some of the sections and headers on this page may be in draft form or just suggestions/framework for later consideration. If you are interested in helping with revisions please connect with us on the #documentation channel on our Discord server . Contributing to the code If you are interested in helping develop the C++ based Nano node we will help you out! Check out our details on contributing code to the Nano node to get started. The original whitepaper for Nano was last updated in November 2017 and since then many improvements to the protocol have been made. The current node implementation has received updates every few months on average over 2018 and 2019. 1 As these updates continue to make the network stronger over time, the static nature of a traditional whitepaper required too much effort to continually update and publish. To ensure information about Nano is kept as up-to-date as possible, a new \"Living Whitepaper\" is being managed through the existing documentation website, which is easier to update and is open source. 2 Protocol vs. Node \u00b6 The two main sections of the Living Whitepaper are the Protocol Design and Node Implementation . Although they were structured to split the required elements to conform to the protocol (Protocol Design) away from optional improvements built into the current node (Node Implementation), there is some overlap between them. Where possible these overlaps have been highlighted; however, those interested in contributing to the development of the protocol or building another node implementation should analyze more closely the differences between these to ensure the necessary rules are followed. Protocol Design \u00b6 This section contains details of the different messages shared between nodes and common data structures which allow data to be stored and communicated consistently across the network. Because Nano is decentralized and uses network-wide consensus to validate transactions, participating on the network requires following the message and data designs, otherwise attempts at transacting will be ignored or not properly confirmed by the network. Many changes done to elements outlined here require a change in the protocol version in addition to the node version . Node Implementation \u00b6 This section expands into methods and mechanisms built into the current node software that aren't required for compliance with protocol rules, but help provide better efficiency and performance for nodes running on the network. These details could be ignored or implemented in different ways by different types or versions of node software, while still maintaining compatibility with other nodes. Existing whitepaper sections related to this page: Introduction Background Other existing content related to this page: Nano Overview Representatives and Voting Incentives to run a node Node Releases: https://docs.nano.org/releases/node-releases/ \u21a9 Nano Documentation Repository: https://github.com/nanocurrency/nano-docs/ \u21a9","title":"Living Whitepaper"},{"location":"what-is-nano/living-whitepaper/#nano-digital-money-for-the-modern-world","text":"Part of work in progress Living Whitepaper This page is part of the Living Whitepaper revisions currently underway to replace the original static whitepaper. These efforts include the Protocol Design and Node Implementation sections of the docs, which will cover and expand on details and topics covered in the original whitepaper . See the bottom of the page for related whitepaper sections and other related details. Some of the sections and headers on this page may be in draft form or just suggestions/framework for later consideration. If you are interested in helping with revisions please connect with us on the #documentation channel on our Discord server . Contributing to the code If you are interested in helping develop the C++ based Nano node we will help you out! Check out our details on contributing code to the Nano node to get started. The original whitepaper for Nano was last updated in November 2017 and since then many improvements to the protocol have been made. The current node implementation has received updates every few months on average over 2018 and 2019. 1 As these updates continue to make the network stronger over time, the static nature of a traditional whitepaper required too much effort to continually update and publish. To ensure information about Nano is kept as up-to-date as possible, a new \"Living Whitepaper\" is being managed through the existing documentation website, which is easier to update and is open source. 2","title":"Nano - Digital money for the modern world"},{"location":"what-is-nano/living-whitepaper/#protocol-vs-node","text":"The two main sections of the Living Whitepaper are the Protocol Design and Node Implementation . Although they were structured to split the required elements to conform to the protocol (Protocol Design) away from optional improvements built into the current node (Node Implementation), there is some overlap between them. Where possible these overlaps have been highlighted; however, those interested in contributing to the development of the protocol or building another node implementation should analyze more closely the differences between these to ensure the necessary rules are followed.","title":"Protocol vs. Node"},{"location":"what-is-nano/living-whitepaper/#protocol-design","text":"This section contains details of the different messages shared between nodes and common data structures which allow data to be stored and communicated consistently across the network. Because Nano is decentralized and uses network-wide consensus to validate transactions, participating on the network requires following the message and data designs, otherwise attempts at transacting will be ignored or not properly confirmed by the network. Many changes done to elements outlined here require a change in the protocol version in addition to the node version .","title":"Protocol Design"},{"location":"what-is-nano/living-whitepaper/#node-implementation","text":"This section expands into methods and mechanisms built into the current node software that aren't required for compliance with protocol rules, but help provide better efficiency and performance for nodes running on the network. These details could be ignored or implemented in different ways by different types or versions of node software, while still maintaining compatibility with other nodes. Existing whitepaper sections related to this page: Introduction Background Other existing content related to this page: Nano Overview Representatives and Voting Incentives to run a node Node Releases: https://docs.nano.org/releases/node-releases/ \u21a9 Nano Documentation Repository: https://github.com/nanocurrency/nano-docs/ \u21a9","title":"Node Implementation"},{"location":"what-is-nano/overview/","text":"What is Nano? \u00b6 Nano is a digital payment protocol designed to be accessible and lightweight, with a focus on removing inefficiencies present in other cryptocurrencies. With ultrafast transactions and zero fees on a secure, green and decentralized network, this makes Nano ideal for everyday transactions. How do transactions work? \u00b6 Nano utilizes the Block Lattice , a data-structure in which individual accounts control their own blockchain. This allows blocks to be added quickly without conflict and sent to the network for confirmation. Transactions occur between accounts with two separate actions: The sender publishes a block debiting their own account for the amount to be sent to the receiving account The receiver publishes a matching block crediting their own account for the amount sent Once a block sending funds is confirmed by the network, the transaction goes into a pending state and cannot be reversed. The receiver can be offline and safely leave the funds in this state until they are ready to publish a matching block receiving the funds to their account. Lightweight, stateful blocks \u00b6 Nano uses a structure for each block which contains all the information about an account at that point in time: account number, balance, representative. Every block must also contain a small, user-generated Proof-of-Work value which is a Quality-of-Service prioritization mechanism allowing occasional, average user transactions to process quickly and consistently. The PoW computation for a transaction typically takes a few seconds on a modern desktop CPU. For more details, see the Blocks and Proof-of-Work specifications in our Integration Guides . Representatives and Voting \u00b6 Nano has a unique consensus mechanism called Open Representative Voting (ORV) . Every account can freely choose a Representative at any time to vote on their behalf, even when the delegating account itself is offline. These Representative accounts are configured on nodes that remain online and vote on the validity of transactions they see on the network. Their voting weight is the sum of balances for accounts delegating to them, and if they have enough voting weight they become a Principal Representative . The votes these Principal Representatives send out will subsequently be rebroadcasted by other nodes. As these votes are shared and rebroadcasted between nodes, they are tallied up and compared against the online voting weight available. Once a node sees a block get enough votes to reach quorum , that block is confirmed. Due to the lightweight nature of blocks and votes, the network is able to reach confirmation for transaction ultrafast, often in under a couple seconds. Also note that delegation of voting weight does not mean staking of any funds - the account delegating can still spend all their available funds at any time without restrictions. Because Nano accounts can freely delegate their voting weight to representatives at any time, the users have more control over who has power with consensus and how decentralized the network is. This is a key advantage to the design of Open Representative Voting (ORV) . With no direct monetary incentive for nodes, this removes emergent centralization forces for longer-term trending toward decentralization of the network. 1 Design Advantages \u00b6 Nano was designed with new data structures, consensus mechanisms and other features to gain some key advantages over competing digital currencies: Minimal block size allows for lightweight communication resulting in ultrafast transaction confirmation times Without traditional Proof-of-Work and mining, nodes use significantly less energy per transaction than other popular networks Emergent centralization forces for node operators are reduced due to the near zero marginal cost of producing consensus in Nano 1 Exploring More \u00b6 Looking for technical details of the protocol and node design? Click Next below to learn about the Living Whitepaper Ready to participate on the network? Try running a node , review integration options or find commands via RPC and CLI Want to know the future of Nano? See the upcoming features for the node or help shape the future by contributing to the development of the protocol if you can! Want to explore less technical aspects of Nano or join our community? Head over to Nano.org https://medium.com/@clemahieu/emergent-centralization-due-to-economies-of-scale-83cc85a7cbef \u21a9 \u21a9","title":"What is Nano?"},{"location":"what-is-nano/overview/#what-is-nano","text":"Nano is a digital payment protocol designed to be accessible and lightweight, with a focus on removing inefficiencies present in other cryptocurrencies. With ultrafast transactions and zero fees on a secure, green and decentralized network, this makes Nano ideal for everyday transactions.","title":"What is Nano?"},{"location":"what-is-nano/overview/#how-do-transactions-work","text":"Nano utilizes the Block Lattice , a data-structure in which individual accounts control their own blockchain. This allows blocks to be added quickly without conflict and sent to the network for confirmation. Transactions occur between accounts with two separate actions: The sender publishes a block debiting their own account for the amount to be sent to the receiving account The receiver publishes a matching block crediting their own account for the amount sent Once a block sending funds is confirmed by the network, the transaction goes into a pending state and cannot be reversed. The receiver can be offline and safely leave the funds in this state until they are ready to publish a matching block receiving the funds to their account.","title":"How do transactions work?"},{"location":"what-is-nano/overview/#lightweight-stateful-blocks","text":"Nano uses a structure for each block which contains all the information about an account at that point in time: account number, balance, representative. Every block must also contain a small, user-generated Proof-of-Work value which is a Quality-of-Service prioritization mechanism allowing occasional, average user transactions to process quickly and consistently. The PoW computation for a transaction typically takes a few seconds on a modern desktop CPU. For more details, see the Blocks and Proof-of-Work specifications in our Integration Guides .","title":"Lightweight, stateful blocks"},{"location":"what-is-nano/overview/#representatives-and-voting","text":"Nano has a unique consensus mechanism called Open Representative Voting (ORV) . Every account can freely choose a Representative at any time to vote on their behalf, even when the delegating account itself is offline. These Representative accounts are configured on nodes that remain online and vote on the validity of transactions they see on the network. Their voting weight is the sum of balances for accounts delegating to them, and if they have enough voting weight they become a Principal Representative . The votes these Principal Representatives send out will subsequently be rebroadcasted by other nodes. As these votes are shared and rebroadcasted between nodes, they are tallied up and compared against the online voting weight available. Once a node sees a block get enough votes to reach quorum , that block is confirmed. Due to the lightweight nature of blocks and votes, the network is able to reach confirmation for transaction ultrafast, often in under a couple seconds. Also note that delegation of voting weight does not mean staking of any funds - the account delegating can still spend all their available funds at any time without restrictions. Because Nano accounts can freely delegate their voting weight to representatives at any time, the users have more control over who has power with consensus and how decentralized the network is. This is a key advantage to the design of Open Representative Voting (ORV) . With no direct monetary incentive for nodes, this removes emergent centralization forces for longer-term trending toward decentralization of the network. 1","title":"Representatives and Voting"},{"location":"what-is-nano/overview/#design-advantages","text":"Nano was designed with new data structures, consensus mechanisms and other features to gain some key advantages over competing digital currencies: Minimal block size allows for lightweight communication resulting in ultrafast transaction confirmation times Without traditional Proof-of-Work and mining, nodes use significantly less energy per transaction than other popular networks Emergent centralization forces for node operators are reduced due to the near zero marginal cost of producing consensus in Nano 1","title":"Design Advantages"},{"location":"what-is-nano/overview/#exploring-more","text":"Looking for technical details of the protocol and node design? Click Next below to learn about the Living Whitepaper Ready to participate on the network? Try running a node , review integration options or find commands via RPC and CLI Want to know the future of Nano? See the upcoming features for the node or help shape the future by contributing to the development of the protocol if you can! Want to explore less technical aspects of Nano or join our community? Head over to Nano.org https://medium.com/@clemahieu/emergent-centralization-due-to-economies-of-scale-83cc85a7cbef \u21a9 \u21a9","title":"Exploring More"},{"location":"whitepaper/english/","text":"Original RaiBlocks/Nano Whitepaper \u00b6 Last updated: November 2017 Info This original whitepaper contains details about the protocol which are no longer accurate, such as voting only being performed on blocks for which forks were detected, but is being left intact for historical reference purposes. For more accurate details, head over to the Living Whitepaper section. Introduction \u00b6 Since the implementation of Bitcoin in 2009, there has been a growing shift away from traditional, government-backed currencies and financial systems towards modern payments systems based on cryptography, which offer the ability to store and transfer funds in a trustless and secure manner 1 . In order to function effectively, a currency must be easily transferable, non-reversible, and have limited or no fees. The increased transaction times, large fees, and questionable network scalability have raised questions about the practicality of Bitcoin as an everyday currency. In this paper, we introduce RaiBlocks, a low-latency cryptocurrency built on an innovative block-lattice data structure offering unlimited scalability and no transaction fees. RaiBlocks by design is a simple protocol with the sole purpose of being a high-performance cryptocurrency. The RaiBlocks protocol can run on low-power hardware, allowing it to be a practical, decentralized cryptocurrency for everyday use. Cryptocurrency statistics reported in this paper are accurate as of publication date. Background \u00b6 In 2008, an anonymous individual under the pseudonym Satoshi Nakamoto published a whitepaper outlining the world's first decentralized cryptocurrency, Bitcoin 1 . A key innovation brought about by Bitcoin was the blockchain, a public, immutable and decentralized data-structure which is used as a ledger for the currency's transactions. Unfortunately, as Bitcoin matured, several issues in the protocol made Bitcoin prohibitive for many applications: Poor scalability: Each block in the blockchain can store a limited amount of data, which means the system can only process so many transactions per second, making spots in a block a commodity. Currently the median transaction fee is $10.38 2 . High latency: The average confirmation time is 164 minutes 3 . Power inefficient: The Bitcoin network consumes an estimated 27.28TWh per year, using on average 260KWh per transaction 4 . Bitcoin, and other cryptocurrencies, function by achieving consensus on their global ledgers in order to verify legitimate transactions while resisting malicious actors. Bitcoin achieves consensus via an economic measure called Proof of Work (PoW). In a PoW system participants compete to compute a number, called a nonce , such that the hash of the entire block is in a target range. This valid range is inversely proportional to the cumulative computation power of the entire Bitcoin network in order to maintain a consistent average time taken to find a valid nonce. The finder of a valid nonce is then allowed to add the block to the blockchain; therefore, those who exhaust more computational resources to compute a nonce play a greater role in the state of the blockchain. PoW provides resistance against a Sybil attack, where an entity behaves as multiple entities to gain additional power in a decentralized system, and also greatly reduces race conditions that inherently exist while accessing a global data-structure. An alternative consensus protocol, Proof of Stake (PoS), was first introduced by Peercoin in 2012 5 . In a PoS system, participants vote with a weight equivalent to the amount of wealth they possess in a given cryptocurrency. With this arrangement, those who have a greater financial investment are given more power and are inherently incentivized to maintain the honesty of the system or risk losing their investment. PoS does away with the wasteful computation power competition, only requiring light-weight software running on low power hardware. The original RaiBlocks paper and first beta implementation were published in December, 2014, making it one of the first Directed Acyclic Graph (DAG) based cryptocurrencies 6 . Soon after, other DAG cryptocurrencies began to develop, most notably DagCoin/Byteball and IOTA 7 8 . These DAG-based cryptocurrencies broke the blockchain mold, improving system performance and security. Byteball achieves consensus by relying on a \"main-chain\" comprised of honest, reputable and user-trusted \"witnesses\", while IOTA achieves consensus via the cumulative PoW of stacked transactions. RaiBlocks achieves consensus via a balance-weighted vote on conflicting transactions. This consensus system provides quicker, more deterministic transactions while still maintaining a strong, decentralized system. RaiBlocks continues this development and has positioned itself as one of the highest performing cryptocurrencies. RaiBlocks Components \u00b6 Before describing the overall RaiBlocks architecture, we define the individual components that make up the system. Account \u00b6 An account is the public-key portion of a digital signature key-pair. The public-key, also referred to as the address, is shared with other network participants while the private-key is kept secret. A digitally signed packet of data ensures that the contents were approved by the private-key holder. One user may control many accounts, but only one public address may exist per account. Block/Transaction \u00b6 The term \"block\" and \"transaction\" are often used interchangeably, where a block contains a single transaction. Transaction specifically refers to the action while block refers to the digital encoding of the transaction. Transactions are signed by the private-key belonging to the account on which the transaction is performed. Ledger \u00b6 The ledger is the global set of accounts where each account has its own transaction chain. This is a key design component that falls under the category of replacing a run-time agreement with a design-time agreement; everyone agrees via signature checking that only an account owner can modify their own chain. This converts a seemingly shared data-structure, a distributed ledger, in to a set of non-shared ones. graph TB subgraph Account C A[\"Block <i>N<sub>C</sub></i>\"]-->B[\"Block <i>N<sub>C</sub></i> - 1\"] B-->C[\"...\"] C-->D[\"Block 1\"] D-->E[\"Block 0\"] end subgraph Account B F[\"Block <i>N<sub>B</sub></i>\"]-->G[\"Block <i>N<sub>B</sub></i> - 1\"] G-->H[\"...\"] H-->I[\"Block 1\"] I-->J[\"Block 0\"] end subgraph Account A K[\"Block <i>N<sub>A</sub></i>\"]-->L[\"Block <i>N<sub>A</sub></i> - 1\"] L-->M[\"...\"] M-->N[\"Block 1\"] N-->O[\"Block 0\"] end Node \u00b6 A node is a piece of software running on a computer that conforms to the RaiBlocks protocol and participates in the RaiBlocks network. The software manages the ledger and any accounts the node may control, if any. A node may either store the entire ledger or a pruned history containing only the last few block of each account's blockchain. When setting up a new node it is recommended to verify the entire history and prune locally. System Overview \u00b6 Unlike blockchains used in many other cryptocurrencies, RaiBlocks uses a block-lattice structure. Each account has its own blockchain (account-chain) equivalent to the account's transaction/balance history Each account-chain can only be updated by the account's owner; this allows each account-chain to be updated immediately and asynchronously to the rest of the block-lattice, resulting in quick transactions. RaiBlocks' protocol is extremely light-weight; each transaction fits within the required minimum UDP packet size for being transmitted over the internet. Hardware requirements for nodes are also minimal, since nodes only have to record and rebroadcast blocks for most transactions. graph BT subgraph Account C idc4[Receive]-->idc5((\"...\")) idc3[Receive]---idc4 idc2[Receive]---idc3 idc1[Send]---idc2 end subgraph Account B idb4[Send]-->idb5((\"...\")) idb3[Send]---idb4 idb2[\"&nbsp;\"]---idb3 idb1[Send]---idb2 end subgraph Account A ida4[Receive]-->ida5((\"...\")) ida3[Receive]---ida4 ida2[Send]---ida3 ida1[\"&nbsp;\"]---ida2 end idb1-.->idc4 ida2-.->idc3 idb3-.->ida4 idc1-.->ida3 The system is initiated with a genesis account containing the genesis balance . The genesis balance is a fixed quantity and can never be increased. The genesis balance is divided and sent to other accounts via send transactions registered on the genesis account-chain. The sum of the balances of all accounts will never exceed the initial genesis balance which gives the system an upper bound on quantity and no ability to increase it. This section will walk through how different types of transactions are constructed and propagated throughout the network. Transactions \u00b6 Transaction Flow graph LR; Receive-->Repeat; Repeat-->Observe; Observe-->Quorum; Quorum-->Confirm; (a) When no conflict is detected, no further overhead is required. graph LR; Receive-->Repeat; Repeat-->Observe; Observe-->Conflict; Conflict-->Vote; Vote-->Confirm; (b) In the event of a conflicting transaction, nodes vote for the valid transaction. Transferring funds from one account to another requires two transactions: a send deducting the amount from the sender's balance and a receive adding the amount to the receiving account's balance. Transferring amounts as separate transactions in the sender's and receiver's accounts serves a few important purposes: Sequencing incoming transfers that are inherently asynchronous. Keeping transactions small to fit in UDP packets. Facilitating ledger pruning by minimizing the data footprint. Isolating settled transactions from unsettled ones. More than one account transferring to the same destination account is an asynchronous operation; network latency and the sending accounts not necessarily being in communication with each other means there is no universally agreeable way to know which transaction happened first. Since addition is associative, the order the inputs are sequenced does not matter, and hence we simply need a global agreement. This is a key design component that converts a run-time agreement in to a design-time agreement. The receiving account has control over deciding which transfer arrived first and is expressed by the signed order of the incoming blocks. If an account wants to make a large transfer that was received as a set of many small transfers, we want to represent this in a way that fits within a UDP packet. When a receiving account sequences input transfers, it keeps a running total of its account balance so that at any time it has the ability to transfer any amount with a fixed size transaction. This differs from the input/output transaction model used by Bitcoin and other cryptocurrencies. Some nodes are uninterested in expending resources to store an account's full transaction history; they are only interested in each account's current balance. When an account makes a transaction, it encodes its accumulated balance and these nodes only need to keep track of the latest block, which allows them to discard historical data while maintaining correctness. Even with a focus on design-time agreements, there is a delay window when validating transactions due to identifying and handling bad actors in the network. Since agreements in RaiBlocks are reached quickly, on the order of milliseconds to seconds, we can present the user with two familiar categories of incoming transactions: settled and unsettled. Settled transactions are transactions where an account has generated receive blocks. Unsettled transactions have not yet been incorporated in to the receiver's cumulative balance. This is a replacement for the more complex and unfamiliar confirmations metric in other cryptocurrencies. Creating an Account \u00b6 To create an account, you need to issue an open transaction. An open transaction is always the first transaction of every account-chain and can be created upon the first receipt of funds. The account field stores the public-key (address) derived from the private-key that is used for signing. The source field contains the hash of the transaction that sent the funds. On account creation, a representative must be chosen to vote on your behalf; this can be changed later. The account can declare itself as its own representative. open { account: DC04354B1...AE8FA2661B2, source: DC1E2B3F7C...182A0E26B4A, representative: xrb_1anr...posrs, work: 0000000000000000, type: open, signature: 83B0...006433265C7B204 } Account Balance \u00b6 The account balance is recorded within the ledger itself. Rather than recording the amount of a transaction, verification requires checking the difference between the balance at the send block and the balance of the preceding block. The receiving account may then increment the previous balance as measured into the final balance given in the new receive block. This is done to improve processing speed when downloading high volumes of blocks. When requesting account history, amounts are already given. Sending From an Account \u00b6 To send from an address, the address must already have an existing open block, and therefore a balance. The previous field contains the hash of the previous block in the account-chain. The destination field contains the account for funds to be sent to. A send block is immutable once confirmed. Once broadcasted to the network, funds are immediately deducted from the balance of the sender's account and wait as pending until the receiving party signs a block to accept these funds. Pending funds should not be considered awaiting confirmation, as they are as good as spent from the sender's account and the sender cannot revoke the transaction. send { previous: 1967EA355...F2F3E5BF801, balance: 010a8044a0...1d49289d88c, destination: xrb_3w...m37goeuufdp, work: 0000000000000000, type: send, signature: 83B0...006433265C7B204 } Receiving a Transaction \u00b6 To complete a transaction, the recipient of sent funds must create a receive block on their own account-chain. The source field references the hash of the associated send transaction. Once this block is created and broadcasted, the account's balance is updated and the funds have officially moved into their account. receive { previous: DC04354B1...AE8FA2661B2, source: DC1E2B3F7C6...182A0E26B4A, work: 0000000000000000, type: receive, signature: 83B0...006433265C7B204 } Assigning a Representative \u00b6 Account holders having the ability to choose a representative to vote on their behalf is a powerful decentralization tool that has no strong analog in Proof of Work or Proof of Stake protocols. In conventional PoS systems, the account owner's node must be running to participate in voting. Continuously running a node is impractical for many users; giving a representative the power to vote on an account's behalf relaxes this requirement. Account holders have the ability to reassign consensus to any account at any time. A change transaction changes the representative of an account by subtracting the vote weight from the old representative and adding the weight to the new representative. No funds are moved in this transaction, and the representative does not have spending power of the account's funds. change { previous: DC04354B1...AE8FA2661B2, representative: xrb_1anrz...posrs, work: 0000000000000000, type: change, signature: 83B0...006433265C7B204 } Forks and Voting \u00b6 A fork occurs when j j signed blocks b_1, b_2, \\dots, b_j b_1, b_2, \\dots, b_j claim the same block as their predecessor. graph RL subgraph Account A ida3[\"Block <i>i</i> + 1\"]---ida4[\"Block <i>i</i>\"] ida2[\"Block <i>i</i> + 2\"]-->ida3 ida1[\"Block <i>i</i> + 2\"]-->ida3 end These blocks cause a conflicting view on the status of an account and must be resolved. Only the account's owner has the ability to sign blocks into their account-chain, so a fork must be the result of poor programming or malicious intent (double-spend) by the account's owner. Upon detection, a representative will create a vote referencing the block \\hat{b}_i \\hat{b}_i in its ledger and broadcast it to the network. The weight of a node's vote, w_i w_i , is the sum of the balances of all accounts that have named it as its representative. The node will observe incoming votes from the other M M online representatives and keep a cumulative tally for 4 voting periods, 1 minute total, and confirm the winning block. \\begin{aligned} v(b_j) &= \\sum_{i=1}^M w_i{1}_{\\hat{b}_i=b_j} \\label{eq:weighted_vote} \\\\ b^* &= \\mathop{\\mathrm{arg\\,max}}_{b_j} v(b_j) \\label{eq:most_votes}\\end{aligned} \\begin{aligned} v(b_j) &= \\sum_{i=1}^M w_i{1}_{\\hat{b}_i=b_j} \\label{eq:weighted_vote} \\\\ b^* &= \\mathop{\\mathrm{arg\\,max}}_{b_j} v(b_j) \\label{eq:most_votes}\\end{aligned} The most popular block b^* b^* will have the majority of the votes and will be retained in the node's ledger. The block(s) that lose the vote are discarded. If a representative replaces a block in its ledger, it will create a new vote with a higher sequence number and broadcast the new vote to the network. This is the only scenario where representatives vote. In some circumstances, brief network connectivity issues may cause a broadcasted block to not be accepted by all peers. Any subsequent block on this account will be ignored as invalid by peers that did not see the initial broadcast. A rebroadcast of this block will be accepted by the remaining peers and subsequent blocks will be retrieved automatically. Even when a fork or missing block occurs, only the accounts referenced in the transaction are affected; the rest of the network proceeds with processing transactions for all other accounts. Proof of Work \u00b6 All four transaction types have a work field that must be correctly populated. The work field allows the transaction creator to compute a nonce such that the hash of the nonce concatenated with the previous field in receive/send/change transactions or the account field in an open transaction is below a certain threshold value. Unlike Bitcoin, the PoW in RaiBlocks is simply used as an anti-spam tool, similar to Hashcash, and can be computed on the order of seconds 9 . Once a transaction is sent, the PoW for the subsequent block can be precomputed since the previous block field is known; this will make transactions appear instantaneous to an end-user so long as the time between transactions is greater than the time required to compute the PoW. Transaction Verification \u00b6 For a block to be considered valid, it must have the following attributes: The block must not already be in the ledger (duplicate transaction). Must be signed by the account's owner. The previous block is the head block of the account-chain. If it exists but is not the head, it is a fork. The account must have an open block. The computed hash meets the PoW threshold requirement. If it is a receive block, check if the source block hash is pending, meaning it has not already been redeemed. If it is a send block, the balance must be less than the previous balance. Attack Vectors \u00b6 RaiBlocks, like all decentralized cryptocurrencies, may be attacked by malicious parties for attempted financial gain or system demise. In this section we outline a few possible attack scenarios, the consequences of such an attack, and how RaiBlock's protocol takes preventative measures. Block Gap Synchronization \u00b6 In a previous section, we discussed the scenario where a block may not be properly broadcasted, causing the network to ignore subsequent blocks. If a node observes a block that does not have the referenced previous block, it has two options: Ignore the block as it might be a malicious garbage block. Request a resync with another node. In the case of a resync, a TCP connection must be formed with a bootstrapping node to facilitate the increased amount of traffic a resync requires. However, if the block was actually a bad block, then the resync was unnecessary and needlessly increased traffic on the network. This is a Network Amplification Attack and results in a denial-of-service. To avoid unnecessary resyncing, nodes will wait until a certain threshold of votes have been observed for a potentially malicious block before initiating a connection to a bootstrap node to synchronize. If a block doesn't receive enough votes it can be assumed to be junk data. Transaction Flooding \u00b6 A malicious entity could send many unnecessary but valid transactions between accounts under its control in an attempt to saturate the network. With no transaction fees they are able to continue this attack indefinitely. However, the PoW required for each transaction limits the transaction rate the malicious entity could generate without significantly investing in computational resources. Even under such an attack in an attempt to inflate the ledger, nodes that are not full historical nodes are able to prune old transactions from their chain; this clamps the storage usage from this type of attack for almost all users. Sybil Attack \u00b6 An entity could create hundreds of RaiBlocks nodes on a single machine; however, since the voting system is weighted based on account balance, adding extra nodes in to the network will not gain an attacker extra votes. Therefore there is no advantage to be gained via a Sybil attack. Penny-Spend Attack \u00b6 A penny-spend attack is where an attacker spends infinitesimal quantities to a large number of accounts in order to waste the storage resources of nodes. Block publishing is rate-limited by the PoW, so this limits the creation of accounts and transactions to a certain extent. Nodes that are not full historical nodes can prune accounts below a statistical metric where the account is most likely not a valid account. Finally, RaiBlocks is tuned to use minimal permanent storage space, so space required to store one additional account is proportional to the size of an \\text{open block} + \\text{indexing} = 96\\text{B} + 32\\text{B} = 128\\text{B} \\text{open block} + \\text{indexing} = 96\\text{B} + 32\\text{B} = 128\\text{B} . This equates to 1GB being able to store 8 million penny-spend account. If nodes wanted to prune more aggressively, they can calculate a distribution based on access frequency and delegate infrequently used accounts to slower storage. Precomputed PoW Attack \u00b6 Since the owner of an account will be the only entity adding blocks to the account-chain, sequential blocks can be computed, along with their PoW, before being broadcasted to the network. Here the attacker generates a myriad of sequential blocks, each of minimal value, over an extended period of time. At a certain point, the attacker performs a Denial of Service (DoS) by flooding the network with lots of valid transactions, which other nodes will process and echo as quickly as possible. This is an advanced version of the transaction flooding described in the Transaction flooding section . Such an attack would only work briefly, but could be used in conjunction with other attacks, such as a >50% Attack to increase effectiveness. Transaction rate-limiting and other techniques are currently being investigated to mitigate attacks. >50% Attack \u00b6 The metric of consensus for RaiBlocks is a balance weighted voting system. If an attacker is able to gain over 50% of the voting strength, they can cause the network to oscillate consensus rendering the system broken. An attacker is able to lower the amount of balance they must forfeit by preventing good nodes from voting through a network DoS. RaiBlocks takes the following measures to prevent such an attack: The primary defense against this type of attack is voting-weight being tied to investment in the system. An account holder is inherently incentivized to maintain the honesty of the system to protect their investment. Attempting to flip the ledger would be destructive to the system as a whole which would destroy their investment. The cost of this attack is proportional to the market capitalization of RaiBlocks. In PoW systems, technology can be invented that gives disproportionate control compared to monetary investment and if the attack is successful, this technology could be repurposed after the attack is complete. With RaiBlocks the cost of attacking the system scales with the system itself and if an attack were to be successful the investment in the attack cannot be recovered. In order to maintain the maximum quorum of voters, the next line of defense is representative voting. Account holders who are unable to reliably participate in voting for connectivity reasons can name a representative who can vote with the weight of their balance. Maximizing the number and diversity of representatives increases network resiliency. Forks in RaiBlocks are never accidental, so nodes can make policy decisions on how to interact with forked blocks. The only time non-attacker accounts are vulnerable to block forks is if they receive a balance from an attacking account. Accounts wanting to be secure from block forks can wait a little or a lot longer before receiving from an account who generated forks or opt to never receive at all. Receivers could also generate separate accounts to use when receiving funds from dubious accounts in order to insulate other accounts. A final line of defense that has not yet been implemented is block cementing . RaiBlocks goes to great lengths to settle block forks quickly via voting. Nodes could be configured to cement blocks, which would prevent them from being rolled back after a certain period of time. The network is sufficiently secured through focusing on fast settling time to prevent ambiguous forks. A more sophisticated version of a >50\\% >50\\% attack is detailed below. \"Offline\" is the percentage of representatives who have been named but are not online to vote. \"Stake\" is the amount of investment the attacker is voting with. \"Active\" is representatives that are online and voting according to the protocol. An attacker can offset the amount of stake they must forfeit by knocking other voters offline via a network DoS attack. If this attack can be sustained, the representatives being attacked will become unsynchronized and this is demonstrated by \"Unsync.\" Finally, an attacker can gain a short burst in relative voting strength by switching their Denial of Service attack to a new set of representatives while the old set is re-synchronizing their ledger, this is demonstrated by \"Attack.\" If an attacker is able to cause Stake >Active by a combination of these circumstances, they would be able to successfully flip votes on the ledger at the expense of their stake. We can estimate how much this type of attack could cost by examining the market cap of other systems. If we estimate 33% of representatives are offline or attacked via DoS, an attacker would need to purchase 33% of the market cap in order to attack the system via voting. Bootstrap Poisoning \u00b6 The longer an attacker is able to hold an old private-key with a balance, the higher the probability that balances that existed at that time will not have participating representatives because their balances or representatives have transferred to newer accounts. This means if a node is bootstrapped to an old representation of the network where the attacker has a quorum of voting stake compared to representatives at that point in time, they would be able to oscillate voting decisions to that node. If this new user wanted to interact with anyone besides the attacking node all of their transactions would be denied since they have different head blocks. The net result is nodes can waste the time of new nodes in the network by feeding them bad information. To prevent this, nodes can be paired with an initial database of accounts and known-good block heads; this is a replacement for downloading the database all the way back to the genesis block. The closer the download is to being current, the higher the probability of accurately defending against this attack. In the end, this attack is probably no worse than feeding junk data to nodes while bootstrapping, since they wouldn't be able to transact with anyone who has a contemporary database. Implementation \u00b6 Currently the reference implementation is implemented in C++ and has been producing releases since 2014 on Github 10 . Design Features \u00b6 The RaiBlocks implementation adheres to the architecture standard outlined in this paper. Additional specifications are described here. Signing Algorithm \u00b6 RaiBlocks uses a modified ED25519 elliptic curve algorithm with Blake2b hashing for all digital signatures 11 . ED25519 was chosen for fast signing, fast verification, and high security. Hashing Algorithm \u00b6 Since the hashing algorithm is only used to prevent network spam, the algorithm choice is less important when compared to mining-based cryptocurrencies. Our implementation uses Blake2b as a digest algorithm against block contents 12 . Key Derivation Function \u00b6 In the reference wallet, keys are encrypted by a password and the password is fed through a key derivation function to protect against ASIC cracking attempts. Presently Argon2 13 is the winner of the only public competition aimed at creating a resilient key derivation function. Block Interval \u00b6 Since each account has its own blockchain, updates can be performed asynchronous to the state of network. Therefore there are no block intervals and transactions can be published instantly. UDP Message Protocol \u00b6 Our system is designed to operate indefinitely using the minimum amount of computing resources as possible. All messages in the system were designed to be stateless and fit within a single UDP packet. This also makes it easier for lite peers with intermittent connectivity to participate in the network without reestablishing short-term TCP connections. TCP is used only for new peers when they want to bootstrap the block chains in a bulk fashion. Nodes can be sure their transaction was received by the network by observing transaction broadcast traffic from other nodes as it should see several copies echoed back to itself. IPv6 and Multicast \u00b6 Building on top of connection-less UDP allows future implementations to use IPv6 multicast as a replacement for traditional transaction flooding and vote broadcast. This will reduce network bandwidth consumption and give more policy flexibility to nodes going forward. Performance \u00b6 At the time of this writing, 4.2 million transactions have been processed by the RaiBlocks network, yielding a blockchain size of 1.7GB. Transaction times are measured on the order of seconds. A current reference implementation operating on commodity SSDs can process over 10,000 transactions per second being primarily IO bound. Resource Usage \u00b6 This is an overview of resources used by a RaiBlocks node. Additionally, we go over ideas for reducing resource usage for specific use cases. Reduced nodes are typically called light, pruned, or simplified payment verification (SPV) nodes. Network \u00b6 The amount of network activity depends on how much the network contributes towards the health of a network. Representative A representative node requires maximum network resources as it observes vote traffic from other representatives and publishes its own votes. Trustless A trustless node is similar to a representative node but is only an observer, it doesn't contain a representative account private key and does not publish votes of its own. Trusting A trusting node observes vote traffic from one representative it trusts to correctly perform consensus. This cuts down on the amount of inbound vote traffic from representatives going to this node. Light A light node is also a trusting node that only observes traffic for accounts in which it is interested allowing minimal network usage. Bootstrap A bootstrap node serves up parts or all of the ledger for nodes that are bringing themselves online. This is done over a TCP connection rather than UDP since it involves a large amount of data that requires advanced flow control. Disk Capacity \u00b6 Depending on the user demands, different node configurations require different storage requirements. Historical A node interested in keeping a full historical record of all transactions will require the maximum amount of storage. Current Due to the design of keeping accumulated balances with blocks, nodes only need to keep the latest or head blocks for each account in order to participate in consensus. If a node is uninterested in keeping a full history it can opt to keep only the head blocks. Light A light node keeps no local ledger data and only participates in the network to observe activity on accounts in which it is interested or optionally create new transactions with private keys it holds. CPU \u00b6 Transaction Generating A node interested in creating new transactions must produce a Proof of Work nonce in order to pass RaiBlock's throttling mechanism. Computation of various hardware is benchmarked in Appendix A. Representative A representative must verify signatures for blocks, votes, and also produce its own signatures to participate in consensus. The amount of CPU resources for a representative node is significantly less than transaction generating and should work with any single CPU in a contemporary computer. Observer An observer node doesn't generate its own votes. Since signature generation overhead is minimal, the CPU requirements are almost identical to running a representative node. Conclusion \u00b6 In this paper we presented the framework for a trustless, feeless, low-latency cryptocurrency that utilizes a novel block-lattice structure and delegated Proof of Stake voting. The network requires minimal resources, no high-power mining hardware, and can process high transaction throughput. All of this is achieved by having individual blockchains for each account, eliminating access issues and inefficiencies of a global data-structure. We identified possible attack vectors on the system and presented arguments on how RaiBlocks is resistant to these forms of attacks. Appendix A: PoW Hardware benchmarks \u00b6 As mentioned previously, the PoW in RaiBlocks is to reduce network spam. Our node implementation provides acceleration that can take advantage of OpenCL compatible GPUs. Table I below provides a real-life benchmark comparison of various hardware. Currently the PoW threshold is fixed, but an adaptive threshold may be implemented as average computing power progresses. Table I Hardware PoW Performance Device Transactions Per Second Nvidia Tesla V100 (AWS) 6.4 Nvidia Tesla P100 (Google,Cloud) 4.9 Nvidia Tesla K80 (Google,Cloud) 1.64 AMD RX 470 OC 1.59 Nvidia GTX 1060 3GB 1.25 Intel Core i7 4790K AVX2 0.33 Intel Core i7 4790K,WebAssembly (Firefox) 0.14 Google Cloud 4 vCores 0.14-0.16 ARM64 server 4 cores (Scaleway) 0.05-0.07 Acknowledgment \u00b6 We would like to thank Brian Pugh and B. Cchung for compiling and formatting this paper. References \u00b6 S. Nakamoto, \u201cBitcoin: A peer-to-peer electronic cash system,\u201d 2008. [Online]. Available: http://bitcoin.org/bitcoin.pdf \u21a9 \u21a9 \u201cBitcoin median transaction fee historical chart.\u201d [Online]. Available: https://bitinfocharts.com/comparison/bitcoin-median-transaction-fee.html \u21a9 \u201cBitcoin average confirmation time.\u201d [Online]. Available: https://blockchain.info/charts/avg-confirmation-time \u21a9 \u201cBitcoin energy consumption index.\u201d [Online]. Available: https://digiconomist.net/bitcoin-energy-consumption \u21a9 S. King and S. Nadal, \u201cPpcoin: Peer-to-peer crypto-currency withproof-of-stake,\u201d 2012. [Online]. Available: https://peercoin.net/assets/paper/peercoin-paper.pdf \u21a9 C. LeMahieu, \u201cRaiblocks distributed ledger network,\u201d 2014. \u21a9 Y. Ribero and D. Raissar, \u201cDagcoin whitepaper,\u201d 2015. \u21a9 S. Popov, \u201cThe tangle,\u201d 2016. \u21a9 A. Back, \u201cHashcash - a denial of service counter-measure,\u201d 2002. [Online]. Available: http://www.hashcash.org/papers/hashcash.pdf \u21a9 C. LeMahieu, \u201cRaiblocks,\u201d 2014. [Online]. Available: https://github.com/clemahieu/raiblocks \u21a9 D. J. Bernstein, N. Duif, T. Lange, P. Shwabe, and B.-Y. Yang, \u201cHigh-speed high-security signatures,\u201d 2011. [Online]. Available: http://ed25519.cr.yp.to/ed25519-20110926.pdf \u21a9 J.-P. Aumasson, S. Neves, Z. Wilcox-O\u2019Hearn, and C. Winnerlein, \u201cBlake2: Simpler, smaller, fast as md5,\u201d 2012. [Online]. Available: https://blake2.net/blake2.pdf \u21a9 A. Biryukov, D. Dinu, and D. Khovratovich, \u201cArgon2: The memoryhard function for password hashing and other applications,\u201d 2015. [Online]. Available: https://password-hashing.net/argon2-specs.pdf \u21a9","title":"Original whitepaper"},{"location":"whitepaper/english/#original-raiblocksnano-whitepaper","text":"Last updated: November 2017 Info This original whitepaper contains details about the protocol which are no longer accurate, such as voting only being performed on blocks for which forks were detected, but is being left intact for historical reference purposes. For more accurate details, head over to the Living Whitepaper section.","title":"Original RaiBlocks/Nano Whitepaper"},{"location":"whitepaper/english/#introduction","text":"Since the implementation of Bitcoin in 2009, there has been a growing shift away from traditional, government-backed currencies and financial systems towards modern payments systems based on cryptography, which offer the ability to store and transfer funds in a trustless and secure manner 1 . In order to function effectively, a currency must be easily transferable, non-reversible, and have limited or no fees. The increased transaction times, large fees, and questionable network scalability have raised questions about the practicality of Bitcoin as an everyday currency. In this paper, we introduce RaiBlocks, a low-latency cryptocurrency built on an innovative block-lattice data structure offering unlimited scalability and no transaction fees. RaiBlocks by design is a simple protocol with the sole purpose of being a high-performance cryptocurrency. The RaiBlocks protocol can run on low-power hardware, allowing it to be a practical, decentralized cryptocurrency for everyday use. Cryptocurrency statistics reported in this paper are accurate as of publication date.","title":"Introduction"},{"location":"whitepaper/english/#background","text":"In 2008, an anonymous individual under the pseudonym Satoshi Nakamoto published a whitepaper outlining the world's first decentralized cryptocurrency, Bitcoin 1 . A key innovation brought about by Bitcoin was the blockchain, a public, immutable and decentralized data-structure which is used as a ledger for the currency's transactions. Unfortunately, as Bitcoin matured, several issues in the protocol made Bitcoin prohibitive for many applications: Poor scalability: Each block in the blockchain can store a limited amount of data, which means the system can only process so many transactions per second, making spots in a block a commodity. Currently the median transaction fee is $10.38 2 . High latency: The average confirmation time is 164 minutes 3 . Power inefficient: The Bitcoin network consumes an estimated 27.28TWh per year, using on average 260KWh per transaction 4 . Bitcoin, and other cryptocurrencies, function by achieving consensus on their global ledgers in order to verify legitimate transactions while resisting malicious actors. Bitcoin achieves consensus via an economic measure called Proof of Work (PoW). In a PoW system participants compete to compute a number, called a nonce , such that the hash of the entire block is in a target range. This valid range is inversely proportional to the cumulative computation power of the entire Bitcoin network in order to maintain a consistent average time taken to find a valid nonce. The finder of a valid nonce is then allowed to add the block to the blockchain; therefore, those who exhaust more computational resources to compute a nonce play a greater role in the state of the blockchain. PoW provides resistance against a Sybil attack, where an entity behaves as multiple entities to gain additional power in a decentralized system, and also greatly reduces race conditions that inherently exist while accessing a global data-structure. An alternative consensus protocol, Proof of Stake (PoS), was first introduced by Peercoin in 2012 5 . In a PoS system, participants vote with a weight equivalent to the amount of wealth they possess in a given cryptocurrency. With this arrangement, those who have a greater financial investment are given more power and are inherently incentivized to maintain the honesty of the system or risk losing their investment. PoS does away with the wasteful computation power competition, only requiring light-weight software running on low power hardware. The original RaiBlocks paper and first beta implementation were published in December, 2014, making it one of the first Directed Acyclic Graph (DAG) based cryptocurrencies 6 . Soon after, other DAG cryptocurrencies began to develop, most notably DagCoin/Byteball and IOTA 7 8 . These DAG-based cryptocurrencies broke the blockchain mold, improving system performance and security. Byteball achieves consensus by relying on a \"main-chain\" comprised of honest, reputable and user-trusted \"witnesses\", while IOTA achieves consensus via the cumulative PoW of stacked transactions. RaiBlocks achieves consensus via a balance-weighted vote on conflicting transactions. This consensus system provides quicker, more deterministic transactions while still maintaining a strong, decentralized system. RaiBlocks continues this development and has positioned itself as one of the highest performing cryptocurrencies.","title":"Background"},{"location":"whitepaper/english/#raiblocks-components","text":"Before describing the overall RaiBlocks architecture, we define the individual components that make up the system.","title":"RaiBlocks Components"},{"location":"whitepaper/english/#account","text":"An account is the public-key portion of a digital signature key-pair. The public-key, also referred to as the address, is shared with other network participants while the private-key is kept secret. A digitally signed packet of data ensures that the contents were approved by the private-key holder. One user may control many accounts, but only one public address may exist per account.","title":"Account"},{"location":"whitepaper/english/#blocktransaction","text":"The term \"block\" and \"transaction\" are often used interchangeably, where a block contains a single transaction. Transaction specifically refers to the action while block refers to the digital encoding of the transaction. Transactions are signed by the private-key belonging to the account on which the transaction is performed.","title":"Block/Transaction"},{"location":"whitepaper/english/#ledger","text":"The ledger is the global set of accounts where each account has its own transaction chain. This is a key design component that falls under the category of replacing a run-time agreement with a design-time agreement; everyone agrees via signature checking that only an account owner can modify their own chain. This converts a seemingly shared data-structure, a distributed ledger, in to a set of non-shared ones. graph TB subgraph Account C A[\"Block <i>N<sub>C</sub></i>\"]-->B[\"Block <i>N<sub>C</sub></i> - 1\"] B-->C[\"...\"] C-->D[\"Block 1\"] D-->E[\"Block 0\"] end subgraph Account B F[\"Block <i>N<sub>B</sub></i>\"]-->G[\"Block <i>N<sub>B</sub></i> - 1\"] G-->H[\"...\"] H-->I[\"Block 1\"] I-->J[\"Block 0\"] end subgraph Account A K[\"Block <i>N<sub>A</sub></i>\"]-->L[\"Block <i>N<sub>A</sub></i> - 1\"] L-->M[\"...\"] M-->N[\"Block 1\"] N-->O[\"Block 0\"] end","title":"Ledger"},{"location":"whitepaper/english/#node","text":"A node is a piece of software running on a computer that conforms to the RaiBlocks protocol and participates in the RaiBlocks network. The software manages the ledger and any accounts the node may control, if any. A node may either store the entire ledger or a pruned history containing only the last few block of each account's blockchain. When setting up a new node it is recommended to verify the entire history and prune locally.","title":"Node"},{"location":"whitepaper/english/#system-overview","text":"Unlike blockchains used in many other cryptocurrencies, RaiBlocks uses a block-lattice structure. Each account has its own blockchain (account-chain) equivalent to the account's transaction/balance history Each account-chain can only be updated by the account's owner; this allows each account-chain to be updated immediately and asynchronously to the rest of the block-lattice, resulting in quick transactions. RaiBlocks' protocol is extremely light-weight; each transaction fits within the required minimum UDP packet size for being transmitted over the internet. Hardware requirements for nodes are also minimal, since nodes only have to record and rebroadcast blocks for most transactions. graph BT subgraph Account C idc4[Receive]-->idc5((\"...\")) idc3[Receive]---idc4 idc2[Receive]---idc3 idc1[Send]---idc2 end subgraph Account B idb4[Send]-->idb5((\"...\")) idb3[Send]---idb4 idb2[\"&nbsp;\"]---idb3 idb1[Send]---idb2 end subgraph Account A ida4[Receive]-->ida5((\"...\")) ida3[Receive]---ida4 ida2[Send]---ida3 ida1[\"&nbsp;\"]---ida2 end idb1-.->idc4 ida2-.->idc3 idb3-.->ida4 idc1-.->ida3 The system is initiated with a genesis account containing the genesis balance . The genesis balance is a fixed quantity and can never be increased. The genesis balance is divided and sent to other accounts via send transactions registered on the genesis account-chain. The sum of the balances of all accounts will never exceed the initial genesis balance which gives the system an upper bound on quantity and no ability to increase it. This section will walk through how different types of transactions are constructed and propagated throughout the network.","title":"System Overview"},{"location":"whitepaper/english/#transactions","text":"Transaction Flow graph LR; Receive-->Repeat; Repeat-->Observe; Observe-->Quorum; Quorum-->Confirm; (a) When no conflict is detected, no further overhead is required. graph LR; Receive-->Repeat; Repeat-->Observe; Observe-->Conflict; Conflict-->Vote; Vote-->Confirm; (b) In the event of a conflicting transaction, nodes vote for the valid transaction. Transferring funds from one account to another requires two transactions: a send deducting the amount from the sender's balance and a receive adding the amount to the receiving account's balance. Transferring amounts as separate transactions in the sender's and receiver's accounts serves a few important purposes: Sequencing incoming transfers that are inherently asynchronous. Keeping transactions small to fit in UDP packets. Facilitating ledger pruning by minimizing the data footprint. Isolating settled transactions from unsettled ones. More than one account transferring to the same destination account is an asynchronous operation; network latency and the sending accounts not necessarily being in communication with each other means there is no universally agreeable way to know which transaction happened first. Since addition is associative, the order the inputs are sequenced does not matter, and hence we simply need a global agreement. This is a key design component that converts a run-time agreement in to a design-time agreement. The receiving account has control over deciding which transfer arrived first and is expressed by the signed order of the incoming blocks. If an account wants to make a large transfer that was received as a set of many small transfers, we want to represent this in a way that fits within a UDP packet. When a receiving account sequences input transfers, it keeps a running total of its account balance so that at any time it has the ability to transfer any amount with a fixed size transaction. This differs from the input/output transaction model used by Bitcoin and other cryptocurrencies. Some nodes are uninterested in expending resources to store an account's full transaction history; they are only interested in each account's current balance. When an account makes a transaction, it encodes its accumulated balance and these nodes only need to keep track of the latest block, which allows them to discard historical data while maintaining correctness. Even with a focus on design-time agreements, there is a delay window when validating transactions due to identifying and handling bad actors in the network. Since agreements in RaiBlocks are reached quickly, on the order of milliseconds to seconds, we can present the user with two familiar categories of incoming transactions: settled and unsettled. Settled transactions are transactions where an account has generated receive blocks. Unsettled transactions have not yet been incorporated in to the receiver's cumulative balance. This is a replacement for the more complex and unfamiliar confirmations metric in other cryptocurrencies.","title":"Transactions"},{"location":"whitepaper/english/#creating-an-account","text":"To create an account, you need to issue an open transaction. An open transaction is always the first transaction of every account-chain and can be created upon the first receipt of funds. The account field stores the public-key (address) derived from the private-key that is used for signing. The source field contains the hash of the transaction that sent the funds. On account creation, a representative must be chosen to vote on your behalf; this can be changed later. The account can declare itself as its own representative. open { account: DC04354B1...AE8FA2661B2, source: DC1E2B3F7C...182A0E26B4A, representative: xrb_1anr...posrs, work: 0000000000000000, type: open, signature: 83B0...006433265C7B204 }","title":"Creating an Account"},{"location":"whitepaper/english/#account-balance","text":"The account balance is recorded within the ledger itself. Rather than recording the amount of a transaction, verification requires checking the difference between the balance at the send block and the balance of the preceding block. The receiving account may then increment the previous balance as measured into the final balance given in the new receive block. This is done to improve processing speed when downloading high volumes of blocks. When requesting account history, amounts are already given.","title":"Account Balance"},{"location":"whitepaper/english/#sending-from-an-account","text":"To send from an address, the address must already have an existing open block, and therefore a balance. The previous field contains the hash of the previous block in the account-chain. The destination field contains the account for funds to be sent to. A send block is immutable once confirmed. Once broadcasted to the network, funds are immediately deducted from the balance of the sender's account and wait as pending until the receiving party signs a block to accept these funds. Pending funds should not be considered awaiting confirmation, as they are as good as spent from the sender's account and the sender cannot revoke the transaction. send { previous: 1967EA355...F2F3E5BF801, balance: 010a8044a0...1d49289d88c, destination: xrb_3w...m37goeuufdp, work: 0000000000000000, type: send, signature: 83B0...006433265C7B204 }","title":"Sending From an Account"},{"location":"whitepaper/english/#receiving-a-transaction","text":"To complete a transaction, the recipient of sent funds must create a receive block on their own account-chain. The source field references the hash of the associated send transaction. Once this block is created and broadcasted, the account's balance is updated and the funds have officially moved into their account. receive { previous: DC04354B1...AE8FA2661B2, source: DC1E2B3F7C6...182A0E26B4A, work: 0000000000000000, type: receive, signature: 83B0...006433265C7B204 }","title":"Receiving a Transaction"},{"location":"whitepaper/english/#assigning-a-representative","text":"Account holders having the ability to choose a representative to vote on their behalf is a powerful decentralization tool that has no strong analog in Proof of Work or Proof of Stake protocols. In conventional PoS systems, the account owner's node must be running to participate in voting. Continuously running a node is impractical for many users; giving a representative the power to vote on an account's behalf relaxes this requirement. Account holders have the ability to reassign consensus to any account at any time. A change transaction changes the representative of an account by subtracting the vote weight from the old representative and adding the weight to the new representative. No funds are moved in this transaction, and the representative does not have spending power of the account's funds. change { previous: DC04354B1...AE8FA2661B2, representative: xrb_1anrz...posrs, work: 0000000000000000, type: change, signature: 83B0...006433265C7B204 }","title":"Assigning a Representative"},{"location":"whitepaper/english/#forks-and-voting","text":"A fork occurs when j j signed blocks b_1, b_2, \\dots, b_j b_1, b_2, \\dots, b_j claim the same block as their predecessor. graph RL subgraph Account A ida3[\"Block <i>i</i> + 1\"]---ida4[\"Block <i>i</i>\"] ida2[\"Block <i>i</i> + 2\"]-->ida3 ida1[\"Block <i>i</i> + 2\"]-->ida3 end These blocks cause a conflicting view on the status of an account and must be resolved. Only the account's owner has the ability to sign blocks into their account-chain, so a fork must be the result of poor programming or malicious intent (double-spend) by the account's owner. Upon detection, a representative will create a vote referencing the block \\hat{b}_i \\hat{b}_i in its ledger and broadcast it to the network. The weight of a node's vote, w_i w_i , is the sum of the balances of all accounts that have named it as its representative. The node will observe incoming votes from the other M M online representatives and keep a cumulative tally for 4 voting periods, 1 minute total, and confirm the winning block. \\begin{aligned} v(b_j) &= \\sum_{i=1}^M w_i{1}_{\\hat{b}_i=b_j} \\label{eq:weighted_vote} \\\\ b^* &= \\mathop{\\mathrm{arg\\,max}}_{b_j} v(b_j) \\label{eq:most_votes}\\end{aligned} \\begin{aligned} v(b_j) &= \\sum_{i=1}^M w_i{1}_{\\hat{b}_i=b_j} \\label{eq:weighted_vote} \\\\ b^* &= \\mathop{\\mathrm{arg\\,max}}_{b_j} v(b_j) \\label{eq:most_votes}\\end{aligned} The most popular block b^* b^* will have the majority of the votes and will be retained in the node's ledger. The block(s) that lose the vote are discarded. If a representative replaces a block in its ledger, it will create a new vote with a higher sequence number and broadcast the new vote to the network. This is the only scenario where representatives vote. In some circumstances, brief network connectivity issues may cause a broadcasted block to not be accepted by all peers. Any subsequent block on this account will be ignored as invalid by peers that did not see the initial broadcast. A rebroadcast of this block will be accepted by the remaining peers and subsequent blocks will be retrieved automatically. Even when a fork or missing block occurs, only the accounts referenced in the transaction are affected; the rest of the network proceeds with processing transactions for all other accounts.","title":"Forks and Voting"},{"location":"whitepaper/english/#proof-of-work","text":"All four transaction types have a work field that must be correctly populated. The work field allows the transaction creator to compute a nonce such that the hash of the nonce concatenated with the previous field in receive/send/change transactions or the account field in an open transaction is below a certain threshold value. Unlike Bitcoin, the PoW in RaiBlocks is simply used as an anti-spam tool, similar to Hashcash, and can be computed on the order of seconds 9 . Once a transaction is sent, the PoW for the subsequent block can be precomputed since the previous block field is known; this will make transactions appear instantaneous to an end-user so long as the time between transactions is greater than the time required to compute the PoW.","title":"Proof of Work"},{"location":"whitepaper/english/#transaction-verification","text":"For a block to be considered valid, it must have the following attributes: The block must not already be in the ledger (duplicate transaction). Must be signed by the account's owner. The previous block is the head block of the account-chain. If it exists but is not the head, it is a fork. The account must have an open block. The computed hash meets the PoW threshold requirement. If it is a receive block, check if the source block hash is pending, meaning it has not already been redeemed. If it is a send block, the balance must be less than the previous balance.","title":"Transaction Verification"},{"location":"whitepaper/english/#attack-vectors","text":"RaiBlocks, like all decentralized cryptocurrencies, may be attacked by malicious parties for attempted financial gain or system demise. In this section we outline a few possible attack scenarios, the consequences of such an attack, and how RaiBlock's protocol takes preventative measures.","title":"Attack Vectors"},{"location":"whitepaper/english/#block-gap-synchronization","text":"In a previous section, we discussed the scenario where a block may not be properly broadcasted, causing the network to ignore subsequent blocks. If a node observes a block that does not have the referenced previous block, it has two options: Ignore the block as it might be a malicious garbage block. Request a resync with another node. In the case of a resync, a TCP connection must be formed with a bootstrapping node to facilitate the increased amount of traffic a resync requires. However, if the block was actually a bad block, then the resync was unnecessary and needlessly increased traffic on the network. This is a Network Amplification Attack and results in a denial-of-service. To avoid unnecessary resyncing, nodes will wait until a certain threshold of votes have been observed for a potentially malicious block before initiating a connection to a bootstrap node to synchronize. If a block doesn't receive enough votes it can be assumed to be junk data.","title":"Block Gap Synchronization"},{"location":"whitepaper/english/#transaction-flooding","text":"A malicious entity could send many unnecessary but valid transactions between accounts under its control in an attempt to saturate the network. With no transaction fees they are able to continue this attack indefinitely. However, the PoW required for each transaction limits the transaction rate the malicious entity could generate without significantly investing in computational resources. Even under such an attack in an attempt to inflate the ledger, nodes that are not full historical nodes are able to prune old transactions from their chain; this clamps the storage usage from this type of attack for almost all users.","title":"Transaction Flooding"},{"location":"whitepaper/english/#sybil-attack","text":"An entity could create hundreds of RaiBlocks nodes on a single machine; however, since the voting system is weighted based on account balance, adding extra nodes in to the network will not gain an attacker extra votes. Therefore there is no advantage to be gained via a Sybil attack.","title":"Sybil Attack"},{"location":"whitepaper/english/#penny-spend-attack","text":"A penny-spend attack is where an attacker spends infinitesimal quantities to a large number of accounts in order to waste the storage resources of nodes. Block publishing is rate-limited by the PoW, so this limits the creation of accounts and transactions to a certain extent. Nodes that are not full historical nodes can prune accounts below a statistical metric where the account is most likely not a valid account. Finally, RaiBlocks is tuned to use minimal permanent storage space, so space required to store one additional account is proportional to the size of an \\text{open block} + \\text{indexing} = 96\\text{B} + 32\\text{B} = 128\\text{B} \\text{open block} + \\text{indexing} = 96\\text{B} + 32\\text{B} = 128\\text{B} . This equates to 1GB being able to store 8 million penny-spend account. If nodes wanted to prune more aggressively, they can calculate a distribution based on access frequency and delegate infrequently used accounts to slower storage.","title":"Penny-Spend Attack"},{"location":"whitepaper/english/#precomputed-pow-attack","text":"Since the owner of an account will be the only entity adding blocks to the account-chain, sequential blocks can be computed, along with their PoW, before being broadcasted to the network. Here the attacker generates a myriad of sequential blocks, each of minimal value, over an extended period of time. At a certain point, the attacker performs a Denial of Service (DoS) by flooding the network with lots of valid transactions, which other nodes will process and echo as quickly as possible. This is an advanced version of the transaction flooding described in the Transaction flooding section . Such an attack would only work briefly, but could be used in conjunction with other attacks, such as a >50% Attack to increase effectiveness. Transaction rate-limiting and other techniques are currently being investigated to mitigate attacks.","title":"Precomputed PoW Attack"},{"location":"whitepaper/english/#50-attack","text":"The metric of consensus for RaiBlocks is a balance weighted voting system. If an attacker is able to gain over 50% of the voting strength, they can cause the network to oscillate consensus rendering the system broken. An attacker is able to lower the amount of balance they must forfeit by preventing good nodes from voting through a network DoS. RaiBlocks takes the following measures to prevent such an attack: The primary defense against this type of attack is voting-weight being tied to investment in the system. An account holder is inherently incentivized to maintain the honesty of the system to protect their investment. Attempting to flip the ledger would be destructive to the system as a whole which would destroy their investment. The cost of this attack is proportional to the market capitalization of RaiBlocks. In PoW systems, technology can be invented that gives disproportionate control compared to monetary investment and if the attack is successful, this technology could be repurposed after the attack is complete. With RaiBlocks the cost of attacking the system scales with the system itself and if an attack were to be successful the investment in the attack cannot be recovered. In order to maintain the maximum quorum of voters, the next line of defense is representative voting. Account holders who are unable to reliably participate in voting for connectivity reasons can name a representative who can vote with the weight of their balance. Maximizing the number and diversity of representatives increases network resiliency. Forks in RaiBlocks are never accidental, so nodes can make policy decisions on how to interact with forked blocks. The only time non-attacker accounts are vulnerable to block forks is if they receive a balance from an attacking account. Accounts wanting to be secure from block forks can wait a little or a lot longer before receiving from an account who generated forks or opt to never receive at all. Receivers could also generate separate accounts to use when receiving funds from dubious accounts in order to insulate other accounts. A final line of defense that has not yet been implemented is block cementing . RaiBlocks goes to great lengths to settle block forks quickly via voting. Nodes could be configured to cement blocks, which would prevent them from being rolled back after a certain period of time. The network is sufficiently secured through focusing on fast settling time to prevent ambiguous forks. A more sophisticated version of a >50\\% >50\\% attack is detailed below. \"Offline\" is the percentage of representatives who have been named but are not online to vote. \"Stake\" is the amount of investment the attacker is voting with. \"Active\" is representatives that are online and voting according to the protocol. An attacker can offset the amount of stake they must forfeit by knocking other voters offline via a network DoS attack. If this attack can be sustained, the representatives being attacked will become unsynchronized and this is demonstrated by \"Unsync.\" Finally, an attacker can gain a short burst in relative voting strength by switching their Denial of Service attack to a new set of representatives while the old set is re-synchronizing their ledger, this is demonstrated by \"Attack.\" If an attacker is able to cause Stake >Active by a combination of these circumstances, they would be able to successfully flip votes on the ledger at the expense of their stake. We can estimate how much this type of attack could cost by examining the market cap of other systems. If we estimate 33% of representatives are offline or attacked via DoS, an attacker would need to purchase 33% of the market cap in order to attack the system via voting.","title":">50% Attack"},{"location":"whitepaper/english/#bootstrap-poisoning","text":"The longer an attacker is able to hold an old private-key with a balance, the higher the probability that balances that existed at that time will not have participating representatives because their balances or representatives have transferred to newer accounts. This means if a node is bootstrapped to an old representation of the network where the attacker has a quorum of voting stake compared to representatives at that point in time, they would be able to oscillate voting decisions to that node. If this new user wanted to interact with anyone besides the attacking node all of their transactions would be denied since they have different head blocks. The net result is nodes can waste the time of new nodes in the network by feeding them bad information. To prevent this, nodes can be paired with an initial database of accounts and known-good block heads; this is a replacement for downloading the database all the way back to the genesis block. The closer the download is to being current, the higher the probability of accurately defending against this attack. In the end, this attack is probably no worse than feeding junk data to nodes while bootstrapping, since they wouldn't be able to transact with anyone who has a contemporary database.","title":"Bootstrap Poisoning"},{"location":"whitepaper/english/#implementation","text":"Currently the reference implementation is implemented in C++ and has been producing releases since 2014 on Github 10 .","title":"Implementation"},{"location":"whitepaper/english/#design-features","text":"The RaiBlocks implementation adheres to the architecture standard outlined in this paper. Additional specifications are described here.","title":"Design Features"},{"location":"whitepaper/english/#signing-algorithm","text":"RaiBlocks uses a modified ED25519 elliptic curve algorithm with Blake2b hashing for all digital signatures 11 . ED25519 was chosen for fast signing, fast verification, and high security.","title":"Signing Algorithm"},{"location":"whitepaper/english/#hashing-algorithm","text":"Since the hashing algorithm is only used to prevent network spam, the algorithm choice is less important when compared to mining-based cryptocurrencies. Our implementation uses Blake2b as a digest algorithm against block contents 12 .","title":"Hashing Algorithm"},{"location":"whitepaper/english/#key-derivation-function","text":"In the reference wallet, keys are encrypted by a password and the password is fed through a key derivation function to protect against ASIC cracking attempts. Presently Argon2 13 is the winner of the only public competition aimed at creating a resilient key derivation function.","title":"Key Derivation Function"},{"location":"whitepaper/english/#block-interval","text":"Since each account has its own blockchain, updates can be performed asynchronous to the state of network. Therefore there are no block intervals and transactions can be published instantly.","title":"Block Interval"},{"location":"whitepaper/english/#udp-message-protocol","text":"Our system is designed to operate indefinitely using the minimum amount of computing resources as possible. All messages in the system were designed to be stateless and fit within a single UDP packet. This also makes it easier for lite peers with intermittent connectivity to participate in the network without reestablishing short-term TCP connections. TCP is used only for new peers when they want to bootstrap the block chains in a bulk fashion. Nodes can be sure their transaction was received by the network by observing transaction broadcast traffic from other nodes as it should see several copies echoed back to itself.","title":"UDP Message Protocol"},{"location":"whitepaper/english/#ipv6-and-multicast","text":"Building on top of connection-less UDP allows future implementations to use IPv6 multicast as a replacement for traditional transaction flooding and vote broadcast. This will reduce network bandwidth consumption and give more policy flexibility to nodes going forward.","title":"IPv6 and Multicast"},{"location":"whitepaper/english/#performance","text":"At the time of this writing, 4.2 million transactions have been processed by the RaiBlocks network, yielding a blockchain size of 1.7GB. Transaction times are measured on the order of seconds. A current reference implementation operating on commodity SSDs can process over 10,000 transactions per second being primarily IO bound.","title":"Performance"},{"location":"whitepaper/english/#resource-usage","text":"This is an overview of resources used by a RaiBlocks node. Additionally, we go over ideas for reducing resource usage for specific use cases. Reduced nodes are typically called light, pruned, or simplified payment verification (SPV) nodes.","title":"Resource Usage"},{"location":"whitepaper/english/#network","text":"The amount of network activity depends on how much the network contributes towards the health of a network. Representative A representative node requires maximum network resources as it observes vote traffic from other representatives and publishes its own votes. Trustless A trustless node is similar to a representative node but is only an observer, it doesn't contain a representative account private key and does not publish votes of its own. Trusting A trusting node observes vote traffic from one representative it trusts to correctly perform consensus. This cuts down on the amount of inbound vote traffic from representatives going to this node. Light A light node is also a trusting node that only observes traffic for accounts in which it is interested allowing minimal network usage. Bootstrap A bootstrap node serves up parts or all of the ledger for nodes that are bringing themselves online. This is done over a TCP connection rather than UDP since it involves a large amount of data that requires advanced flow control.","title":"Network"},{"location":"whitepaper/english/#disk-capacity","text":"Depending on the user demands, different node configurations require different storage requirements. Historical A node interested in keeping a full historical record of all transactions will require the maximum amount of storage. Current Due to the design of keeping accumulated balances with blocks, nodes only need to keep the latest or head blocks for each account in order to participate in consensus. If a node is uninterested in keeping a full history it can opt to keep only the head blocks. Light A light node keeps no local ledger data and only participates in the network to observe activity on accounts in which it is interested or optionally create new transactions with private keys it holds.","title":"Disk Capacity"},{"location":"whitepaper/english/#cpu","text":"Transaction Generating A node interested in creating new transactions must produce a Proof of Work nonce in order to pass RaiBlock's throttling mechanism. Computation of various hardware is benchmarked in Appendix A. Representative A representative must verify signatures for blocks, votes, and also produce its own signatures to participate in consensus. The amount of CPU resources for a representative node is significantly less than transaction generating and should work with any single CPU in a contemporary computer. Observer An observer node doesn't generate its own votes. Since signature generation overhead is minimal, the CPU requirements are almost identical to running a representative node.","title":"CPU"},{"location":"whitepaper/english/#conclusion","text":"In this paper we presented the framework for a trustless, feeless, low-latency cryptocurrency that utilizes a novel block-lattice structure and delegated Proof of Stake voting. The network requires minimal resources, no high-power mining hardware, and can process high transaction throughput. All of this is achieved by having individual blockchains for each account, eliminating access issues and inefficiencies of a global data-structure. We identified possible attack vectors on the system and presented arguments on how RaiBlocks is resistant to these forms of attacks.","title":"Conclusion"},{"location":"whitepaper/english/#appendix-a-pow-hardware-benchmarks","text":"As mentioned previously, the PoW in RaiBlocks is to reduce network spam. Our node implementation provides acceleration that can take advantage of OpenCL compatible GPUs. Table I below provides a real-life benchmark comparison of various hardware. Currently the PoW threshold is fixed, but an adaptive threshold may be implemented as average computing power progresses. Table I Hardware PoW Performance Device Transactions Per Second Nvidia Tesla V100 (AWS) 6.4 Nvidia Tesla P100 (Google,Cloud) 4.9 Nvidia Tesla K80 (Google,Cloud) 1.64 AMD RX 470 OC 1.59 Nvidia GTX 1060 3GB 1.25 Intel Core i7 4790K AVX2 0.33 Intel Core i7 4790K,WebAssembly (Firefox) 0.14 Google Cloud 4 vCores 0.14-0.16 ARM64 server 4 cores (Scaleway) 0.05-0.07","title":"Appendix A: PoW Hardware benchmarks"},{"location":"whitepaper/english/#acknowledgment","text":"We would like to thank Brian Pugh and B. Cchung for compiling and formatting this paper.","title":"Acknowledgment"},{"location":"whitepaper/english/#references","text":"S. Nakamoto, \u201cBitcoin: A peer-to-peer electronic cash system,\u201d 2008. [Online]. Available: http://bitcoin.org/bitcoin.pdf \u21a9 \u21a9 \u201cBitcoin median transaction fee historical chart.\u201d [Online]. Available: https://bitinfocharts.com/comparison/bitcoin-median-transaction-fee.html \u21a9 \u201cBitcoin average confirmation time.\u201d [Online]. Available: https://blockchain.info/charts/avg-confirmation-time \u21a9 \u201cBitcoin energy consumption index.\u201d [Online]. Available: https://digiconomist.net/bitcoin-energy-consumption \u21a9 S. King and S. Nadal, \u201cPpcoin: Peer-to-peer crypto-currency withproof-of-stake,\u201d 2012. [Online]. Available: https://peercoin.net/assets/paper/peercoin-paper.pdf \u21a9 C. LeMahieu, \u201cRaiblocks distributed ledger network,\u201d 2014. \u21a9 Y. Ribero and D. Raissar, \u201cDagcoin whitepaper,\u201d 2015. \u21a9 S. Popov, \u201cThe tangle,\u201d 2016. \u21a9 A. Back, \u201cHashcash - a denial of service counter-measure,\u201d 2002. [Online]. Available: http://www.hashcash.org/papers/hashcash.pdf \u21a9 C. LeMahieu, \u201cRaiblocks,\u201d 2014. [Online]. Available: https://github.com/clemahieu/raiblocks \u21a9 D. J. Bernstein, N. Duif, T. Lange, P. Shwabe, and B.-Y. Yang, \u201cHigh-speed high-security signatures,\u201d 2011. [Online]. Available: http://ed25519.cr.yp.to/ed25519-20110926.pdf \u21a9 J.-P. Aumasson, S. Neves, Z. Wilcox-O\u2019Hearn, and C. Winnerlein, \u201cBlake2: Simpler, smaller, fast as md5,\u201d 2012. [Online]. Available: https://blake2.net/blake2.pdf \u21a9 A. Biryukov, D. Dinu, and D. Khovratovich, \u201cArgon2: The memoryhard function for password hashing and other applications,\u201d 2015. [Online]. Available: https://password-hashing.net/argon2-specs.pdf \u21a9","title":"References"}]}